<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>11｜VAE系列：如何压缩图像给GPU腾腾地方 | geekbang</title><meta name="author" content="码农张三"><meta name="copyright" content="码农张三"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="11｜VAE系列：如何压缩图像给GPU腾腾地方你好，我是南柯。 在前几讲中，我们已经学习了Transformer、UNet、Clip三个关键模块。在Stable Diffusion的知识地图上，还差最后的一环，便是今天的主角VAE模块。 在Stable Diffusion中，所有的去噪和加噪过程并不是在图像空间直接进行的。VAE模块的作用便是将图像“压缩”到一个特殊的空间，这个空间的“分辨率”要低">
<meta property="og:type" content="article">
<meta property="og:title" content="11｜VAE系列：如何压缩图像给GPU腾腾地方">
<meta property="og:url" content="https://zhuansun.github.io/geekbang/posts/2277561835.html">
<meta property="og:site_name" content="geekbang">
<meta property="og:description" content="11｜VAE系列：如何压缩图像给GPU腾腾地方你好，我是南柯。 在前几讲中，我们已经学习了Transformer、UNet、Clip三个关键模块。在Stable Diffusion的知识地图上，还差最后的一环，便是今天的主角VAE模块。 在Stable Diffusion中，所有的去噪和加噪过程并不是在图像空间直接进行的。VAE模块的作用便是将图像“压缩”到一个特殊的空间，这个空间的“分辨率”要低">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg">
<meta property="article:published_time" content="2024-02-29T12:01:07.000Z">
<meta property="article:modified_time" content="2024-03-21T11:04:50.309Z">
<meta property="article:author" content="码农张三">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://zhuansun.github.io/geekbang/posts/2277561835"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":false,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '11｜VAE系列：如何压缩图像给GPU腾腾地方',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-03-21 11:04:50'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="geekbang" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://pic.imgdb.cn/item/653470a0c458853aef5813f1.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">1345</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">23</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">geekbang</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">11｜VAE系列：如何压缩图像给GPU腾腾地方</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2024-02-29T12:01:07.000Z" title="发表于 2024-02-29 12:01:07">2024-02-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI%E7%BB%98%E7%94%BB%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/">AI绘画核心技术与实战</a></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="11｜VAE系列：如何压缩图像给GPU腾腾地方"><a href="#11｜VAE系列：如何压缩图像给GPU腾腾地方" class="headerlink" title="11｜VAE系列：如何压缩图像给GPU腾腾地方"></a>11｜VAE系列：如何压缩图像给GPU腾腾地方</h1><p>你好，我是南柯。</p>
<p>在前几讲中，我们已经学习了Transformer、UNet、Clip三个关键模块。在Stable Diffusion的知识地图上，还差最后的一环，便是今天的主角VAE模块。</p>
<p>在Stable Diffusion中，所有的去噪和加噪过程并不是在图像空间直接进行的。VAE模块的作用便是将图像“压缩”到一个特殊的空间，这个空间的“分辨率”要低于图像空间，便于快速地完成加噪和去噪的任务。之后，还能便捷地将特殊空间“解压”到图像空间。</p>
<p>这一讲，我们将一起了解VAE的基本原理。学完VAE，我们便了解了Stable Diffusion模型的全部核心模块。之后我们训练自己的Stable Diffusion模型时，也会用上VAE这个模块。</p>
<h2 id="初识VAE"><a href="#初识VAE" class="headerlink" title="初识VAE"></a>初识VAE</h2><p>VAE的全称是变分自动编码器（Variational Autoencoder），在2013年被提出，是自动编码器（AE，Autoencoder）的一种扩展。你可能听过很多不同的名词，比如AE、VAE、DAE、MAE、VQVAE等。其实这些带 “AE” 的名字，你都可以理解成是一个编码器和一个解码器。</p>
<p>提到编码器和解码器，你也许会联想到我们在 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/682762">第7讲</a> 中学过的Transformer结构。这里我需要提醒你注意，尽管术语一样，但是VAE和Transformer中的编码器、解码器解决的是不同类型的问题，并具有不同的结构和原理。</p>
<p>在正式学习VAE之前。我们先要了解潜在空间的概念，也就是开头我们提起的“特殊空间”。我们可以通过神经网络，在保留原始数据的关键信息的条件下，将输入的原始数据压缩到一个更低维度的空间，得到一个低维的向量表示，并且这个低维的向量表示可以通过解码恢复出原始的数据。</p>
<p><strong>这里的低维空间就是潜在空间（latent space</strong>， <strong>也称为隐空间），低维的向量也叫潜在表示（latent representation）</strong>。你可以这样理解，潜在空间是较低维度的空间，用于表示原始数据的结构和特征。潜在表示便是原始数据在潜在空间中对应的特征向量。</p>
<p>以VAE为代表的 “AE” 系列工作，都是 <strong>希望编码器将原始数据编码成低维的潜在表示，并且这个潜在表示可以通过解码器近乎无损地恢复出原始数据</strong>。这里的原始数据，可以是图像、文本等多种模态。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/a23f7b84fbce851de31b6af1ce44037c.jpg"></p>
<p>对于AI绘画任务而言，潜在空间的维度通常是原始图像的1&#x2F;8大小。例如，原始图像的分辨率如果是512x512，潜在空间的大小就可以是64x64。我们在64x64的空间上进行加噪和去噪，自然比在原始图像分辨率上进行加噪和去噪要快得多。得到去噪后的潜在表示，只需要经过解码器便可以获得AI绘画的最终输出图像。</p>
<h2 id="VAE细节探究"><a href="#VAE细节探究" class="headerlink" title="VAE细节探究"></a>VAE细节探究</h2><p>仅仅了解 “AE” 类工作的整体思路，还不足以帮助我们区分各个 “AE” 的能力，也不足以解决AI绘画实操中遇到的相关问题。我们不妨深入探究其中的关键技术点。</p>
<h3 id="AE的长处和短板"><a href="#AE的长处和短板" class="headerlink" title="AE的长处和短板"></a>AE的长处和短板</h3><p>首先是AE结构（自编码器）。AE结构使用无监督的方式进行训练，以图像任务为例，使用大量的图像数据，依次经过编码器和解码器得到重建图像，训练目标是最小化原始数据与重构数据之间的差异。实际操作中，损失函数可以是L1损失或者L2损失。</p>
<p>为了帮你加深理解，我在后面提供了一个AE训练过程的伪代码供你参考。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> batch <span class="token keyword">in</span> dataset_loader<span class="token punctuation">.</span>get_batches<span class="token punctuation">(</span>training_data<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># 清零梯度</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 将本批次数据传递给自动编码器</span>
        encoded_data <span class="token operator">=</span> autoencoder<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>
        reconstructed_data <span class="token operator">=</span> autoencoder<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>encoded_data<span class="token punctuation">)</span>

        <span class="token comment"># 计算损失，比如使用L2损失</span>
        loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>reconstructed_data<span class="token punctuation">,</span> batch<span class="token punctuation">)</span>

        <span class="token comment"># 反向传播</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 更新参数</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>之所以说AE结构是无监督学习，是因为损失函数的计算只依赖于输入数据本身，而不涉及任何标签或类别信息。</p>
<p>AE结构虽然可以对数据降维，也存在明显的缺点。</p>
<p>第一，潜在表示缺乏直接的约束，在潜在空间中一个个孤立的点。如果对于输入图像的潜在表示稍加扰动，比如加上一个标准高斯噪声，解码器便会得到无意义的输出。</p>
<p>第二，潜在表示难以解释和编辑。我举个例子来说明，比如我们想得到“半月图像”的潜在表示，但手里又只有满月和新月图片。</p>
<p>那我们很自然就会觉得，满月和新月的中间状态应该是“半月”状态，而满月和新月图片对应的潜在表示分别是潜在空间中的一个点。如果对这两个点取平均，是不是就会得到一个新的潜在表示，来代表“半月图像”的信息。接着把这个新的潜在表示给到解码器，是不是就可以输出半月图片了？</p>
<p>这样想，从逻辑推导似乎没问题，但我们将插值后的潜在表示给到AE的解码器，我们甚至无法得到一张有意义的图片。</p>
<p>针对第一个缺点，DAE（去噪自编码器）的改进方式就是故意在输入数据中加入噪声，这样得到的潜在表示更加鲁棒。训练目标仍然是最小化原始引入噪声前的数据和重构数据之间的差异。你可以参考后面的伪代码来理解。不过我想强调一下， <strong>DAE只是改善了AE的表现，并没有真正补全AE的短板。</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 添加噪声函数</span>
<span class="token keyword">def</span> <span class="token function">add_noise</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> factor<span class="token punctuation">)</span><span class="token punctuation">:</span>
    noise <span class="token operator">=</span> factor <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>size<span class="token operator">=</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    noisy_data <span class="token operator">=</span> data <span class="token operator">+</span> noise
    <span class="token keyword">return</span> noisy_data<span class="token punctuation">.</span>clip<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># 开始训练循环</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> batch <span class="token keyword">in</span> dataset_loader<span class="token punctuation">.</span>get_batches<span class="token punctuation">(</span>training_data<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># 给本批次数据添加噪声</span>
        noisy_batch <span class="token operator">=</span> add_noise<span class="token punctuation">(</span>batch<span class="token punctuation">,</span> noise_factor<span class="token punctuation">)</span>

        <span class="token comment"># 清零梯度</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 将带噪声的本批次数据传递给降噪自动编码器</span>
        encoded_data <span class="token operator">=</span> denoising_autoencoder<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>noisy_batch<span class="token punctuation">)</span>
        reconstructed_data <span class="token operator">=</span> denoising_autoencoder<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>encoded_data<span class="token punctuation">)</span>

        <span class="token comment"># 计算损失</span>
        loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>reconstructed_data<span class="token punctuation">,</span> batch<span class="token punctuation">)</span>

        <span class="token comment"># 反向传播</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 更新参数</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="VAE的工作原理"><a href="#VAE的工作原理" class="headerlink" title="VAE的工作原理"></a>VAE的工作原理</h3><p>真正解决AE两大痛点的工作就是VAE。在VAE中，编码器的输出不再是潜在表示，而是某种已知概率分布的均值$\mu$和方差$\sigma$，比如最常用的高斯分布。根据均值、方差和一个随机噪声$\epsilon$，我们便可以根据下面的公式计算出最终的潜在表示，给到解码器。</p>
<p>$$z &#x3D; e^{\sigma} \times \epsilon + \mu$$</p>
<p>VAE中计算潜在表示的过程便是大名鼎鼎的 <strong>重参数化</strong> 技巧，解决了梯度不能直接通过随机采样操作进行传播的问题。关于VAE的整体过程，你可以查看下面的图片。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/485f86c2dabd06574343523a83a4e50b.jpg"></p>
<p>那么VAE训练的目标函数是什么呢？你可能已经想到，需要使用类似AE模型的重构损失，还需要对均值$\mu$和方差$\sigma$进行约束，避免方差$\sigma$优化到负无穷。</p>
<p>你可以查看后面的伪代码，我们同时使用重构损失和KL散度损失来训练VAE。对于VAE损失函数，我们掌握到这个程度就足够了。至于背后更复杂的数学推理，有兴趣的话你可以课后查阅资料了解更多细节。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 定义损失函数</span>
<span class="token keyword">def</span> <span class="token function">loss_function</span><span class="token punctuation">(</span>reconstructed_data<span class="token punctuation">,</span> original_data<span class="token punctuation">,</span> mean<span class="token punctuation">,</span> log_variance<span class="token punctuation">)</span><span class="token punctuation">:</span>
    reconstruction_loss <span class="token operator">=</span> mean_squared_error<span class="token punctuation">(</span>reconstructed_data<span class="token punctuation">,</span> original_data<span class="token punctuation">)</span>
    kl_loss <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">0.5</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> log_variance <span class="token operator">-</span> mean<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">-</span> log_variance<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    total_loss <span class="token operator">=</span> reconstruction_loss <span class="token operator">+</span> kl_loss
    <span class="token keyword">return</span> total_loss

<span class="token comment"># 定义优化器（如梯度下降）</span>
optimizer <span class="token operator">=</span> optimizer<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>variational_autoencoder<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span>

<span class="token comment"># 开始训练循环</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> batch <span class="token keyword">in</span> dataset_loader<span class="token punctuation">.</span>get_batches<span class="token punctuation">(</span>training_data<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># 清零梯度</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 将本批次数据传递给变分自动编码器</span>
        mean<span class="token punctuation">,</span> log_variance <span class="token operator">=</span> variational_autoencoder<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>

        <span class="token comment"># 重参数化技巧</span>
        z <span class="token operator">=</span> mean <span class="token operator">+</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>log_variance <span class="token operator">*</span> <span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span>log_variance<span class="token punctuation">)</span>

        <span class="token comment"># 解码</span>
        reconstructed_data <span class="token operator">=</span> variational_autoencoder<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span>

        <span class="token comment"># 计算损失</span>
        loss <span class="token operator">=</span> loss_function<span class="token punctuation">(</span>reconstructed_data<span class="token punctuation">,</span> batch<span class="token punctuation">,</span> mean<span class="token punctuation">,</span> log_variance<span class="token punctuation">)</span>

        <span class="token comment"># 反向传播</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 更新参数</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="用VAE做图像插值"><a href="#用VAE做图像插值" class="headerlink" title="用VAE做图像插值"></a>用VAE做图像插值</h3><p>讲了这么多原理，也是在为VAE的应用做铺垫。VAE不仅可以有效地压缩和重构图像，它得到的潜在表示还可以进行插值编辑。我们分别动手来验证这两个功能。我为你准备了一个 <a target="_blank" rel="noopener" href="https://colab.research.google.com/github/NightWalker888/ai_painting_journey/blob/main/lesson11/VAE%E4%BD%BF%E7%94%A8update.ipynb">Colab代码</a>，你可以点开后运行。</p>
<p>使用VAE做图像重建的效果怎样呢？首先我在网上找到两张月相图。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/8b70bc6a10765c20640526b382596c14.jpg"></p>
<p>然后我们使用Stable Diffusion中使用的VAE权重进行重建验证，下面我贴出重建部分的代码。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> diffusers <span class="token keyword">import</span> AutoencoderKL

device <span class="token operator">=</span> <span class="token string">'cuda'</span>

<span class="token comment"># 加载VAE模型</span>
vae <span class="token operator">=</span> AutoencoderKL<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
    <span class="token string">'CompVis/stable-diffusion-v1-4'</span><span class="token punctuation">,</span> subfolder<span class="token operator">=</span><span class="token string">'vae'</span><span class="token punctuation">)</span>
vae <span class="token operator">=</span> vae<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

pths <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"test_imgs/new.png"</span><span class="token punctuation">,</span> <span class="token string">"test_imgs/full.png"</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> pth <span class="token keyword">in</span> pths<span class="token punctuation">:</span>
    img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>pth<span class="token punctuation">)</span><span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'RGB'</span><span class="token punctuation">)</span>
    img <span class="token operator">=</span> img<span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    img_latents <span class="token operator">=</span> encode_img_latents<span class="token punctuation">(</span>img<span class="token punctuation">)</span> <span class="token comment"># 编码</span>
    dec_img <span class="token operator">=</span> decode_img_latents<span class="token punctuation">(</span>img_latents<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment">#解码</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>你可以点开图片看看VAE的效果，左边是原始图像，右边是VAE重建图像。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/a0d40070025a6912296a41501b1fa99c.jpg"></p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/e89cdece51a6c7e0748b2957594fc6cd.jpg"></p>
<p>看完以后，有没有发现从我们视觉来看，几乎是100%复原？在上面的代码中，潜在表示（img_latents）的“宽高”只有原始图像的1&#x2F;8，可见VAE编码器对原始数据的压缩能力。</p>
<p>我们前面提到，VAE的潜在表示可以进行插值。这里我们也通过代码实现一下，帮助你加深理解。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">num_steps <span class="token operator">=</span> <span class="token number">4</span> <span class="token comment"># 假定插值得到中间的2张图</span>
interpolation_weight <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> num_steps<span class="token punctuation">)</span>
<span class="token keyword">for</span> weight <span class="token keyword">in</span> interpolation_weight<span class="token punctuation">:</span>
    interval_latents <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> weight<span class="token punctuation">)</span> <span class="token operator">*</span> all_img_latents<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> weight <span class="token operator">*</span> all_img_latents<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    dec_img <span class="token operator">=</span> decode_img_latents<span class="token punctuation">(</span>interval_latents<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>你同样可以点开图像查看插值的结果。利用VAE的潜在表示插值这个功能，我们可以合成很多有趣味的图像。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/52c9d8d50c40de9a302d8179ed421311.jpg"></p>
<h2 id="VAE的应用"><a href="#VAE的应用" class="headerlink" title="VAE的应用"></a>VAE的应用</h2><p>VAE技术在很多领域得到了成功应用，既包含一些经典的机器学习任务，也包含我们要学习的AI绘画模型。</p>
<h3 id="VAE与经典任务"><a href="#VAE与经典任务" class="headerlink" title="VAE与经典任务"></a>VAE与经典任务</h3><p>VAE可以用于图像生成，比如人脸、动漫等角色的创建。以动漫角色生成为例，VAE 可以用来创建具有独特外观和特征的全新动漫角色。为此，我们首先需要使用现有的动漫角色数据集训练VAE的编码器和解码器。完成后，我们在潜在空间中采样，便可以得到新的角色图像。</p>
<p>VAE可以用于自然语言处理，比如用于带情感的评论生成等任务。假设我们有一个餐馆评论数据集（包含正、负评论），我们可以使用 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/682762">第7讲</a> 提到的时序模型设计VAE的编码器，比如RNN、LSTM、Transformer等，得到潜在表示，然后再把潜在表示与特定情感信息（如正面或负面）一起传递至解码器进行训练。</p>
<p>训练完成后，我们便得到了一个能够控制情感倾向的餐馆评论生成模型。下面我提供了实现评论生成任务的伪代码，推荐你课后实验一下，训练一个某某餐厅的评论“机器人”。至于训练用的数据，可以考虑用GPT来生成。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 导入所需的库</span>
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> functional <span class="token keyword">as</span> F

<span class="token comment"># 定义VAE模型</span>
<span class="token keyword">class</span> <span class="token class-name">SentimentVAE</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> latent_dim<span class="token punctuation">,</span> sentiment_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>SentimentVAE<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 编码器 - 我们可以使用RNN，LSTM，Transformer等时序模型</span>
        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span>

        <span class="token comment"># 将编码器的输出转换为潜在空间的均值和方差</span>
        self<span class="token punctuation">.</span>fc_mu <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> latent_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc_var <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> latent_dim<span class="token punctuation">)</span>

        <span class="token comment"># 解码器</span>
        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>latent_dim <span class="token operator">+</span> sentiment_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span>

        <span class="token comment"># 最后的全连接层</span>
        self<span class="token punctuation">.</span>fc_output <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> input_dim<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">reparameterize</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> log_var<span class="token punctuation">)</span><span class="token punctuation">:</span>
        std <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token operator">*</span>log_var<span class="token punctuation">)</span>
        eps <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span>std<span class="token punctuation">)</span>
        <span class="token keyword">return</span> mu <span class="token operator">+</span> eps<span class="token operator">*</span>std

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> sentiment<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 编码器</span>
        hidden<span class="token punctuation">,</span> _ <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token comment"># 得到潜在空间的均值和方差</span>
        mu<span class="token punctuation">,</span> log_var <span class="token operator">=</span> self<span class="token punctuation">.</span>fc_mu<span class="token punctuation">(</span>hidden<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>fc_var<span class="token punctuation">(</span>hidden<span class="token punctuation">)</span>

        <span class="token comment"># 重参数化技巧</span>
        z <span class="token operator">=</span> self<span class="token punctuation">.</span>reparameterize<span class="token punctuation">(</span>mu<span class="token punctuation">,</span> log_var<span class="token punctuation">)</span>

        <span class="token comment"># 将潜在表示和情感信息拼接</span>
        z <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>z<span class="token punctuation">,</span> sentiment<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment"># 解码器</span>
        out<span class="token punctuation">,</span> _ <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>z<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc_output<span class="token punctuation">(</span>out<span class="token punctuation">)</span>

        <span class="token keyword">return</span> out<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> log_var
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>VAE还可以用于聚类分析和异常检测。比如，在数据的潜在空间中把具有相似结构和内容的数据聚集在一起，为后续的聚类分析提供便利，或者用于识别潜在空间中明显异常的数据。</p>
<h3 id="VAE与扩散模型"><a href="#VAE与扩散模型" class="headerlink" title="VAE与扩散模型"></a>VAE与扩散模型</h3><p>原始的扩散模型需要在原图上进行加噪和去噪操作，过程非常耗时。</p>
<p>学完今天的知识，我们自然会想到，为什么不在VAE的潜在空间上进行加噪和去噪呢？没错，Stable Diffusion就是这么做的。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/2e46cc49db8yy763142561173d527850.jpg"></p>
<p>通常情况下，VAE模型是按照我们前面讲的VAE训练过程预先获得的。我们使用LoRA等技术训练自己的AI绘画模型时，并不会改变 VAE 模型的权重。但这并不意味着 VAE 对图像质量没有影响。其实在某种程度上，VAE代表了AI绘画生成质量的上限。</p>
<p>虽然我们上面新月满月的例子证明了VAE的图像重建能力几乎无损，但如果是更困难复杂的场景，VAE重建的图像会存在明显的模糊。</p>
<p>比如下面这个例子中，红框内人脸区域的重建效果明显变差。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/c4615bayy9f8e77e3d9a244b80b5c06f.png"></p>
<p>如前面的图所示，即使图像没有经过UNet，仅经过编码和解码过程，我们也会发现人脸的细节信息非常模糊。</p>
<p>这也很容易理解，因为输入图像经过 VAE 编码器后，会降低 8 倍采样率。512x512分辨率图像的潜在表示“分辨率”只有64x64。在如此小的潜在表示上恢复人脸细节确实是一项挑战。所以，我们见到的AI绘画模型如果小脸生成效果不佳，可能是VAE解码器本身无法生成高清的小脸图像。</p>
<p>那么如何解决这个问题呢？最直接的方法就是 <a target="_blank" rel="noopener" href="https://github.com/cccntu/fine-tune-models/#fine-tuning-vae-decoder-of-stable-diffusion">重新训练 VAE</a>，使用更高的VAE潜在表示的分辨率。你可以参考后面的例子，对照图片可以看出，微调后的VAE可以明显提升生成图像的质量。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/b3de51fd286e2338069e80516ffbb6d0.jpg"></p>
<h2 id="总结时刻"><a href="#总结时刻" class="headerlink" title="总结时刻"></a>总结时刻</h2><p>这一讲我们深入学习了Stable Diffusion中的核心模块VAE。</p>
<p>各种AE的功能就是对输入数据进行编码和解码。我们探讨了AE（自编码器）、DAE（去噪自编码器）和VAE（变分自编码器）三种深度学习模型，学习了这些模型的基本原理、网络结构和损失函数，明确了AE和DAE的设计短板。</p>
<p>而VAE在AE的基础上加入了更复杂的概念，解决了AE的潜在表示难以解释和编辑的缺陷。我们详细解读了重参数化这个技巧，并分析了VAE训练的损失函数。之后，我们通过多个实例介绍了VAE的应用，如图像重建和插值、加速Stable Diffusion模型的训练过程等。此外，我们列举了一个VAE用作餐厅评论机器人的趣味例子。</p>
<p>需要关注的是，VAE对原始图像进行压缩，会出现小脸无法有效重建等问题。所以在配合SD模型进行AI绘画任务时，我们需要尽可能选择重建效果更好的VAE。</p>
<p>关于这一讲的知识点，你可以查看下面的知识导图进行回顾、查漏补缺。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/f0cafa74bc6de3f39b36487dc43ff457.jpg"></p>
<h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>VAE和Transformer中的编码器、解码器，在结构、原理、功能上有怎样的不同？</p>
<p>欢迎你在留言区和我交流讨论。如果这节课对你有启发，也推荐你分享给身边更多朋友。</p>
</article><div class="tag_share"><div class="post_share"></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#11%EF%BD%9CVAE%E7%B3%BB%E5%88%97%EF%BC%9A%E5%A6%82%E4%BD%95%E5%8E%8B%E7%BC%A9%E5%9B%BE%E5%83%8F%E7%BB%99GPU%E8%85%BE%E8%85%BE%E5%9C%B0%E6%96%B9"><span class="toc-number">1.</span> <span class="toc-text">11｜VAE系列：如何压缩图像给GPU腾腾地方</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9D%E8%AF%86VAE"><span class="toc-number">1.1.</span> <span class="toc-text">初识VAE</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#VAE%E7%BB%86%E8%8A%82%E6%8E%A2%E7%A9%B6"><span class="toc-number">1.2.</span> <span class="toc-text">VAE细节探究</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#AE%E7%9A%84%E9%95%BF%E5%A4%84%E5%92%8C%E7%9F%AD%E6%9D%BF"><span class="toc-number">1.2.1.</span> <span class="toc-text">AE的长处和短板</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#VAE%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-number">1.2.2.</span> <span class="toc-text">VAE的工作原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%A8VAE%E5%81%9A%E5%9B%BE%E5%83%8F%E6%8F%92%E5%80%BC"><span class="toc-number">1.2.3.</span> <span class="toc-text">用VAE做图像插值</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#VAE%E7%9A%84%E5%BA%94%E7%94%A8"><span class="toc-number">1.3.</span> <span class="toc-text">VAE的应用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#VAE%E4%B8%8E%E7%BB%8F%E5%85%B8%E4%BB%BB%E5%8A%A1"><span class="toc-number">1.3.1.</span> <span class="toc-text">VAE与经典任务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#VAE%E4%B8%8E%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.3.2.</span> <span class="toc-text">VAE与扩散模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%E6%97%B6%E5%88%BB"><span class="toc-number">1.4.</span> <span class="toc-text">总结时刻</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98"><span class="toc-number">1.5.</span> <span class="toc-text">思考题</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By 码农张三</div></div><script src="https://cdn.bootcdn.net/ajax/libs/mermaid/9.4.0/mermaid.min.js"></script></footer></div><div id="rightside"><div id="rightside-config-hide"></div><div id="rightside-config-show"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div></div></body></html>