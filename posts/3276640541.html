<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>16｜Langchain里的“记忆力”，让AI只记住有用的事儿 | geekbang</title><meta name="author" content="码农张三"><meta name="copyright" content="码农张三"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="16｜Langchain里的“记忆力”，让AI只记住有用的事儿你好，我是徐文浩。 在过去的两讲里，我们深入了解了Langchain的第一个核心功能，也就是LLMChain。 LLMChain能够帮助我们链式地调用一系列命令，这里面既包含直接调用OpenAI的API，也包括调用其他外部接口，或者自己实现的Python代码。但是这一连串的调用，还只是完成一个小任务。我们很多时候还是希望用一个互动聊天的">
<meta property="og:type" content="article">
<meta property="og:title" content="16｜Langchain里的“记忆力”，让AI只记住有用的事儿">
<meta property="og:url" content="https://zhuansun.github.io/geekbang/posts/3276640541.html">
<meta property="og:site_name" content="geekbang">
<meta property="og:description" content="16｜Langchain里的“记忆力”，让AI只记住有用的事儿你好，我是徐文浩。 在过去的两讲里，我们深入了解了Langchain的第一个核心功能，也就是LLMChain。 LLMChain能够帮助我们链式地调用一系列命令，这里面既包含直接调用OpenAI的API，也包括调用其他外部接口，或者自己实现的Python代码。但是这一连串的调用，还只是完成一个小任务。我们很多时候还是希望用一个互动聊天的">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg">
<meta property="article:published_time" content="2023-10-20T09:48:40.000Z">
<meta property="article:modified_time" content="2024-03-21T11:04:49.920Z">
<meta property="article:author" content="码农张三">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://zhuansun.github.io/geekbang/posts/3276640541"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":false,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '16｜Langchain里的“记忆力”，让AI只记住有用的事儿',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-03-21 11:04:49'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="geekbang" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://pic.imgdb.cn/item/653470a0c458853aef5813f1.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">1345</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">23</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">geekbang</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">16｜Langchain里的“记忆力”，让AI只记住有用的事儿</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2023-10-20T09:48:40.000Z" title="发表于 2023-10-20 09:48:40">2023-10-20</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E7%BE%8E/">AI大模型之美</a></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="16｜Langchain里的“记忆力”，让AI只记住有用的事儿"><a href="#16｜Langchain里的“记忆力”，让AI只记住有用的事儿" class="headerlink" title="16｜Langchain里的“记忆力”，让AI只记住有用的事儿"></a>16｜Langchain里的“记忆力”，让AI只记住有用的事儿</h1><p>你好，我是徐文浩。</p>
<p>在过去的两讲里，我们深入了解了Langchain的第一个核心功能，也就是LLMChain。 LLMChain能够帮助我们链式地调用一系列命令，这里面既包含直接调用OpenAI的API，也包括调用其他外部接口，或者自己实现的Python代码。但是这一连串的调用，还只是完成一个小任务。我们很多时候还是希望用一个互动聊天的过程，来完成整个任务。</p>
<p>所以LangChain并不是只有链式调用这样一个核心功能，它还封装了很多其他能力，来方便我们开发AI应用。比如，让AI能够拥有“记忆力”，也就是记住我们聊天上下文的能力。不知道你还记不记得，我们在 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/643915">第 6 讲</a> 里做的聊天机器人。在那个里面，为了能够让ChatGPT知道整个聊天的上下文，我们需要把历史的对话记录都传给它。但是，因为能够接收的Token数量有上限，所以我们只能设定一个参数，只保留最后几轮对话。我们最后把这个功能，抽象成了一个Conversation类。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> openai
<span class="token keyword">import</span> os

openai<span class="token punctuation">.</span>api_key <span class="token operator">=</span> os<span class="token punctuation">.</span>environ<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"OPENAI_API_KEY"</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">Conversation</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> prompt<span class="token punctuation">,</span> num_of_round<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>prompt <span class="token operator">=</span> prompt
        self<span class="token punctuation">.</span>num_of_round <span class="token operator">=</span> num_of_round
        self<span class="token punctuation">.</span>messages <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>messages<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>prompt<span class="token punctuation">&#125;</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">ask</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> question<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">try</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>messages<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> question<span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
            response <span class="token operator">=</span> openai<span class="token punctuation">.</span>ChatCompletion<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
                model<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo"</span><span class="token punctuation">,</span>
                messages<span class="token operator">=</span>self<span class="token punctuation">.</span>messages<span class="token punctuation">,</span>
                temperature<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>
                max_tokens<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span>
                top_p<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span>
        <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span>
            <span class="token keyword">return</span> e

        message <span class="token operator">=</span> response<span class="token punctuation">[</span><span class="token string">"choices"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"message"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"content"</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>messages<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> message<span class="token punctuation">&#125;</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>messages<span class="token punctuation">)</span> <span class="token operator">></span> self<span class="token punctuation">.</span>num_of_round<span class="token operator">*</span><span class="token number">2</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span>
            <span class="token keyword">del</span> self<span class="token punctuation">.</span>messages<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">//</span>Remove the first <span class="token builtin">round</span> conversation left<span class="token punctuation">.</span>
        <span class="token keyword">return</span> message
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>不知道你是否还记得这个Conversation类。</p>
<h2 id="BufferWindow，滑动窗口记忆"><a href="#BufferWindow，滑动窗口记忆" class="headerlink" title="BufferWindow，滑动窗口记忆"></a>BufferWindow，滑动窗口记忆</h2><p>这个基于一个固定长度的滑动窗口的“记忆”功能，被直接内置在LangChain里面了。在Langchain里，把对于整个对话过程的上下文叫做Memory。任何一个LLMChain，我们都可以给它加上一个Memory，来让它记住最近的对话上下文。我也把对应的代码放在了下面。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>memory <span class="token keyword">import</span> ConversationBufferWindowMemory

template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:
1. 你的回答必须是中文
2. 回答限制在100个字以内

&#123;chat_history&#125;
Human: &#123;human_input&#125;
Chatbot:"""</span>

prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"chat_history"</span><span class="token punctuation">,</span> <span class="token string">"human_input"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    template<span class="token operator">=</span>template
<span class="token punctuation">)</span>
memory <span class="token operator">=</span> ConversationBufferWindowMemory<span class="token punctuation">(</span>memory_key<span class="token operator">=</span><span class="token string">"chat_history"</span><span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
llm_chain <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>
    llm<span class="token operator">=</span>OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    prompt<span class="token operator">=</span>prompt<span class="token punctuation">,</span>
    memory<span class="token operator">=</span>memory<span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>
llm_chain<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>human_input<span class="token operator">=</span><span class="token string">"你是谁？"</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token string">' 我是一个中国厨师，我可以帮助你做菜。我会根据你的口味和特殊要求，精心烹饪出独特美味的中国菜肴。'</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>可以看到，我们做的事情其实和之前的Conversation类似，我们定义了一个PromptTemplate来输入我们的指示。然后，在LLMChain构造的时候，我们为它指定了一个叫做 ConversationBufferWindowMemory的memory对象，并且为这个memory对象定义了k&#x3D;3，也就是只保留最近三轮的对话内容。</p>
<p>如果我们和 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/643915">第 6 讲</a> 一样，和它连续进行几轮对话，你会发现，到第四轮的时候它还是能够记得我们问它的第一个问题是“你是谁”，但是第5轮的时候，已经变成“鱼香肉丝怎么做？”了。这就是因为我们选择只保留过去3轮对话。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">llm_chain<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>human_input<span class="token operator">=</span><span class="token string">"鱼香肉丝怎么做？"</span><span class="token punctuation">)</span>
llm_chain<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>human_input<span class="token operator">=</span><span class="token string">"那宫保鸡丁呢？"</span><span class="token punctuation">)</span>
llm_chain<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>human_input<span class="token operator">=</span><span class="token string">"我问你的第一句话是什么？"</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token string">' 你是谁？'</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>再次询问第一句话是什么：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">llm_chain<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>human_input<span class="token operator">=</span><span class="token string">"我问你的第一句话是什么？"</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token string">' 你问我的第一句话是“鱼香肉丝怎么做？”'</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>事实上，你可以直接调用memory的load_memory_variables方法，它会直接返回memory里实际记住的对话内容。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">memory<span class="token punctuation">.</span>load_memory_variables<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">&#123;</span><span class="token string">'chat_history'</span><span class="token punctuation">:</span> <span class="token string">'Human: 那宫保鸡丁呢？\nAI:  宫保鸡丁是一道经典的中国家常菜，需要准备鸡肉、花生米、干辣椒、葱、姜、蒜、料酒、盐、糖、胡椒粉、鸡精和醋。将鸡肉切成小块，放入盐水中浸泡，把其他食材切成小块，将花生米放入油锅中炸，再加入鸡肉和其他食材，炒至入味即可。\nHuman: 我问你的第一句话是什么？\nAI:  你是谁？\nHuman: 我问你的第一句话是什么？\nAI:  你问我的第一句话是“鱼香肉丝怎么做？”'</span><span class="token punctuation">&#125;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h2 id="SummaryMemory，把小结作为历史记忆"><a href="#SummaryMemory，把小结作为历史记忆" class="headerlink" title="SummaryMemory，把小结作为历史记忆"></a>SummaryMemory，把小结作为历史记忆</h2><p>使用BufferWindow这样的滑动窗口有一个坏处，就是几轮对话之后，AI就把一开始聊的内容给忘了。所以在 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/644544">第 7 讲</a> 的时候我们讲过，遇到这种情况，可以让AI去总结一下前面几轮对话的内容。这样，我们就不怕对话轮数太多或者太长了。</p>
<p>同样的，Langchain也提供了一个ConversationSummaryMemory，可以实现这样的功能，我们还是通过一段简单的代码来看看它是怎么用的。</p>
<p>代码中只有两个需要注意的点。</p>
<p>第一个是对于我们定义的 ConversationSummaryMemory，它的构造函数也接受一个LLM对象。这个对象会专门用来生成历史对话的小结，是可以和对话本身使用的LLM对象不同的。</p>
<p>第二个是这次我们没有使用LLMChain这个对象，而是用了封装好的ConversationChain。用ConversationChain的话，其实我们是可以不用自己定义PromptTemplate来维护历史聊天记录的，但是为了使用中文的PromptTemplate，我们在这里还是自定义了对应的Prompt。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> ConversationChain
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>memory <span class="token keyword">import</span> ConversationSummaryMemory
llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
memory <span class="token operator">=</span> ConversationSummaryMemory<span class="token punctuation">(</span>llm<span class="token operator">=</span>OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

prompt_template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:
1. 你的回答必须是中文
2. 回答限制在100个字以内

&#123;history&#125;
Human: &#123;input&#125;
AI:"""</span>
prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"history"</span><span class="token punctuation">,</span> <span class="token string">"input"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> template<span class="token operator">=</span>prompt_template
<span class="token punctuation">)</span>
conversation_with_summary <span class="token operator">=</span> ConversationChain<span class="token punctuation">(</span>
    llm<span class="token operator">=</span>llm<span class="token punctuation">,</span>
    memory<span class="token operator">=</span>memory<span class="token punctuation">,</span>
    prompt<span class="token operator">=</span>prompt<span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>
conversation_with_summary<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span><span class="token string">"你好"</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">
<span class="token operator">></span> Entering new ConversationChain chain<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
Prompt after formatting<span class="token punctuation">:</span>
你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求<span class="token punctuation">:</span>
<span class="token number">1.</span> 你的回答必须是中文
<span class="token number">2.</span> 回答限制在<span class="token number">100</span>个字以内

Human<span class="token punctuation">:</span> 你好
AI<span class="token punctuation">:</span>
<span class="token operator">></span> Finished chain<span class="token punctuation">.</span>
<span class="token string">' 你好，我可以帮你做菜。我会根据你的口味和喜好，结合当地的食材，制作出美味可口的菜肴。我会尽力做出最好的菜肴，让你满意。'</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>在我们打开了ConversationChain的Verbose模式，然后再次询问AI第二个问题的时候，你可以看到，在Verbose的信息里面，没有历史聊天记录，而是多了一段对之前聊天内容的英文小结。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">conversation_with_summary<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span><span class="token string">"鱼香肉丝怎么做？"</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">></span> Entering new ConversationChain chain<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
Prompt after formatting<span class="token punctuation">:</span>
你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求<span class="token punctuation">:</span>
<span class="token number">1.</span> 你的回答必须是中文
<span class="token number">2.</span> 回答限制在<span class="token number">100</span>个字以内

The human greeted the AI <span class="token keyword">and</span> the AI responded that it can <span class="token builtin">help</span> cook by combining local ingredients <span class="token keyword">and</span> tailor the meal to the human<span class="token string">'s tastes and preferences. It promised to make the best dishes possible to the human'</span>s satisfaction<span class="token punctuation">.</span>
Human<span class="token punctuation">:</span> 鱼香肉丝怎么做？
AI<span class="token punctuation">:</span>
<span class="token operator">></span> Finished chain<span class="token punctuation">.</span>

<span class="token string">' 鱼香肉丝是一道经典的家常菜，需要准备肉丝、葱姜蒜、鱼香调料、豆瓣酱、醋、糖、盐等调料，先将肉丝用盐、料酒、胡椒粉腌制，然后炒锅里放入葱姜蒜爆香，加入肉丝翻炒，加入鱼香调料、豆瓣酱、醋、糖等调料，最后放入少许水煮熟即可。'</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>而如果这个时候我们调用 memory的load_memory_variables方法，可以看到记录下来的history是一小段关于对话的英文小结。而不是像上面那样，记录完整的历史对话。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">memory<span class="token punctuation">.</span>load_memory_variables<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">&#123;</span><span class="token string">'history'</span><span class="token punctuation">:</span> <span class="token string">'\nThe human greeted the AI, to which the AI replied that it was a Chinese chef that enjoyed making Chinese dishes such as braised pork, Kung Pao chicken, and Fish-fragrant pork shreds. The AI also said that it would use fresh ingredients and carefully cook each dish to make them delicious. When the human asked about how to make Fish-fragrant pork shreds, the AI replied that it needed to prepare ingredients such as meat shreds, scallions, ginger, garlic, peppers, Sichuan pepper, soy sauce, sugar, vinegar, cooking wine, and cornstarch. The AI then explained that the meat shreds should first be marinated with cornstarch, cooking wine, salt, and pepper, and then the scallions, ginger, garlic, and peppers should be stir-fried in a wok, followed by the addition of the meat shreds. Finally, soy sauce, sugar, vinegar, and cornstarch should be added to season the dish.'</span><span class="token punctuation">&#125;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>而如果我们进一步通过conversation_with_summary去和AI对话，就会看到英文的小结内容会随着对话内容不断变化。每一次AI都是把之前的小结和新的对话交给memory中定义的LLM再次进行小结。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">conversation_with_summary<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span><span class="token string">"那蚝油牛肉呢？"</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">></span> Entering new ConversationChain chain<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
Prompt after formatting<span class="token punctuation">:</span>
你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求<span class="token punctuation">:</span>
<span class="token number">1.</span> 你的回答必须是中文
<span class="token number">2.</span> 回答限制在<span class="token number">100</span>个字以内

The human greeted the AI <span class="token keyword">and</span> the AI responded that it can <span class="token builtin">help</span> cook by combining local ingredients <span class="token keyword">and</span> tailor the meal to the human<span class="token string">'s tastes and preferences. It promised to make the best dishes possible to the human'</span>s satisfaction<span class="token punctuation">.</span> When asked how to make 鱼香肉丝<span class="token punctuation">,</span> the AI responded that it requires the preparation of meat slices<span class="token punctuation">,</span> scallion<span class="token punctuation">,</span> ginger<span class="token punctuation">,</span> garlic<span class="token punctuation">,</span> fish sauce<span class="token punctuation">,</span> doubanjiang<span class="token punctuation">,</span> vinegar<span class="token punctuation">,</span> sugar <span class="token keyword">and</span> salt<span class="token punctuation">.</span> The meat slices should be marinated <span class="token keyword">with</span> salt<span class="token punctuation">,</span> cooking wine <span class="token keyword">and</span> pepper<span class="token punctuation">,</span> then stir<span class="token operator">-</span>fried <span class="token keyword">with</span> scallion<span class="token punctuation">,</span> ginger <span class="token keyword">and</span> garlic<span class="token punctuation">.</span> The fish sauce<span class="token punctuation">,</span> doubanjiang<span class="token punctuation">,</span> vinegar<span class="token punctuation">,</span> sugar <span class="token keyword">and</span> salt should be added <span class="token keyword">in</span><span class="token punctuation">,</span> <span class="token keyword">with</span> some water added to cook the dish<span class="token punctuation">.</span>
Human<span class="token punctuation">:</span> 那蚝油牛肉呢？
AI<span class="token punctuation">:</span>
<span class="token operator">></span> Finished chain<span class="token punctuation">.</span>

<span class="token string">' 蚝油牛肉需要准备牛肉、蚝油、葱、姜、蒜、料酒、盐、糖、醋、淀粉和水。牛肉应先用盐、料酒和胡椒粉腌制，然后和葱、姜、蒜一起爆炒，再加入蚝油、糖、盐、醋和水，最后加入淀粉勾芡即可。'</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="两者结合，使用SummaryBufferMemory"><a href="#两者结合，使用SummaryBufferMemory" class="headerlink" title="两者结合，使用SummaryBufferMemory"></a>两者结合，使用SummaryBufferMemory</h2><p>虽然SummaryMemory可以支持更长的对话轮数，但是它也有一个缺点，就是 <strong>即使是最近几轮的对话，记录的也不是精确的内容</strong>。当你问“上一轮我问的问题是什么？”的时候，它其实没法给出准确的回答。不过，相信你也想到了，我们把BufferMemory和SummaryMemory结合一下不就好了吗？没错，LangChain里还真提供了一个这样的解决方案，就叫做ConversationSummaryBufferMemory。</p>
<p>下面，我们就来看看ConversationSummaryBufferMemory怎么用。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain <span class="token keyword">import</span> PromptTemplate
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> ConversationChain
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>memory <span class="token keyword">import</span> ConversationSummaryBufferMemory
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI

SUMMARIZER_TEMPLATE <span class="token operator">=</span> <span class="token triple-quoted-string string">"""请将以下内容逐步概括所提供的对话内容，并将新的概括添加到之前的概括中，形成新的概括。

EXAMPLE
Current summary:
Human询问AI对人工智能的看法。AI认为人工智能是一种积极的力量。

New lines of conversation:
Human：为什么你认为人工智能是一种积极的力量？
AI：因为人工智能将帮助人类发挥他们的潜能。

New summary:
Human询问AI对人工智能的看法。AI认为人工智能是一种积极的力量，因为它将帮助人类发挥他们的潜能。
END OF EXAMPLE

Current summary:
&#123;summary&#125;

New lines of conversation:
&#123;new_lines&#125;

New summary:"""</span>

SUMMARY_PROMPT <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"summary"</span><span class="token punctuation">,</span> <span class="token string">"new_lines"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> template<span class="token operator">=</span>SUMMARIZER_TEMPLATE
<span class="token punctuation">)</span>

memory <span class="token operator">=</span> ConversationSummaryBufferMemory<span class="token punctuation">(</span>llm<span class="token operator">=</span>OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> prompt<span class="token operator">=</span>SUMMARY_PROMPT<span class="token punctuation">,</span> max_token_limit<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">)</span>

CHEF_TEMPLATE <span class="token operator">=</span> <span class="token triple-quoted-string string">"""你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:
1. 你的回答必须是中文。
2. 对于做菜步骤的回答尽量详细一些。

&#123;history&#125;
Human: &#123;input&#125;
AI:"""</span>
CHEF_PROMPT <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"history"</span><span class="token punctuation">,</span> <span class="token string">"input"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> template<span class="token operator">=</span>CHEF_TEMPLATE
<span class="token punctuation">)</span>

conversation_with_summary <span class="token operator">=</span> ConversationChain<span class="token punctuation">(</span>
    llm<span class="token operator">=</span>OpenAI<span class="token punctuation">(</span>model_name<span class="token operator">=</span><span class="token string">"text-davinci-003"</span><span class="token punctuation">,</span> stop<span class="token operator">=</span><span class="token string">"\n\n"</span><span class="token punctuation">,</span> max_tokens<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> temperature<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    prompt<span class="token operator">=</span>CHEF_PROMPT<span class="token punctuation">,</span>
    memory<span class="token operator">=</span>memory<span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>
answer <span class="token operator">=</span> conversation_with_summary<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span><span class="token string">"你是谁？"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>answer<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-plain" data-language="plain"><code class="language-plain">> Entering new ConversationChain chain...
Prompt after formatting:
你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:
1. 你的回答必须是中文。
2. 对于做菜步骤的回答尽量详细一些。

Human: 你是谁？
AI:
> Finished chain.
 我是一个中国厨师，您有什么可以问我的关于做菜的问题吗？
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ol>
<li>这个代码显得有些长，这是为了演示的时候让你看得更加清楚一些。我把Langchain原来默认的对Memory进行小结的提示语模版从英文改成中文的了，不过这个翻译工作我也是让ChatGPT帮我做的。如果你想了解原始的英文提示语是什么样的，可以去看一下它源码里面的 _DEFAULT_SUMMARIZER_TEMPLATE，对应的链接我也放在 <a target="_blank" rel="noopener" href="https://github.com/hwchase17/langchain/blob/master/langchain/memory/prompt.py">这里</a> 了。</li>
<li>我们定义了一个 ConversationSummaryBufferMemory，在这个Memory的构造函数里面，我们指定了使用的LLM、提示语，以及一个max_token_limit参数。max_token_limit参数，其实就是告诉我们，当对话的长度到多长之后，我们就应该调用LLM去把文本内容小结一下。</li>
<li>后面的代码其实就和前面其他的例子基本一样了。</li>
</ol>
<p>因为我们在代码里面打开了Verbose模式，所以你能看到实际AI记录的整个对话历史是怎么样的。当我们连续多问AI几句话，你就会看到，随着对话轮数的增加，Token数量超过了前面的max_token_limit 。于是SummaryBufferMemory就会触发，对前面的对话进行小结，也就会出现一个 System的信息部分，里面是聊天历史的小结，而后面完整记录的实际对话轮数就变少了。</p>
<p>我们先问鱼香肉丝怎么做，Verbose的信息里还是显示历史的聊天记录。</p>
<pre class="line-numbers language-plain" data-language="plain"><code class="language-plain">answer = conversation_with_summary.predict(input="请问鱼香肉丝怎么做？")
print(answer)
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-plain" data-language="plain"><code class="language-plain">
> Entering new ConversationChain chain...
Prompt after formatting:
你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:
1. 你的回答必须是中文。
2. 对于做菜步骤的回答尽量详细一些。
Human: 你是谁？
AI:  我是一个中国厨师，您有什么可以问我的关于做菜的问题吗？
Human: 请问鱼香肉丝怎么做？
AI:
> Finished chain.
 鱼香肉丝是一道很受欢迎的中国菜，准备材料有：猪肉、木耳、胡萝卜、葱姜蒜、花椒、八角、辣椒、料酒、糖、盐、醋、麻油、香油。做法步骤如下：1. 将猪肉切成薄片，用料酒、盐、糖、醋、麻油抓匀；2. 将木耳洗净，切碎；3. 将胡萝卜切丝；4. 将葱姜蒜切碎；5. 将花椒、八角、辣椒放入油锅中炸熟；6. 将葱姜蒜炒香；7. 加入猪肉片翻炒；8. 加入木耳、胡萝卜丝、花椒、八角、辣椒翻炒；9. 加入盐、糖、醋、麻油、香油调味；10. 加入水煮熟，即可出锅。
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>等到我们再问蚝油牛肉，前面的对话就被小结到System下面去了。</p>
<pre class="line-numbers language-plain" data-language="plain"><code class="language-plain">answer = conversation_with_summary.predict(input="那蚝油牛肉呢？")
print(answer)
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-plain" data-language="plain"><code class="language-plain">
> Entering new ConversationChain chain...
Prompt after formatting:
你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:
1. 你的回答必须是中文。
2. 对于做菜步骤的回答尽量详细一些。
System:
Human询问AI是谁，AI回答自己是一个中国厨师，并问Human是否有关于做菜的问题。Human问AI如何做出鱼香肉丝，AI回答准备材料有猪肉、木耳、胡萝卜、葱姜蒜、花椒、八角、辣椒、料酒、糖、盐、醋、麻油、香油，做法步骤是将猪肉切成薄片，用料酒、盐、糖、醋、麻油抓匀，木耳
Human: 那蚝油牛肉呢？
AI:
> Finished chain.
 准备材料有牛肉、葱、姜、蒜、蚝油、料酒、醋、糖、盐、香油，做法步骤是先将牛肉切成薄片，用料酒、盐、糖、醋、麻油抓匀，然后将葱、姜、蒜切碎，加入蚝油拌匀，最后加入香油搅拌均匀即可。
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>当然，在你实际使用SummaryBufferMemory的时候，并不需要把各个Prompt都改成自定义的中文版本。用默认的英文Prompt就足够了。因为在Verbose信息里出现的System信息并不会在实际的对话进行过程中显示给用户。这部分提示，只要AI自己能够理解就足够了。当然，你也可以根据实际对话的效果，来改写自己需要的提示语。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/4fd464abb35dcaa62266e3fc3bf24c76.png" alt="图片"></p>
<p>Pinecone 在自己网站上给出了一个数据对比，不同类型的Memory，随着对话轮数的增长，占用的Token数量的变化。你可以去看一看，不同的Memory在不同的参数下，占用的Token数量是不同的。比较合理的方式，还是使用这里的ConversationSummaryBufferMemory，这样既可以在记录少数对话内容的时候，记住的东西更加精确，也可以在对话轮数增长之后，既能够记住各种信息，又不至于超出Token数量的上限。</p>
<p>不过，在运行程序的过程里，你应该可以感觉到现在程序跑得有点儿慢。这是因为我们使用 ConversationSummaryBufferMemory很多时候要调用多次OpenAI的API。在字数超过 max_token_limit 的时候，需要额外调用一次API来做小结。而且这样做，对应的Token数量消耗也是不少的。</p>
<p>所以， <strong>不是所有的任务，都适合通过调用一次ChatGPT的API来解决。</strong> 很多时候，你还是可以多思考是否可以用上一讲介绍的 UtilityChain 和 TransformChain 来解决问题。</p>
<h2 id="让AI记住点有用的信息"><a href="#让AI记住点有用的信息" class="headerlink" title="让AI记住点有用的信息"></a>让AI记住点有用的信息</h2><p>我们不仅可以在整个对话过程里，使用我们的Memory功能。如果你之前已经有了一系列的历史对话，我们也可以通过Memory提供的save_context接口，把历史聊天记录灌进去。然后基于这个Memory让AI接着和用户对话。比如下面我们就把一组电商客服历史对话记录给了SummaryBufferMemory。</p>
<pre class="line-numbers language-plain" data-language="plain"><code class="language-plain">memory = ConversationSummaryBufferMemory(llm=OpenAI(), prompt=SUMMARY_PROMPT, max_token_limit=40)
memory.save_context(
    &#123;"input": "你好"&#125;,
    &#123;"ouput": "你好，我是客服李四，有什么我可以帮助您的么"&#125;
    )
memory.save_context(
    &#123;"input": "我叫张三，在你们这里下了一张订单，订单号是 2023ABCD，我的邮箱地址是 customer@abc.com，但是这个订单十几天了还没有收到货"&#125;,
    &#123;"ouput": "好的，您稍等，我先为您查询一下您的订单"&#125;
    )
memory.load_memory_variables(&#123;&#125;)
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-plain" data-language="plain"><code class="language-plain">&#123;'history': 'System: \nHuman和AI打招呼，AI介绍自己是客服李四，问Human有什么可以帮助的。Human提供订单号和邮箱地址，AI表示会为其查询订单状态。'&#125;
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>注：为了演示方便，我设置了一个很小的 max_token_limit，但是这个问题在大的 max_token_limit 下，面对上下文比较多的会话一样会有问题。</p>
<p>通过调用 memory.load_memory_variables 方法，我们发现AI对整段对话做了小结。但是这个小结有个问题，就是 <strong>它并没有提取到我们最关注的信息</strong>，比如用户的订单号、用户的邮箱。只有有了这些信息，AI才能够去查询订单，拿到结果然后回答用户的问题。</p>
<p>以前在还没有ChatGPT的时代，在客服聊天机器人这样的领域，我们会通过命名实体识别的方式，把邮箱、订单号之类的关键信息提取出来。在有了ChatGPT这样的大语言模型之后，我们还是应该这样做。不过我们不是让专门的命名实体识别的算法做，而是直接让ChatGPT帮我们做。Langchain也内置了一个EntityMemory的封装，让AI自动帮我们提取这样的信息。我们来试一试。</p>
<pre class="line-numbers language-plain" data-language="plain"><code class="language-plain">from langchain.chains import ConversationChain
from langchain.memory import ConversationEntityMemory
from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE

entityMemory = ConversationEntityMemory(llm=llm)
conversation = ConversationChain(
    llm=llm,
    verbose=True,
    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,
    memory=entityMemory
)

answer=conversation.predict(input="我叫张老三，在你们这里下了一张订单，订单号是 2023ABCD，我的邮箱地址是 customer@abc.com，但是这个订单十几天了还没有收到货")
print(answer)
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-plain" data-language="plain"><code class="language-plain">> Entering new ConversationChain chain...
Prompt after formatting:
You are an assistant to a human, powered by a large language model trained by OpenAI.
You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.
You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.
Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.
Context:
&#123;'张老三': '', '2023ABCD': '', 'customer@abc.com': ''&#125;
Current conversation:
Last line:
Human: 我叫张老三，在你们这里下了一张订单，订单号是 2023ABCD，我的邮箱地址是 customer@abc.com，但是这个订单十几天了还没有收到货
You:
> Finished chain.
 您好，张老三，我很抱歉你没有收到货。我们会尽快核实订单信息，并尽快给您处理，请您耐心等待，如果有任何疑问，欢迎您随时联系我们。
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>我们还是使用ConversationChain，只是这一次，我们指定使用EntityMemory。可以看到，在Verbose的日志里面，整个对话的提示语，多了一个叫做 Context 的部分，里面包含了刚才用户提供的姓名、订单号和邮箱。</p>
<p>进一步，我们把memory里面存储的东西打印出来。</p>
<pre class="line-numbers language-plain" data-language="plain"><code class="language-plain">print(conversation.memory.entity_store.store)
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-plain" data-language="plain"><code class="language-plain">&#123;'张老三': '张老三是一位订单号为2023ABCD、邮箱地址为customer@abc.com的客户。', '2023ABCD': '2023ABCD is an order placed by customer@abc.com that has not been received after more than ten days.', 'customer@abc.com': 'Email address of Zhang Lao San, who placed an order with Order Number 2023ABCD, but has not received the goods more than ten days later.'&#125;
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>可以看到，EntityMemory里面不仅存储了这些命名实体的名字，也对应的把命名实体所关联的上下文记录了下来。这个时候，如果我们再通过对话来询问相关的问题，AI也能够答上来。</p>
<p>问题1：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">answer<span class="token operator">=</span>conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span><span class="token string">"我刚才的订单号是多少？"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>answer<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">您的订单号是2023ABCD。
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>问题2：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">answer<span class="token operator">=</span>conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span><span class="token string">"订单2023ABCD是谁的订单？"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>answer<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">订单2023ABCD是您张老三的订单，您的邮箱地址是customer@abc<span class="token punctuation">.</span>com。
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>这些往往才是我们在聊天的过程中真正关注的信息。如果我们要做一个电商客服，后续的对话需要查询订单号、用户姓名的时候，这些信息是必不可少的。</p>
<p>事实上，我们不仅可以把这些Memory放在内存里面，还可以进一步把它们存放在Redis这样的外部存储里面。这样即使我们的服务进程消失了，这些“记忆”也不会丢失。你可以对照着 <a target="_blank" rel="noopener" href="https://python.langchain.com/en/latest/modules/memory/examples/agent_with_memory_in_db.html">官方文档</a> 尝试一下。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>最后，我们来做个小结。这一讲，我主要为你讲解了Langchain里面的Memory功能。Memory对整个对话的过程里我们希望记住的东西做了封装。我们可以通过BufferWindowMemory记住过去几轮的对话，通过SummaryMemory概括对话的历史并记下来。也可以将两者结合，使用BufferSummaryMemory来维护一个对整体对话做了小结，同时又记住最近几轮对话的“记忆”。</p>
<p>不过， <strong>更具有实用意义的是 EntityMemory</strong>。在实际使用AI进行对话的过程中，并不是让它不分轻重地记住一切内容，而是有一些我们要关注的核心要点。比如，如果你要搭建一个电商客服的聊天机器人，你肯定希望它记住具体的订单号、用户的邮箱等等。这个时候，我们就可以使用EntityMemory，它会帮助我们记住整个对话里面的“命名实体”（Entity），保留实际在对话中我们最关心的信息。</p>
<p>在过去的几讲里面，从llama-index开始，我们已经学会了将外部的资料库索引起来进行问答，也学会了通过Langchain的链式调用，实时获取外部的数据信息，或者运行Python程序。这一讲，我们又专门研究了怎样记住对话中我们关心的部分。</p>
<p><strong>将这些能力组合起来，我们就可以搭建一个完整的，属于自己的聊天机器人。</strong> 我们可以根据用户提供的订单号，去查询订单物流信息，安抚客户；也可以根据用户想要了解的商品，查询我们的商品库，进行商品导购。而这些，也是我们下一讲要解决的问题。</p>
<h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>最后，我给你留一道思考题。在这一讲里，我为你介绍了EntityMemory的使用方法，Langchain里面还提供了一个 <a target="_blank" rel="noopener" href="https://langchain.readthedocs.io/en/latest/modules/memory/types/kg.html">KnowledgeGraphMemory</a>，你能不能去试着用一下，看看它能在什么样的场景下帮你解决问题？</p>
<h2 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h2><p>在Pinecone提供的Langchain AI Handbook里面，专门测试了一下，从BufferWindowMemory到BufferSummaryMemory，对于上下文保持的能力，以及消耗的Token数量的统计。那个 <a target="_blank" rel="noopener" href="https://www.pinecone.io/learn/langchain-conversational-memory/">教程</a> 你也可以去看一下。</p>
</article><div class="tag_share"><div class="post_share"></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#16%EF%BD%9CLangchain%E9%87%8C%E7%9A%84%E2%80%9C%E8%AE%B0%E5%BF%86%E5%8A%9B%E2%80%9D%EF%BC%8C%E8%AE%A9AI%E5%8F%AA%E8%AE%B0%E4%BD%8F%E6%9C%89%E7%94%A8%E7%9A%84%E4%BA%8B%E5%84%BF"><span class="toc-number">1.</span> <span class="toc-text">16｜Langchain里的“记忆力”，让AI只记住有用的事儿</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#BufferWindow%EF%BC%8C%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E8%AE%B0%E5%BF%86"><span class="toc-number">1.1.</span> <span class="toc-text">BufferWindow，滑动窗口记忆</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SummaryMemory%EF%BC%8C%E6%8A%8A%E5%B0%8F%E7%BB%93%E4%BD%9C%E4%B8%BA%E5%8E%86%E5%8F%B2%E8%AE%B0%E5%BF%86"><span class="toc-number">1.2.</span> <span class="toc-text">SummaryMemory，把小结作为历史记忆</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%A4%E8%80%85%E7%BB%93%E5%90%88%EF%BC%8C%E4%BD%BF%E7%94%A8SummaryBufferMemory"><span class="toc-number">1.3.</span> <span class="toc-text">两者结合，使用SummaryBufferMemory</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A9AI%E8%AE%B0%E4%BD%8F%E7%82%B9%E6%9C%89%E7%94%A8%E7%9A%84%E4%BF%A1%E6%81%AF"><span class="toc-number">1.4.</span> <span class="toc-text">让AI记住点有用的信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-number">1.5.</span> <span class="toc-text">小结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98"><span class="toc-number">1.6.</span> <span class="toc-text">思考题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A8%E8%8D%90%E9%98%85%E8%AF%BB"><span class="toc-number">1.7.</span> <span class="toc-text">推荐阅读</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By 码农张三</div></div><script src="https://cdn.bootcdn.net/ajax/libs/mermaid/9.4.0/mermaid.min.js"></script></footer></div><div id="rightside"><div id="rightside-config-hide"></div><div id="rightside-config-show"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div></div></body></html>