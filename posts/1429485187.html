<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>13｜前浪DALL-E 2：帮你魔改经典画作 | geekbang</title><meta name="author" content="码农张三"><meta name="copyright" content="码农张三"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="13｜前浪DALL-E 2：帮你魔改经典画作你好，我是南柯。 通过上一章的学习，我们已经掌握了AI绘画的基础知识，了解了扩散模型、CLIP模型、自回归模型等模块的基本原理。从今天开始我们进入进阶篇的学习，我会带你基于已经了解的基础知识，继续探索业界最新最火的AI绘画模型。学完这部分内容，AI绘画的黑魔法在你面前就不是秘密了。 这一讲，我们将要学习的是引爆本轮AI绘画技术热潮的明星模型：DALL-E">
<meta property="og:type" content="article">
<meta property="og:title" content="13｜前浪DALL-E 2：帮你魔改经典画作">
<meta property="og:url" content="https://zhuansun.github.io/geekbang/posts/1429485187.html">
<meta property="og:site_name" content="geekbang">
<meta property="og:description" content="13｜前浪DALL-E 2：帮你魔改经典画作你好，我是南柯。 通过上一章的学习，我们已经掌握了AI绘画的基础知识，了解了扩散模型、CLIP模型、自回归模型等模块的基本原理。从今天开始我们进入进阶篇的学习，我会带你基于已经了解的基础知识，继续探索业界最新最火的AI绘画模型。学完这部分内容，AI绘画的黑魔法在你面前就不是秘密了。 这一讲，我们将要学习的是引爆本轮AI绘画技术热潮的明星模型：DALL-E">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg">
<meta property="article:published_time" content="2024-02-29T12:01:07.000Z">
<meta property="article:modified_time" content="2024-03-21T11:07:55.971Z">
<meta property="article:author" content="码农张三">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://zhuansun.github.io/geekbang/posts/1429485187"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":false,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '13｜前浪DALL-E 2：帮你魔改经典画作',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-03-21 11:07:55'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="geekbang" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://pic.imgdb.cn/item/653470a0c458853aef5813f1.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">1345</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">23</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">geekbang</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">13｜前浪DALL-E 2：帮你魔改经典画作</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2024-02-29T12:01:07.000Z" title="发表于 2024-02-29 12:01:07">2024-02-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI%E7%BB%98%E7%94%BB%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/">AI绘画核心技术与实战</a></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="13｜前浪DALL-E-2：帮你魔改经典画作"><a href="#13｜前浪DALL-E-2：帮你魔改经典画作" class="headerlink" title="13｜前浪DALL-E 2：帮你魔改经典画作"></a>13｜前浪DALL-E 2：帮你魔改经典画作</h1><p>你好，我是南柯。</p>
<p>通过上一章的学习，我们已经掌握了AI绘画的基础知识，了解了扩散模型、CLIP模型、自回归模型等模块的基本原理。从今天开始我们进入进阶篇的学习，我会带你基于已经了解的基础知识，继续探索业界最新最火的AI绘画模型。学完这部分内容，AI绘画的黑魔法在你面前就不是秘密了。</p>
<p>这一讲，我们将要学习的是引爆本轮AI绘画技术热潮的明星模型：DALL-E 2。</p>
<p>DALL-E 2是2022年4月由OpenAI发布的AI绘画模型，它的绘画效果相比过去的工作有了质的飞跃，而且它提出的unCLIP结构、图像变体能力也被后来的方法所效仿。我们只有真正理解了DALL-E 2，才算拿到了进入AI绘画世界的钥匙。</p>
<h2 id="初识DALL-E-2"><a href="#初识DALL-E-2" class="headerlink" title="初识DALL-E 2"></a>初识DALL-E 2</h2><p>DALL-E这个名字源自西班牙艺术家Salvador Dali和皮克斯动画机器人Wall-E的组合。如果你想体验OpenAI的DALL-E 2原汁原味的效果，可以使用Edge浏览器NewBing的AI绘画能力。目前，NewBing的AI绘画能力还没有向中国大陆地区开放，需要你发挥聪明才智来体验它。如果你有好的办法，也欢迎你分享在评论区。</p>
<p>比如我们要求DALL-E 2帮我们生成一只可爱的精灵。你可以点开图像查看效果。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/44a729e0f2404e52b72159505836f089.jpg"></p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/497f0bfb0d326bc7bfcc5f0dc810e06a.jpg"></p>
<p>这里如果我们使用中文描述，生成的图像效果似乎打了点折扣。这是因为中文描述在输入到模型前需要先翻译成英文，翻译的结果和刚刚我们使用的英文描述并不一致。感兴趣的同学可以自己动手体验更多AI绘画的效果。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/49794cea0b77cd21c3bf5a317fb3370e.jpg"></p>
<p>除了上面展示的基于文本描述生成高清图像的基本能力，DALL-E 2还有其他好玩的功能，我们继续来探索。</p>
<p>第一种玩法就是 <strong>生成图像变体，</strong> 我们可以对经典画作进行“魔改”。像后面这样，输入一张图片，DALL-E 2可以保留图像中的关键信息，并生成图像的变体。</p>
<p>不要小看这种魔改，实际工作里它能快速提供很多风格的demo，激发我们的设计灵感。比如当我们设计一个产品logo的时候，只需要提供一个设计效果，便可以用图像变体这个功能生成出更多的不同效果。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/3159b2059bdb3ba11100fd05fcf7dc9e.jpg"></p>
<p>第二种玩法就是 <strong>图像的融合</strong>。比如输入两张图片，DALL-E 2可以对两张图片进行插值，生成融合后的新图片。这里的融合既可以是图像风格上的融合，也可以是图像内容上的融合，或者是图像内容和图像风格二者的融合。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/070cb9bbd41281c36aebeec7e8caea94.jpg"></p>
<p>第三种是局部编辑。输入一张图片，DALL-E 2可以根据我们的指令局部编辑图像，让我们仿佛拥有了指令级PS的能力。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/4583a5d8d3102dba4962daf6963a57cd.jpg"></p>
<p>了解了这些，相信你一定会感到好奇：为什么 DALL-E 2 能拥有这些神奇的能力呢？接下来，我们将一起来探究它的工作原理，搞清楚这个模型背后的秘密。</p>
<h2 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h2><p>我们结合论文给出的整体流程，来拆解一下DALL-E 2都有哪些关键内容。如果你学过前面的章节，可能对图里的很多专业名词都已经很熟悉了。</p>
<p>其实，DALL-E 2就是个“缝合怪”。我们把CLIP和扩散模型，或者CLIP和自回归模型组合到一起，引入大量图像文本数据进行模型训练后，便得到了DALL-E 2。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/979f48c856460411e2fb65cf57cbcec7.jpg"></p>
<p>在基础篇中，我们已经学习过了CLIP、扩散模型、自回归模型的基本原理。在正式学习DALL-E 2的工作原理前，我先带你简单回顾下这些基础知识。如果前面内容你已经了然于胸了，也可以跳过后面这几段回顾内容。</p>
<p>CLIP，目的是训练一对图像编码器和文本编码器。使用成对的4亿图文数据，通过图像编码器和文本编码器将图像、文本描述分别映射到一个表征空间，然后计算图像和文本表征向量的距离。训练的目标是让成对的图像文本描述之间的距离更接近。对于 CLIP 的细节感兴趣的同学可以去复习下第10讲的课程。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/17befe1b7beaea9a5b0fbc08de6cb8bc.gif" alt="图片"></p>
<p>扩散模型可以从噪声生成图片。这个过程需要多步去噪，每一步都使用权重共享的UNet结构。对于文生图任务而言，UNet的输入信息包括当前带噪声的图像、时间步编码、文本表征。对于扩散模型细节感兴趣的同学，可以去复习下第6至第9讲的内容。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/8403d99c51303bb5yy520c9df710f12f.jpg"></p>
<p>自回归模型常用于文本生成任务，特点是可以根据前面的单词预测下一个单词，是一种处理时间序列的方法。我们熟悉的ChatGPT就是基于自回归模型实现的，每次输入一串文本去精准地预测下一个单词。不过，自回归模型也有缺点，因为序列预测无法并行，所以它的运行效率比较低。</p>
<p>回顾了刚才的基础知识，我们再来细细品鉴DALL-E 2的工作原理。我们先看看原论文中方案的流程图。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/979f48c856460411e2fb65cf57cbcec7.jpg"></p>
<p>我们乍一看，也许感觉这张图比较唬人，并且有一定的迷惑性。不过别担心，我给这张图做了6种不同颜色标记，每种颜色代表一个模块，我们分别看看图中各个模块的作用，就很容易理解了。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/61e94454a6b6480d1869a455372ff97b.jpg"></p>
<p>先看标记 1。它是原始的 CLIP 结构，这部分在 DALL-E 2 的链路中是固定住的，无需训练。</p>
<p>然后是标记 2。它代表CLIP 的文本编码器提取的文本表征。文本表征是指根据输入的文本，用CLIP文本编码器提取得到的数值特征。图中三处标记为 2 的表征是完全相同的。</p>
<p>标记3和标记4是两种可以互相替代的方案。标记 3代表需要训练的自回归先验模型，也称为Prior模型。先验模型的作用，就是 <strong>将CLIP提取的文本表征转换为CLIP图像表征。</strong></p>
<p>注意，这里提到的CLIP文本表征是用CLIP文本编码器从文本中提取的，而这里提到的CLIP图像表征是经过先验模型预测得到的，而不是CLIP图像编码器提取的，我们可以将其视为类似于CLIP图像编码器提取的图像表征。</p>
<p>标记 4 表示需要训练的扩散先验模型。DALL-E 2 经过实验验证，使用扩散先验模型和自回归先验模型在生成效果上差不太多，扩散先验模型在计算效率上更有优势。既然原论文主要是围绕扩散先验展开的，所以我们也主要来学习扩散先验的用法。</p>
<p>最后来看标记5和标记6，完成这两步以后文本表征才能转化成真正的图像。标记 5 是先验模块输出的 <strong>图像表征，该表征类似于CLIP图像编码器提取的特征</strong>。标记 6 则是扩散模型，作用是将上一步得到的图像表征转换为图像。</p>
<p>这样拆解完，DALL-E 2 的结构就非常简单明朗了。可以归纳为后面这三个步骤。</p>
<ol>
<li>首先，使用一个预训练好的CLIP文本编码器将文本描述映射为文本表征。</li>
<li>然后，训练一个扩散先验模型，将文本表征映射为对应的图像表征。</li>
<li>最后，训练一个基于扩散模型的图像解码器，该解码器可以基于图像表征生成图像。</li>
</ol>
<p>这三步便是 DALL-E 2 实现 AI 绘画能力的全部过程。我们用一句话总结就是，DALL-E 2 设计的核心思路是，用 CLIP 提取文本表征，通过一个扩散模型将文本表征转换为图像表征，然后通过另一个扩散模型指导图像的生成。我还给你画了流程图，你可以通过看图再加深一下理解。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/603a92df0664a52d3e3ee5c9b2058bc7.jpg" alt="P11"></p>
<p>到这里，距离完全理解DALL-E 2，我们还剩下两个最关键的问题。第一，扩散先验模型要如何训练呢？第二，扩散模型图像解码器要如何训练呢？</p>
<p><strong>我们先来看看扩散先验模型该如何训练。</strong></p>
<p>前面已经说过，扩散先验模型的目标是将CLIP文本表征转换为CLIP图像表征。DALL-E 2的扩散先验模型并没有使用UNet结构，而是直接使用一个Transformer解码器。</p>
<p>我们都知道，UNet结构擅长解决图像分割问题，因为UNet的输入和输出都是类似于图像的特征图；而Transformer的输入输出是序列化的特征，更适合完成CLIP文本表征到图像表征的转换。基于Transformer的扩散先验并不是预测每一步的噪声值，而是直接预测每一步去噪后的图像表征。</p>
<p>基于图像-文本成对训练数据，扩散先验模型的训练可以分为以下几个步骤。</p>
<ol>
<li>首先，使用预训练好的 CLIP 文本编码器提取文本描述的文本表征。</li>
<li>然后，使用预训练好的 CLIP 图像编码器提取对应的图像表征。</li>
<li>之后，随机采样一个时间步 t，以时间步 t、CLIP 提取的文本表征、加噪之后的图像表征作为条件，基于 Transformer 去预测下一步去噪后的图像表征。</li>
</ol>
<p>为了帮你彻底搞懂基于Transformer的扩散先验模型和普通扩散模型的区别，我准备了后面这张图。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/5f0ba205ccaee283309aa629b74abd78.jpg"></p>
<p><strong>学习完扩散先验模型的结构，那么基于扩散模型的图像解码器该如何实现呢？同为扩散模型，二者有什么不同？</strong></p>
<p>关于图像解码器模块，DALL-E 2 在 OpenAI 的另一个名为 GLIDE 的论文基础上做了一些改进。GLIDE 仅使用文本编码作为图像解码器的输入，而 DALL-E 2 使用文本编码和经过扩散先验之后得到的 CLIP 图像表征作为输入。</p>
<p>图像解码器得到的输出是 64x64 分辨率的图像，这对于我们来说是远远不够的。因此，作者又设计了两个连续的上采样器，实现图像的超分辨率处理，最终得到 1024x1024 的高清图像。我们需要留意的是，这里用到的两个上采样器都是扩散模型。</p>
<h2 id="图像变体"><a href="#图像变体" class="headerlink" title="图像变体"></a>图像变体</h2><p>到此为止，我们已经完整了解了DALL-E 2的技术原理。</p>
<p>虽然在生图效果、生图速度等方面，标准的Stable Diffusion毫不逊色于DALL-E 2，但图像变体功能仍是DALL-E 2的亮点功能之一。那么，DALL-E 2是如何实现图像变体功能的呢？</p>
<p>我们常常把 DALL-E 2 的文生图方案称为 unCLIP，这种方案和Stable Diffusion 的技术链路是不同的。unCLIP 模型有一些独特的优势，比如用户输入一张图像，unCLIP 模型可以保留原始图像的关键信息，生成一系列图像变体。</p>
<p>前面已经说过，预训练好的 CLIP 图像编码器可以提取到图像表征，文本编码器可以提取到文本表征。 <strong>DALL-E 2 从图像表征直接生成图像，正好和 CLIP 从图像提取图像表征是一个相反的过程，这个过程被称为 unCLIP</strong>。</p>
<p>下面这张图描述的就是生成图像变体的过程。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/d7d6c16fede2bce9dfe124b13b8524ee.jpg"></p>
<p>对照图解可以看到，用户输入一张图像，使用CLIP的图像编码器提取图像表征作为图像解码器的输入，这样就实现了生成图像变体的能力。前面我们提到扩散先验模型的作用是得到类似于CLIP图像编码器提取的图像表征，而图像变体功能使用CLIP图像编码器提取图像表征，二者是类似的。unCLIP的精妙之处就在这里，你可以仔细品味一下。</p>
<p>我们继续思考，为什么DALL-E 2可以生成很多变体图像呢？</p>
<p>虽然CLIP的图像编码器是固定的，从给定原始图像得到的图像表征是一个确定性的过程。但扩散解码器每次从随机噪声出发，结合CLIP图像表征会生成变体图像，这个生成图像的过程是有随机性的，所以DALL-E 2才会轻易得到很多变体图像。</p>
<p>当我们了解了整个技术方案，细心的你也许会有这样的疑惑——既然CLIP的图像表征和文本表征是使用海量图文对训练得到的，训练的方式也是让匹配的图像表征和文本表征尽可能靠近，那么必须要有扩散先验模块么？</p>
<p><strong>在DALL-E 2中，答案是必须的。</strong> DALL-E 2在论文中使用文本编码、CLIP 文本表征、扩散先验模型得到的图像表征作为输入，分别验证了这三种方式的图像生成效果。从实验效果来看，使用扩散先验模型的生成效果是最好的。</p>
<p>有趣的是，下一讲我们要学习的Imagen模型并没有使用扩散先验，而是直接从文本表征生成图像，效果优于DALL-E 2。从后来主流模型如Stable Diffusion的做法来看，扩散先验并不是必须的，代价是失去了生成图像变体的能力。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/dea2eb35a9cd3a065a3fb82ca93ed12d.jpg"></p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/d65a95532e4020cfccf16908d2082bc8.jpg"></p>
<p>遗憾的是DALL-E 2并没有官方开源，我们无法通过代码使用上面展示的能力。这一讲我们重在搞懂原理，后续课程中我们会动手写代码实现出不逊色于DALL-E 2的AI绘画效果和图像编辑能力。</p>
<h2 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h2><p>当然，任何事物都不是完美的，DALL-E 2 这个工作也存在一些局限性。</p>
<p>首先，DALL-E 2 并不擅长处理逻辑关系。比如我们要求其生成“蓝色方块上面放一个红色的方块”，对比 GLIDE 这个论文，DALL-E 2 得到的效果并不准确。</p>
<p>刚刚我们说过，DALL-E 2 图像解码器的输入，是在 GLIDE 文本编码的基础上又增加了图像表征。之所以保留 GLIDE 的文本编码作为输入，就是因为发现 GLIDE 的文本编码输入更擅长处理这类包含逻辑关系的图像生成。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/7a33070868250dce4595b2c6424de88a.jpg"></p>
<p>其次，DALL-E 2 并不擅长在生成的图像中写出要求的文字。比如我们要求 DALL-E 2 生成一幅图，“写着 Deep Learning 的标志板”，结果并不理想。之后我们要介绍的其他 AI 绘画方案便可以解决这个问题，这里先埋一个伏笔。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/4e712634922f60e78c6c4401042502cb.jpg"></p>
<p>此外，DALL-E 2 不擅长生成复杂的场景，细节不足。比如我们要求其生成“一张高质量的时代广场的照片”，得到的结果很粗糙。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/667584b73294c53d291397cfdc1ff8db.jpg"></p>
<p>除了上面这些，DALL-E 2 生成的内容还存在一些种族偏见，比如一些特定的职业会生成特定的有色人种；DALL-E 2也会生成一些色情暴力的内容，这是由于训练的数据中包括这类内容。</p>
<p>这些问题的存在孕育了更多优秀的改善思路，涌现出更多解决方案，随着我们学习的深入，你会发现在过去的一年里上述问题都得到了较大的改善。</p>
<h2 id="总结时刻"><a href="#总结时刻" class="headerlink" title="总结时刻"></a>总结时刻</h2><p>总结一下，今天我们学习了 DALL-E 2 这个具有开创性意义的 AI 绘画模型。DALL-E 2 可以用于文生图、图像变体生成、图像插值等任务，生成的图像可以达到 1024x1024 分辨率。</p>
<p>从原理上，我们学习了 DALL-E 2 如何使用预训练的 CLIP 模型，如何设计和训练扩散先验模型、图像解码模型，还了解了 unCLIP 的设计思路以及如何实现图像变体。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/603a92df0664a52d3e3ee5c9b2058bc7.jpg"></p>
<p>我们也了解到 DALL-E 2 在处理逻辑关系、生成包含指定文字内容的图像上仍有不足。非常鼓励你去读读 <a target="_blank" rel="noopener" href="https://openai.com/research/hierarchical-text-conditional-image-generation-with-clip-latents">原始论文</a>、看一些开源代码实现来加深对这个工作的理解。这一讲的知识我整理成了后面的思维导图，方便你课后复习。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/81f4c1d6606c37471397fc8285ebbf13.jpg"></p>
<p>AI绘画模型一直在进步，如今最新的AI绘画模型在生图效果上相比于DALL-E 2又有了较大提升，很大程度上归功于更强大的文本编码器、更高质量的训练图像。即便如此，DALL-E 2的处理思路仍然对我们很有启发。比如图像变体功能，就非常适合设计师、产品经理根据原始的理念生成更多创意。</p>
<h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>DALL-E 2使用两个基于扩散模型的上采样模块，相比于不使用扩散模型的超分算法，有哪些优势？（提示：了解超分算法有助于回答这个问题）</p>
<p>欢迎你在留言区和我交流讨论。如果这节课对你有启发，也推荐你分享给身边更多同事、朋友。</p>
</article><div class="tag_share"><div class="post_share"></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#13%EF%BD%9C%E5%89%8D%E6%B5%AADALL-E-2%EF%BC%9A%E5%B8%AE%E4%BD%A0%E9%AD%94%E6%94%B9%E7%BB%8F%E5%85%B8%E7%94%BB%E4%BD%9C"><span class="toc-number">1.</span> <span class="toc-text">13｜前浪DALL-E 2：帮你魔改经典画作</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9D%E8%AF%86DALL-E-2"><span class="toc-number">1.1.</span> <span class="toc-text">初识DALL-E 2</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-number">1.2.</span> <span class="toc-text">工作原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E5%8F%98%E4%BD%93"><span class="toc-number">1.3.</span> <span class="toc-text">图像变体</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B1%80%E9%99%90%E6%80%A7"><span class="toc-number">1.4.</span> <span class="toc-text">局限性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%E6%97%B6%E5%88%BB"><span class="toc-number">1.5.</span> <span class="toc-text">总结时刻</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98"><span class="toc-number">1.6.</span> <span class="toc-text">思考题</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By 码农张三</div></div><script src="https://cdn.bootcdn.net/ajax/libs/mermaid/9.4.0/mermaid.min.js"></script></footer></div><div id="rightside"><div id="rightside-config-hide"></div><div id="rightside-config-show"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div></div></body></html>