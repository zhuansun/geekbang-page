<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>23｜实战项目（五）：做一个类似LensaAI的梦幻照相馆 | geekbang</title><meta name="author" content="码农张三"><meta name="copyright" content="码农张三"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="23｜实战项目（五）：做一个类似LensaAI的梦幻照相馆你好，我是南柯。 第18讲 和 第19讲 我们学习了定制化图像生成的常见方法，初步了解了如何训练LoRA，得到代表内容和风格的定制化模型。经过训练LoRA模型的实战，我们发现训练一个LoRA并不困难，但是想实现LensaAI或者妙鸭相机类似的效果却并不容易。 今天这一讲，我们将目光聚焦到人像生成上，继续探讨使用LoRA进行定制化图像生成的技">
<meta property="og:type" content="article">
<meta property="og:title" content="23｜实战项目（五）：做一个类似LensaAI的梦幻照相馆">
<meta property="og:url" content="https://zhuansun.github.io/geekbang/posts/2792069406.html">
<meta property="og:site_name" content="geekbang">
<meta property="og:description" content="23｜实战项目（五）：做一个类似LensaAI的梦幻照相馆你好，我是南柯。 第18讲 和 第19讲 我们学习了定制化图像生成的常见方法，初步了解了如何训练LoRA，得到代表内容和风格的定制化模型。经过训练LoRA模型的实战，我们发现训练一个LoRA并不困难，但是想实现LensaAI或者妙鸭相机类似的效果却并不容易。 今天这一讲，我们将目光聚焦到人像生成上，继续探讨使用LoRA进行定制化图像生成的技">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg">
<meta property="article:published_time" content="2024-02-29T12:01:07.000Z">
<meta property="article:modified_time" content="2024-03-21T11:10:30.826Z">
<meta property="article:author" content="码农张三">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://zhuansun.github.io/geekbang/posts/2792069406"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":false,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '23｜实战项目（五）：做一个类似LensaAI的梦幻照相馆',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-03-21 11:10:30'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="geekbang" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://pic.imgdb.cn/item/653470a0c458853aef5813f1.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">1343</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">23</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">geekbang</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">23｜实战项目（五）：做一个类似LensaAI的梦幻照相馆</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2024-02-29T12:01:07.000Z" title="发表于 2024-02-29 12:01:07">2024-02-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI%E7%BB%98%E7%94%BB%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/">AI绘画核心技术与实战</a></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="23｜实战项目（五）：做一个类似LensaAI的梦幻照相馆"><a href="#23｜实战项目（五）：做一个类似LensaAI的梦幻照相馆" class="headerlink" title="23｜实战项目（五）：做一个类似LensaAI的梦幻照相馆"></a>23｜实战项目（五）：做一个类似LensaAI的梦幻照相馆</h1><p>你好，我是南柯。</p>
<p><a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/690349">第18讲</a> 和 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/691354">第19讲</a> 我们学习了定制化图像生成的常见方法，初步了解了如何训练LoRA，得到代表内容和风格的定制化模型。经过训练LoRA模型的实战，我们发现训练一个LoRA并不困难，但是想实现LensaAI或者妙鸭相机类似的效果却并不容易。</p>
<p>今天这一讲，我们将目光聚焦到人像生成上，继续探讨使用LoRA进行定制化图像生成的技巧。你可不要小看这些技巧，它们正是很多商业产品惊艳效果下的黑魔法。</p>
<p>通过这一讲的实战，我们的LoRA模型效果也会大为改观。最后，我们会训练出一个能高度还原人像效果的LoRA模型，有了这个模型，你就能实现一个梦幻照相馆的项目。课程讲解里的目标形象我们设置为奥黛丽赫本，当然你也可以使用自己的几张照片或者是宠物的照片来制作你的专属照相馆。</p>
<h2 id="如何做一个梦幻照相馆"><a href="#如何做一个梦幻照相馆" class="headerlink" title="如何做一个梦幻照相馆"></a>如何做一个梦幻照相馆</h2><p>在正式开始实战前，按照惯例，我们需要先准备训练数据，并选好基础模型。</p>
<h3 id="模型和数据"><a href="#模型和数据" class="headerlink" title="模型和数据"></a>模型和数据</h3><p>和上一个实战项目不同，今天我们要做的梦幻照相馆希望呈现出真人风格，我向你推荐一个名为“墨幽人造人”的模型，你可以点开 <a target="_blank" rel="noopener" href="https://civitai.com/models/86232?modelVersionId=143001">Colab</a> 通过图中的方式获取 <a target="_blank" rel="noopener" href="https://civitai.com/api/download/models/143001">下载链接</a>。当然你也可以尝试自己喜欢的其他基础模型。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/1ed0de5e9f11650b96c378b2846ab049.png"></p>
<p>在Colab中，我们可以通过后面这两行代码指定模型的保存路径，并下载模型。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">pretrained_model_name_or_path <span class="token operator">=</span> <span class="token string">"/content/pretrained_model/moyou.safetensors"</span>
!wget <span class="token operator">-</span>c https<span class="token punctuation">:</span><span class="token operator">//</span>civitai<span class="token punctuation">.</span>com<span class="token operator">/</span>api<span class="token operator">/</span>download<span class="token operator">/</span>models<span class="token operator">/</span><span class="token number">143001</span> <span class="token operator">-</span>O $pretrained_model_name_or_path
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>搞定了基础模型，我们再来看训练数据。我准备了10张赫本的图片，你可以通过后面这两行代码拉取数据。你也可以使用自己手中图片来训练模型，5~10张图片即可。为了保证我们能得到理想的效果，训练图片中的人脸需要清晰可辨。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 下载赫本的图片</span>
!wget https<span class="token punctuation">:</span><span class="token operator">//</span>github<span class="token punctuation">.</span>com<span class="token operator">/</span>NightWalker888<span class="token operator">/</span>ai_painting_journey<span class="token operator">/</span>raw<span class="token operator">/</span>main<span class="token operator">/</span>live<span class="token operator">/</span>herburn_images<span class="token punctuation">.</span>tar

<span class="token comment"># 将赫本图片解压到目标训练路径</span>
!tar <span class="token operator">-</span>xvf herburn_images<span class="token punctuation">.</span>tar <span class="token operator">-</span>C <span class="token operator">/</span>content<span class="token operator">/</span>LoRA<span class="token operator">/</span>train_data<span class="token operator">/</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>解压完成后，我们通过后面几行代码实现图片可视化，检查一下图片中的人像是否正面无遮挡。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">pths <span class="token operator">=</span> glob<span class="token punctuation">(</span><span class="token string">r"/content/LoRA/train_data/herburn_images/*"</span><span class="token punctuation">)</span>
imgs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> pth <span class="token keyword">in</span> pths<span class="token punctuation">:</span>
  img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>pth<span class="token punctuation">)</span>
  imgs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>img<span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

image_grid<span class="token punctuation">(</span>imgs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/8309a5744cb51eaf0851097b6f5a137f.png"></p>
<h3 id="解读tags"><a href="#解读tags" class="headerlink" title="解读tags"></a>解读tags</h3><p>在实战项目三( <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/691354">第19讲</a>)，我们已经学习了如何使用BLIP这个模型为每一张图片生成prompt描述。在这一讲的代码部分，我们可以用同样的方法给图片生成prompt描述。</p>
<p>如果使用我们课程中用到的 <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Salesforce/BLIP">BLIP模型</a> 或者 <a target="_blank" rel="noopener" href="https://huggingface.co/docs/transformers/main/model_doc/blip-2">BLIP2模型</a> 生成prompt。我们得到的prompt是一些完整的句子，比如后面这个例子，BLIP打标的结果是 “a picture of the starry night in blue and yellow”。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/bcyyf8ab278027d5b11da2cfb3653c35.png"></p>
<p>其实，除了使用BLIP，我们还有很多其他选择。在一些关于LoRA训练的教程中，我们经常看到关于tags的使用技巧。 <strong>所谓tags，本质上就是我们给图片生成标签式的prompt</strong>。</p>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/hysts/DeepDanbooru">DeepDanbooru</a> 等模型经常用于生成标签式的prompt。你可以点开 <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/hysts/DeepDanbooru">超链接</a>，在截图左侧的相应区域上传图片，然后点击 “run” 按钮，即可得到图片对应的prompt。这里右侧需要选中“text”标签，方便我们复制prompt文本。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/bfa551fd4a73bc417da83d163b3f4f18.png"></p>
<p>这里我说明一下，图中的分数阈值（Score threshold）表示我们对于每个tag的过滤强度。DeepDanBooru模型在预测每一个tag时会同时输出一个置信度，范围是0-1，分数越高越置信。因此在实际使用中，阈值设置越高，得到的tag会越少。这里我们选默认的0.5就行。</p>
<p>仔细观察你会发现，和BLIP模型的打标效果不同，这里我们生成的prompt是一系列标签短语，也就是人们常说的tags。在LoRA的训练中，我们可以对这些tags进一步处理。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/e1b5eb097b8f2f25c59bf3f694856afe.png"></p>
<p>以生成人物的LoRA模型为例，我们可以将tags中的人物外在特征删除，比如黑头发、帽子、耳环等，而保留一些诸如1girl、solo这类通俗的描述词。这是因为，我们利用LoRA想固定的是人物本身的特征，你可以理解成“素颜状态”下的人物，而不是人物的装饰品。</p>
<p>在此基础上，我们还可以给每一个生成的prompt加上我们自定义的关键词，比如<sks>。这样，我们训练的LoRA便可以被1girl、solo、<sks>这样的关键词来触发。</p>
<p>这里我还想提醒一下你，如果使用BLIP系列模型生成prompt，得到的prompt是完整的句子，也就不需要删除特定描述词，否则句子会不通顺。但是，我们仍然可以在句子开头加上<sks>这样的自定义触发词。</p>
<h2 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a>代码实战</h2><p>在代码实战环节，我为你准备了三种不同的训练方式。</p>
<ul>
<li>方式1：使用上个实战篇改造后的Colab代码进行训练。</li>
<li>方式2：使用开源妙鸭相机的NoteBook代码进行训练。</li>
<li>方式3：使用开源妙鸭相机项目的python代码在GPU环境下进行训练。</li>
</ul>
<p>第一种训练方式使用Colab提供的免费T4显卡即可完成，第二种方式需要大约19G的GPU资源，课程中我们使用阿里云NoteBook的免费计算资源，第三种方式需要你拥有一张显存大于19GB的显卡。</p>
<p>如果想做一个人像或者宠物的“梦幻照相馆”，利用免费的Colab资源通过方式1来进行模型训练就可以。如果想要体验“妙鸭相机”的效果，实现出海马体的风格，推荐使用方式2。如果希望用python代码来实现“妙鸭相机”，并做出进一步的算法改进，比如替换基础模型、增加更多人脸美化处理或者部署一个自己的服务，推荐使用方式3。</p>
<p>接下来，我们就具体看看这三种训练方式，要怎么实现。</p>
<h3 id="训练方式1：Colab训练"><a href="#训练方式1：Colab训练" class="headerlink" title="训练方式1：Colab训练"></a>训练方式1：Colab训练</h3><p>首先我们使用第一种方式进行训练。你可以点开 <a target="_blank" rel="noopener" href="https://colab.research.google.com/github/NightWalker888/ai_painting_journey/blob/main/lesson23/LoRA_train_herburn.ipynb">Colab链接</a> 和我一起操作。</p>
<p>为了方便你进行操作，在配置好Colab的GPU环境后，你可以直接点击全部运行，这样就能“一键”完成LoRA的训练。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/d4e208333ee72218df531dfd80yy1abf.png"></p>
<p>耐心等待LoRA训练完成，我们便可以看到LoRA模型的生成效果。我们使用后面的prompt来测试一下得到的LoRA模型。</p>
<pre class="line-numbers language-plain" data-language="plain"><code class="language-plain">Prompt：masterpiece, best quality, 1girl moyou (ink sketch) fantasy, surreal muted color (Russ Mills Anna Dittmann)
Negative Prompt：lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry
随机种子：1024
采样步数：20
分辨率：512x768
CFG Scale: 7
LoRA：hb_pro.safetensors [使用Colab训练]
LoRA weight：1.0
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>我们在prompt中指定了ink sketch这样的风格要求，希望模型帮我们生成赫本的墨水素描照片。你可以点开后面的图看一下我们的LoRA效果。你也可以发挥自己的创造力，生成更多独特的图像。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/4982be1f957068a63ce14e61abdc0215.png"></p>
<p>搞定了LoRA模型的训练，咱们再把它加入到WebUI上试试效果。</p>
<p>我们可以将训练得到的LoRA模型下载到本地，放在WebUI的LoRA文件夹中，然后就可以在WebUI上，直接使用我们刚刚训练的LoRA模型了。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># LoRA模型放置路径为：</span>
/你的WebUI安装路径/extensions/sd-webui-additional-networks/models/lora
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>把模型放到相应位置后，别忘了刷新WebUI的LoRA模型库，加载我们刚刚放置的LoRA模型。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/f7deb9887d498cf38bd8e4ec7feb8f3c.png"></p>
<p>一切准备完毕，我们这就来测试下WebUI的使用效果，使用下面这组prompt即可测试赫本模型。</p>
<pre class="line-numbers language-plain" data-language="plain"><code class="language-plain">Prompt：1girl bubbles fog water long hair Paolo Roversi (best shadow, dramatic lighting) ( masterpiece,realistic, photorealistic) (best quality)
Negative Prompt： (worst quality, greyscale)
采样器：DPM++ SDE Karras
随机种子：603579159
采样步数：20
分辨率：512x768
CFG Scale: 7
LoRA：hb_pro.safetensors [使用Colab训练]
LoRA weight：1.0
超分功能：打开
重绘强度：0.38
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>你可以点开图片查看生成效果。可以看到，配合上人脸修复、图像超分功能，得到的赫本图像还是非常美观的。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/338c9ee2392fa5024fb144ce162e591a.jpg"></p>
<h3 id="训练方式2：开源妙鸭的NoteBook"><a href="#训练方式2：开源妙鸭的NoteBook" class="headerlink" title="训练方式2：开源妙鸭的NoteBook"></a>训练方式2：开源妙鸭的NoteBook</h3><p><a target="_blank" rel="noopener" href="https://github.com/modelscope/facechain">facechain</a> 是阿里达摩院给出的“阉割版妙鸭”相机的代码实现，我们可以通过阅读这份代码了解妙鸭相机的技术思路。</p>
<p>总的来说，“阉割版妙鸭”相机使用一个达摩院提供的基础模型，通过3~10张图进行LoRA模型的训练。在模型训练完成后，使用一系列图像后处理技术提升图像生成的效果。</p>
<p>运行“阉割版妙鸭”的 <a target="_blank" rel="noopener" href="https://github.com/modelscope/facechain/blob/main/facechain_demo.ipynb">NoteBook文件</a> 需要19G左右的显存，使用Colab的同学需要付费后选择A100显卡才能运行。如果想免费体验这个NoteBook功能，可以使用阿里云ModelScope的计算资源，你可以 <a target="_blank" rel="noopener" href="https://modelscope.cn/my/mynotebook/preset">点开链接</a> 进行操作，首次登录需要进行账号注册。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/aeb0aa567f854626a5d31499f5cf35fe.png"></p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/1d703b2f78efe0fcefd1d843c8952852.png"></p>
<p>当我写这一讲时，官方的NoteBook还有一些bug，你可以下载我修正后的jupyter文件，具体方式是在Notebook中新建一个Terminal环境，然后输入后面的指令即可。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/775bfb3f820f36b31dee4b2051eedfbe.png"></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">wget</span> <span class="token parameter variable">-c</span> https://raw.githubusercontent.com/NightWalker888/ai_painting_journey/main/lesson23/facechain_deploy_demo_notebook.ipynb facechain_deploy_demo_notebook.ipynb
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>我们点开下载完成的文件，就可以像Colab一样点击全部执行。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/0fb56f8a69b48d7955df263ee19e4c63.png"></p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/17f16a03efcaedd794aa392de7f450af.png"></p>
<p>运行完NoteBook中全部代码后，你会获得一个url链接。在浏览器中输入这个链接，就可以进入妙鸭相机交互式操作的界面。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/957eca9a19425c524553d0e3803c12ac.png"></p>
<p>然后，我们上传3到10张图片，耐心等待上传完成，便可以点击模型训练。后台运行的代码会自动完成图片的prompt打标、基础模型下载等工作。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/8e7be7a1c0c70ba3ef8387e7f4f88b9c.png"></p>
<p>如果训练过程中，窗口中提示 “Error”，我们需要检查下NoteBook是否在正常运行。如果模型的训练仍在继续，那我们便可以忽略训练面板中的 “Error”，耐心等待NoteBook中的模型训练完成即可。默认的训练步数是图片数x200，比如我们上传5张图，训练步数就是1000步。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/6336f3f81e0676fe2989942e7dd2ee96.png"></p>
<p>大约等待10分钟，就能完成LoRA模型的训练。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/26946c8c2f985024e14051e99859d88b.png"></p>
<p>最后，我们可以使用一个自己的prompt进行模型效果测试。比如我们测试后面文稿中的prompt。具体操作方法可以查看后面图片中的标记。</p>
<pre class="line-numbers language-plain" data-language="plain"><code class="language-plain">prompt：1girl bubbles fog water long hair Paolo Roversi (best shadow, dramatic lighting) ( masterpiece,realistic, photorealistic) (best quality)
风格权重：0.25
生成图像数量：3
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/bd011ba49e8b6b1658355cdd7a140224.png"></p>
<p>图像生成过程中，你可以通过NoteBook查看图像生成的进度。耐心等待大约1分钟便可以完成图像生成，你可以点开图片查看模型的生成效果。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/b52b97a178bb9f8907d45233b3250d1a.png"></p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/ea62c0bdaf89ac0dc2954fyyb9f064e2.png"></p>
<h3 id="训练方式3：妙鸭相机代码训练"><a href="#训练方式3：妙鸭相机代码训练" class="headerlink" title="训练方式3：妙鸭相机代码训练"></a>训练方式3：妙鸭相机代码训练</h3><p>现在我们再来看看如何通过写代码的方式，在你的GPU环境下进行妙鸭相机的训练。这里我们仍旧使用 <a target="_blank" rel="noopener" href="https://github.com/modelscope/facechain">facechain</a> 这个达摩院官方的代码实现。</p>
<p>首先，你需要在你的命令行环境下，将这个代码仓库拉取到本地，并创建一个用来存放训练图片的文件夹路径。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> clone https://github.com/modelscope/facechain.git

<span class="token comment"># 跳转到安装路径</span>
<span class="token builtin class-name">cd</span> facechain

<span class="token comment"># 为了避免由于代码更新引出新的bug，我们使用我测试有效的一次代码提交</span>
<span class="token function">git</span> checkout bd1ff6ffad16e11febd4d319817c70dcc391964d

<span class="token comment"># 创建图像文件夹</span>
<span class="token function">mkdir</span> <span class="token parameter variable">-p</span> images/upload_source
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>然后，我们需要安装运行facechain的运行环境。以Anaconda虚拟环境的使用为例，在你的命令行环境下，需要依次执行后面的指令。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">conda create <span class="token parameter variable">-n</span> facechain <span class="token assign-left variable">python</span><span class="token operator">=</span><span class="token number">3.8</span>    <span class="token comment"># Verified environments: 3.8 and 3.10</span>
conda activate facechain

pip3 <span class="token function">install</span> <span class="token parameter variable">-r</span> requirements.txt
pip3 <span class="token function">install</span> <span class="token parameter variable">-U</span> openmim
mim <span class="token function">install</span> mmcv-full<span class="token operator">==</span><span class="token number">1.7</span>.0
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>然后我们将赫本的图像下载到本地，解压后将其放置到刚刚创建的训练数据文件夹中。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 下载赫本的图片</span>
<span class="token operator">!</span>wget https://github.com/NightWalker888/ai_painting_journey/raw/main/live/herburn_images.tar
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>接下来，我们在facechain路径下创建一个名为image_processing.py的文件，并拷贝后面的代码。这段代码的主要作用是统一上传图片的格式，并使用BLIP2模型生成prompt。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">from</span> glob <span class="token keyword">import</span> glob
<span class="token keyword">from</span> facechain<span class="token punctuation">.</span>train_text_to_image_lora <span class="token keyword">import</span> get_rot<span class="token punctuation">,</span> data_process_fn
<span class="token keyword">from</span> facechain<span class="token punctuation">.</span>inference <span class="token keyword">import</span> data_process_fn

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>

    instance_images <span class="token operator">=</span> glob<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"images/upload_source/*"</span></span><span class="token punctuation">)</span>

    <span class="token comment"># 确保提供3~10张训练图片</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>instance_images<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">raise</span> Exception

    <span class="token comment"># 将图片格式和命名统一</span>
    output_dataset_dir <span class="token operator">=</span> <span class="token string">"images/train_images"</span>
    os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>output_dataset_dir<span class="token punctuation">,</span> exist_ok <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> temp_path <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>instance_images<span class="token punctuation">)</span><span class="token punctuation">:</span>
        image <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>temp_path<span class="token punctuation">)</span>
        image <span class="token operator">=</span> image<span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'RGB'</span><span class="token punctuation">)</span>
        image <span class="token operator">=</span> get_rot<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
        out_path <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">&#123;</span>output_dataset_dir<span class="token punctuation">&#125;</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">&#123;</span>i<span class="token punctuation">:</span><span class="token format-spec">03d</span><span class="token punctuation">&#125;</span></span><span class="token string">.jpg'</span></span>
        image<span class="token punctuation">.</span>save<span class="token punctuation">(</span>out_path<span class="token punctuation">,</span> <span class="token builtin">format</span><span class="token operator">=</span><span class="token string">'JPEG'</span><span class="token punctuation">,</span> quality<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>

    <span class="token comment"># 为图像生成训练用prompt</span>
    data_process_fn<span class="token punctuation">(</span>output_dataset_dir<span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 在Terminal中运行Python代码</span>
python image_processing.py
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>搞定了数据，我们创建一个名为train.sh的文件，并拷贝后面的代码。这段代码的含义是启动模型训练，并指定基础模型、训练数据路径等关键参数。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">export</span> <span class="token assign-left variable">MODEL_NAME</span><span class="token operator">=</span><span class="token string">'ly261666/cv_portrait_model'</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">VERSION</span><span class="token operator">=</span><span class="token string">'v2.0'</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">SUB_PATH</span><span class="token operator">=</span><span class="token string">"film/film"</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">OUTPUT_DATASET_NAME</span><span class="token operator">=</span><span class="token string">"images/train_images"</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">WORK_DIR</span><span class="token operator">=</span><span class="token string">"logs/experiment"</span>

accelerate launch facechain/train_text_to_image_lora.py <span class="token punctuation">\</span>
    <span class="token parameter variable">--pretrained_model_name_or_path</span><span class="token operator">=</span><span class="token variable">$MODEL_NAME</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--revision</span><span class="token operator">=</span><span class="token variable">$VERSION</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--sub_path</span><span class="token operator">=</span><span class="token variable">$SUB_PATH</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--output_dataset_name</span><span class="token operator">=</span><span class="token variable">$OUTPUT_DATASET_NAME</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--caption_column</span><span class="token operator">=</span><span class="token string">"text"</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--resolution</span><span class="token operator">=</span><span class="token number">512</span> <span class="token parameter variable">--random_flip</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--train_batch_size</span><span class="token operator">=</span><span class="token number">1</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--num_train_epochs</span><span class="token operator">=</span><span class="token number">200</span> <span class="token parameter variable">--checkpointing_steps</span><span class="token operator">=</span><span class="token number">5000</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--learning_rate</span><span class="token operator">=</span>1e-04 <span class="token parameter variable">--lr_scheduler</span><span class="token operator">=</span><span class="token string">"cosine"</span> <span class="token parameter variable">--lr_warmup_steps</span><span class="token operator">=</span><span class="token number">0</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--seed</span><span class="token operator">=</span><span class="token number">42</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--output_dir</span><span class="token operator">=</span><span class="token variable">$WORK_DIR</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--lora_r</span><span class="token operator">=</span><span class="token number">32</span> <span class="token parameter variable">--lora_alpha</span><span class="token operator">=</span><span class="token number">32</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--lora_text_encoder_r</span><span class="token operator">=</span><span class="token number">32</span> <span class="token parameter variable">--lora_text_encoder_alpha</span><span class="token operator">=</span><span class="token number">32</span> <span class="token punctuation">\</span>
    <span class="token parameter variable">--mixed_precision</span><span class="token operator">=</span><span class="token string">"no"</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 在Terminal中启动训练任务</span>
<span class="token function">sh</span> train.sh
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>耐心等待10分钟，我们就完成了妙鸭相机模型的训练。细心的你可能已经发现，妙鸭的训练代码就是我们在第19讲中已经学过的 <a target="_blank" rel="noopener" href="https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_lora.py">diffusers的LoRA训练</a> 代码。</p>
<p>接着，我们可以用自己训练好LoRA模型来生成图片，看看效果如何。你可以参考后面的代码完成这一步。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">python run_inference.py
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>你可以点开图片查看我们LoRA模型的生成效果，可以看到，我们的LoRA模型能够为赫本生成“海马体”效果的证件照。你也可以用自己手中的其他图片完成模型的训练和测试。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/cb5ccda05150dea69f676468e2625e06.jpg"></p>
<p>你觉得上面证件照的效果如何呢？其实facechain在生成AI绘画图像后，会做一些图像后处理提升算法效果（具体代码你可以参考后面的截图）。</p>
<p>具体做法就是先分析原始训练图像的质量分，选择一张最高质量的人脸，把它和生成的LoRA图像做人脸融合。这一步有点作弊的成分了，但确实让最终的图像和赫本更相似了。</p>
<p>然后，我们要对融合后的人脸进行姿态矫正和人像风格化。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/b7a701ca00dbe2cb98ced77c774cbec5.png"></p>
<h2 id="总结时刻"><a href="#总结时刻" class="headerlink" title="总结时刻"></a>总结时刻</h2><p>今天我们通过实战的形式完成了自己的梦幻照相馆。</p>
<p>和第19讲不同，我们今天的实战任务是真人形象生成，所以我们选择了一个名为“墨幽人造人”的基础模型。之后我们详细探讨了prompt生成的两种模式：使用BLIP类模型和使用DeepDanbooru类模型。对于后者，我们会得到一系列tags，为了保证LoRA模型的生成能力，我们需要对tags进行针对性删减。</p>
<p>之后我们提供了三种方式来实现我们的梦幻照相馆。具体来说，分别是使用之前实战篇改造后的Colab代码进行训练、使用开源妙鸭相机的NoteBook代码和使用“阉割版妙鸭”相机项目的python代码。我们也将训练的LoRA模型与WebUI结合，验证了梦幻照相馆的生成效果。</p>
<p>此外，经过分析我们发现，“阉割版妙鸭”相机的本质是在diffusers的LoRA训练代码基础上，换了专用基础模型，并增加了人脸融合等图像处理技巧。这对我们的启发是，一款成功的产品背后往往搭配使用了多种技术，即使是有了扩散模型这个大杀器，我们仍旧可以使用人脸融合、美颜算法等后期处理方法，进一步提升我们的产品效果。</p>
<p>建议你课后自己多练习，也可以将自己训练的LoRA模型发布到开源社区，让其他朋友也能参与体验和分享，这样学习效果会更好。</p>
<p>这一讲的重点，你可以点开后面的导图复习回顾。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/b6f883e0c589d2cda625bd7bfdcf5aaa.jpg"></p>
<h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>今天我们的课程实战是以赫本的任务为例设计的。我为你预留了两个实战任务。</p>
<ol>
<li>希望你选择一个课程外的基础模型，选择一个自己的图片、偶像的图片或者宠物的图片，利用现有的计算资源，完成你的LoRA模型训练。</li>
<li>希望你使用标签类prompt生成工具，完成赫本的LoRA训练。在prompt生成时，需要对tags做针对性地删减，也可以增加你的专用激活词。</li>
</ol>
<p>欢迎你在留言区记录自己的收获或者疑问，也推荐你把这一讲分享给身边更多朋友。</p>
</article><div class="tag_share"><div class="post_share"></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#23%EF%BD%9C%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE%EF%BC%88%E4%BA%94%EF%BC%89%EF%BC%9A%E5%81%9A%E4%B8%80%E4%B8%AA%E7%B1%BB%E4%BC%BCLensaAI%E7%9A%84%E6%A2%A6%E5%B9%BB%E7%85%A7%E7%9B%B8%E9%A6%86"><span class="toc-number">1.</span> <span class="toc-text">23｜实战项目（五）：做一个类似LensaAI的梦幻照相馆</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%81%9A%E4%B8%80%E4%B8%AA%E6%A2%A6%E5%B9%BB%E7%85%A7%E7%9B%B8%E9%A6%86"><span class="toc-number">1.1.</span> <span class="toc-text">如何做一个梦幻照相馆</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%95%B0%E6%8D%AE"><span class="toc-number">1.1.1.</span> <span class="toc-text">模型和数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E8%AF%BBtags"><span class="toc-number">1.1.2.</span> <span class="toc-text">解读tags</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98"><span class="toc-number">1.2.</span> <span class="toc-text">代码实战</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%96%B9%E5%BC%8F1%EF%BC%9AColab%E8%AE%AD%E7%BB%83"><span class="toc-number">1.2.1.</span> <span class="toc-text">训练方式1：Colab训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%96%B9%E5%BC%8F2%EF%BC%9A%E5%BC%80%E6%BA%90%E5%A6%99%E9%B8%AD%E7%9A%84NoteBook"><span class="toc-number">1.2.2.</span> <span class="toc-text">训练方式2：开源妙鸭的NoteBook</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%96%B9%E5%BC%8F3%EF%BC%9A%E5%A6%99%E9%B8%AD%E7%9B%B8%E6%9C%BA%E4%BB%A3%E7%A0%81%E8%AE%AD%E7%BB%83"><span class="toc-number">1.2.3.</span> <span class="toc-text">训练方式3：妙鸭相机代码训练</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%E6%97%B6%E5%88%BB"><span class="toc-number">1.3.</span> <span class="toc-text">总结时刻</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98"><span class="toc-number">1.4.</span> <span class="toc-text">思考题</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By 码农张三</div></div><script src="https://cdn.bootcdn.net/ajax/libs/mermaid/9.4.0/mermaid.min.js"></script></footer></div><div id="rightside"><div id="rightside-config-hide"></div><div id="rightside-config-show"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div></div></body></html>