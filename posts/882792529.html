<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>20｜ControlNet：出道即巅峰，构图控制没有对手 | geekbang</title><meta name="author" content="码农张三"><meta name="copyright" content="码农张三"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="20｜ControlNet：出道即巅峰，构图控制没有对手你好，我是南柯。 我们知道Stable Diffusion可以用文本引导图像生成。除了使用prompt这种比较原始的方式，还有没有控制能力更强的方法呢？ 其实早在第2讲，我就留过一个思考题，AI 绘画生成的图像在手部和脸部细节存在瑕疵有哪些解决方式。而我们今天要讲的技术—— ControlNet 就可以解决这个问题，对图像结构做出一定的限制，">
<meta property="og:type" content="article">
<meta property="og:title" content="20｜ControlNet：出道即巅峰，构图控制没有对手">
<meta property="og:url" content="https://zhuansun.github.io/geekbang/posts/882792529.html">
<meta property="og:site_name" content="geekbang">
<meta property="og:description" content="20｜ControlNet：出道即巅峰，构图控制没有对手你好，我是南柯。 我们知道Stable Diffusion可以用文本引导图像生成。除了使用prompt这种比较原始的方式，还有没有控制能力更强的方法呢？ 其实早在第2讲，我就留过一个思考题，AI 绘画生成的图像在手部和脸部细节存在瑕疵有哪些解决方式。而我们今天要讲的技术—— ControlNet 就可以解决这个问题，对图像结构做出一定的限制，">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg">
<meta property="article:published_time" content="2024-02-29T12:01:07.000Z">
<meta property="article:modified_time" content="2024-03-21T11:14:53.297Z">
<meta property="article:author" content="码农张三">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://zhuansun.github.io/geekbang/posts/882792529"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":false,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '20｜ControlNet：出道即巅峰，构图控制没有对手',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-03-21 11:14:53'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="geekbang" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://pic.imgdb.cn/item/653470a0c458853aef5813f1.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">1342</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">23</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">geekbang</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">20｜ControlNet：出道即巅峰，构图控制没有对手</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2024-02-29T12:01:07.000Z" title="发表于 2024-02-29 12:01:07">2024-02-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI%E7%BB%98%E7%94%BB%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/">AI绘画核心技术与实战</a></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="20｜ControlNet：出道即巅峰，构图控制没有对手"><a href="#20｜ControlNet：出道即巅峰，构图控制没有对手" class="headerlink" title="20｜ControlNet：出道即巅峰，构图控制没有对手"></a>20｜ControlNet：出道即巅峰，构图控制没有对手</h1><p>你好，我是南柯。</p>
<p>我们知道Stable Diffusion可以用文本引导图像生成。除了使用prompt这种比较原始的方式，还有没有控制能力更强的方法呢？</p>
<p>其实早在第2讲，我就留过一个思考题，AI 绘画生成的图像在手部和脸部细节存在瑕疵有哪些解决方式。而我们今天要讲的技术—— <a target="_blank" rel="noopener" href="https://github.com/lllyasviel/ControlNet">ControlNet</a> 就可以解决这个问题，对图像结构做出一定的限制，比如手部的关键点信息、五官信息等。</p>
<p>2023年2月，ControlNet这个方法一经提出，便凭借其对于AI绘画效果的控制能力火遍全网。最初的ControlNet主要用于线稿上色、图像风格化、可控姿态的人体生成等任务。如今各路网友脑洞大开，使用ControlNet做出了创意二维码、将文字自然地融入照片等趣味效果。</p>
<p>这一讲，我们一起来探讨ControlNet背后的技术原理和各种应用场景。掌握了ControlNet这个“大杀器”，你对于AI绘画效果的控制能力会上一个台阶，在下个实战篇实现创意AI绘画任务时也会更加得心应手。</p>
<h2 id="初识ControlNet"><a href="#初识ControlNet" class="headerlink" title="初识ControlNet"></a>初识ControlNet</h2><p>如果说prompt是对于AI绘画模型指令级的控制，ControlNet无疑是构图级的控制。为了让你对它建立感性认识，我们先结合一些图片例子，感受一下ControlNet的构图控制能力。</p>
<p>我们首先需要准备一张原始图片，比如一张鹿的照片，我们可以通过图像边缘提取算法获取图像轮廓。把这个轮廓图作为ControlNet的输入，同时使用这样一句prompt “a high-quality, detailed, and professional image”生成图片，便可以得到右侧的四张图片。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/f1489b3757yy7c15dd42d67544a4fa43.png"></p>
<p>这里有两个要点值得我们关注。第一，我们的prompt中并不包括任何描述图像内容的信息，便可以得到四张不同鹿的照片。第二，生成的四张照片都满足我们输入的轮廓限制，并且效果各异。</p>
<p>类似地，我们可以提供建筑的外形线条，通过简单的prompt引导，得到各种风格迥异的建筑效果图。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/7db673697d79900f2b5c110eb837041c.png"></p>
<p>再比如，我们随手画一个草图，比如简单几笔勾勒出乌龟、奶牛和热气球，同样是配合上我们随手写出的prompt，便可以生成精美的图片。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/862958b8bbdbe5953e15183255ae2bf4.png"></p>
<p>事实上，ControlNet可用的控制条件还远不止这些。比如后面这些图，展示的就是使用HED边缘、人体姿态点、图像分割结果作为控制条件，配合上各种不同prompt生成的图像效果。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/1398bf3f48b2ee66cb5836e61f96253b.png"></p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/5db39dyy71e55e5ab4841e659b514fd5.png"></p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/5e5c57115429b47e56750d69a73a60df.png"></p>
<h2 id="ControlNet算法原理"><a href="#ControlNet算法原理" class="headerlink" title="ControlNet算法原理"></a>ControlNet算法原理</h2><p>那么，ControlNet是如何控制生成结果的呢？这就需要我们深入了解它的算法原理了。</p>
<p>因为ControlNet要和SD结合起来使用，所以我们先回顾下SD模型（为了描述方便，我们接下来都用SD来指代Stable Diffusion）的图像生成过程。你可以看后面这张图，VAE编码器输出的潜在表示，经过一个UNet模型结构便可以完成当前时间步t的噪声预测。对于SD1.x系列，输入的潜在表示和预测得到的噪声都是一个64x64x4的向量。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/4acfb9c5a2yy94e5d2ee8b619848a9d7.jpg"></p>
<p>我们 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/683992">第9讲</a> 学过的采样器负责在输入的潜在表示上将我们预测的噪声去除，这样便完成了SD模型的一步去噪。将这个过程重复N次（N是我们的采样步数），我们便可以得到最终潜在表示。这个潜在表示经过VAE解码器，便可以生成一张清晰的图像。</p>
<h3 id="ControlNet的基本结构"><a href="#ControlNet的基本结构" class="headerlink" title="ControlNet的基本结构"></a>ControlNet的基本结构</h3><p>接下来我们看看ControlNet的基本结构。</p>
<p>ControlNet并没有改变SD模型的VAE、CLIP文本编码器和UNet结构，而是在这个方案的基础上多加了一些东西。</p>
<p>后面这张图便是ControlNet的算法原理图，红框中的区域是我们熟悉的SD模型，绿框中的区域便是ControlNet模型。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/cae7ecd9c0ab972792f91285707d9ab7.jpg"></p>
<p>SD部分带有锁的标志表示在ControlNet模型的训练过程中，SD模型的权重不进行更新。为什么要这样做呢？</p>
<p>有两个原因。第一，ControlNet作为一个即插即用的插件，训练过程应该避免影响到SD模型的部分。第二，固定SD权重可以减少一半以上的可学习参数，这么做能节省计算资源。</p>
<p><strong>也就是说，训练ControlNet的前提是，我们手中已经拥有了一个训练完成的SD模型，比如SD1.5这样的预训练模型。ControlNet的训练目标是得到绿框中新增的模型权重</strong>。</p>
<p>那么，为了实现通过条件控制图像生成这一目的，ControlNet这个插件模型该怎么设计呢？</p>
<p>我们需要考虑三个问题。</p>
<ol>
<li>如何设计ControlNet的模型结构。</li>
<li>控制条件该怎么输入。</li>
<li>ControlNet和SD模型之间的信息要如何交互。</li>
</ol>
<p>先来看第一个问题，如何设计ControlNet的模型结构。要回答这个问题，我们还需要再回顾一下前面的ControlNet算法原理图。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/cae7ecd9c0ab972792f91285707d9ab7.jpg"></p>
<p>红框中SD模型部分展示的是我们熟悉的UNet结构，我们能看到，这里的UNet由12个编码器模块、1个中间模块和12个解码器模块构成。Prompt的文本表征和时间步t的编码都直接作用于这些模块。更多细节，你可以复习我们课程的 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/688429">第15讲</a>。</p>
<p>为了能够对齐控制信号和SD特征之间的维度， <strong>ControlNet部分直接拷贝了UNet的12个编码器模块和中间模块的权重，并加入了14个名为零卷积（zero convolution）的层</strong>。需要注意的是，prompt的文本表征和时间步t的编码同样作用于ControlNet部分的UNet编码模块。零卷积的作用我们等会再讨论。</p>
<p>理解了ControlNet的模型结构设计之后，我们再来看第二个问题，ControlNet的控制条件该如何输入。我们知道，SD模型UNet部分的输入是潜在表示，而ControlNet的输入是我们使用的控制条件，比如图像轮廓、手绘线稿等。</p>
<p>潜在表示是经过VAE编码器处理后的特征，分辨率是64x64x4。而ControlNet的输入，比如我们提供的目标轮廓线，通常是512x512这样的图像。这样ControlNet的控制信号和SD模型就不一致了，因此我们 <strong>需要使用一个小型深度学习网络，将512x512维度的控制条件转换为64x64维度的特征</strong>。</p>
<p>之后，我们再来看第三个问题，处理ControlNet和SD模型之间的信息交互。</p>
<p>仔细观察ControlNet的方案图你会发现，ControlNet输入的特征经过一层零卷积层计算后，就会与SD模型输入的潜在表示相加。这样，SD模型便将潜在表示传递给了ControlNet模块。而ControlNet后面13个零卷积层的输出特征，直接和SD模型UNet部分对应的特征相加，这么做是为了将控制条件引入到SD模型。</p>
<p>了解了ControlNet与SD模型的关系，最后我们再来看看零卷积的作用。 <strong>所谓零卷积，就是初始化权重为零的卷积算子</strong>。</p>
<p>之所以要将权重初始化为零，是为了在ControlNet训练的第一步，无论控制条件是什么，经过全零卷积后得到的数值都为零。这样，ControlNet后面13个零卷积层的输出特征也全为零，和SD模型UNet部分对应的特征相加便没有任何效果。</p>
<p>因为原始的SD模型已经在海量数据上充分训练过了，ControlNet使用零卷积在一开始不会对SD产生任何影响，这样一来，引入新的ControlNet权重仍可以最大程度保留SD模型的AI绘画能力。</p>
<p>随着ControlNet模型的训练，这些初始化为零的权重会根据梯度进行更新，逐渐开始发挥对SD模型的控制作用。</p>
<h3 id="训练ControlNet"><a href="#训练ControlNet" class="headerlink" title="训练ControlNet"></a>训练ControlNet</h3><p>搞定了原理，我们再来深入聊一聊该如何训练一个ControlNet。</p>
<p>这个过程可以分为两步。</p>
<p>第一，根据你要使用的控制方法，在你的数据集上生成这些控制条件，比如提取图像边缘轮廓或者提取人体姿态点。</p>
<p>第二，按照标准的SD模型训练流程进行训练， <strong>UNet的输入包括带噪声的潜在表示、时间步t的编码、prompt文本表征和ControlNet的控制信号</strong>。</p>
<p>与常规SD模型的训练不同，UNet的输入多了一个ControlNet的控制信号。值得一提的是，在 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/688429">第15讲</a> 我们已经知道，标准SD训练过程中使用无分类器引导，一般有10%的概率会将训练的prompt设置为空字符串。而ControlNet的训练中，这个概率是50%！</p>
<p>这是为了让SD模型在预测噪声时，有更多信号源自ControlNet的控制信号，而不是prompt文本表征。说到底，还是为了加强控制。</p>
<p>在训练ControlNet时，针对每一种控制条件需要单独完成。这里的控制条件可以是轮廓线（Canny、HED等），也可以是法线、深度图等。所以，在Hugging Face中我们可以找到20余种不同的ControlNet模型权重。下一讲我们会探讨这些权重的使用方式。</p>
<h2 id="ControlNet的持续进化"><a href="#ControlNet的持续进化" class="headerlink" title="ControlNet的持续进化"></a>ControlNet的持续进化</h2><p>前面我们学习了ControlNet1.0的算法效果和技术原理。在两个月之后的2023年4月，ControlNet又推出了1.1版本。1.1和1.0两个版本的设计思路完全相同，不过1.1改进了1.0版本模型的图像生成效果，并推出了几个全新的ControlNet模型。</p>
<p>我精选了其中最有趣的两个新模型，我们一起来看看。</p>
<h3 id="指令级修图"><a href="#指令级修图" class="headerlink" title="指令级修图"></a>指令级修图</h3><p>首先是指令级修图的ControlNet。比如后面这张风景图片，我们希望转换图片里的季节，就可以通过prompt写下“make it winter”。图中的五个冬季效果是使用不同随机种子得到的。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/5c4f25a1024e47143d717de6063185a5.png"></p>
<p>再比如后面这个例子，原始照片是一张人像照，我们可以利用prompt把绿衬衫的男人换成钢铁侠。可以看到，ControlNet保持了原始人像轮廓，生成了钢铁侠的效果。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/97d4f6d005b36478c4993b5c105cbdfb.png"></p>
<p>有了这个功能，我们不用复杂的PS，写个prompt就能修图。但它背后的原理是怎样的呢？</p>
<p>其实也并不复杂，只不过在训练ControlNet的时候使用了 <a target="_blank" rel="noopener" href="https://github.com/timothybrooks/instruct-pix2pix">特殊的成对数据</a>，我们看个例子就明白了。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/1d187d81a9a6feff42b684068f6aeeba.jpeg"></p>
<p>图片中的文本就是训练ControlNet用的prompt，原始图像作为ControlNet的输入条件，而指令修图后的图像作为SD模型的目标输出。更多训练细节你有兴趣的话，可以看看 <a target="_blank" rel="noopener" href="https://github.com/lllyasviel/ControlNet-v1-1-nightly/tree/main#controlnet-11-instruct-pix2pix">这个链接</a>。</p>
<h3 id="Tile功能"><a href="#Tile功能" class="headerlink" title="Tile功能"></a>Tile功能</h3><p>Tile在中文里是瓷砖的意思，字面理解是将图片切分成棋盘格的样式分别处理再拼接。这个功能很强大，因为它可以帮我们补充图像中的细节。</p>
<p>Tile功能对于生成超高分辨率的图片（比如4K图像）非常有用，比如后面这张图片，我们的prompt是“a handsome man”，希望AI绘画模型帮我们补充各种局部细节。如果是使用传统SD模型切块生成再合并，每个切块内都会有一个帅哥，拼接起来的画面自然很鬼畜。</p>
<p>而使用Tile功能时，ControlNet模型的Tile功能会先识别当前切片中的图片内容，如果切片内容和prompt无关，使用Tile功能生成切片内图像的时候就会降低prompt对于生成图像的影响。图片中树叶部分的切片经过Tile功能的处理，就会变得格外清晰。你可以点开后面的图片查看效果。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/9e5d7030264d0b9711d9e8368649cf92.png"></p>
<p>我们再来看一个超分辨率的例子。比如后面这张图，输入图像是一张64x64分辨率的小狗，使用Tile功能配合上“dog on grassland”这个prompt，可以轻松实现图像的8倍超分，得到512x512分辨率的效果。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/1b9888e32bbb3c136667888ddb913493.png"></p>
<p>作为对比，如果选择经典的超分算法Real-ESRGAN，同样是将64x64分辨率超分到512x512，得到的效果是后面这个样子。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/288dd350a060faf34a6214b3fd44a07a.png"></p>
<p>观察图片可以发现，看到超分的效果并不理想。这样的对比也体现了ControlNet Tile功能的优势。</p>
<h2 id="总结时刻"><a href="#总结时刻" class="headerlink" title="总结时刻"></a>总结时刻</h2><p>今天这一讲我们探讨了ControlNet这个强大的AI绘画工具，包括它的算法原理、控图效果和最新能力。</p>
<p>ControlNet模型需要与预训练好的SD模型配合使用。ControlNet拷贝了原始SD模型的12个编码器模块和中间模块权重，并加入了14个零卷积层。在训练过程中，SD的权重保持不动，仅更新ControlNet部分的模型权重。</p>
<p>此外，我们还探讨了全零卷积这种特殊设计背后的思考，以及它如何用于SD模型和ControlNet模型之间的信息传输。</p>
<p>之后，我们详细讨论了ControlNet1.1两个亮眼的能力：指令级修图和Tile功能。有了这两项能力，我们“动动嘴”便可以实现强大的P图和超分功能。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202402/6795b15f052d10f0e4a908d4c4342353.jpg"></p>
<p>了解了ControlNet的基本原理，下一讲我们便会使用Control1.0和1.1，完成各种有趣的实战项目，比如创意二维码生成、图像风格化等，敬请期待！</p>
<h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>这一讲中我们介绍了ControlNet的几种控制条件，比如边缘轮廓、分割图、人体关键点等。你还知道ControlNet有哪些控制条件？这些控制条件我们需要通过怎样的方式获得？</p>
<p>欢迎你在留言区和我交流讨论。如果这一讲对你有启发，也推荐你分享给身边更多同事、朋友。</p>
</article><div class="tag_share"><div class="post_share"></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#20%EF%BD%9CControlNet%EF%BC%9A%E5%87%BA%E9%81%93%E5%8D%B3%E5%B7%85%E5%B3%B0%EF%BC%8C%E6%9E%84%E5%9B%BE%E6%8E%A7%E5%88%B6%E6%B2%A1%E6%9C%89%E5%AF%B9%E6%89%8B"><span class="toc-number">1.</span> <span class="toc-text">20｜ControlNet：出道即巅峰，构图控制没有对手</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9D%E8%AF%86ControlNet"><span class="toc-number">1.1.</span> <span class="toc-text">初识ControlNet</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ControlNet%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86"><span class="toc-number">1.2.</span> <span class="toc-text">ControlNet算法原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ControlNet%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84"><span class="toc-number">1.2.1.</span> <span class="toc-text">ControlNet的基本结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83ControlNet"><span class="toc-number">1.2.2.</span> <span class="toc-text">训练ControlNet</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ControlNet%E7%9A%84%E6%8C%81%E7%BB%AD%E8%BF%9B%E5%8C%96"><span class="toc-number">1.3.</span> <span class="toc-text">ControlNet的持续进化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%87%E4%BB%A4%E7%BA%A7%E4%BF%AE%E5%9B%BE"><span class="toc-number">1.3.1.</span> <span class="toc-text">指令级修图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tile%E5%8A%9F%E8%83%BD"><span class="toc-number">1.3.2.</span> <span class="toc-text">Tile功能</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%E6%97%B6%E5%88%BB"><span class="toc-number">1.4.</span> <span class="toc-text">总结时刻</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98"><span class="toc-number">1.5.</span> <span class="toc-text">思考题</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By 码农张三</div></div><script src="https://cdn.bootcdn.net/ajax/libs/mermaid/9.4.0/mermaid.min.js"></script></footer></div><div id="rightside"><div id="rightside-config-hide"></div><div id="rightside-config-show"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div></div></body></html>