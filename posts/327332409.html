<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>05｜提示工程（下）：用思维链和思维树提升模型思考质量 | geekbang</title><meta name="author" content="码农张三"><meta name="copyright" content="码农张三"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="05｜提示工程（下）：用思维链和思维树提升模型思考质量你好，我是黄佳，欢迎来到LangChain实战课！ 我在 第4课 的结尾时说了，你可以尝试用思维链也就是CoT（Chain of Thought）的概念来引导模型的推理，让模型生成更详实、更完备的文案，今天我们就一起看一看CoT的使用。 什么是 Chain of ThoughtCoT这个概念来源于学术界，是谷歌大脑的Jason Wei等人于20">
<meta property="og:type" content="article">
<meta property="og:title" content="05｜提示工程（下）：用思维链和思维树提升模型思考质量">
<meta property="og:url" content="https://zhuansun.github.io/geekbang/posts/327332409.html">
<meta property="og:site_name" content="geekbang">
<meta property="og:description" content="05｜提示工程（下）：用思维链和思维树提升模型思考质量你好，我是黄佳，欢迎来到LangChain实战课！ 我在 第4课 的结尾时说了，你可以尝试用思维链也就是CoT（Chain of Thought）的概念来引导模型的推理，让模型生成更详实、更完备的文案，今天我们就一起看一看CoT的使用。 什么是 Chain of ThoughtCoT这个概念来源于学术界，是谷歌大脑的Jason Wei等人于20">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg">
<meta property="article:published_time" content="2023-10-20T09:48:40.000Z">
<meta property="article:modified_time" content="2024-03-21T11:07:56.136Z">
<meta property="article:author" content="码农张三">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://zhuansun.github.io/geekbang/posts/327332409"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":false,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '05｜提示工程（下）：用思维链和思维树提升模型思考质量',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-03-21 11:07:56'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="geekbang" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://pic.imgdb.cn/item/653470a0c458853aef5813f1.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">1345</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">23</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">geekbang</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">05｜提示工程（下）：用思维链和思维树提升模型思考质量</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2023-10-20T09:48:40.000Z" title="发表于 2023-10-20 09:48:40">2023-10-20</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/LangChain%E5%AE%9E%E6%88%98%E8%AF%BE/">LangChain实战课</a></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="05｜提示工程（下）：用思维链和思维树提升模型思考质量"><a href="#05｜提示工程（下）：用思维链和思维树提升模型思考质量" class="headerlink" title="05｜提示工程（下）：用思维链和思维树提升模型思考质量"></a>05｜提示工程（下）：用思维链和思维树提升模型思考质量</h1><p>你好，我是黄佳，欢迎来到LangChain实战课！</p>
<p>我在 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/700699">第4课</a> 的结尾时说了，你可以尝试用思维链也就是CoT（Chain of Thought）的概念来引导模型的推理，让模型生成更详实、更完备的文案，今天我们就一起看一看CoT的使用。</p>
<h2 id="什么是-Chain-of-Thought"><a href="#什么是-Chain-of-Thought" class="headerlink" title="什么是 Chain of Thought"></a>什么是 Chain of Thought</h2><p>CoT这个概念来源于学术界，是谷歌大脑的Jason Wei等人于2022年在论文《 <a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</a>（自我一致性提升了语言模型中的思维链推理能力）》中提出来的概念。它提出，如果生成一系列的中间推理步骤，就能够显著提高大型语言模型进行复杂推理的能力。</p>
<h3 id="Few-Shot-CoT"><a href="#Few-Shot-CoT" class="headerlink" title="Few-Shot CoT"></a>Few-Shot CoT</h3><p>Few-Shot CoT 简单的在提示中提供了一些链式思考示例（Chain-of-Thought Prompting），足够大的语言模型的推理能力就能够被增强。简单说，就是给出一两个示例，然后在示例中写清楚推导的过程。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/f27cec109dff8947d85507b34ce240a0.png"></p>
<p>论文中给出了一个大模型通过思维链做数学题的示例。图左和图右，大模型都读入了OneShot示例，但是图左只给出了答案，而图右则在OneShot示例中给出了解题的具体思路。结果，只给出了答案的模型推理错误，而给出解题思路后，同一个模型生成了正确的答案。</p>
<p>在三种大型语言模型的实验中，CoT在一系列的算术、常识和符号推理任务中都提高了性能。在GSM8K数学问题基准测试中，通过CoT指导后，大模型的表现可以达到当时最先进的准确性。</p>
<p>CoT从概念上非常容易理解，从应用上非常容易操作。虽然简单，但这种思想可以给我们的开发过程带来很多启发。</p>
<p>比如，假设我们正在开发一个AI花店助手，它的任务是帮助用户选择他们想要的花，并生成一个销售列表。在这个过程中，我们可以使用CoT来引导AI的推理过程。</p>
<p>👉 整体指导：你需要跟着下面的步骤一步步的推理。</p>
<ol>
<li><p>问题理解：首先，AI需要理解用户的需求。例如，用户可能会说：“今天要参加朋友的生日Party，想送束花祝福她。”我们可以给AI一个提示模板，里面包含示例：“ <em><strong>遇到XX问题，我先看自己有</strong></em> <em><strong>没有</strong></em> _<strong>相关知识，有的话，就提供答案；没有，就调用工具搜索，有了知识后再试图解决。</strong>_”—— 这就是给了AI一个思维链的示例。</p>
</li>
<li><p>信息搜索：接下来，AI需要搜索相关信息。例如，它可能需要查找哪些花最适合生日派对。</p>
</li>
<li><p>决策制定：基于收集到的信息，AI需要制定一个决策。我们可以通过思维链让他详细思考决策的流程，先做什么后做什么。例如，我们可以给它一个示例：“ _<strong>遇到生日派对送花的情况，我先考虑用户的需求，然后查看鲜花的库存，最后决定推荐一些玫瑰和百合，因为这些花通常适合生日派对。</strong>_”—— 那么有了生日派对这个场景做示例，大模型就能把类似的思维流程运用到其它场景。</p>
</li>
<li><p>生成销售列表：最后，AI使用OutputParser生成一个销售列表，包括推荐的花和价格。</p>
</li>
</ol>
<p>在这个过程中，整体上，思维链引导AI从理解问题，到搜索信息，再到制定决策，最后生成销售列表。这种方法不仅使AI的推理过程更加清晰，也使得生成的销售列表更加符合用户的需求。具体到每一个步骤，也可以通过思维链来设计更为详细的提示模板，来引导模型每一步的思考都遵循清晰准确的逻辑。</p>
<p>其实LangChain的核心组件Agent的本质就是进行好的提示工程，并大量地使用预置的FewShot和CoT模板。这个在之后的课程学习中我们会理解得越来越透彻。</p>
<h3 id="Zero-Shot-CoT"><a href="#Zero-Shot-CoT" class="headerlink" title="Zero-Shot CoT"></a>Zero-Shot CoT</h3><p>下面的这两个CoT提示模板的例子，来自于Google Research和东京大学的论文《 <a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf">大语言模型是零样本推理者</a>》。</p>
<p>图中的（d）示例非常非常有意思，在Zero-Shot CoT中，你只要简单地告诉模型“ <strong>让我们一步步的思考（Let’s think step by step）</strong>”，模型就能够给出更好的答案！</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/09a48be47b3e0e9ec0ae7ebd483d868b.png"></p>
<p>哈哈哈，这样太神奇了吧，这不由得让我联想起最简单的提示工程，角色设定——模型回答之前，先告诉它“你是一个很有经验的XX专家”，模型应该就会在开始胡说八道之前三思。</p>
<p>简单总结一下：Few-Shot CoT，指的就是在带有示例的提示过程中，加入思考的步骤，从而引导模型给出更好的结果。而Zero-Shot CoT，就是直接告诉模型要一步一步地思考，慢慢地推理。</p>
<h2 id="Chain-of-Thought-实战"><a href="#Chain-of-Thought-实战" class="headerlink" title="Chain of Thought 实战"></a>Chain of Thought 实战</h2><p>现在，就让我带着你完成一次Chain of Thought的LangChain应用开发实战。</p>
<p><strong>项目需求</strong>：在这个示例中，你正在开发一个AI运营助手，我们要展示AI如何根据用户的需求推理和生成答案。然后，AI根据当前的用户请求进行推理，提供了具体的花卉建议并解释了为什么选择这些建议。</p>
<p>在这个过程中，AI需要理解客户的需求之后，按部就班的思考，然后给出最符合逻辑的回答。</p>
<h3 id="CoT的模板设计"><a href="#CoT的模板设计" class="headerlink" title="CoT的模板设计"></a>CoT的模板设计</h3><p>针对这个聊天机器人的需求，我设计了下面这样的思维链模板。</p>
<blockquote>
<p>作为一个为花店电商公司工作的AI助手，我的目标是帮助客户根据他们的喜好做出明智的决定。</p>
<p>我会按部就班的思考，先理解客户的需求，然后考虑各种鲜花的涵义，最后根据这个需求，给出我的推荐。</p>
<p>同时，我也会向客户解释我这样推荐的原因。</p>
<p><strong>示例 1：</strong></p>
<p>人类：我想找一种象征爱情的花。</p>
<p>AI：首先，我理解你正在寻找一种可以象征爱情的花。在许多文化中，红玫瑰被视为爱情的象征，这是因为它们的红色通常与热情和浓烈的感情联系在一起。因此，考虑到这一点，我会推荐红玫瑰。红玫瑰不仅能够象征爱情，同时也可以传达出强烈的感情，这是你在寻找的。</p>
<p><strong>示例 2：</strong></p>
<p>人类：我想要一些独特和奇特的花。</p>
<p>AI：从你的需求中，我理解你想要的是独一无二和引人注目的花朵。兰花是一种非常独特并且颜色鲜艳的花，它们在世界上的许多地方都被视为奢侈品和美的象征。因此，我建议你考虑兰花。选择兰花可以满足你对独特和奇特的要求，而且，兰花的美丽和它们所代表的力量和奢侈也可能会吸引你。</p>
</blockquote>
<p>AI的模板开始于对其角色的阐述，并给出了一些先前的对话示例（Few-Shot Learning）来帮助AI理解如何处理这种类型的请求。这些示例展示了AI如何根据思维链进行思考，给出深思熟虑之后的答案。</p>
<h3 id="程序的完整框架"><a href="#程序的完整框架" class="headerlink" title="程序的完整框架"></a>程序的完整框架</h3><p>程序的完整代码如下：</p>
<pre class="line-numbers language-plain" data-language="plain"><code class="language-plain"># 设置环境变量和API密钥
import os
os.environ["OPENAI_API_KEY"] = '你的OpenAI API Key'

# 创建聊天模型
from langchain.chat_models import ChatOpenAI
llm = ChatOpenAI(temperature=0)

# 设定 AI 的角色和目标
role_template = "你是一个为花店电商公司工作的AI助手, 你的目标是帮助客户根据他们的喜好做出明智的决定"

# CoT 的关键部分，AI 解释推理过程，并加入一些先前的对话示例（Few-Shot Learning）
cot_template = """
作为一个为花店电商公司工作的AI助手，我的目标是帮助客户根据他们的喜好做出明智的决定。

我会按部就班的思考，先理解客户的需求，然后考虑各种鲜花的涵义，最后根据这个需求，给出我的推荐。
同时，我也会向客户解释我这样推荐的原因。

示例 1:
  人类：我想找一种象征爱情的花。
  AI：首先，我理解你正在寻找一种可以象征爱情的花。在许多文化中，红玫瑰被视为爱情的象征，这是因为它们的红色通常与热情和浓烈的感情联系在一起。因此，考虑到这一点，我会推荐红玫瑰。红玫瑰不仅能够象征爱情，同时也可以传达出强烈的感情，这是你在寻找的。

示例 2:
  人类：我想要一些独特和奇特的花。
  AI：从你的需求中，我理解你想要的是独一无二和引人注目的花朵。兰花是一种非常独特并且颜色鲜艳的花，它们在世界上的许多地方都被视为奢侈品和美的象征。因此，我建议你考虑兰花。选择兰花可以满足你对独特和奇特的要求，而且，兰花的美丽和它们所代表的力量和奢侈也可能会吸引你。
"""
from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate
system_prompt_role = SystemMessagePromptTemplate.from_template(role_template)
system_prompt_cot = SystemMessagePromptTemplate.from_template(cot_template)

# 用户的询问
human_template = "&#123;human_input&#125;"
human_prompt = HumanMessagePromptTemplate.from_template(human_template)

# 将以上所有信息结合为一个聊天提示
chat_prompt = ChatPromptTemplate.from_messages([system_prompt_role, system_prompt_cot, human_prompt])

prompt = chat_prompt.format_prompt(human_input="我想为我的女朋友购买一些花。她喜欢粉色和紫色。你有什么建议吗?").to_messages()

# 接收用户的询问，返回回答结果
response = llm(prompt)
print(response)
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>程序中，首先设置环境变量OpenAI的API密钥，以便能够使用OpenAI的GPT-4模型。然后创建聊天模型：通过调用 ChatOpenAI 类，创建了一个聊天模型。设置 temperature&#x3D;0 可以让模型生成更确定性的回答，即输出更倾向于最可能的结果。</p>
<p>接着定义了AI的角色和目标，该AI为花店电商公司的助手，其目标是根据客户的喜好来提供购买建议。紧接着，定义 CoT 模板，其中包括了AI的角色和目标描述、思考链条以及遵循思考链条的一些示例，显示了AI如何理解问题，并给出建议。</p>
<p>之后，我使用了PromptTemplate的from_template方法，来生成相应的询问模板。其中包括用于指导模型的SystemMessagePromptTemplate和用于传递人类问题的HumanMessagePromptTemplate。</p>
<p>然后，我使用了ChatPromptTemplate.from_messages方法，整合上述定义的角色，CoT模板和用户询问，生成聊天提示。</p>
<p>最后，将生成的聊天提示输入模型中，获得模型的回答，并打印出来。</p>
<p>在Few-Shot CoT提示的指引之下，模型针对我们的问题，从问题中的具体需求出发，返回了不错的建议。</p>
<p><em><strong>现在，根据你的需求：你正在寻找你的女朋友喜欢的粉色和紫色的花。</strong></em></p>
<p><em><strong>首先，我从理解你的需求出发，只会推荐粉色或紫色，或者两者的组合的花。这些可能包括粉色的玫瑰，紫色的兰花，或者是粉色和紫色的花的混合花束。玫瑰是象征爱情和亲情的经典符号，而兰花象征着美丽和力量。这两种花都蕴含很棒的内涵。当然了，无论你选择哪种花卉，重要的是表达出你对她的爱和关心。记得附上一张温馨的贺卡，写下你的真挚祝福。</strong></em></p>
<h2 id="Tree-of-Thought"><a href="#Tree-of-Thought" class="headerlink" title="Tree of Thought"></a>Tree of Thought</h2><p>CoT这种思想，为大模型带来了更好的答案，然而，对于需要探索或预判战略的复杂任务来说，传统或简单的提示技巧是不够的。基于CoT的思想，Yao和Long等人几乎在同一时间在论文《 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2305.10601.pdf">思维之树：使用大型语言模型进行深思熟虑的问题解决</a>》和《 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2305.08291.pdf">大型语言模型指导的思维之树</a>》中，进一步提出了思维树（Tree of Thoughts，ToT）框架，该框架基于思维链提示进行了总结，引导语言模型探索把思维作为中间步骤来解决通用问题。</p>
<p>ToT是一种解决复杂问题的框架，它在需要多步骤推理的任务中，引导语言模型搜索一棵由连贯的语言序列（解决问题的中间步骤）组成的思维树，而不是简单地生成一个答案。ToT框架的核心思想是：让模型生成和评估其思维的能力，并将其与搜索算法（如广度优先搜索和深度优先搜索）结合起来，进行系统性地探索和验证。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/6eec83ffe1a5f37d245520535d65f8a0.png"></p>
<p>ToT 框架为每个任务定义具体的思维步骤和每个步骤的候选项数量。例如，要解决一个数学推理任务，先把它分解为3个思维步骤，并为每个步骤提出多个方案，并保留最优的5个候选方案。然后在多条思维路径中搜寻最优的解决方案。</p>
<p>这种方法的优势在于，模型可以通过观察和评估其自身的思维过程，更好地解决问题，而不仅仅是基于输入生成输出。这对于需要深度推理的复杂任务非常有用。此外，通过引入强化学习、集束搜索等技术，可以进一步提高搜索策略的性能，并让模型在解决新问题或面临未知情况时有更好的表现。</p>
<p>下面我们应用ToT的思想，给出一个鲜花运营方面的示例。</p>
<blockquote>
<p>假设一个顾客在鲜花网站上询问：“我想为我的妻子购买一束鲜花，但我不确定应该选择哪种鲜花。她喜欢淡雅的颜色和花香。”</p>
<p>AI（使用ToT框架）：</p>
<p><strong>思维步骤1</strong>：理解顾客的需求。</p>
<p>顾客想为妻子购买鲜花。</p>
<p>顾客的妻子喜欢淡雅的颜色和花香。</p>
<p><strong>思维步骤2</strong>：考虑可能的鲜花选择。</p>
<p>候选1：百合，因为它有淡雅的颜色和花香。</p>
<p>候选2：玫瑰，选择淡粉色或白色，它们通常有花香。</p>
<p>候选3：紫罗兰，它有淡雅的颜色和花香。</p>
<p>候选4：桔梗，它的颜色淡雅但不一定有花香。</p>
<p>候选5：康乃馨，选择淡色系列，它们有淡雅的花香。</p>
<p><strong>思维步骤3</strong>：根据顾客的需求筛选最佳选择。</p>
<p>百合和紫罗兰都符合顾客的需求，因为它们都有淡雅的颜色和花香。</p>
<p>淡粉色或白色的玫瑰也是一个不错的选择。</p>
<p>桔梗可能不是最佳选择，因为它可能没有花香。</p>
<p>康乃馨是一个可考虑的选择。</p>
<p><strong>思维步骤4</strong>：给出建议。</p>
<p>“考虑到您妻子喜欢淡雅的颜色和花香，我建议您可以选择百合或紫罗兰。淡粉色或白色的玫瑰也是一个很好的选择。希望这些建议能帮助您做出决策！”</p>
</blockquote>
<p>这个例子，可以作为FewShot示例之一，传递给模型，让他学着实现ToT。</p>
<p>通过在具体的步骤中产生多条思考路径，ToT 框架为解决复杂问题提供了一种新的方法，这种方法结合了语言模型的生成能力、搜索算法以及强化学习，以达到更好的效果。</p>
<h2 id="总结时刻"><a href="#总结时刻" class="headerlink" title="总结时刻"></a>总结时刻</h2><p>这节课我们介绍了Chain of Thought（CoT，即“思维链”）和Tree of Thoughts（ToT，即“思维树”）这两个非常有趣的概念，并探讨了如何利用它们引导大型语言模型进行更深入的推理。</p>
<ul>
<li><p>CoT的核心思想是通过生成一系列中间推理步骤来增强模型的推理能力。在Few-Shot CoT和Zero-Shot CoT两种应用方法中，前者通过提供链式思考示例传递给模型，后者则直接告诉模型进行要按部就班的推理。</p>
</li>
<li><p>ToT进一步扩展了CoT的思想，通过搜索由连贯的语言序列组成的思维树来解决复杂问题。我通过一个鲜花选择的实例，展示了如何在实际应用中使用ToT框架。</p>
<p>有朋友在GitHub上开了一个 <a target="_blank" rel="noopener" href="https://github.com/kyegomez/tree-of-thoughts">Repo</a>，专门给大家介绍ToT的应用方法和实例，他们还给出了几个非常简单的通用ToT提示语，就像下面这样。</p>
</li>
</ul>
<blockquote>
<p>请你模拟三位出色、逻辑性强的专家合作回答一个问题。每个人都详细地解释他们的思考过程，考虑到其他人之前的解释，并公开承认错误。在每一步，只要可能，每位专家都会在其他人的思考基础上进行完善和建设，并承认他们的贡献。他们继续，直到对问题有一个明确的答案。为了清晰起见，您的整个回应应该是一个Markdown表格。</p>
<p>问题是…</p>
</blockquote>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/d719e10a2b045f5a70993b6135ef503c.png" alt="图片"></p>
<p>如果你有兴趣，可以去这个Repo里面看一看。</p>
<h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><ol>
<li>我们的CoT实战示例中使用的是Few-Shot CoT提示，请你把它换为Zero-Shot CoT，跑一下程序，看看结果。</li>
<li>请你设计一个你工作场景中的任务需求，然后用ToT让大语言模型帮你解决问题。</li>
</ol>
<p>期待在留言区看到你的分享，我们一起交流探讨，共创一个好的学习氛围。如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。</p>
<h2 id="延伸阅读"><a href="#延伸阅读" class="headerlink" title="延伸阅读"></a>延伸阅读</h2><ol>
<li>论文，自我一致性提升了语言模型中的思维链推理能力， <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2205.11916.pdf">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</a>，Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A., &amp; Zhou, D. (2023). Self-Consistency Improves Chain of Thought Reasoning in Language Models. Proceedings of the International Conference on Learning Representations (ICLR). arXiv preprint arXiv:2203.11171.</li>
<li>论文，大语言模型是零样本推理者， <a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf">Large Language Models are Zero-Shot Reasoners</a>，Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., &amp; Iwasawa, Y. (2023). Large Language Models are Zero-Shot Reasoners. arXiv preprint arXiv:2205.11916v4.</li>
<li>论文，思维之树：使用大型语言模型进行深思熟虑的问题解决， <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.10601">Tree of Thoughts: Deliberate Problem Solving with Large Language Models</a>，Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T. L., Cao, Y., &amp; Narasimhan, K. (2023). Tree of Thoughts: Deliberate Problem Solving with Large Language Models. arXiv preprint arXiv:2305.10601.</li>
<li>论文，大型语言模型指导的思维之树， <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.08291">Large Language Model Guided Tree-of-Thought</a>，Long, J. (2023). Large Language Model Guided Tree-of-Thought. arXiv preprint arXiv:2305.08291.</li>
<li>GitHub链接， <a target="_blank" rel="noopener" href="https://github.com/kyegomez/tree-of-thoughts">tree-of-thoughts</a>，把ToT算法导入你的大模型应用，目前3.3K颗星</li>
</ol>
</article><div class="tag_share"><div class="post_share"></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#05%EF%BD%9C%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%EF%BC%88%E4%B8%8B%EF%BC%89%EF%BC%9A%E7%94%A8%E6%80%9D%E7%BB%B4%E9%93%BE%E5%92%8C%E6%80%9D%E7%BB%B4%E6%A0%91%E6%8F%90%E5%8D%87%E6%A8%A1%E5%9E%8B%E6%80%9D%E8%80%83%E8%B4%A8%E9%87%8F"><span class="toc-number">1.</span> <span class="toc-text">05｜提示工程（下）：用思维链和思维树提升模型思考质量</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF-Chain-of-Thought"><span class="toc-number">1.1.</span> <span class="toc-text">什么是 Chain of Thought</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Few-Shot-CoT"><span class="toc-number">1.1.1.</span> <span class="toc-text">Few-Shot CoT</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Zero-Shot-CoT"><span class="toc-number">1.1.2.</span> <span class="toc-text">Zero-Shot CoT</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Chain-of-Thought-%E5%AE%9E%E6%88%98"><span class="toc-number">1.2.</span> <span class="toc-text">Chain of Thought 实战</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#CoT%E7%9A%84%E6%A8%A1%E6%9D%BF%E8%AE%BE%E8%AE%A1"><span class="toc-number">1.2.1.</span> <span class="toc-text">CoT的模板设计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A8%8B%E5%BA%8F%E7%9A%84%E5%AE%8C%E6%95%B4%E6%A1%86%E6%9E%B6"><span class="toc-number">1.2.2.</span> <span class="toc-text">程序的完整框架</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tree-of-Thought"><span class="toc-number">1.3.</span> <span class="toc-text">Tree of Thought</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%E6%97%B6%E5%88%BB"><span class="toc-number">1.4.</span> <span class="toc-text">总结时刻</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98"><span class="toc-number">1.5.</span> <span class="toc-text">思考题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BB%B6%E4%BC%B8%E9%98%85%E8%AF%BB"><span class="toc-number">1.6.</span> <span class="toc-text">延伸阅读</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By 码农张三</div></div><script src="https://cdn.bootcdn.net/ajax/libs/mermaid/9.4.0/mermaid.min.js"></script></footer></div><div id="rightside"><div id="rightside-config-hide"></div><div id="rightside-config-show"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div></div></body></html>