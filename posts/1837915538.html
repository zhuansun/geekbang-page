<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>122 | 计算机视觉领域的深度学习模型（二）：VGG &amp; GoogleNet | geekbang</title><meta name="author" content="码农张三"><meta name="copyright" content="码农张三"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="122 | 计算机视觉领域的深度学习模型（二）：VGG &amp; GoogleNet在上第一期的分享中，我们通过一篇经典论文讲了AlexNet这个模型。可以说，这篇文章是深度学习在计算机视觉领域发挥作用的奠基之作。 AlexNet在2012年发表之后，研究界对这个模型做了很多改进工作，使得这个模型得到了不断优化，特别是在ImageNet上的表现获得了显著提升。今天我们就来看看针对AlexNet模">
<meta property="og:type" content="article">
<meta property="og:title" content="122 | 计算机视觉领域的深度学习模型（二）：VGG &amp; GoogleNet">
<meta property="og:url" content="https://zhuansun.github.io/geekbang/posts/1837915538.html">
<meta property="og:site_name" content="geekbang">
<meta property="og:description" content="122 | 计算机视觉领域的深度学习模型（二）：VGG &amp; GoogleNet在上第一期的分享中，我们通过一篇经典论文讲了AlexNet这个模型。可以说，这篇文章是深度学习在计算机视觉领域发挥作用的奠基之作。 AlexNet在2012年发表之后，研究界对这个模型做了很多改进工作，使得这个模型得到了不断优化，特别是在ImageNet上的表现获得了显著提升。今天我们就来看看针对AlexNet模">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg">
<meta property="article:published_time" content="2023-10-20T09:48:40.000Z">
<meta property="article:modified_time" content="2024-03-21T11:14:53.181Z">
<meta property="article:author" content="码农张三">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://zhuansun.github.io/geekbang/posts/1837915538"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":false,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '122 | 计算机视觉领域的深度学习模型（二）：VGG & GoogleNet',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-03-21 11:14:53'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="geekbang" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://pic.imgdb.cn/item/653470a0c458853aef5813f1.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">1342</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">23</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">geekbang</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">122 | 计算机视觉领域的深度学习模型（二）：VGG &amp; GoogleNet</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2023-10-20T09:48:40.000Z" title="发表于 2023-10-20 09:48:40">2023-10-20</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI%E6%8A%80%E6%9C%AF%E5%86%85%E5%8F%82/">AI技术内参</a></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="122-计算机视觉领域的深度学习模型（二）：VGG-GoogleNet"><a href="#122-计算机视觉领域的深度学习模型（二）：VGG-GoogleNet" class="headerlink" title="122 | 计算机视觉领域的深度学习模型（二）：VGG &amp; GoogleNet"></a>122 | 计算机视觉领域的深度学习模型（二）：VGG &amp; GoogleNet</h1><p>在上第一期的分享中，我们通过一篇经典论文讲了AlexNet这个模型。可以说，这篇文章是深度学习在计算机视觉领域发挥作用的奠基之作。</p>
<p>AlexNet在2012年发表之后，研究界对这个模型做了很多改进工作，使得这个模型得到了不断优化，特别是在ImageNet上的表现获得了显著提升。今天我们就来看看针对AlexNet模型的两个重要改进，分别是VGG和GoogleNet。</p>
<h2 id="VGG网络"><a href="#VGG网络" class="headerlink" title="VGG网络"></a>VGG网络</h2><p>我们要分享的第一篇论文题目是《用于大规模图像识别的深度卷积网络》（Very Deep Convolutional Networks for Large-Scale Image Recognition）[1]。这篇文章的作者都来自于英国牛津大学的“视觉几何实验室”（Visual Geometry Group），简称VGG，所以文章提出的模型也被叫作 <strong>VGG网络</strong>。到目前为止，这篇论文的引用次数已经多达1万4千次。</p>
<p>首先，我们简单来了解一下这篇论文的作者。</p>
<p>第一作者叫卡伦·西蒙彦（Karen Simonyan），发表论文的时候他在牛津大学计算机系攻读博士学位。之后，西蒙彦加入了谷歌，在DeepMind任职，继续从事深度学习的研究。</p>
<p>第二作者叫安德鲁·兹泽曼（Andrew Zisserman），是牛津大学计算机系的教授，也是计算机视觉领域的学术权威。他曾经三次被授予计算机视觉最高荣誉“马尔奖”（Marr Prize）。</p>
<p>这篇论文的主要贡献是什么呢？一个重要贡献就是研究 <strong>如何把之前的模型（例如AlexNet）加深层次，从而能够拥有更好的模型泛化能力，最终实现更小的分类错误率</strong>。</p>
<p>为了更好地理解这篇文章的贡献，我们来回忆一下AlexNet的架构。AlexNet拥有8层神经网络，分别是5层卷积层和3层全联通层。AlexNet之所以能够有效地进行训练，是因为这个模型利用了“线性整流函数”（ReLu）、数据增强（Data Augmentation）以及Dropout等手段。这些方法让AlexNet能够达到8层。</p>
<p>但是，学术界一直以来都认为，从理论上看，神经网络应该是层数越多，泛化能力越好。而且在理论上，一个8层的神经网络完全可以加到18层或者80层。但是在现实中，梯度消失和过拟合等情况让加深神经网络变得非常困难。在这篇论文中，VGG网络就尝试从AlexNet出发，看能否加入更多的神经网络层数，来达到更好的模型效果。</p>
<p>那VGG是怎么做到加深神经网络层数的呢？总体来说，VGG对卷积层的“过滤器”（Filter）进行了更改，达到了19层的网络结构。从结果上看，和AlexNet相比，VGG在ImageNet上的错误率要降低差不多一半。可以说， <strong>这是第一个真正意义上达到了“深层”的网络结构</strong>。</p>
<p>VGG在“过滤器”上着手更改，那么具体的改变细节究竟有哪些呢？简单来说，就是在卷积层中仅仅使用“3*3”的“接受域”（Receptive Field），使得每一层都非常小。我们可以从整个形象上来理解，认为这是一组非常“瘦”的网络架构。在卷积层之后，是三层全联通层以及最后一层进行分类任务的层。一个细节是，VGG放弃了我们之前介绍的AlexNet中引入的一个叫“局部响应归一化”（Local Response Normalization）的技术，原因是这个技巧并没有真正带来模型效果的提升。</p>
<p>VGG架构在训练上的一个要点是先从一个小的结构开始，我们可以理解为首先训练一个AlexNet，然后利用训练的结果来初始化更深结构的网络。作者们发现采用这种“ <strong>初始训练</strong>”（Pre-Training）的办法要比完全从随机状态初始化模型训练得更加稳定。</p>
<h2 id="GoogleNet"><a href="#GoogleNet" class="headerlink" title="GoogleNet"></a>GoogleNet</h2><p>我们要分享的第二篇论文题目是《更深层的卷积》（Going deeper with convolutions）[2]。因为这篇论文的作者基本都来自于谷歌，所以文章提出的模型有时候又被叫作 <strong>GoogleNet</strong>。这篇论文拥有8千多次的引用数。</p>
<p>GoogleNet不仅和VGG一样在把架构做“深”上下文章，而且在模型的效率上比AlexNet更加优秀。作者们利用了比AlexNet少12倍的参数，在更深的架构上达到了更好的效果。</p>
<p><strong>GoogleNet创新的重点是在网络架构上</strong>。和AlexNet以及VGG都不同的是，GoogleNet的作者们认为更加合适的网络架构不是简单地把相同的卷积层叠加起来，然后再把相同的全联通层叠加。如果我们需要更深的架构，必须从原理上对网络架构有一个不同的理解。作者们认为，网络结构必须走向“稀疏化”（Sparsity），才能够达到更深层次、更高效的目的。</p>
<p>那么，能否直接用稀疏结构来进行网络的架构呢？过去的经验表明，这条路并不那么直观。第一，直接利用稀疏的结构所表达的网络结构效果并不好，第二，这样做就无法利用现代的硬件，特别是GPU的加速功能。现代的GPU之所以能够高效地处理视觉以及其他一系列类似的问题，主要的原因就是 <strong>快速的紧密矩阵运算</strong>。所以，直接使用稀疏结构有一定的挑战。</p>
<p>这篇论文的核心思想就是希望 <strong>用一组“局部的”（Local）紧密结构来逼近理想中的最优的稀疏化结构</strong>，从而能够在计算上达到高效率，同时在理论思想上，能够利用稀疏化结构来达到更深的网络架构。</p>
<p>这种局部模块被作者们称作是 <strong>Inception模块</strong>。什么意思呢？传统上，卷积层都是直接叠加起来的。而这篇论文提出的Inception模块，其实就是让卷积层能够在水平方向上排列起来，然后整个模块再进行垂直方向的叠加。至于水平方向排列多少个卷积层，垂直方向排列多少Inception模块，都是采用经验试错的方式来进行实验的。</p>
<p>这篇论文最终提出的GoogleNet有22层网络结构。如果把所有的平行结构都算上的话，整个网络超过了100层。为了能够在这么深的结构上训练模型，作者们还采用了一种方法，那就是在中间的一些层次中 <strong>插入分类器</strong>。相比之下，我们之前遇到过的网络结构都是在最后一层才有一个分类器。分类器层的特点就是最终的标签信息会在这里被利用，也就是说，分类的准确性，或者说是图片中物体究竟是什么，都会被这个标签信息所涵盖。在中间层加入分类器，其实就是希望标签信息能够正确引导中间层的目标，并且能够让梯度依然有效经过。</p>
<p>在实验中，GoogleNet模型可以说是达到了非常好的效果。在2014年的ImageNet竞赛中，GoogleNet和VGG分列比赛的第一名和第二名。两个模型之间的差距仅有不到1个百分点。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>今天我为你讲了两篇基于深度学习的经典论文，讨论了两个模型VGG和GoogleNet。这两个模型在AlexNet的基础上做了不少的革新。</p>
<p>一起回顾一下要点：第一，VGG模型对卷积层的“过滤器”进行了更改，实现了19层的网络结构，可以说是第一个真正意义上达到了“深层”的网络结构；第二，GoogleNet模型的创新是在网络架构上，利用稀疏化结构达到了更深的网络架构。</p>
<p>最后，给你留一个思考题，总结和比较VGG和GoogleNet这两个模型，我们看到了深度模型研发的一个什么趋势？</p>
<p>欢迎你给我留言，我们一起讨论。</p>
<p><strong>参考文献</strong></p>
<ol>
<li><p>K. Simonyan, A. Zisserman. <strong>Very Deep Convolutional Networks for Large-Scale Image Recognition</strong>. International Conference on Learning Representations, 2015.</p>
</li>
<li><p>C. Szegedy et al. <strong>Going deeper with convolutions</strong>. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Boston, MA, pp. 1-9, 2015.</p>
</li>
</ol>
</article><div class="tag_share"><div class="post_share"></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#122-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E9%A2%86%E5%9F%9F%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9AVGG-GoogleNet"><span class="toc-number">1.</span> <span class="toc-text">122 | 计算机视觉领域的深度学习模型（二）：VGG &amp; GoogleNet</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#VGG%E7%BD%91%E7%BB%9C"><span class="toc-number">1.1.</span> <span class="toc-text">VGG网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GoogleNet"><span class="toc-number">1.2.</span> <span class="toc-text">GoogleNet</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-number">1.3.</span> <span class="toc-text">小结</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By 码农张三</div></div><script src="https://cdn.bootcdn.net/ajax/libs/mermaid/9.4.0/mermaid.min.js"></script></footer></div><div id="rightside"><div id="rightside-config-hide"></div><div id="rightside-config-show"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div></div></body></html>