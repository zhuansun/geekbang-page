<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>18｜流式生成与模型微调，打造极致的对话体验 | geekbang</title><meta name="author" content="码农张三"><meta name="copyright" content="码农张三"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="18｜流式生成与模型微调，打造极致的对话体验你好，我是徐文浩。 在之前介绍llama-index和LangChain的几讲里面，我们学习了如何将大语言模型和你自己的知识库组合到一起来解决问题。这个方法中，我们不需要对我们使用的模型做任何调整，而是通过将我们的数据用Embedding向量索引起来，然后在使用的时候查询索引来解决问题。 不过，其实我们也完全可以利用我们自己的数据，创建一个新的模型来回答">
<meta property="og:type" content="article">
<meta property="og:title" content="18｜流式生成与模型微调，打造极致的对话体验">
<meta property="og:url" content="https://zhuansun.github.io/geekbang/posts/1546945427.html">
<meta property="og:site_name" content="geekbang">
<meta property="og:description" content="18｜流式生成与模型微调，打造极致的对话体验你好，我是徐文浩。 在之前介绍llama-index和LangChain的几讲里面，我们学习了如何将大语言模型和你自己的知识库组合到一起来解决问题。这个方法中，我们不需要对我们使用的模型做任何调整，而是通过将我们的数据用Embedding向量索引起来，然后在使用的时候查询索引来解决问题。 不过，其实我们也完全可以利用我们自己的数据，创建一个新的模型来回答">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg">
<meta property="article:published_time" content="2023-10-20T09:48:40.000Z">
<meta property="article:modified_time" content="2024-03-21T11:10:30.360Z">
<meta property="article:author" content="码农张三">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://zhuansun.github.io/geekbang/posts/1546945427"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":false,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '18｜流式生成与模型微调，打造极致的对话体验',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-03-21 11:10:30'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="geekbang" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://pic.imgdb.cn/item/653470a0c458853aef5813f1.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">1343</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">23</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">geekbang</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">18｜流式生成与模型微调，打造极致的对话体验</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2023-10-20T09:48:40.000Z" title="发表于 2023-10-20 09:48:40">2023-10-20</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E7%BE%8E/">AI大模型之美</a></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="18｜流式生成与模型微调，打造极致的对话体验"><a href="#18｜流式生成与模型微调，打造极致的对话体验" class="headerlink" title="18｜流式生成与模型微调，打造极致的对话体验"></a>18｜流式生成与模型微调，打造极致的对话体验</h1><p>你好，我是徐文浩。</p>
<p>在之前介绍llama-index和LangChain的几讲里面，我们学习了如何将大语言模型和你自己的知识库组合到一起来解决问题。这个方法中，我们不需要对我们使用的模型做任何调整，而是通过将我们的数据用Embedding向量索引起来，然后在使用的时候查询索引来解决问题。</p>
<p>不过，其实我们也完全可以利用我们自己的数据，创建一个新的模型来回答问题。这个方法，就是OpenAI提供的模型微调（Fine-tune）功能。这也是我们要探讨的大语言模型的最后一个主题。</p>
<h2 id="如何进行模型微调？"><a href="#如何进行模型微调？" class="headerlink" title="如何进行模型微调？"></a>如何进行模型微调？</h2><p>模型微调，是因为无论是ChatGPT还是GPT-4都不是全知全能的AI。在很多垂直的领域，它的回答还是常常会出错。其中很大一部分原因，是它也缺少特定领域的训练数据。而如果我们有比较丰富的垂直领域的数据，那么就可以利用这些数据来“微调”一个特别擅长这个垂直领域的模型。在这个模型“微调”完成之后，我们就可以直接向模型提问了。而不用再像之前使用llama-index或者LangChain那样，先通过Embedding来查询相关资料，然后把查找到的资料也一并提交给OpenAI来获得所需要的答案。</p>
<p>OpenAI模型微调的过程，并不复杂。你只需要把数据提供给OpenAI就好了，对应的整个微调的过程是在云端的“黑盒子”里进行的。需要提供的数据格式是一个文本文件，每一行都是一个Prompt，以及对应这个Prompt的Completion接口会生成的内容。</p>
<p>就像下面的示例：</p>
<pre class="line-numbers language-plain" data-language="plain"><code class="language-plain">&#123;"prompt": "&lt;prompt text>", "completion": "&lt;ideal generated text>"&#125;
&#123;"prompt": "&lt;prompt text>", "completion": "&lt;ideal generated text>"&#125;
&#123;"prompt": "&lt;prompt text>", "completion": "&lt;ideal generated text>"&#125;
...
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>模型微调的过程，就是根据输入的内容，在原来的基础模型上训练。这个基础模型，就是我们 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/644790">第 8 讲</a> 介绍过的 Ada、Babbage、Curie和Davinci 其中的一个。每一个示例，都会导致基础模型原有参数发生变化。整个微调过程结束之后，变化后的参数就会被固定下来，变成一个只有你可以使用的新模型。</p>
<p>如果你提供了很多医疗行业的文本内容，那么微调出来的新模型就会拥有更多医疗领域的知识，以及对话的风格。而如果你给的是笑话大全，那么微调出来的模型就更擅长讲笑话。而且要注意，微调之后的模型，不仅有你用来微调的数据的相关知识，原先基础模型里面的绝大部分知识和能力它也还都保留着。</p>
<h2 id="来一个擅长写“历史英雄人物和奥特曼一起打怪兽”的AI"><a href="#来一个擅长写“历史英雄人物和奥特曼一起打怪兽”的AI" class="headerlink" title="来一个擅长写“历史英雄人物和奥特曼一起打怪兽”的AI"></a>来一个擅长写“历史英雄人物和奥特曼一起打怪兽”的AI</h2><p>那今天我们来微调一个什么样的模型呢？我周围有不少朋友家里都有孩子，都特别迷恋奥特曼打怪兽的故事。他们就向我提过一个需求，说能不能利用ChatGPT来做一个专门讲奥特曼打怪兽故事的应用。可以是可以，不过，为了让这个故事既能精彩一点，又有点教育意义，我们就再找一些历史上的英雄人物，赋予他们一些超能力，来和奥特曼一起打怪兽。而对应的故事数据，我们也用ChatGPT的模型来帮我们生成。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os<span class="token punctuation">,</span>openai<span class="token punctuation">,</span>backoff
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

openai<span class="token punctuation">.</span>api_key <span class="token operator">=</span> os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">"OPENAI_API_KEY"</span><span class="token punctuation">)</span>
dynasties<span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'唐'</span><span class="token punctuation">,</span> <span class="token string">'宋'</span><span class="token punctuation">,</span> <span class="token string">'元'</span><span class="token punctuation">,</span> <span class="token string">'明'</span><span class="token punctuation">,</span> <span class="token string">'清'</span><span class="token punctuation">,</span> <span class="token string">'汉'</span><span class="token punctuation">,</span> <span class="token string">'魏'</span><span class="token punctuation">,</span> <span class="token string">'晋'</span><span class="token punctuation">,</span> <span class="token string">'南北朝'</span><span class="token punctuation">]</span>
super_powers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'隐形'</span><span class="token punctuation">,</span> <span class="token string">'飞行'</span><span class="token punctuation">,</span> <span class="token string">'读心术'</span><span class="token punctuation">,</span> <span class="token string">'瞬间移动'</span><span class="token punctuation">,</span> <span class="token string">'不死之身'</span><span class="token punctuation">,</span> <span class="token string">'喷火'</span><span class="token punctuation">]</span>
story_types <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'轻松'</span><span class="token punctuation">,</span> <span class="token string">'努力'</span><span class="token punctuation">,</span> <span class="token string">'艰难'</span><span class="token punctuation">]</span>

<span class="token decorator annotation punctuation">@backoff<span class="token punctuation">.</span>on_exception</span><span class="token punctuation">(</span>backoff<span class="token punctuation">.</span>expo<span class="token punctuation">,</span> openai<span class="token punctuation">.</span>error<span class="token punctuation">.</span>RateLimitError<span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">gpt35</span><span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> max_tokens<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> temperature<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> top_p<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> frequency_penalty<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> presence_penalty<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    response <span class="token operator">=</span> openai<span class="token punctuation">.</span>Completion<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
        engine<span class="token operator">=</span><span class="token string">"text-davinci-003"</span><span class="token punctuation">,</span>
        prompt<span class="token operator">=</span>prompt<span class="token punctuation">,</span>
        max_tokens<span class="token operator">=</span>max_tokens<span class="token punctuation">,</span>
        temperature<span class="token operator">=</span>temperature<span class="token punctuation">,</span>
        top_p<span class="token operator">=</span>top_p<span class="token punctuation">,</span>
        frequency_penalty<span class="token operator">=</span>frequency_penalty<span class="token punctuation">,</span>
        presence_penalty<span class="token operator">=</span>presence_penalty<span class="token punctuation">)</span>
    <span class="token keyword">return</span> response<span class="token punctuation">[</span><span class="token string">"choices"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span>

<span class="token keyword">def</span> <span class="token function">prepare_stories</span><span class="token punctuation">(</span>dynasties<span class="token punctuation">,</span> super_powers<span class="token punctuation">,</span> story_types<span class="token punctuation">,</span> output_file<span class="token operator">=</span><span class="token string">"data/ultraman_stories.csv"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">)</span>
    repeat <span class="token operator">=</span> <span class="token number">3</span>
    <span class="token keyword">for</span> dynasty <span class="token keyword">in</span> dynasties<span class="token punctuation">:</span>
        <span class="token keyword">for</span> super_power <span class="token keyword">in</span> super_powers<span class="token punctuation">:</span>
            <span class="token keyword">for</span> story_type <span class="token keyword">in</span> story_types<span class="token punctuation">:</span>
                   <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>repeat<span class="token punctuation">)</span><span class="token punctuation">:</span>
                        prompt <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"""请你用中文写一段300字的故事，情节跌宕起伏，讲述一位</span><span class="token interpolation"><span class="token punctuation">&#123;</span>dynasty<span class="token punctuation">&#125;</span></span><span class="token string">朝时期的英雄人物，穿越到现代，拥有了</span><span class="token interpolation"><span class="token punctuation">&#123;</span>super_power<span class="token punctuation">&#125;</span></span><span class="token string">这样的超能力，通过</span><span class="token interpolation"><span class="token punctuation">&#123;</span>story_type<span class="token punctuation">&#125;</span></span><span class="token string">的战斗，帮助奥特曼一起打败了怪兽的故事。"""</span></span>
                        story <span class="token operator">=</span> gpt35<span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>
                        row <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">"dynasty"</span><span class="token punctuation">:</span> dynasty<span class="token punctuation">,</span> <span class="token string">"super_power"</span><span class="token punctuation">:</span> super_power<span class="token punctuation">,</span> <span class="token string">"story_type"</span><span class="token punctuation">:</span> story_type<span class="token punctuation">,</span> <span class="token string">"story"</span><span class="token punctuation">:</span> story<span class="token punctuation">&#125;</span>
                        row <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">[</span>row<span class="token punctuation">]</span><span class="token punctuation">)</span>
                        df <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>df<span class="token punctuation">,</span> row<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> ignore_index<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">"data/ultraman_stories.csv"</span><span class="token punctuation">)</span>

prepare_stories<span class="token punctuation">(</span>dynasties<span class="token punctuation">,</span> super_powers<span class="token punctuation">,</span> story_types<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>这部分代码非常简单，我们定义了一系列朝代、超能力和故事的类型。然后通过三重循环，让AI根据这三者的组合来生成一系列故事。这些生成出来的故事，也就构成了我们用来微调模型的训练数据。因为数据量不大，我就直接用CSV把它存下来了。在这个过程中，数据是一条条生成的，比较慢，也比较消耗Token，你可以不用运行，直接拿我运行后生成的结果数据就好。</p>
<p>拿到了这些数据，我们就可以来微调模型了。我们之前已经通过pip安装了OpenAI的包，这里面自带了命令行工具，方便我们把对应的CSV格式的数据转换成微调模型所需要的JSONL格式的文件。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"data/ultraman_stories.csv"</span><span class="token punctuation">)</span>
df<span class="token punctuation">[</span><span class="token string">'sub_prompt'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'dynasty'</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">","</span> <span class="token operator">+</span> df<span class="token punctuation">[</span><span class="token string">'super_power'</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">","</span> <span class="token operator">+</span> df<span class="token punctuation">[</span><span class="token string">'story_type'</span><span class="token punctuation">]</span>
prepared_data <span class="token operator">=</span> df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'sub_prompt'</span><span class="token punctuation">,</span><span class="token string">'story'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
prepared_data<span class="token punctuation">.</span>rename<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">'sub_prompt'</span><span class="token punctuation">:</span><span class="token string">'prompt'</span><span class="token punctuation">,</span> <span class="token string">'story'</span><span class="token punctuation">:</span><span class="token string">'completion'</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
prepared_data<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">'data/prepared_data.csv'</span><span class="token punctuation">,</span>index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token keyword">import</span> subprocess

subprocess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token string">'openai tools fine_tunes.prepare_data --file data/prepared_data.csv --quiet'</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">……
Wrote modified <span class="token builtin">file</span> to `data<span class="token operator">/</span>prepared_data_prepared<span class="token punctuation">.</span>jsonl`
Feel free to take a look!
Now use that <span class="token builtin">file</span> when fine<span class="token operator">-</span>tuning<span class="token punctuation">:</span>
<span class="token operator">></span> openai api fine_tunes<span class="token punctuation">.</span>create <span class="token operator">-</span>t <span class="token string">"data/prepared_data_prepared.jsonl"</span>
After you’ve fine<span class="token operator">-</span>tuned a model<span class="token punctuation">,</span> remember that your prompt has to end <span class="token keyword">with</span> the indicator string ` <span class="token operator">-</span><span class="token operator">></span>` <span class="token keyword">for</span> the model to start generating completions<span class="token punctuation">,</span> rather than continuing <span class="token keyword">with</span> the prompt<span class="token punctuation">.</span> Make sure to include `stop<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"."</span><span class="token punctuation">]</span>` so that the generated texts ends at the expected place<span class="token punctuation">.</span>
Once your model starts training<span class="token punctuation">,</span> it'll approximately take <span class="token number">8.82</span> minutes to train a `curie` model<span class="token punctuation">,</span> <span class="token keyword">and</span> less <span class="token keyword">for</span> `ada` <span class="token keyword">and</span> `babbage`<span class="token punctuation">.</span> Queue will approximately take half an hour per job ahead of you<span class="token punctuation">.</span>

CompletedProcess<span class="token punctuation">(</span>args<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'openai'</span><span class="token punctuation">,</span> <span class="token string">'tools'</span><span class="token punctuation">,</span> <span class="token string">'fine_tunes.prepare_data'</span><span class="token punctuation">,</span> <span class="token string">'--file'</span><span class="token punctuation">,</span> <span class="token string">'data/prepared_data.csv'</span><span class="token punctuation">,</span> <span class="token string">'--quiet'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> returncode<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>上面的代码主要做了两个动作。首先，是对数据做了一些处理，来准备微调。对于微调，我们使用的Prompt不再是一个完整的句子，而是只用了“朝代”+“超能力”+“故事类型”拼接在一起的字符串，中间用逗号隔开。然后把这个字符串和生成的故事，用Prompt和Completion作为列名存储成了一个CSV。</p>
<p>其次，我们通过subprocess调用了命令行里的OpenAI工具，把上面的CSV文件，转化成了一个JSONL格式的文件。从输出的日志里面可以看到，这个文件叫做 data&#x2F;prepared_data_prepared.jsonl。</p>
<p>如果我们打开这个JSONL文件看一眼，是下面这样的。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">&#123;</span><span class="token string">"prompt"</span><span class="token punctuation">:</span><span class="token string">"唐,隐形,轻松 ->"</span><span class="token punctuation">,</span><span class="token string">"completion"</span><span class="token punctuation">:</span><span class="token string">" \n\n一位叫做李明的英雄人物，出生在唐朝时期。他是一个勇敢的将军，在他的一生中，他打败了许多敌人，为自己的国家和人民做出了许多贡献。\n\n一天，李明意外被一道神秘的光束穿越到了现代。他发现自己拥有了超能力，可以隐形，可以飞行，可以发射光束，可以放出火焰，可以穿墙而过等等。\n\n李明发现，在现代，怪兽们正在摧毁地球，他决定和奥特曼一起，用自己的超能力，帮助奥特曼消灭怪兽们。\n\n于是，李明和奥特曼开始了一场艰苦的战斗，他们用自己的超能力，一招一式，击退了怪兽们，最终成功地拯救了地球。\n\n在这场战斗之后，地球上的人们都对李明充满了敬佩，他从此成为了一位英雄，他的事迹也被传颂了很久。李明也因此被永远铭记在人们心中，成为了一位不朽的英雄。."</span><span class="token punctuation">&#125;</span>
<span class="token punctuation">&#123;</span><span class="token string">"prompt"</span><span class="token punctuation">:</span><span class="token string">"唐,隐形,轻松 ->"</span><span class="token punctuation">,</span><span class="token string">"completion"</span><span class="token punctuation">:</span><span class="token string">" \n\n这是一个关于英雄的故事，发生在唐朝时期的中国。一个叫李自成的勇士，他拥有过人的勇气，英勇的行为让他成为当时最受尊敬的人物。\n\n一天，李自成被一道神秘的光芒笼罩住，他突然发现自己似乎穿越时空，来到了现代。他惊讶地发现，自己竟然拥有了一种超能力，可以让自己隐形。\n\n李自成接受了这种超能力，他发现这种能力可以让自己变得更加强大，他决定利用这种能力来帮助人们。\n\n一次，李自成发现有一群怪兽正在破坏城市，他决定和奥特曼一起出动，利用自己的超能力，把怪兽一个个击败，最终成功拯救了城市，令众人欢呼雀跃。\n\n自此，李自成受到了众人的尊敬，他成为了这个城市的英雄，他也把自己的超能力用在了正义的事业上，为人们做出了许多贡献，他也成为了一个英雄。."</span><span class="token punctuation">&#125;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>可以看到，转换后的数据文件，在Prompt的最后，多了一个“-&gt;”符号。而在Completion的开头，多了两个“\n\n”的换行，结尾则是多了一个“.”。这是为了方便我们后续在使用这个模型生成数据的时候，控制生成结果。未来在使用模型的时候，Prompt需要以“-&gt;\n”这个提示符结束，并且将stop设置成“.”。这样，模型就会自然套用我们微调里的模式来生成文本。</p>
<p>有了准备好的数据，我们只要再通过subprocess调用OpenAI的命令行工具，来提交微调的指令就可以了。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">subprocess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token string">'openai api fine_tunes.create --training_file data/prepared_data_prepared.jsonl --model curie --suffix "ultraman"'</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">Upload progress<span class="token punctuation">:</span> <span class="token number">100</span><span class="token operator">%</span><span class="token operator">|</span>██████████<span class="token operator">|</span> 446k<span class="token operator">/</span>446k <span class="token punctuation">[</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token operator">&lt;</span><span class="token number">00</span><span class="token punctuation">:</span><span class="token number">00</span><span class="token punctuation">,</span> 201Mit<span class="token operator">/</span>s<span class="token punctuation">]</span>
Uploaded <span class="token builtin">file</span> <span class="token keyword">from</span> data<span class="token operator">/</span>prepared_data_prepared<span class="token punctuation">.</span>jsonl<span class="token punctuation">:</span> <span class="token builtin">file</span><span class="token operator">-</span>yn0BfnPmgvf7n0sfQzQRbbeE
Created fine<span class="token operator">-</span>tune<span class="token punctuation">:</span> ft<span class="token operator">-</span>3oxkr1zBVB4fJWogJDDjQbr0
Streaming events until fine<span class="token operator">-</span>tuning <span class="token keyword">is</span> complete<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">(</span>Ctrl<span class="token operator">-</span>C will interrupt the stream<span class="token punctuation">,</span> but <span class="token keyword">not</span> cancel the fine<span class="token operator">-</span>tune<span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token number">2023</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">04</span> <span class="token number">10</span><span class="token punctuation">:</span><span class="token number">51</span><span class="token punctuation">:</span><span class="token number">51</span><span class="token punctuation">]</span> Created fine<span class="token operator">-</span>tune<span class="token punctuation">:</span> ft<span class="token operator">-</span>3oxkr1zBVB4fJWogJDDjQbr0

CompletedProcess<span class="token punctuation">(</span>args<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'openai'</span><span class="token punctuation">,</span> <span class="token string">'api'</span><span class="token punctuation">,</span> <span class="token string">'fine_tunes.create'</span><span class="token punctuation">,</span> <span class="token string">'--training_file'</span><span class="token punctuation">,</span> <span class="token string">'data/prepared_data_prepared.jsonl'</span><span class="token punctuation">,</span> <span class="token string">'--model'</span><span class="token punctuation">,</span> <span class="token string">'curie'</span><span class="token punctuation">,</span> <span class="token string">'--suffix'</span><span class="token punctuation">,</span> <span class="token string">'"ultraman"'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> returncode<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>在这个微调的指令里面，我们指定了三个参数，分别是用来训练的数据文件、一个基础模型，以及生成模型的后缀。这里，我们选用了Curie作为基础模型，因为是讲奥特曼的故事，所以模型后缀我给它取了一个ultraman的名字。</p>
<p>我们的数据量不大，所以微调很快，几分钟就能完成。那接下来我们就可以使用这个模型了。我们可以通过下面的fine_tunes.list指令，找出所有我们微调的模型。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">subprocess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token string">'openai api fine_tunes.list'</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">&#123;</span>
  <span class="token string">"data"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
    <span class="token punctuation">&#123;</span>
      <span class="token string">"created_at"</span><span class="token punctuation">:</span> <span class="token number">1680576711</span><span class="token punctuation">,</span>
      <span class="token string">"fine_tuned_model"</span><span class="token punctuation">:</span> <span class="token string">"curie:ft-bothub-ai:ultraman-2023-04-04-03-03-26"</span><span class="token punctuation">,</span>
      <span class="token string">"hyperparams"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span>
        <span class="token string">"batch_size"</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span>
        <span class="token string">"learning_rate_multiplier"</span><span class="token punctuation">:</span> <span class="token number">0.2</span><span class="token punctuation">,</span>
        <span class="token string">"n_epochs"</span><span class="token punctuation">:</span> <span class="token number">4</span><span class="token punctuation">,</span>
        <span class="token string">"prompt_loss_weight"</span><span class="token punctuation">:</span> <span class="token number">0.01</span>
      <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
      <span class="token string">"id"</span><span class="token punctuation">:</span> <span class="token string">"ft-3oxkr1zBVB4fJWogJDDjQbr0"</span><span class="token punctuation">,</span>
      <span class="token string">"model"</span><span class="token punctuation">:</span> <span class="token string">"curie"</span><span class="token punctuation">,</span>
      <span class="token string">"object"</span><span class="token punctuation">:</span> <span class="token string">"fine-tune"</span><span class="token punctuation">,</span>
      <span class="token string">"organization_id"</span><span class="token punctuation">:</span> <span class="token string">"YOUR_ORGANIZATION_ID"</span><span class="token punctuation">,</span>
      <span class="token string">"result_files"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
        <span class="token punctuation">&#123;</span>
          <span class="token string">"bytes"</span><span class="token punctuation">:</span> <span class="token number">107785</span><span class="token punctuation">,</span>
          <span class="token string">"created_at"</span><span class="token punctuation">:</span> <span class="token number">1680577408</span><span class="token punctuation">,</span>
          <span class="token string">"filename"</span><span class="token punctuation">:</span> <span class="token string">"compiled_results.csv"</span><span class="token punctuation">,</span>
          <span class="token string">"id"</span><span class="token punctuation">:</span> <span class="token string">"RESULT_FILE_ID"</span><span class="token punctuation">,</span>
          <span class="token string">"object"</span><span class="token punctuation">:</span> <span class="token string">"file"</span><span class="token punctuation">,</span>
          <span class="token string">"purpose"</span><span class="token punctuation">:</span> <span class="token string">"fine-tune-results"</span><span class="token punctuation">,</span>
          <span class="token string">"status"</span><span class="token punctuation">:</span> <span class="token string">"processed"</span><span class="token punctuation">,</span>
          <span class="token string">"status_details"</span><span class="token punctuation">:</span> null
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    <span class="token punctuation">&#125;</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token string">"object"</span><span class="token punctuation">:</span> <span class="token string">"list"</span>
<span class="token punctuation">&#125;</span>
CompletedProcess<span class="token punctuation">(</span>args<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'openai'</span><span class="token punctuation">,</span> <span class="token string">'api'</span><span class="token punctuation">,</span> <span class="token string">'fine_tunes.list'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> returncode<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>在输出的JSON里面，你可以看到我们有一个fine_tuned_model字段，里面的值叫做“curie:ft-bothub-ai:ultraman-2023-04-04-03-03-26”，这个就是刚刚让OpenAI给我们微调完的模型。</p>
<p>这个模型的使用方法，和我们使用text-davinci-003之类的模型是一样的，只要在API里面把对应的model字段换掉就好了，对应的代码我也放在了下面。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> openai

openai<span class="token punctuation">.</span>api_key <span class="token operator">=</span> os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">"OPENAI_API_KEY"</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">write_a_story</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span><span class="token punctuation">:</span>
    response <span class="token operator">=</span> openai<span class="token punctuation">.</span>Completion<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
        model<span class="token operator">=</span><span class="token string">"curie:ft-bothub-ai:ultraman-2023-04-04-03-03-26"</span><span class="token punctuation">,</span>
        prompt<span class="token operator">=</span>prompt<span class="token punctuation">,</span>
        temperature<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">,</span>
        max_tokens<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">,</span>
        top_p<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
        stop<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"."</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> response<span class="token punctuation">[</span><span class="token string">"choices"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span>

story <span class="token operator">=</span> write_a_story<span class="token punctuation">(</span><span class="token string">"宋,发射激光,艰难 ->\n"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>story<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">宋朝时期，有一位叫林先生的英雄人物，他勇敢而又坚韧，曾经拯救过无数的人民，他的英勇表现让他赢得了众多的尊敬。
一天，林先生突然发现自己穿越到了现代，他发现自己拥有了一种神奇的超能力，可以发射激光，他开始研究自己的能力，发现自己可以用激光来攻击敌人。
林先生决定把自己的能力用来拯救人类，于是他和奥特曼一起出发，开始与怪兽作战。他们一路走来，林先生用他的激光来打击怪兽，奥特曼则用他的武器来打击怪兽。
在一场艰苦的战斗中，林先生和奥特曼终于击败了怪兽，拯救了人类。林先生也因此获得了无数的赞誉，他也成为了一位传奇英雄。
林先生的故事被传唱了几百年，他的英勇事迹也成为了一个永恒的传奇，让人们永远不忘。
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>对应在调用模型的时候，我们使用的提示语就是“朝代”+“超能力”+“故事类型”，并且跟着“-&gt;\n”，而stop则是设置成了“.”。</p>
<p>因为这是一个微调的模型，它不仅拥有我们训练数据提供的知识，也包括基础模型里的各种信息。所以我们使用的朝代、超能力和故事类型也可以是在之前微调数据里面没有出现过的。比如，上面的例子里，我们使用的超能力叫做“发射激光”，并不是我们拿来微调的数据里面有的一种超能力。你可以试试看，使用别的朝代、故事的类型，效果会是怎么样的。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">story <span class="token operator">=</span> write_a_story<span class="token punctuation">(</span><span class="token string">"秦,龙卷风,辛苦 ->\n"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>story<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">
曾经有一位叫苏轼的英雄人物，他曾经英勇地抵抗过许多强大的敌人，拯救了许多被危险封印的百姓。他曾经在一次战争中发挥过自己的作用，赢得了许多胜利，被尊为英雄。
然而，苏轼却在一次激烈的战斗中牺牲了，他的灵魂被封印在一个古老的石头里，隔着一层玻璃，一直沉睡了几百年。
苏轼的灵魂在穿越时空，来到了现代，他发现自己拥有了一种超能力，这就是龙卷风，他可以使自己的身体具有超强的力量，甚至可以抵抗恶魔的攻击。
苏轼在现代的世界里，发现了一种可怕的怪兽，它们正在摧毁着人类的家园，苏轼决定要拯救这个世界，于是他和奥特曼一起出发，开始了一场史诗般的战斗。
在苏轼和奥特曼的帮助下，苏轼利用自己的超能力，一次次击退怪兽的攻击，最终他们成功地打败了怪兽，拯救了人类。
苏轼的事迹在这里传唱了很久，他成为了一位永恒的英雄，他的故事也被传唱了下来，让人们永远不会忘记他的英勇事迹。
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="模型微调的成本考量"><a href="#模型微调的成本考量" class="headerlink" title="模型微调的成本考量"></a>模型微调的成本考量</h2><p>细心的人可能注意到了，我们这里选用的基础模型是Curie，而不是效果最好的Davinci。之所以做出这样的选择，是出于成本的考虑。</p>
<p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/22d5be5879b0284b7cc6807a1e005fb6.png"></p>
<p>注：数据来源于 <a target="_blank" rel="noopener" href="https://openai.com/pricing#language-models">https://openai.com/pricing#language-models</a></p>
<p><strong>使用微调模型的成本要远远高于使用OpenAI内置的模型。</strong> 以Davinci为基础微调的模型，使用的时候，每1000个Token的成本是0.12美元，是使用内置的text-davinci-003的6倍，是我们最常用的 gpt-3.5-turbo 的60倍。所以，如果只是一般的讲故事的应用，这个成本实在是太高了。就算是我们选择基于Curie微调，1000个Token的使用成本也在0.012美元，虽然比text-davinci-003要便宜，但也是gpt-3.5-turbo的6倍。</p>
<p>对于模型微调的效果，我们也可以通过一个OpenAI提供的命令fine_tunes.results来看。对应的，我们需要提供给它一个微调任务的id。这个id，可以在fine_tunes.list列出的fine_tunes模型的id参数里找到。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">subprocess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token string">'openai api fine_tunes.results -i ft-3oxkr1zBVB4fJWogJDDjQbr0'</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">step<span class="token punctuation">,</span>elapsed_tokens<span class="token punctuation">,</span>elapsed_examples<span class="token punctuation">,</span>training_loss<span class="token punctuation">,</span>training_sequence_accuracy<span class="token punctuation">,</span>training_token_accuracy
<span class="token number">1</span><span class="token punctuation">,</span><span class="token number">625</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0.8805545861742778</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.75</span>
<span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1258</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0.8059815050491868</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.7766830870279147</span>
<span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1859</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">0.7964038042175758</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.7862068965517242</span>
<span class="token number">4</span><span class="token punctuation">,</span><span class="token number">2548</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">0.805052303553852</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.7774436090225564</span>
<span class="token number">5</span><span class="token punctuation">,</span><span class="token number">3197</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">0.7503930440556053</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.7808</span>
<span class="token number">6</span><span class="token punctuation">,</span><span class="token number">3846</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">0.7992317049403261</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.7770700636942676</span>
<span class="token number">7</span><span class="token punctuation">,</span><span class="token number">4775</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">0.6649006477473822</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.7927232635060639</span>
<span class="token number">8</span><span class="token punctuation">,</span><span class="token number">5432</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">0.6493354803676822</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.8049921996879875</span>
<span class="token number">9</span><span class="token punctuation">,</span><span class="token number">6265</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">0.6568901059838095</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.802937576499388</span>
<span class="token number">10</span><span class="token punctuation">,</span><span class="token number">7122</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">0.6578856167468091</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.8100358422939068</span>
<span class="token number">11</span><span class="token punctuation">,</span><span class="token number">7827</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">0.5687322367928961</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.8279411764705882</span>
<span class="token number">12</span><span class="token punctuation">,</span><span class="token number">8404</span><span class="token punctuation">,</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">0.6334827334911788</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.8172043010752689</span>
<span class="token number">13</span><span class="token punctuation">,</span><span class="token number">9061</span><span class="token punctuation">,</span><span class="token number">13</span><span class="token punctuation">,</span><span class="token number">0.5771709139683721</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.825</span>
<span class="token number">14</span><span class="token punctuation">,</span><span class="token number">9822</span><span class="token punctuation">,</span><span class="token number">14</span><span class="token punctuation">,</span><span class="token number">0.6079089517825593</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.8100407055630936</span>
<span class="token number">15</span><span class="token punctuation">,</span><span class="token number">10399</span><span class="token punctuation">,</span><span class="token number">15</span><span class="token punctuation">,</span><span class="token number">0.6481047367374327</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.8154121863799283</span>
<span class="token number">16</span><span class="token punctuation">,</span><span class="token number">11208</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">0.5528688982071029</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.8352490421455939</span>
<span class="token number">17</span><span class="token punctuation">,</span><span class="token number">11913</span><span class="token punctuation">,</span><span class="token number">17</span><span class="token punctuation">,</span><span class="token number">0.6525803676480848</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.8093841642228738</span>
<span class="token number">18</span><span class="token punctuation">,</span><span class="token number">12546</span><span class="token punctuation">,</span><span class="token number">18</span><span class="token punctuation">,</span><span class="token number">0.5230526420679229</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.8363047001620746</span>
<span class="token number">19</span><span class="token punctuation">,</span><span class="token number">13163</span><span class="token punctuation">,</span><span class="token number">19</span><span class="token punctuation">,</span><span class="token number">0.6065665546680247</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.8236272878535774</span>
<span class="token number">20</span><span class="token punctuation">,</span><span class="token number">13796</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">0.5983224045073889</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.8199672667757774</span>
<span class="token number">21</span><span class="token punctuation">,</span><span class="token number">14549</span><span class="token punctuation">,</span><span class="token number">21</span><span class="token punctuation">,</span><span class="token number">0.6440337136896056</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.8267394270122783</span>
<span class="token number">22</span><span class="token punctuation">,</span><span class="token number">15190</span><span class="token punctuation">,</span><span class="token number">22</span><span class="token punctuation">,</span><span class="token number">0.6029605409912032</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.8110749185667753</span>
<span class="token number">23</span><span class="token punctuation">,</span><span class="token number">15759</span><span class="token punctuation">,</span><span class="token number">23</span><span class="token punctuation">,</span><span class="token number">0.5089513997451476</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.838475499092559</span>
<span class="token number">24</span><span class="token punctuation">,</span><span class="token number">16440</span><span class="token punctuation">,</span><span class="token number">24</span><span class="token punctuation">,</span><span class="token number">0.557213810807506</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.8265460030165912</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token number">1855</span><span class="token punctuation">,</span><span class="token number">1228711</span><span class="token punctuation">,</span><span class="token number">1855</span><span class="token punctuation">,</span><span class="token number">0.2610049068084409</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.9219765929778934</span>
<span class="token number">1856</span><span class="token punctuation">,</span><span class="token number">1229312</span><span class="token punctuation">,</span><span class="token number">1856</span><span class="token punctuation">,</span><span class="token number">0.21196416716076574</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.9312714776632303</span>
<span class="token number">1857</span><span class="token punctuation">,</span><span class="token number">1229945</span><span class="token punctuation">,</span><span class="token number">1857</span><span class="token punctuation">,</span><span class="token number">0.14050147435694596</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.9556650246305419</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>在这个命令的输出结果里，你可以在第二列elapsed_tokens看到训练消耗的Token数量。而最后一列 training_token_accuracy，则代表微调后的模型，成功预测微调的数据里下一个Token的准确率。在我们使用的这个例子里面，可以看到一开始准确率只有75%，但是随着训练数据迭代轮数的增加，准确率越来越高，达到了95%以上。</p>
<h2 id="增量训练，不断优化模型"><a href="#增量训练，不断优化模型" class="headerlink" title="增量训练，不断优化模型"></a>增量训练，不断优化模型</h2><p>微调模型比较高昂的价格，限制了它的使用。 <strong>不过，微调模型还有一个能力，就是我们可以在已经微调了的模型上根据新数据做进一步地微调。</strong> 这个在很多垂直领域是非常有用，比如在医学、金融这样的领域，我们就可以不断收集新的数据，不断在前一个微调模型的基础之上继续微调我们的模型，让模型的效果越来越好。而这些领域往往也能承受更高一些的成本。</p>
<p>进一步地微调其实操作起来并不复杂，就是再准备一些数据，以之前已经微调好的模型为基础模型来操作就好了。</p>
<p>生成一些额外的数据：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">dynasties<span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'秦'</span><span class="token punctuation">,</span> <span class="token string">'五代'</span><span class="token punctuation">,</span> <span class="token string">'隋'</span><span class="token punctuation">]</span>
super_powers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'龙卷风'</span><span class="token punctuation">,</span> <span class="token string">'冰冻大海'</span><span class="token punctuation">,</span> <span class="token string">'流星火雨'</span><span class="token punctuation">]</span>
story_types <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'轻松'</span><span class="token punctuation">,</span> <span class="token string">'努力'</span><span class="token punctuation">,</span> <span class="token string">'艰难'</span><span class="token punctuation">,</span> <span class="token string">'勇敢'</span><span class="token punctuation">,</span> <span class="token string">'辛苦'</span><span class="token punctuation">]</span>

new_stories <span class="token operator">=</span> <span class="token string">"data/ultraman_stories_more.csv"</span>
prepare_stories<span class="token punctuation">(</span>dynasties<span class="token punctuation">,</span> super_powers<span class="token punctuation">,</span> story_types<span class="token punctuation">,</span> repeat<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> output_file<span class="token operator">=</span>new_stories<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>转换数据：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>new_stories<span class="token punctuation">)</span>
df<span class="token punctuation">[</span><span class="token string">'sub_prompt'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'dynasty'</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">","</span> <span class="token operator">+</span> df<span class="token punctuation">[</span><span class="token string">'super_power'</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">","</span> <span class="token operator">+</span> df<span class="token punctuation">[</span><span class="token string">'story_type'</span><span class="token punctuation">]</span>
prepared_data <span class="token operator">=</span> df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'sub_prompt'</span><span class="token punctuation">,</span><span class="token string">'story'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
prepared_data<span class="token punctuation">.</span>rename<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">&#123;</span><span class="token string">'sub_prompt'</span><span class="token punctuation">:</span><span class="token string">'prompt'</span><span class="token punctuation">,</span> <span class="token string">'story'</span><span class="token punctuation">:</span><span class="token string">'completion'</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
new_stories_prepared <span class="token operator">=</span> <span class="token string">'data/prepared_data_more.csv'</span>
prepared_data<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>new_stories_prepared<span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

subprocess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token string">'openai tools fine_tunes.prepare_data --file data/prepared_data_more.csv --quiet'</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>继续微调：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">subprocess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token string">'openai api fine_tunes.create --training_file data/prepared_data_more_prepared.jsonl --model curie:ft-bothub-ai:ultraman-2023-04-04-03-03-26 --suffix "ultraman" --learning_rate_multiplier 0.2'</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>在原有的模型上微调的时候，我们要修改两个参数。</p>
<ol>
<li>第一个是model参数，我们把Curie换成了我们刚才微调之后的模型 <strong>curie:ft-bothub-ai:ultraman-2023-04-04-03-03-26</strong>。</li>
<li>第二个是learning_rate_multiplier，这个参数的默认值是根据你的样本数量在0.05 到 0.2 不等。如果你继续微调的样本数要比之前微调的数据量小很多，你就可以调得大一点。</li>
</ol>
<p>微调更新之后，模型的名称没有变，老的模型就被更新成了微调后的新模型，我们再来试一下这个新模型。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">fine_tuned <span class="token operator">=</span> write_a_story<span class="token punctuation">(</span><span class="token string">"五代,流星火雨,艰难 ->\n"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>fine_tuned<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">这是一个发生在一个古老的世界，一个叫做“六代”的世界。这个世界有着一种叫做“超能力”的特性，可以让人穿越时空，穿越到现代。
一位叫做“英雄”的人物，他来自于六代，但他拥有了一种叫做“流星火雨”的超能力，他可以把自己的身体变成一个火焰，然后穿越时空，来到现代。
他来到现代，发现这个世界变得越来越危险，有一种叫做“怪兽”的存在，他们想要毁灭这个世界。英雄决定帮助奥特曼一起打败怪兽，于是他们开始了一场激烈的战斗。
英雄凭借着自己的超能力，以及奥特曼的力量，战胜了怪兽，拯救了这个世界。最后，英雄又一次穿越回六代，这次他拥有了一种叫做“流星火雨”的超能力，他可以把自己的身体变成一个火焰，然后穿越时空，拯救又一次六代。
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="流式生成"><a href="#流式生成" class="headerlink" title="流式生成"></a>流式生成</h2><p>通过模型微调，我们拥有了一个可以讲故事的AI模型。不过，故事生成的体验稍微有点差。它不像是我们在ChatGPT的Web界面里那样一个词一个词地蹦出来，就像一个真人在给你讲故事那样。不过要做到这一点也并不难，因为OpenAI的Completion接口是提供了这样返回结果的模式的，你只需要把代码小小地修改一下就好了。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">write_a_story_by_stream</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span><span class="token punctuation">:</span>
    response <span class="token operator">=</span> openai<span class="token punctuation">.</span>Completion<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
        model<span class="token operator">=</span><span class="token string">"curie:ft-bothub-ai:ultraman-2023-04-04-03-03-26"</span><span class="token punctuation">,</span>
        prompt<span class="token operator">=</span>prompt<span class="token punctuation">,</span>
        temperature<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">,</span>
        max_tokens<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">,</span>
        stream<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        top_p<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
        stop<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"."</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> response

response <span class="token operator">=</span> write_a_story_by_stream<span class="token punctuation">(</span><span class="token string">"汉,冰冻大海,艰难 ->\n"</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> event <span class="token keyword">in</span> response<span class="token punctuation">:</span>
    event_text <span class="token operator">=</span> event<span class="token punctuation">[</span><span class="token string">'choices'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'text'</span><span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>event_text<span class="token punctuation">,</span> end <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>输出结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">一位叫李英的汉朝时期的英雄人物，穿越到了现代，拥有了一种超能力，可以把自己的身体冰冻到极限，他发现自己可以拥有超越情感的力量，可以把任何人都冻僵，他也发现自己可以控制全局，可以控制时间，可以控制物质，可以控制情景，他发现自己可以控制一切，他变得更加强大。
李英发现，地球正面临着一个叫做怪兽的强大敌人的威胁，他决定去帮助奥特曼一起打败怪兽。于是，他和奥特曼一起开始了一系列的战斗，他们一起抵抗着怪兽的攻击，最终，他们成功地消灭了怪兽，拯救了地球。
李英受到了所有人的赞赏，他也成为了一个英雄，他的事迹被传颂了几百年，他的故事也被记录在历史书中，他也成为了一个永恒的传奇。
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>我们在调用Completion接口的时候，启用了stream&#x3D;True这个参数。然后对于返回结果，我们不再是直接拿到整个response然后打印出来。而是拿到一个可以通过迭代器访问的一系列events，每一个event都包含了一部分新生成的文本。你试着运行一下这段代码，就能体验到AI把一个个词吐给你，好像真的在实时讲故事一样的感觉了。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>好了，今天的课程到这里也就结束了。这一讲里，我们一起学习了OpenAI大语言模型里的最后两个功能。</p>
<p>第一个是模型微调，模型微调给我们提供了一个非常实用的能力， <strong>我们可以利用自己的数据，在OpenAI的基础模型上，调整模型参数生成一个新模型</strong>。这样我们就能够根据自己专有的垂直领域的数据，来生产一个专属于我们自己的模型。而且，我们可以根据新收集到的数据，不断在这个模型上继续微调迭代。不过，微调后的模型使用成本比较高，你需要自己核算一下，究竟是微调模型ROI比较高，还是使用前面的外部知识库的方式更划算一些。</p>
<p>在模型微调之外，我们还了解了OpenAI接口上的一个小功能，也就是 <strong>流式地数据生成</strong>。通过开启流式地文本生成，我们可以交付给用户更好的交互体验。特别是在使用比较慢的模型，比如GPT-4，或者生成的文本很长的时候，效果特别明显。用户不需要等上几十秒才能看到结果。</p>
<p>那到这里，整个课程的大语言模型部分我们也就介绍完了。从最基本的两个API，Completion和Embedding开始，我为你介绍了各种各样的应用场景和使用方法。可以看到，现在的大语言模型几乎是“万能”的。下可以拿来做机器学习的输入数据，上可以直接让它自己决定调用什么API，怎么解决用户的问题。相信看到这里的你，已经掌握如何使用大语言模型了，接下来就要多想想在你的实际工作里如何把它用起来了。</p>
<h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>这是大语言模型部分的最后一讲，所以我就多给你留一些练习题。</p>
<ol>
<li>在这一讲生成数据的时候，我们一条条去生成故事特别慢，而且每个组合的故事都要生成三条，特别消耗Token。你想想这部分的代码，如何根据之前学到的内容优化一下呢？</li>
<li>你能不能尝试通过流式处理，做一个讲故事的小应用？并且在界面上，用户能够看到故事真的是一个词儿一个词儿地蹦出来的。</li>
<li>OpenAI的模型微调，其实还有很多更丰富的用法，比如可以拿来做分类，或者命名实体的提取。你可以去官网的 <a target="_blank" rel="noopener" href="https://platform.openai.com/docs/guides/fine-tuning/specific-guidelines">Specific Guidelines</a> 部分看一看，来试着微调一个模型，根据电商商品页的属性信息来写商品的详情描述。</li>
</ol>
<p>欢迎你把你实现这个功能的方法，以及最后的效果体验分享到评论区，也欢迎你把这一讲分享给感兴趣的朋友，我们下一讲再见。</p>
<h2 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h2><p>OpenAI在自己的 <a target="_blank" rel="noopener" href="https://platform.openai.com/docs/guides/fine-tuning/weights-biases">官方文档</a> 里，推荐了通过 Weight &amp; Bias 这个公司的产品，来追踪微调后的模型的实验、模型与数据集。Weight &amp; Bias 也在自己的 <a target="_blank" rel="noopener" href="https://docs.wandb.ai/guides/integrations/openai?utm_source=wandb_docs&utm_medium=code&utm_campaign=OpenAI+API">文档</a> 里，提供了一个对WIT数据集进行模型微调的 <a target="_blank" rel="noopener" href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/openai/Fine_tune_GPT_3_with_Weights_%26_Biases.ipynb#scrollTo=Qnxnp5uZZQOi">Notebook</a>，你有兴趣的话也可以去看一下。</p>
</article><div class="tag_share"><div class="post_share"></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#18%EF%BD%9C%E6%B5%81%E5%BC%8F%E7%94%9F%E6%88%90%E4%B8%8E%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%EF%BC%8C%E6%89%93%E9%80%A0%E6%9E%81%E8%87%B4%E7%9A%84%E5%AF%B9%E8%AF%9D%E4%BD%93%E9%AA%8C"><span class="toc-number">1.</span> <span class="toc-text">18｜流式生成与模型微调，打造极致的对话体验</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%EF%BC%9F"><span class="toc-number">1.1.</span> <span class="toc-text">如何进行模型微调？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9D%A5%E4%B8%80%E4%B8%AA%E6%93%85%E9%95%BF%E5%86%99%E2%80%9C%E5%8E%86%E5%8F%B2%E8%8B%B1%E9%9B%84%E4%BA%BA%E7%89%A9%E5%92%8C%E5%A5%A5%E7%89%B9%E6%9B%BC%E4%B8%80%E8%B5%B7%E6%89%93%E6%80%AA%E5%85%BD%E2%80%9D%E7%9A%84AI"><span class="toc-number">1.2.</span> <span class="toc-text">来一个擅长写“历史英雄人物和奥特曼一起打怪兽”的AI</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E7%9A%84%E6%88%90%E6%9C%AC%E8%80%83%E9%87%8F"><span class="toc-number">1.3.</span> <span class="toc-text">模型微调的成本考量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A2%9E%E9%87%8F%E8%AE%AD%E7%BB%83%EF%BC%8C%E4%B8%8D%E6%96%AD%E4%BC%98%E5%8C%96%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.4.</span> <span class="toc-text">增量训练，不断优化模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B5%81%E5%BC%8F%E7%94%9F%E6%88%90"><span class="toc-number">1.5.</span> <span class="toc-text">流式生成</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-number">1.6.</span> <span class="toc-text">小结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98"><span class="toc-number">1.7.</span> <span class="toc-text">思考题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A8%E8%8D%90%E9%98%85%E8%AF%BB"><span class="toc-number">1.8.</span> <span class="toc-text">推荐阅读</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://s2.loli.net/2023/10/21/vq13okXnTbxDG2R.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By 码农张三</div></div><script src="https://cdn.bootcdn.net/ajax/libs/mermaid/9.4.0/mermaid.min.js"></script></footer></div><div id="rightside"><div id="rightside-config-hide"></div><div id="rightside-config-show"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div></div></body></html>