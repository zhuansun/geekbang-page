[{"title":"加餐丨拜占庭将军问题：如何基于签名消息实现作战计划的一致性？","url":"/posts/1924459455.html","content":"\n你好，我是韩健。\n\n现在，课程更新了一大半，我也一直关注着留言区的问题，我发现很多同学还是对一些知识有一些误区，再三考虑之后，决定利用今天这节课，先解决留言区提到的一个比较多的问题：如何基于签名消息实现作战计划的一致性？\n\n**除此之外，在论文学习中，很多同学遇到的共性问题比较多（比如 ZAB 协议的细节，后面我会补充几讲），在这里，我十分感谢你提出了这样宝贵的意见，不同的声音会帮助我不断优化课程。**\n\n所以，在课程结束之后，我会再从头梳理一遍，按照关注点通过更多的加餐不断优化内容，把相关的理论和算法的内容展开，帮你彻底吃透相关的内容。\n\n说回咱们的拜占庭将军问题。在01 讲中，为了不啰嗦，让你举一反三地学习，我对签名消息型拜占庭问题之解，没有详细展开，而是聚焦在最核心的点“签名约束了叛徒的作恶行为”，但从留言来看，很多同学在理解签名和如何实现作战一致性上，还是遇到了问题。比如不理解如何实现作战计划的一致性。\n\n另外，考虑到签名消息是一些常用的拜占庭容错算法（比如 PBFT）的实现基础，很重要，所以这节课我会对签名消息型拜占庭问题之解进行补充。在今天的内容中，除了具体讲解如何基于签名消息实现作战计划的一致性之外，我还会说一说什么是签名消息。希望在帮你掌握签名消息型拜占庭问题之解的同时，还帮你吃透相关的基础知识。\n\n在这里，我想强调一下，为了更好地理解这一讲的内容，我建议你先回顾一下 01 讲，加深印象。当然，在学完 01 讲之后，相信你已经明白了，签名消息拜占庭问题之解，之所以能够容忍任意数量的叛徒，关键就在于通过消息的签名，约束了叛徒的作恶行为，也就是说，任何篡改和伪造忠将的消息的行为，都会被发现。\n\n既然签名消息这么重要，那么什么是签名消息呢？\n\n## 什么是签名消息？\n\n签名消息指的就是带有数字签名的消息，你可以这么理解“数字签名”：类似在纸质合同上进行签名来确认合同内容和证明身份。\n\n在这里我想说的是，数字签名既可以证实内容的完整性，又可以确认内容的来源，实现不可抵赖性（Non-Repudiation）。既然签名消息优点那么多，**那么如何实现签名消息呢？**\n\n你应该还记得密码学的学术 CP（Bob 和 Alice）吧（不记得的话也没关系，你把他们当作 2 个人就可以了），今天 Bob 要给 Alice 发送一个消息，告诉她，“我已经到北京了”，但是 Bob 希望这个消息能被 Alice 完整地接收到，内容不能被篡改或者伪造，我们一起帮 Bob 和 Alice 想想办法，看看如何实现这个消息。\n\n首先，为了避免密钥泄露，我们推荐 Bob 和 Alice 使用非对称加密算法（比如 RSA）。也就是说，加密和解密使用不同的秘钥，在这里，Bob 持有需要安全保管的私钥，Alice 持有公开的公钥。\n\n然后，Bob 用哈希算法（比如 MD5）对消息进行摘要，然后用私钥对摘要进行加密，生成数字签名（Signature），就像下图的样子：\n\n![image-20230927223005903](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927223005903.png)\n\n\n\n接着，Bob 将加密摘要和消息一起发送给 Alice：\n\n\n\n![image-20230927223015748](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927223015748.png)\n\n\n\n接下来，当 Alice 接收到消息和加密摘要（Signature）后，她会用自己的公钥对加密摘要（Signature）进行解密，并对消息内容进行摘要（Degist-2），然后将新获取的摘要（Degist-2）和解密后的摘要（Degist-1）进行对比，如果 2 个摘要（Digest-1 和 Digest-2）一致，就说明消息是来自 Bob 的，并且是完整的，就像下图的样子：\n\n\n\n![image-20230927223025858](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927223025858.png)\n\n\n\n你看，通过这种方法，Bob 的消息就能被 Alice 完整接收到了，任何篡改和伪造 Bob 消息的行为，都会因为摘要不一致，而被发现。**而这个消息就是签名消息。**\n\n现在，你应该理解了什么是签名消息了吧？另外，关于在留言区提到的“为什么签名消息能约束叛将们的作恶行为？”，在这里，我再补充下，通过上面的 Bob 和 Alice 的故事，我们可以看到，在数字签名的约束下，叛将们是无法篡改和伪造忠将的消息的，因为任何篡改和伪造消息的行为都会被发现，也就是作恶的行为被约束了。也就是说，叛将这时能做“小”恶（比如，不响应消息，或者叛将们相互串通发送指定的消息）但他们无法篡改或伪造忠将的消息了。\n\n既然数字签名约束了叛将们的作恶行为，那么苏秦怎么做才能实现作战的一致性的呢？也就是忠将们执行一致的作战计划。\n\n## 如何实现作战计划的一致性？\n\n之前我已经提到了，苏秦可以通过签名消息的方式，不仅能在不增加将军人数的情况下，解决二忠一叛的难题，还能实现无论叛将数多少，忠诚的将军们始终能达成一致的作战计划。\n\n为了方便你理解，我以二忠二叛（更复杂的叛徒作恶模型，因为叛徒们可以相互勾结串通）为例具体演示一下，是怎样实现作战计划的一致性的：\n\n\n\n![image-20230927223038471](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927223038471.png)\n\n\n\n需要你注意的是，4 位将军约定了一些流程来发送作战信息、执行作战指令。\n\n**第一轮：**\n\n先发送作战指令的将军，作为指挥官，其他的将军作为副官。\n\n指挥官将他的签名的作战指令发送给每位副官。\n\n每位副官，将从指挥官处收到的新的作战指令（也就与之前收的作战指令不同），按照顺序（比如按照首字母字典排序）放到一个盒子里。\n\n**第二轮：**\n\n除了第一轮的指挥官外，剩余的 3 位将军将分别作为指挥官，在上一轮收到的作战指令上，加上自己的签名，并转发给其他将军。\n\n**第三轮：**\n\n除了第一、二轮的指挥官外，剩余的 2 位将军将分别作为指挥官，在上一轮收到的作战指令上，加上自己的签名，并转发给其他将军。\n\n最后，各位将军按照约定，比如使用盒子里最中间的那个指令来执行作战指令。（假设盒子中的指令为 A、B、C，那中间的指令也就是第 n /2 个命令。其中，n 为盒子里的指令数，指令从 0 开始编号，也就是 B）。\n\n为了帮你直观地理解，如何基于签名消息实现忠将们作战计划的一致性，我来演示一下作战信息协商过程。**而且我会分别以忠将和叛将先发送作战信息为例来演示，**这样可以完整地演示叛将对作战计划干扰破坏的可能性。\n\n那么忠诚的将军先发送作战信息的情况是什么呢？\n\n为了演示方便，假设苏秦先发起带有签名的作战信息，作战指令是“进攻”。那么在第一轮作战信息协商中，苏秦向齐、楚、燕发送作战指令“进攻”。\n\n![image-20230927223052727](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927223052727.png)\n\n\n\n在第二轮作战信息协商中，齐、楚、燕分别作为指挥官，向另外 2 位发送作战信息“进攻”。可是楚、燕已经叛变了，**但在签名的约束下，他们无法篡改和伪造忠将的消息，**为了达到干扰作战计划的目的，他们俩一个选择发送消息，一个默不作声，不配合。\n\n\n\n![image-20230927223102672](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927223102672.png)\n\n\n\n在第三轮作战信息协商中，齐、楚分别作为指挥官，将接收到的作战信息，附加上自己的签名，并转发给另外一位（这时的叛徒燕，还是默不作声，不配合）。\n\n\n\n![image-20230927223111367](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927223111367.png)\n\n\n\n最终，齐收到的作战信息都是“进攻”（它收到了苏秦和楚的），按照“执行盒子最中间的指令”的约定，齐会和苏秦一起执行作战指令“进攻”，实现忠将们作战计划的一致性。\n\n那么如果是叛徒楚先发送作战信息，干扰作战计划，结果会有所不同吗？我们来具体看一看。在第一轮作战信息协商中，楚向苏秦发送作战指令“进攻”，向齐、燕发送作战指令“撤退”。（当然还有其他的情况，这里只是选择了其中一种，其他的情况，你可以都推导着试试，看看结果是不是一样？）\n\n\n\n![image-20230927223119526](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927223119526.png)\n\n\n\n然后，在第二轮作战信息协商中，苏秦、齐、燕分别作为指挥官，将接收到的作战信息，附加上自己的签名，并转发给另外两位。\n\n![image-20230927223127998](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927223127998.png)\n\n\n\n**为了达到干扰作战计划的目的，叛徒楚和燕相互勾结了。**比如，燕拿到了楚的私钥，也就是燕可以伪造楚的签名，这个时候，燕为了干扰作战计划，给苏秦发送作战指令“进攻”，给齐发送作战指令却是“撤退”。\n\n接着，在第三轮作战信息协商中，苏秦、齐、燕分别作为指挥官，将接收到的作战信息，附加上自己的签名，并转发给另外一位。\n\n\n\n![image-20230927223136827](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927223136827.png)\n\n\n\n最终，苏秦和齐收到的作战信息都是“撤退、进攻”，按照“执行盒子最中间的指令”的约定，苏秦、齐和燕一起执行作战指令“撤退”，实现了作战计划的一致性。也就是说，无论叛将楚和燕如何捣乱，苏秦和齐都能执行一致的作战计划，保证作战的胜利。\n\n另外在这里，我想补充一点，签名消息的拜占庭问题之解，也是需要进行 m+1 轮（其中 m 为叛将数，所以你看，只有楚、燕是叛变的，那么就进行了三轮协商）。你也可以从另外一个角度理解：n 位将军，能容忍 (n - 2) 位叛将（只有一位忠将没有意义，因为此时不需要达成共识了）。**关于这个公式，你只需要记住就好了，推导过程你可以参考论文。**\n\n最后，我想说的是，签名消息型拜占庭问题之解，解决的是忠将们如何就作战计划达成共识的问题，也就只要忠将们执行了一致的作战计划就可以了。但它不关心这个共识是什么，比如，在适合进攻的时候，忠将们可能执行的作战计划是撤退。也就是，这个算法比较理论化。\n\n关于理论化这一点，有的同学会想知道它如何去用，在我看来呢，这个算法解决的是共识的问题，没有与实际场景结合，是很难在实际场景中落地的。在实际场景中，你可以考虑后来的改进过后的拜占庭容错算法，比如 PBFT 算法。\n\n## 内容小结\n\n本节课我主要带你了解了什么签名消息，以及忠将们如何通过签名消息实现作战的一致性，我希望你明确这样几个重点：\n\n1. 数字签名是基于非对称加密算法（比如 RSA、DSA、DH）实现的，它能防止消息的内容被篡改和消息被伪造。\n2. 签名消息约束了叛徒的作恶行为，比如，叛徒可以不响应，可以相互勾结串通，但叛徒无法篡改和伪造忠将的消息。\n3. 需要你注意的是，签名消息拜占庭问题之解，虽然实现了忠将们作战计划的一致性，但它不关心达成共识的结果是什么。\n\n最后，我想说的是，签名消息、拜占庭将军问题的签名消息之解是非常经典的基础知识，影响和启发了后来的众多拜占庭容错算法（比如 PBFT），理解了本讲的内容后，你能更好地理解其他的拜占庭容错算法，以及它们如何改进的？为什么要这么改进？比如，在 PBFT 中，基于性能的考虑，大部分场景的消息采用消息认证码（MAC），只有在视图变更（View Change）等少数场景中采用了数字签名。\n\n## 课堂思考\n\n我演示了在“二忠二叛”情况下，忠将们如何实现作战计划的一致性，那么你不妨推演下，在“二忠一叛”情况下，忠将们如何实现作战计划的一致性呢？欢迎在留言区分享你的看法，与我一同讨论。\n\n最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。\n\n\n\n---\n\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/215640\" > </iframe>","categories":["分布式协议与算法实战"]},{"title":"结束语丨静下心来，享受技术的乐趣","url":"/posts/1734230882.html","content":"\n\n\n你好，我是韩健。\n\n一晃几个月的时间就过去了，这段日子里，我们一起在课程里沟通交流，与我而言，这是一段很特别的经历。我看到很多同学凌晨还在学习、留言，留言区里经常会看到熟悉的身影，比如约书亚、唔多志、每天晒白牙、小晏子，很感谢你们一直保持着学习的热情。\n\n就要说再见了，借今天这个机会，我想跟你唠点儿心里话。我问自己，如果只说一句话会是啥？想来想去，我觉得就是它了：**静下心来，享受技术的乐趣。**其实这与我之前的经历有关，我想你也能从我的经历中，看到你自己的影子。\n\n我们都有这样的感觉，无论任何事情，如果想把它做好，其实都不容易。我记得自己在开发 InfluxDB 系统期间，为了确保进度不失控，常常睡在公司，加班加点；在写稿期间，为了交付更高质量的课程，我总是会有很多想法，偶尔会通宵写稿，核对每句话、每个细节；再比如，为了解答 kernel_distribution 同学的一个关于外部 PPT 的问题，我通过 Google 找到相关代码的出处，然后反复推敲，在凌晨 4 点准备了一个答案。\n\n当然，技术的学习就更加不容易了，不是读几遍材料、调调代码就可以了，而是需要我们设计检测模型，来验证自己是否准确地理解了技术。我曾见过一些团队，做技术决策的依据是不成立的，设计和开发的系统，尽管迭代多版，也始终稳定不下来。在我看来，这些团队最大的问题，就是对技术的理解不准、不够。\n\n在我看来，我们需要调整下心态，也就是静下心来，全身心地投入，去体会技术的乐趣，“Hack it and enjoy it!”。然后学习和工作中的小成就，又会不断地给我们正反馈，激励我们，最终可以行云流水般地把事情越做越好。\n\n具体到我们课程的主题，也就是分布式技术，该怎么继续精进呢？我们都知道，分布式技术属于新技术，仍在快速发展（比如 Raft 在 2013 年才提出），没有体系化的学习材料，而且知识碎片，学习起来尤为不易。今天我想再补充几点个人看法。\n\n**首先是“杨不悔”。**也就是我们要“衣带渐宽终不悔，为伊消得人憔悴”。想想你在大学的时候，是不是很执着呢？学习分布式技术，也需要这么个劲头儿。\n\n**其次是“张无忌”。**也就是我们要“不唯书不唯上只唯实”。理论是为了解决问题的，而不是为了“正确”，理论也是在实战中不断发展的，所以在日常学习和使用技术时，我们要注意妥协，没有十全十美的技术，我们需要根据场景特点，权衡折中使用技术，并且实战也会进一步加深我们对技术的理解。\n\n**最后是“师夷长技以制夷”。**也就是我们要科学上网，多阅读英文资料。\n\n另外，有些同学可能刚刚接触分布式系统和分布式技术，我对你的建议是“单点突破，再全面开花”。比如，你可以反复研究 20 讲的分布式 KV 系统，然后研究 Raft 算法，最后再去研究其他分布式算法，循序渐进地学习。\n\n为了帮助你更好地学习，掌握“渔”的技巧。在这里，我推荐一些适合入门和深究的学习材料（当然材料不能太多，太多了，相当于没推荐）。\n\n迭戈·安加罗（Diego Ongaro）的博士论文：安加罗的博士论文，对 Raft 算法做了很详细的描述，我建议你反复读，结合源码（比如 Hashicorp Raft）读，直到读懂每一句话。\n\n《Paxos Made Live》：这是 Google 团队的 Paxos 实践总结，我建议你从工程实践的角度去阅读，多想想如果是你，你会怎么做。\n\n《Eventually Consistent》：了解下沃纳·威格尔（亚马逊 CTO）对一致性的理解和定义。\n\n说到这里，我还想强调一点，希望能在后续的工作和学习中帮到你。那就是，“技术要具有成本优势”。什么意思呢？\n\n基于开源软件，我们很容易“堆砌”一套业务需要的功能。基于大型互联网后台（比如 QQ）的架构理念，我们能支撑极其海量的服务和流量。也就是说，实现功能或支撑海量流量，相关的软件和理念，都已经很成熟，不是挑战了，但功能背后的成本问题突出。\n\n而成本就是钱，功能背后的成本问题是需要重视和解决的，比如，自研 KV 存储相比 Redis 降低了数量级倍数的成本。另外，分布式技术本身就是适用于规模业务的，而且随着业务规模的增加，成本的痛点会更加突出。我希望你能注意到这点，在根据实际场景设计系统架构时，如果需要的话，也将成本作为一个权衡点考虑进去。\n\n为什么要考虑这些？**因为我真心希望你是分布式系统的架构师、开发者，而不仅仅是开源软件的使用者。**\n\n好了，专栏到此就告一段落了。但专栏的结束，也是另一种开始。我会花时间处理还没来得及回复的留言，也会针对一些同学的共性问题策划答疑或者加餐（这是一个承诺，也请你监督）。总的来说，我会继续帮你吃透算法原理，让你掌握分布式系统的开发实战能力。当然，你可以随时在遇到问题时，在留言区留言，我们一起交流讨论。\n\n在文章结尾，我为你准备了一份调查问卷，题目不多，希望你能抽出两三分钟填写一下。我非常希望听听你对这个专栏的意见和建议，期待你的反馈！\n\n最后，我想用一段话结束今天的分享，学习技术的路上你可能会遇到对无法准确理解某技术原理的问题，但你不要觉得孤单，因为这是一个正常的情况，大家都会遇到。如果你觉得某技术的原理，理解起来很吃力，你不妨先把这个技术使用起来，然后多想想，如果是你，你会怎么设计，接着你可以带着自己的猜测去研究技术背后的原理。\n\n希望你能在繁忙的工作中，保持一颗极客的初心，享受技术的乐趣！\n\n\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/218938\" > </iframe>","categories":["分布式协议与算法实战"]},{"title":"20丨基于Raft的分布式KV系统开发实战（二）：如何实现代码？","url":"/posts/280707866.html","content":"\n\n\n你好，我是韩健。\n\n学完上一讲后，相信你已经了解了分布式 KV 系统的架构设计，同时应该也很好奇，架构背后的细节代码是怎么实现的呢？\n\n别着急，今天这节课，我会带你弄明白这个问题。我会具体讲解分布式 KV 系统核心功能点的实现细节。比如，如何实现读操作对应的 3 种一致性模型。而我希望你能在课下反复运行程序，多阅读源码，掌握所有的细节实现。\n\n话不多说，我们开始今天的学习。\n\n在上一讲中，咱们将系统划分为三大功能块（接入协议、KV 操作、分布式集群），那么今天我会按顺序具体说一说每块功能的实现，帮助你掌握架构背后的细节代码。首先，先来了解一下，如何实现接入协议。\n\n## 如何实现接入协议？\n\n在 19 讲提到，我们选择了 HTTP 协议作为通讯协议，并设计了\"/key\"和\"/join\"2 个 HTTP RESTful API，分别用于支持 KV 操作和增加节点的操作，那么，它们是如何实现的呢？\n\n接入协议的核心实现，就是下面的样子。\n\n![image-20230927222415760](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927222415760.png)\n\n我带你走一遍这三个步骤，便于你加深印象。\n\n- 在 ServeHTTP() 中，会根据 URL 路径设置相关的路由信息。比如，会在 handlerKeyRequest() 中处理 URL 路径前缀为\"/key\"的请求，会在 handleJoin() 中处理 URL 路径为\"/join\"的请求。\n- 在 handleKeyRequest() 中，处理来自客户端的 KV 操作请求，也就是基于 HTTP POST 请求的赋值操作、基于 HTTP GET 请求的查询操作、基于 HTTP DELETE 请求的删除操作。\n- 在 handleJoin() 中，处理增加节点的请求，最终调用 raft.AddVoter() 函数，将新节点加入到集群中。\n\n在这里，需要你注意的是，在根据 URL 设置相关路由信息时，你需要考虑是路径前缀匹配（比如 strings.HasPrefix(r.URL.Path, “/key”)），还是完整匹配（比如 r.URL.Path == “/join”），避免在实际运行时，路径匹配出错。比如，如果对\"/key\"做完整匹配（比如 r.URL.Path == “/key”），那么下面的查询操作会因为路径匹配出错，无法找到路由信息，而执行失败。\n\n\n\n```sh\ncurl -XGET raft-cluster-host01:8091/key/foo\n```\n\n\n\n另外，还需要你注意的是，只有领导者节点才能执行 raft.AddVoter() 函数，也就是说，handleJoin() 函数，只能在领导者节点上执行。\n\n说完接入协议后，接下来咱们来分析一下第二块功能的实现，也就是，如何实现 KV 操作。\n\n## 如何实现 KV 操作？\n\n上一节课，我提到这个分布式 KV 系统会实现赋值、查询、删除 3 类操作，那具体怎么实现呢？你应该知道，赋值操作是基于 HTTP POST 请求来实现的，就像下面的样子。\n\n```sh\ncurl -XPOST http://raft-cluster-host01:8091/key -d '{\"foo\": \"bar\"}'\n```\n\n\n\n也就是说，我们是通过 HTTP POST 请求，实现了赋值操作。\n\n![image-20230927222512463](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927222512463.png)\n\n\n\n同样的，我们走一遍这个过程，加深一下印象。\n\n当接收到 KV 操作的请求时，系统将调用 handleKeyRequest() 进行处理。\n\n在 handleKeyRequest() 函数中，检测到 HTTP 请求类型为 POST 请求时，确认了这是一个赋值操作，将执行 store.Set() 函数。\n\n在 Set() 函数中，将创建指令，并通过 raft.Apply() 函数将指令提交给 Raft。最终指令将被应用到状态机。\n\n当 Raft 将指令应用到状态机后，最终将执行 applySet() 函数，创建相应的 key 和值到内存中。\n\n在这里，我想补充一下，FSM 结构复用了 Store 结构体，并实现了 fsm.Apply()、fsm.Snapshot()、fsm.Restore()3 个函数。最终应用到状态机的数据，以 map[string]string 的形式，存放在 Store.m 中。\n\n那查询操作是怎么实现的呢？它是基于 HTTP GET 请求来实现的。\n\n\n\n```sh\ncurl -XGET http://raft-cluster-host01:8091/key/foo\n\n```\n\n也就是说，我们是通过 HTTP GET 请求实现了查询操作。在这里我想强调一下，相比需要将指令应用到状态机的赋值操作，查询操作要简单多了，因为系统只需要查询内存中的数据就可以了，不涉及状态机。具体的代码流程如图所示。\n\n![image-20230927222534481](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927222534481.png)\n\n我们走一遍这个过程，加深一下印象。\n\n当接收到 KV 操作的请求时，系统将调用 handleKeyRequest() 进行处理。\n\n在 handleKeyRequest() 函数中，检测到 HTTP 请求类型为 GET 请求时，确认了这是一个赋值操作，将执行 store.Get() 函数。\n\nGet() 函数在内存中查询指定 key 对应的值。\n\n而最后一个删除操作，是基于 HTTP DELETE 请求来实现的。\n\n```sh\ncurl -XDELETE http://raft-cluster-host01:8091/key/foo\n\n```\n\n也就是说，我们是通过 HTTP DELETE 请求，实现了删除操作。\n\n![image-20230927222554461](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927222554461.png)\n\n\n\n同样的，我们走一遍这个过程。\n\n1、当接收到 KV 操作的请求时，系统将调用 handleKeyRequest() 进行处理。\n\n2、在 handleKeyRequest() 函数中，检测到 HTTP 请求类型为 DELETE 请求时，确认了这是一个删除操作，将执行 store.Delete() 函数。\n\n3、在 Delete() 函数中，将创建指令，并通过 raft.Apply() 函数，将指令提交给 Raft。最终指令将被应用到状态机。\n\n4、当前 Raft 将指令应用到状态机后，最终执行 applyDelete() 函数，删除 key 和值。\n\n学习这部分内容的时候，有一些同学可能会遇到，不知道如何判断指定的操作是否需要在领导者节点上执行的问题，我给的建议是这样的。\n\n- 需要向 Raft 状态机中提交指令的操作，是必须要在领导者节点上执行的，也就是所谓的写请求，比如赋值操作和删除操作。\n- 需要读取最新数据的查询操作（比如客户端设置查询操作的读一致性级别为 consistent），是必须在领导者节点上执行的。\n\n说完了如何实现 KV 操作后，来看一下最后一块功能，如何实现分布式集群。\n\n## 如何实现分布式集群？\n\n### 创建集群\n\n实现一个 Raft 集群，首先我们要做的就是创建集群，创建 Raft 集群，主要分为两步。首先，第一个节点通过 Bootstrap 的方式启动，并作为领导者节点。启动命令就像下面的样子。\n\n```sh\n$GOPATH/bin/raftdb -id node01  -haddr raft-cluster-host01:8091 -raddr raft-cluster-host01:8089 ~/.raftdb\n```\n\n\n\n这时将在 Store.Open() 函数中，调用 BootstrapCluster() 函数将节点启动起来。\n\n接着，其他节点会通过 -join 参数指定领导者节点的地址信息，并向领导者节点发送，包含当前节点配置信息的增加节点请求。启动命令就像下面的样子。\n\n```sh\n$GOPATH/bin/raftdb -id node02 -haddr raft-cluster-host02:8091 -raddr raft-cluster-host02:8089 -join raft-cluster-host01:8091 ~/.raftdb\n```\n\n\n\n当领导者节点接收到来自其他节点的增加节点请求后，将调用 handleJoin() 函数进行处理，并最终调用 raft.AddVoter() 函数，将新节点加入到集群中。\n\n在这里，需要你注意的是，只有在向集群中添加新节点时，才需要使用 -join 参数。当节点加入集群后，就可以像下面这样，正常启动进程就可以了。\n\n```sh\n$GOPATH/bin/raftdb -id node02 -haddr raft-cluster-host02:8091 -raddr raft-cluster-host02:8089  ~/.raftdb\n```\n\n\n\n集群运行起来后，因为领导者是可能会变的，那么如何实现写操作，来保证写请求都在领导者节点上执行呢？\n\n### 写操作\n\n在 19 讲中，我们选择了方法 2 来实现写操作。也就是，当跟随者接收到写请求后，将拒绝处理该请求，并将领导者的地址信息转发给客户端。后续客户端就可以直接访问领导者（为了演示方便，我们以赋值操作为例）。\n\n![image-20230927222653086](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927222653086.png)\n\n\n\n我们来看一下具体的内容。\n\n调用 Set() 函数执行赋值操作。\n\n如果执行 Set() 函数成功，将执行步骤 3；如果执行 Set() 函数出错，且提示出错的原因是当前节点不是领导者，那这就说明了当前节点不是领导者，不能执行写操作，将执行步骤 4；如果执行 Set() 函数出错，且提示出错的原因不是因为当前节点不是领导者，将执行步骤 5。\n\n赋值操作执行成功，正常返回。\n\n节点将构造包含领导者地址信息的重定向响应，并返回给客户端。然后客户端直接访问领导者节点执行赋值操作。\n\n系统运行出错，返回错误信息给客户端。\n\n需要你注意的是，赋值操作和删除操作属于写操作，必须在领导者节点上执行。而查询操作，只是查询内存中的数据，不涉及指令提交，可以在任何节点上执行。\n\n而为了更好的利用 curl 客户端的 HTTP 重定向功能，我实现了 HTTP 307 重定向，这样，你在执行赋值操作时，就不需要关心访问节点是否是领导者节点了。比如，你可以使用下面的命令，访问节点 2（也就是 raft-cluster-host02，192.168.0.20）执行赋值操作。\n\n```sh\ncurl -XPOST raft-cluster-host02:8091/key -d '{\"foo\": \"bar\"}' -L\n```\n\n\n\n如果当前节点（也就是节点 2）不是领导者，它将返回包含领导者地址信息的 HTTP 307 重定向响应给 curl。这时，curl 根据响应信息，重新发起赋值操作请求，并直接访问领导者节点（也就是节点 1，192.168.0.10）。具体的过程，就像下面的 Wireshark 截图。\n\n![image-20230927222712159](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927222712159.png)\n\n\n\n相比写请求必须在领导者节点上执行，虽然查询操作属于读操作，可以在任何节点上执行，但是如何实现却更加复杂，因为读操作的实现关乎着一致性的实现。那么，具体怎么实现呢？\n\n### 读操作\n\n我想说的是，我们可以实现 3 种一致性模型（也就是 stale、default、consistent），这样，用户就可以根据场景特点，按需选择相应的一致性级别，是不是很灵活呢？\n\n具体的读操作的代码实现，就像下面的样子。\n\n![image-20230927222723662](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927222723662.png)\n\n我们走一遍这个过程。\n\n1、当接收到 HTTP GET 的查询请求时，系统会先调用 level() 函数，来获取当前请求的读一致性级别。\n\n2、调用 Get() 函数，查询指定 key 和读一致性级别对应的数据。\n\n3、如果执行 Get() 函数成功，将执行步骤 4；如果执行 Get() 函数出错，且提示出错的原因是当前节点不是领导者节点，那么这就说明了，在当前节点上执行查询操作不满足读一致性级别，必须要到领导者节点上执行查询操作，将执行步骤 5；如果执行 Get() 函数出错，且提示出错的原因不是因为当前节点不是领导者，将执行步骤 6。\n\n4、查询操作执行成功，返回查询到的值给客户端。\n\n5、节点将构造，包含领导者地址信息的重定向响应，并返回给客户端。然后客户端直接访问领导者节点查询数据。\n\n6、系统运行出错，返回错误信息给客户端。\n\n在这里，为了更好地利用 curl 客户端的 HTTP 重定向功能，我同样实现了 HTTP 307 重定向（具体原理，前面已经介绍了，这里就不啰嗦了）。比如，你可以使用下面的命令，来实现一致性级别为 consistent 的查询操作，不需要关心访问节点（raft-cluster-host02）是否是领导者节点。\n\n```sh\ncurl -XGET raft-cluster-host02:8091/key/foo?level=consistent  -L\n\n```\n\n\n\n\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/218093\" > </iframe>","categories":["分布式协议与算法实战"]},{"title":"01｜LangChain系统安装和快速入门","url":"/posts/343780227.html","content":"\n\n\n# 01｜LangChain系统安装和快速入门\n\n你好，我是黄佳，欢迎来到LangChain实战课！\n\n在我们开始正式的学习之前，先做一些基本知识储备。虽然大语言模型的使用非常简单，但是如果我们通过API来进行应用开发，那么还是有些基础知识应该先了解了解，比如什么是大模型，怎么安装LangChain，OpenAI的API有哪些类型，以及常用的开源大模型从哪里下载等等。\n\n## 什么是大语言模型\n\n大语言模型是一种人工智能模型，通常使用深度学习技术，比如神经网络，来理解和生成人类语言。这些模型的“大”在于它们的参数数量非常多，可以达到数十亿甚至更多，这使得它们能够理解和生成高度复杂的语言模式。\n\n你可以 **将大语言模型想象成一个巨大的预测机器，其训练过程主要基于“猜词”**：给定一段文本的开头，它的任务就是预测下一个词是什么。模型会根据大量的训练数据（例如在互联网上爬取的文本），试图理解词语和词组在语言中的用法和含义，以及它们如何组合形成意义。它会通过不断地学习和调整参数，使得自己的预测越来越准确。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/5730e6debb8c1a0876f79814c0fb78e5.png)\n\n比如我们给模型一个句子：“今天的天气真”，模型可能会预测出“好”作为下一个词，因为在它看过的大量训练数据中，“今天的天气真好”是一个常见的句子。这种预测并不只基于词语的统计关系，还包括对上下文的理解，甚至有时能体现出对世界常识的认知，比如它会理解到，人们通常会在天气好的时候进行户外活动。因此也就能够继续生成或者说推理出相关的内容。\n\n但是，大语言模型并不完全理解语言，它们没有人类的情感、意识或理解力。它们只是通过复杂的数学函数学习到的语言模式，一个概率模型来做预测，所以有时候它们会犯错误，或者生成不合理甚至偏离主题的内容。\n\n咱们当然还是主说LangChain。 **LangChain 是一个全方位的、基于大语言模型这种预测能力的应用开发工具**，它的灵活性和模块化特性使得处理语言模型变得极其简便。不论你在何时何地，都能利用它流畅地调用语言模型，并基于语言模型的“预测”或者说“推理”能力开发新的应用。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/6259a17134fd5a080fc3d9856a08050c.png)\n\nLangChain 的预构建链功能，就像乐高积木一样，无论你是新手还是经验丰富的开发者，都可以选择适合自己的部分快速构建项目。对于希望进行更深入工作的开发者，LangChain 提供的模块化组件则允许你根据自己的需求定制和创建应用中的功能链条。\n\nLangChain支持Python和JavaScript两个开发版本，我们这个教程中全部使用Python版本进行讲解。\n\n## 安装LangChain\n\nLangChain的基本安装特别简单。\n\n```plain\npip install langchain\n\n```\n\n这是安装 LangChain 的最低要求。这里我要提醒你一点，LangChain 要与各种模型、数据存储库集成，比如说最重要的OpenAI的API接口，比如说开源大模型库HuggingFace Hub，再比如说对各种向量数据库的支持。默认情况下，是没有同时安装所需的依赖项。\n\n也就是说，当你 `pip install langchain` 之后，可能还需要 `pip install openai`、 `pip install chroma`（一种向量数据库）……\n\n用下面两种方法，我们就可以在安装 LangChain 的方法时，引入大多数的依赖项。\n\n安装LangChain时包括常用的开源LLM（大语言模型） 库：\n\n```plain\npip install langchain[llms]\n\n```\n\n安装完成之后，还需要更新到 LangChain 的最新版本，这样才能使用较新的工具。\n\n```plain\npip install --upgrade langchain\n\n```\n\n如果你想从源代码安装，可以克隆存储库并运行：\n\n```plain\npip install -e\n\n```\n\n我个人觉得非常好的学习渠道也在这儿分享给你。\n\nLangChain 的 [GitHub](https://github.com/langchain-ai/langchain) 社区非常活跃，你可以在这里找到大量的教程和最佳实践，也可以和其他开发者分享自己的经验和观点。\n\nLangChain也提供了详尽的 [API 文档](https://python.langchain.com/docs/get_started)，这是你在遇到问题时的重要参考。不过呢，我觉得因为 LangChain太新了，有时你可能会发现文档中有一些错误。在这种情况下，你可以考虑更新你的版本，或者在官方平台上提交一个问题反馈。\n\n当我遇到问题，我通常会在LangChain的GitHub开一个Issue，很快就可以得到解答。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/ff014c517a428cc970e26a34b700c2a8.png)\n\n跟着LangChain其快速的更新步伐，你就能在这个领域取得显著的进步。\n\n## OpenAI API\n\n下面我想说一说OpenAI的API。\n\n关于ChatGPT和GPT-4，我想就没有必要赘言了，网上已经有太多资料了。但是要继续咱们的LangChain实战课，你需要对OpenAI的API有进一步的了解。因为， **LangChain本质上就是对各种大模型提供的API的套壳，是为了方便我们使用这些API，搭建起来的一些框架、模块和接口。**\n\n因此，要了解LangChain的底层逻辑，需要了解大模型的API的基本设计思路。而目前接口最完备的、同时也是最强大的大语言模型，当然是OpenAI提供的GPT家族模型。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/413abcbb7c08bd0a2655a15368b980e4.png)\n\n当然，要使用OpenAI API，你需要先用科学的方法进行注册，并得到一个API Key。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/205151183f71bdd86c25c01f99e248bf.png)\n\n有了OpenAI的账号和Key，你就可以在面板中看到各种信息，比如模型的费用、使用情况等。下面的图片显示了各种模型的访问数量限制信息。其中，TPM和RPM分别代表tokens-per-minute、requests-per-minute。也就是说，对于GPT-4，你通过API最多每分钟调用200次、传输40000个字节。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/66e055f3c48b4bc3e11ffe0e85a5c7f3.png)\n\n这里，我们需要重点说明的两类模型，就是图中的Chat Model和Text Model。这两类Model，是大语言模型的代表。当然，OpenAI还提供Image、Audio和其它类型的模型，目前它们不是LangChain所支持的重点，模型数量也比较少。\n\n- **Chat Model，聊天模型**，用于产生人类和AI之间的对话，代表模型当然是gpt-3.5-turbo（也就是ChatGPT）和GPT-4。当然，OpenAI还提供其它的版本，gpt-3.5-turbo-0613代表ChatGPT在2023年6月13号的一个快照，而gpt-3.5-turbo-16k则代表这个模型可以接收16K长度的Token，而不是通常的4K。（注意了，gpt-3.5-turbo-16k并未开放给我们使用，而且你传输的字节越多，花钱也越多）\n- **Text Model，文本模型**，在ChatGPT出来之前，大家都使用这种模型的API来调用GPT-3，文本模型的代表作是text-davinci-003（基于GPT3）。而在这个模型家族中，也有专门训练出来做文本嵌入的text-embedding-ada-002，也有专门做相似度比较的模型，如text-similarity-curie-001。\n\n上面这两种模型，提供的功能类似，都是接收对话输入（input，也叫prompt），返回回答文本（output，也叫response）。但是，它们的调用方式和要求的输入格式是有区别的，这个我们等下还会进一步说明。\n\n下面我们用简单的代码段说明上述两种模型的调用方式。先看比较原始的Text模型（GPT3.5之前的版本）。\n\n### 调用Text模型\n\n第1步，先注册好你的API Key。\n\n第2步，用 `pip install openai` 命令来安装OpenAI库。\n\n第3步，导入 OpenAI API Key。\n\n导入API Key有多种方式，其中之一是通过下面的代码：\n\n```plain\nimport os\nos.environ[\"OPENAI_API_KEY\"] = '你的Open API Key'\n\n```\n\nOpenAI库就会查看名为OPENAI\\_API\\_KEY的环境变量，并使用它的值作为API密钥。\n\n也可以像下面这样先导入OpenAI库，然后指定api\\_key的值。\n\n```plain\nimport openai\nopenai.api_key = '你的Open API Key'\n\n```\n\n当然，这种把Key直接放在代码里面的方法最不可取，因为你一不小心共享了代码，密钥就被别人看到了，他就可以使用你的GPT-4资源！所以，建议你给自己的OpenAI账户设个上限，比如每月10美元啥的。\n\n所以更好的方法是在操作系统中定义环境变量，比如在Linux系统的命令行中使用：\n\n```plain\nexport OPENAI_API_KEY='你的Open API Key'\n\n```\n\n或者，你也可以考虑把环境变量保存在.env文件中，使用python-dotenv库从文件中读取它，这样也可以降低API密钥暴露在代码中的风险。\n\n第4步，导入OpenAI库。（如果你在上一步导入OpenAI API Key时并没有导入OpenAI库）\n\n```plain\nimport openai\n\n```\n\n第5步，调用Text模型，并返回结果。\n\n```plain\nresponse = openai.Completion.create(\n  model=\"text-davinci-003\",\n  temperature=0.5,\n  max_tokens=100,\n  prompt=\"请给我的花店起个名\")\n\n```\n\n在使用OpenAI的文本生成模型时，你可以通过一些参数来控制输出的内容和样式。这里我总结为了一些常见的参数。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/34aaeaff93368c3c3596c12523c1ccc3.jpg)\n\n第6步，打印输出大模型返回的文字。\n\n```plain\nprint(response.choices[0].text.strip())\n\n```\n\n当你调用OpenAI的Completion.create方法时，它会返回一个响应对象，该对象包含了模型生成的输出和其他一些信息。这个响应对象是一个字典结构，包含了多个字段。\n\n在使用Text模型（如text-davinci-003）的情况下，响应对象的主要字段包括：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/4cb717e0258971c7e92dace9c4d8f2ce.jpg)\n\nchoices字段是一个列表，因为在某些情况下，你可以要求模型生成多个可能的输出。每个选择都是一个字典，其中包含以下字段：\n\n- text：模型生成的文本。\n- finish\\_reason：模型停止生成的原因，可能的值包括 stop（遇到了停止标记）、length（达到了最大长度）或 temperature（根据设定的温度参数决定停止）。\n\n所以， `response.choices[0].text.strip()` 这行代码的含义是：从响应中获取第一个（如果在调用大模型时，没有指定n参数，那么就只有唯一的一个响应）选择，然后获取该选择的文本，并移除其前后的空白字符。这通常是你想要的模型的输出。\n\n至此，任务完成，模型的输出如下：\n\n```plain\n心动花庄、芳华花楼、轩辕花舍、簇烂花街、满园春色\n\n```\n\n不错。下面，让我们再来调用Chat模型（GPT-3.5和GPT-4）。\n\n### 调用Chat模型\n\n整体流程上，Chat模型和Text模型的调用是完全一样的，只是输入（prompt）和输出（response）的数据格式有所不同。\n\n示例代码如下：\n\n```plain\nresponse = openai.ChatCompletion.create(\n  model=\"gpt-4\",\n  messages=[\n        {\"role\": \"system\", \"content\": \"You are a creative AI.\"},\n        {\"role\": \"user\", \"content\": \"请给我的花店起个名\"},\n    ],\n  temperature=0.8,\n  max_tokens=60\n)\nprint(response['choices'][0]['message']['content'])\n\n```\n\n这段代码中，除去刚才已经介绍过的temperature、max\\_tokens等参数之外，有两个专属于Chat模型的概念，一个是消息，一个是角色！\n\n先说 **消息**，消息就是传入模型的提示。此处的messages参数是一个列表，包含了多个消息。每个消息都有一个role（可以是system、user或assistant）和content（消息的内容）。系统消息设定了对话的背景（你是一个很棒的智能助手），然后用户消息提出了具体请求（请给我的花店起个名）。模型的任务是基于这些消息来生成回复。\n\n再说 **角色**，在OpenAI的Chat模型中，system、user和assistant都是消息的角色。每一种角色都有不同的含义和作用。\n\n- system：系统消息主要用于设定对话的背景或上下文。这可以帮助模型理解它在对话中的角色和任务。例如，你可以通过系统消息来设定一个场景，让模型知道它是在扮演一个医生、律师或者一个知识丰富的AI助手。系统消息通常在对话开始时给出。\n- user：用户消息是从用户或人类角色发出的。它们通常包含了用户想要模型回答或完成的请求。用户消息可以是一个问题、一段话，或者任何其他用户希望模型响应的内容。\n- assistant：助手消息是模型的回复。例如，在你使用API发送多轮对话中新的对话请求时，可以通过助手消息提供先前对话的上下文。然而，请注意在对话的最后一条消息应始终为用户消息，因为模型总是要回应最后这条用户消息。\n\n在使用Chat模型生成内容后，返回的 **响应**，也就是response会包含一个或多个choices，每个choices都包含一个message。每个message也都包含一个role和content。role可以是system、user或assistant，表示该消息的发送者，content则包含了消息的实际内容。\n\n一个典型的response对象可能如下所示：\n\n```plain\n{\n 'id': 'chatcmpl-2nZI6v1cW9E3Jg4w2Xtoql0M3XHfH',\n 'object': 'chat.completion',\n 'created': 1677649420,\n 'model': 'gpt-4',\n 'usage': {'prompt_tokens': 56, 'completion_tokens': 31, 'total_tokens': 87},\n 'choices': [\n   {\n    'message': {\n      'role': 'assistant',\n      'content': '你的花店可以叫做\"花香四溢\"。'\n     },\n    'finish_reason': 'stop',\n    'index': 0\n   }\n  ]\n}\n\n```\n\n以下是各个字段的含义：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/934aaf3e187de074348198e0b0d307bd.jpg)\n\n这就是response的基本结构，其实它和Text模型返回的响应结构也是很相似，只是choices字段中的Text换成了Message。你可以通过解析这个对象来获取你需要的信息。例如，要获取模型的回复，可使用 response\\[‘choices’\\]\\[0\\]\\[‘message’\\]\\[‘content’\\]。\n\n### Chat模型 vs Text模型\n\nChat模型和Text模型都有各自的优点，其适用性取决于具体的应用场景。\n\n相较于Text模型，Chat模型的设计更适合处理对话或者多轮次交互的情况。这是因为它可以接受一个消息列表作为输入，而不仅仅是一个字符串。这个消息列表可以包含system、user和assistant的历史信息，从而在处理交互式对话时提供更多的上下文信息。\n\n这种设计的主要优点包括：\n\n1. 对话历史的管理：通过使用Chat模型，你可以更方便地管理对话的历史，并在需要时向模型提供这些历史信息。例如，你可以将过去的用户输入和模型的回复都包含在消息列表中，这样模型在生成新的回复时就可以考虑到这些历史信息。\n2. 角色模拟：通过system角色，你可以设定对话的背景，给模型提供额外的指导信息，从而更好地控制输出的结果。当然在Text模型中，你在提示中也可以为AI设定角色，作为输入的一部分。\n\n然而，对于简单的单轮文本生成任务，使用Text模型可能会更简单、更直接。例如，如果你只需要模型根据一个简单的提示生成一段文本，那么Text模型可能更适合。从上面的结果看，Chat模型给我们输出的文本更完善，是一句完整的话，而Text模型输出的是几个名字。这是因为ChatGPT经过了对齐（基于人类反馈的强化学习），输出的答案更像是真实聊天场景。\n\n好了，我们对OpenAI的API调用，理解到这个程度就可以了。毕竟我们主要是通过LangChain这个高级封装的框架来访问Open AI。\n\n## 通过LangChain调用Text和Chat模型\n\n最后，让我们来使用LangChain来调用OpenAI的Text和Chat模型，完成了这两个任务，我们今天的课程就可以结束了！\n\n### 调用Text模型\n\n代码如下：\n\n```plain\nimport os\nos.environ[\"OPENAI_API_KEY\"] = '你的Open API Key'\nfrom langchain.llms import OpenAI\nllm = OpenAI(\n    model=\"text-davinci-003\",\n    temperature=0.8,\n    max_tokens=60,)\nresponse = llm.predict(\"请给我的花店起个名\")\nprint(response)\n\n```\n\n输出：\n\n```plain\n花之缘、芳华花店、花语心意、花风旖旎、芳草世界、芳色年华\n\n```\n\n这只是一个对OpenAI API的简单封装：先导入LangChain的OpenAI类，创建一个LLM（大语言模型）对象，指定使用的模型和一些生成参数。使用创建的LLM对象和消息列表调用OpenAI类的\\_\\_call\\_\\_方法，进行文本生成。生成的结果被存储在response变量中。没有什么需要特别解释之处。\n\n### 调用Chat模型\n\n代码如下：\n\n```plain\nimport os\nos.environ[\"OPENAI_API_KEY\"] = '你的Open API Key'\nfrom langchain.chat_models import ChatOpenAI\nchat = ChatOpenAI(model=\"gpt-4\",\n                    temperature=0.8,\n                    max_tokens=60)\nfrom langchain.schema import (\n    HumanMessage,\n    SystemMessage\n)\nmessages = [\n    SystemMessage(content=\"你是一个很棒的智能助手\"),\n    HumanMessage(content=\"请给我的花店起个名\")\n]\nresponse = chat(messages)\nprint(response)\n\n```\n\n这段代码也不难理解，主要是通过导入LangChain的ChatOpenAI类，创建一个Chat模型对象，指定使用的模型和一些生成参数。然后从LangChain的schema模块中导入LangChain的SystemMessage和HumanMessage类，创建一个消息列表。消息列表中包含了一个系统消息和一个人类消息。你已经知道系统消息通常用来设置一些上下文或者指导AI的行为，人类消息则是要求AI回应的内容。之后，使用创建的chat对象和消息列表调用ChatOpenAI类的\\_\\_call\\_\\_方法，进行文本生成。生成的结果被存储在response变量中。\n\n输出：\n\n```plain\ncontent='当然可以，叫做\"花语秘境\"怎么样？'\nadditional_kwargs={} example=False\n\n```\n\n从响应内容“ **当然可以，叫做‘花语秘境’怎么样？**”不难看出，GPT-4的创造力真的是胜过GPT-3，她给了我们这么有意境的一个店名，比我自己起的“易速鲜花”好多了。\n\n另外，无论是langchain.llms中的OpenAI（Text模型），还是langchain.chat\\_models中的ChatOpenAI中的ChatOpenAI（Chat模型），其返回的结果response变量的结构，都比直接调用OpenAI API来得简单一些。这是因为，LangChain已经对大语言模型的output进行了解析，只保留了响应中最重要的文字部分。\n\n## 总结时刻\n\n好了，今天课程的内容不少，我希望你理解OpenAI从Text模型到Chat模型的进化，以及什么时候你会选用Chat模型，什么时候会选用Text模型。另外就是这两种模型的最基本调用流程，掌握了这些内容，我们就可以继续后面的学习。\n\n另外，大语言模型可不是OpenAI一家独大，知名的大模型开源社群HugginFace网站上面提供了很多开源模型供你尝试使用。就在我写这节课的时候，Meta的Llama-2最受热捧，而且通义千问（Qwen）则刚刚开源。这些趋势，你点击下面的图片就看得到。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/05f5c16f3d908b4b0a16958e28842e0e.png)\n\n两点提醒，一是这个领域进展太快，当你学这门课程的时候，流行的开源模型肯定变成别的了；二是这些新的开源模型，LangChain还不一定提供很好的接口，因此通过LangChain来使用最新的开源模型可能不容易。\n\n不过LangChain作为最流行的LLM框架，新的开源模型被封装进来是迟早的事情。而且，LangChain的框架也已经定型，各个组件的设计都基本固定了。\n\n## 思考题\n\n最后给你留几个有难度的思考题，有些题目你可能现在没有答案，但是我希望你带着这些问题去继续学习后续课程。\n\n1. 从今天的两个例子看起来，使用LangChain并不比直接调用OpenAI API来得省事？而且也仍然需要OpenAI API才能调用GPT家族模型。那么LangChain的核心价值在哪里？至少从这两个示例中没看出来。针对这个问题，你仔细思考思考。\n\n   **提示**：这个问题没有标准答案，仁者见仁智者见智，等学完了课程，我们可以再回过头来回答一次。\n\n2. LangChain支持的可绝不只有OpenAI模型，那么你能否试一试HuggingFace开源社区中的其它模型，看看能不能用。\n\n   **提示**：你要选择Text-Generation、Text-Text Generation和Question-Answer这一类的文本生成式模型。\n\n```plain\nfrom langchain import HuggingFaceHub\nllm = HuggingFaceHub(model_id=\"bigscience/bloom-1b7\")\n\n```\n\n1. 上面我提到了生成式模型，那么，大语言模型除了文本生成式模型，还有哪些类别的模型？比如说有名的Bert模型，是不是文本生成式的模型？\n\n   **提示**：如果你没有太多NLP基础知识，建议你可以看一下我的专栏《 [零基础实战机器学习](https://time.geekbang.org/column/intro/100085501)》和公开课《 [ChatGPT和预训练模型实战课](https://time.geekbang.org/opencourse/videointro/100541201)》。\n\n期待在留言区看到你的思考，如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。\n\n# 延伸阅读\n\n1. LangChain官方文档（ [Python版](https://python.langchain.com/docs/get_started/introduction.html)）（ [JavaScript版](https://js.langchain.com/docs/get_started/introduction.html)），这是你学习专栏的过程中，有任何疑惑都可以随时去探索的知识大本营。我个人觉得，目前LangChain的文档还不够体系化，有些杂乱，讲解也不大清楚。但是，这是官方文档，会维护得越来越好。\n2. [OpenAI API 官方文档](https://platform.openai.com/docs/introduction)，深入学习OpenAI API的地方。\n3. [HuggingFace 官方网站](https://huggingface.co/)，玩开源大模型的好地方。","categories":["LangChain实战课"]},{"title":"开篇词｜带你亲证AI应用开发的“奇点”时刻","url":"/posts/2414557174.html","content":"\n\n\n# 开篇词｜带你亲证AI应用开发的“奇点”时刻\n\n你好，我是黄佳，欢迎来到 LangChain 实战课！\n\n可能你对我并不陌生，这已经是我第三次和极客时间合作课程了，另外我也是书籍《零基础学机器学习》和《数据分析咖哥十话》的作者。现在在新加坡科研局，任职首席研究员，这些年来一直从事AI科研，尤其是大语言模型的研究。我的主要任务就是为最新的AI技术寻找实际应用场景。想必你应该能理解，学术研究与实际应用是两个完全不同的领域，架设它们之间的桥梁是极具挑战的。\n\n然而，当ChatGPT和GPT-4横空出世时，全人类都在为之震撼——通用人工智能的奇点，真的即将来临了吗？作为科研人员，我们也惊喜地发现， **最前沿的AI技术与最实用的落地应用之间的距离，竟然如此之近！**\n\n更为关键的是，ChatGPT不仅是技术革命，它还能为企业提供便捷的服务。在类似ChatGPT这样的模型基础上所开发出的应用，可以助力企业优化客户服务、提升客户服务质量、加强市场营销、优化产品设计、改进供应链管理…ChatGPT 所代表的大语言模型落地场景，覆盖千行百业的方方面面。\n\n## AI 应用开发——新的历史节点\n\n事实上，没有任何一种突破能够不经历重重失败，不体验一轮轮的痛苦，就能直接展现在人类面前。AI技术自诞生之初直至今日，其发展之路从未一帆风顺——辉煌与寒冬交替，希望与失望交织。现代AI的核心驱动力神经网络，70年间两落三起；自然语言处理技术亦不例外，在ChatGPT和GPT-4出现之前，NLP技术也曾受过质疑，长期经历低谷期。\n\n每一次AI新技术突然流行之时，总会有人发问：这次，会不会又是昙花一现？\n\n在我看来，这次大模型领域的突破的的确确是真切的、清晰可见的。“ChatGPT将引发巨变！” 诸多业界“真大佬”掷地有声地给出了同样肯定的答案。\n\n阿里巴巴集团董事会主席张勇在2023年阿里云峰会宣布：“AI大模型的出现是一个划时代的里程碑，就像工业革命一样，大模型将会被各行各业广泛应用，带来生产力的巨大提升，并深刻改变我们的生活方式。”“ **面向AI时代，所有产品都值得用大模型重新升级。**”\n\n英伟达的创始人、CEO黄仁勋也在英伟达 GTC 线上大会上将 ChatGPT 称为AI的 “iPhone时刻”。\n\n更有人认为，“iPhone 时刻”把ChatGPT和大模型的技术影响力和未来前景说小了。其实，这并不是iPhone时刻，而是互联网时刻。因为很多互联网应用比平台都大，而在人工智能基础功能平台上，会成长出超过平台的企业，也就是说， **未来的人工智能应用企业有可能会超过 Apple、微软、谷歌等平台企业。**\n\n无论如何，有一点毋庸置疑。我们正站在一个崭新的历史节点上。\n\n在这个节点上，ChatGPT、GPT-4和其他大语言模型为我们提供了新的视角和新的可能性，在大语言模型的基础上，有可能成长出跨平台的企业，改变未来的科技格局。\n\n在这个节点上，LangChain 这个以大模型为引擎的全新应用开发框架从天而降，几乎和 ChatGPT 一起面世。作为程序设计者的我们，现在 **可以利用大模型的潜能以及LangChain的便捷，开发出令人惊叹的智能应用**。LangChain作为新一代AI开发框架，必将受到程序员的追捧，点燃AI应用开发的新热潮。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/a44339c249df750ff3efa194a9d36b63.png)\n\n这样的预期，正是我们开设这门课程，以及邀请你来学习这门课程的原因。\n\n## 何谓 LangChain？释放大语言模型潜能的利器\n\n在这门课程中，我们将共同探索如何使用LangChain。那么如何理解 LangChain 呢？\n\n作为一种专为开发基于语言模型的应用而设计的框架，通过LangChain，我们不仅可以通过API调用如 ChatGPT、GPT-4、Llama 2 等大型语言模型，还可以实现更高级的功能。\n\n我们相信，真正有潜力且具有创新性的应用，不仅仅在于能通过API调用语言模型，更重要的是能够具备以下两个特性：\n\n1. **数据感知：** 能够将语言模型与其他数据源连接起来，从而实现对更丰富、更多样化数据的理解和利用。\n2. **具有代理性：** 能够让语言模型与其环境进行交互，使得模型能够对其环境有更深入的理解，并能够进行有效的响应。\n\n因此，LangChain框架的设计目标，是使这种AI类型的应用成为可能，并帮助我们最大限度地释放大语言模型的潜能。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/76619cf2f73ef200dd57cd16c0d55ec4.png)\n\n现在你应该已经知道，LangChain是一个基于大语言模型（LLMs）用于构建端到端语言模型应用的框架，它可以让开发者使用语言模型来实现各种复杂的任务，例如文本到图像的生成、文档问答、聊天机器人等。LangChain提供了一系列工具、套件和接口，可以简化创建由LLMs和聊天模型提供支持的应用程序的过程。\n\n## 打通 LangChain 从原理到应用的最后一公里\n\n既然 LangChain 这么棒，又这么新，我们怎么学？谁来指导？\n\n不怕！在这门课程中，我为你精心设计了 4 大模块。带你从各个角度把LangChain的精髓吃透。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/5dd717bb90c4ec4b79a36ca295691a2f.jpg)\n\n**启程篇：从0到1**\n\n在这个模块中，我会介绍LangChain系统的安装流程，以及如何进行快速的入门操作。同时，\n\n详细指导你如何使用LangChain来构建一个基于“易速鲜花”本地知识库的智能问答系统，让你直接感受LangChain强大的功能。\n\n**基础篇：深入 6 大组件**\n\nLangChain中的具体组件包括：\n\n- **模型（Models）**，包含各大语言模型的LangChain接口和调用细节，以及输出解析机制。\n- **提示模板（Prompts）**，使提示工程流线化，进一步激发大语言模型的潜力。\n- **数据检索（Indexes）**，构建并操作文档的方法，接受用户的查询并返回最相关的文档，轻松搭建本地知识库。\n- **记忆（Memory）**，通过短时记忆和长时记忆，在对话过程中存储和检索数据，让ChatBot记住你是谁。\n- **链（Chains）**，是LangChain中的核心机制，以特定方式封装各种功能，并通过一系列的组合，自动而灵活地完成常见用例。\n- **代理（Agents）**，是另一个LangChain中的核心机制，通过“代理”让大模型自主调用外部工具和内部工具，使强大的“智能化”自主Agent成为可能！ **你的** **App** **将产生自驱力！**\n\n这些组件是LangChain的基石，是赋予其智慧和灵魂的核心要素，它们相互协作，形成一个强大而灵活的系统。在基础篇中，我们将深入探索这些组件的工作原理和使用方法，并给出大量用例，夯实你对这些组件的理解和应用能力。\n\n**应用篇** **：积累** **场景中的智慧**\n\n在这个模块中，我们会展示如何将LangChain组件应用到实际场景中。你将学会如何使用LangChain的工具和接口，进行嵌入式存储，连接数据库，引入异步通信机制，通过智能代理进行各种角色扮演、头脑风暴，并进行自主搜索，制定自动策略，尝试不同方案完成任务。\n\n我们将不仅仅是讲解这些组件的功能，还会通过实际应用场景来展示它们是如何互相配合，共同完成复杂任务的。本模块中的很多机制都来源于最新论文，其中对AI智能代理机制的各种使用方式将令你大开脑洞，或许你会哈哈一笑，或许你会击节赞叹，钦佩设计者思路之清奇。\n\n**实战篇** **：** **动手！**\n\n你将学习如何部署一个鲜花网络电商的人脉工具，并开发一个易速鲜花聊天客服机器人。从模型的调用细节，到数据连接的策略，再到记忆的存储与检索，每一个环节都是为了打造出一个更加智能、更加人性化的系统。\n\n至此，你将能够利用LangChain构建出属于自己的智能问答系统，不论是用于企业的应用开发，还是个人的日常应用，都能够得心应手，游刃有余。\n\n## LangChain 有趣用例抢先看\n\n也许，你已经听说过太多大语言模型和LangChain的神奇妙用，迫不及待地想见识见识。那样也好，百闻不如一见，下面我就给你展示两个使用大语言模型和LangChain的具体应用，一起来看看它有多好用。\n\n在我上一个专栏 [《零基础实战机器学习》](https://time.geekbang.org/column/intro/100085501) 中，我创建了一个虚拟的电商平台“易速鲜花”，并围绕着这个电商场景，构建了很多机器学习应用，如销售量预测、渠道优化、A/B测试、推广裂变策略等等。在《LangChain实战课》中，咱们就继续运营“易速鲜花”，看看大语言模型能够帮我们做些什么。当然，这两门课内容上是完全独立的，没看过另一门也不要紧，并不影响你从这里的起步。\n\n### **应用1：情人节玫瑰宣传语**\n\n_情人节到啦，你的花店需要推销红色玫瑰，那么咱们让大语言模型做的第一个应用，就是给咱们生成简短的宣传语。_\n\n这个需求极为简单，你直接去ChatGPT网站，或者用文心一言、星火认知等大模型，都做得到。不过，怎样通过LangChain来用程序的方式实现呢？也很容易。\n\n第一步是安装两个包，通过 `pip install langchain` 来安装LangChain，通过 `pip install openai` 来安装OpenAI。\n\n第二步，你还需要在OpenAI网站注册属于自己的OpenAI Key。（当然，LangChain也支持其他的开源大语言模型，但是推理效果没有GPT那么好，所以我们这个课程里面的大多数示例都是用OpenAI的GPT系列模型来完成。）\n\n完成了上面两个步骤，就可以写代码了。\n\n```plain\nimport os\nos.environ[\"OPENAI_API_KEY\"] = '你的OpenAI Key'\nfrom langchain.llms import OpenAI\nllm = OpenAI(model_name=\"text-davinci-003\",max_tokens=200)\ntext = llm(\"请给我写一句情人节红玫瑰的中文宣传语\")\nprint(text)\n\n```\n\n这里，我们先导入了OpenAI的API Key，然后从LangChain中导入OpenAI的Text模型接口，并初始化这个大语言模型，把我们的需求作为提示信息，传递给大语言模型。\n\n运行程序，我得到了好几个漂亮的文案。而且每次运行都会有新的惊喜。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/50b8a37c1b713f49b3f0d046d0fe7629.png)\n\n你也许会觉得，这个应用太简单了，直接去大模型的网页上问更方便。的确如此，那下面我们再来一个无法直接在网页上完成的应用。\n\n### **应用2：海报文案生成器**\n\n_你已经制作好了一批鲜花的推广海报，想为每一个海报的内容，写一两句话，然后post到社交平台上，以期图文并茂。_\n\n这个需求，特别适合让AI帮你批量完成，不过，ChatGPT网页可不能读图。下面，我们就用LangChain的“代理”调用“工具”来完成自己做不到的事情。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/f1e55d0c8yy2189eb2d7d23978272699.png)\n\n我们就用一段简单的代码实现上述功能。这段代码主要包含三个部分：\n\n1. 初始化图像字幕生成模型（HuggingFace中的image-caption模型）。\n2. 定义LangChain图像字幕生成工具。\n3. 初始化并运行LangChain Agent（代理），这个Agent是OpenAI的大语言模型，会自动进行分析，调用工具，完成任务。\n\n不过，这段代码需要的包比较多。在运行这段代码之前，你需要先更新LangChain到最新版本，安装HuggingFace的Transformers库（开源大模型工具），并安装 Pillow（Python图像处理工具包）和 PyTorch（深度学习框架）。\n\n```python\npip install --upgrade langchain\npip install transformers\npip install pillow\npip install torch torchvision torchaudio\n\n```\n\n```python\n#---- Part 0 导入所需要的类\nimport os\nimport requests\nfrom PIL import Image\nfrom transformers import BlipProcessor, BlipForConditionalGeneration\nfrom langchain.tools import BaseTool\nfrom langchain import OpenAI\nfrom langchain.agents import initialize_agent, AgentType\n\n#---- Part I 初始化图像字幕生成模型\n# 指定要使用的工具模型（HuggingFace中的image-caption模型）\nhf_model = \"Salesforce/blip-image-captioning-large\"\n\n# 初始化处理器和工具模型\n# 预处理器将准备图像供模型使用\nprocessor = BlipProcessor.from_pretrained(hf_model)\n# 然后我们初始化工具模型本身\nmodel = BlipForConditionalGeneration.from_pretrained(hf_model)\n\n#---- Part II 定义图像字幕生成工具类\nclass ImageCapTool(BaseTool):\n\n    name = \"Image captioner\"\n    description = \"为图片创作说明文案.\"\n\n    def _run(self, url: str):\n        # 下载图像并将其转换为PIL对象\n        image = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n        # 预处理图像\n        inputs = processor(image, return_tensors=\"pt\")\n        # 生成字幕\n        out = model.generate(**inputs, max_new_tokens=20)\n        # 获取字幕\n        caption = processor.decode(out[0], skip_special_tokens=True)\n        return caption\n\n    def _arun(self, query: str):\n        raise NotImplementedError(\"This tool does not support async\")\n\n#---- PartIII 初始化并运行LangChain智能代理\n# 设置OpenAI的API密钥并初始化大语言模型（OpenAI的Text模型）\nos.environ[\"OPENAI_API_KEY\"] = '你的OpenAI API Key'\nllm = OpenAI(temperature=0.2)\n\n# 使用工具初始化智能代理并运行它\ntools = [ImageCapTool()]\nagent = initialize_agent(\n    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n    tools=tools,\n    llm=llm,\n    verbose=True,\n)\nimg_url = 'https://mir-s3-cdn-cf.behance.net/project_modules/hd/eec79e20058499.563190744f903.jpg'\nagent.run(input=f\"{img_url}\\n请给出合适的中文文案\")\n\n```\n\n根据输入的图片URL，由OpenAI大语言模型驱动的LangChain Agent，首先利用图像字幕生成工具将图片转化为字幕，然后对字幕做进一步处理，生成中文推广文案。\n\n运行结果1：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/222e9ff74e75e08a73eae6ed5e8339f1.png)\n\n运行结果2：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/95aa68999e279b08d23f25d2588d4a1f.png)\n\n运行结果3：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/b908c91172306b32ae9fa392007cddea.png)\n\n说明：因为temperature=0.2代表模型拥有一定的随机性，所以大模型每次的推理过程生成的文案都不尽相同。\n\n针对上面的鲜花图片，程序进入了AgentExecutor链，开始思考推理，并采取行动——调用Image Cationer工具，接收该工具给出的结果，并根据其返回的内容，再次进行思考推理，最后给出的文案是：“ **爱，让每一天充满美丽，让每一个心情都充满甜蜜。**” 多么浪漫而又富有创意，大模型懂我！\n\n当然，这个过程中还有很多很多的细节，比如大模型是怎么思考的？LangChain调用大模型时传入的具体提示文本是什么？代理是什么？AgentExecutor Chain 是什么？它究竟是怎样调度工具的？你现在可能有很多的疑惑。\n\n在后续的课程中，我会带着你手撕 LangChain 内部源代码，把所有这些一点一滴地剖析清楚。\n\n关于 LangChain，我想向你分享的还有太多太多，短短的开篇词已经无法容纳了。那么，就让我最后告诉你：玩 LangChain，真的很有意思，越深入，越发觉大语言模型是一个无尽的宝藏。在这样的系统中， **我们并不是生硬的去设计什么固定的逻辑，而是由语言模型通过理解和推理来决定执行什么操作以及执行的顺序**。\n\n现在你准备好了吗？让我们一同投身到LangChain的世界中，解锁AI的无限可能！","categories":["LangChain实战课"]},{"title":"000开篇词 | 洞悉技术的本质，享受科技的乐趣","url":"/posts/893575325.html","content":"\n\n\n你好，我是陈皓，网名左耳朵耗子。我目前在创业，MegaEase 是我的公司，致力于为企业提供高可用、高并发、高性能的分布式技术产品，同时也提供物联网（IoT）方向的技术产品。\n\n我之前在阿里巴巴、亚马逊、汤森路透等公司任职，职业背景是金融和电子商务行业，主要研究的技术方向是一些大规模分布式系统的基础架构。\n\n从大学毕业一直做技术工作，到今天有 20 年了，还在写代码，因为我对技术有很大的热情。我从 2002 年开始写技术博客，到 2009 年左右开始在独立的域名 [CoolShell.cn](http://CoolShell.cn)（酷壳）上分享我对技术的一些见解和心得。\n\n本来只想记录一下，没想到得到了很多人的认可，这对我来说是一个不小的鼓励。我的文章和分享始终坚持观点鲜明的特点，因为我希望可以引发大家的讨论和批评，这样分享才更有意义。\n\n无论我的观点是否偏激、不成熟，或者言辞犀利，在经历过大家的批评和讨论后，我都能够从中得到不在我视角内的思考和认知，这对我来说是非常重要的补充，对我的个人成长非常重要。\n\n我相信，看到这些文章和讨论的人，也能从中收获到更多的东西。\n\n坦率地讲，刚收到专栏撰写邀请的时候，我心里面是拒绝的。正如前面所说的，我分享的目的是跟大家交流和讨论，我认为，全年付费专栏这样的方式可能并不好。而且，付费专栏还有文章更新频率的 KPI，这对于像我这样一定要有想法才会写文章的人来说是很痛苦的，因为我不想为了写而写。\n\n所以，最初，我是非常不情愿的。\n\n极客邦科技的编辑跟我沟通过很多次，也问过我是否在做一些收费的咨询或是培训，并表明这个专栏就是面对这样的场景的。我想想也是。我其实从 2003 年就开始为很多企业做内部的培训和分享了。\n\n这些培训涵盖了很多方面，如软件团队管理、架构技术、编程语言、操作系统等，以及一些为企业量身定制的咨询或软件开发，这些都是收费的。\n\n而我一直以来也没有把这些内容分享在我的博客里，主要原因是我觉得这些内容是有商业价值的，是适合收费的。它们都是实实在在的，是我多年来对实战经验的深入总结和思考，非常来之不易。\n\n我不太舍得拿出来大范围地分享，以前基本上仅小范围地在企业内部比较封闭的环境里讲讲。所以说，我这边其实是有两种分享，一种是企业内的分享，一种则是像 CoolShell 或是大会这样的公开分享。\n\n前者更企业化一些，后者更通俗化一些。\n\n在这个付费专栏中，除了继续保持观点鲜明的行文风格，我会分享一些与个人或企业切身利益更为相关的内容，或者说更具指导性、更有商业价值的东西。而 CoolShell，我还会保持现有的风格继续写下去。\n\n正如这个专栏的 Slogan 所说：“洞悉技术的本质，享受科技的乐趣”，我会在这个专栏里分享包括但不限于如下这些内容。\n\n# 技术\n\n对于技术方面，我不会写太多关于知识点的东西，因为这些知识点你可以自行 Google 可以 RTFM。我要写的一定是以体系化的，而且要能直达技术的本质。入行这 20 年来，我最擅长的就是架构和开发各种大规模的系统，所以，我会有 2-3 个和分布式系统相关的系列文章。\n\n我学过也用过好多编程语言，所以，也会有一系列的关于编程本质的文章。而我对一些基础知识研究得也比较多，所以，还会有一系列与基础知识相关的文章。\n\n当然，其中还会穿插一些其它的技术文章，比如一些热点事件，还有一些经验之谈，包括我会把我的《程序员技术练级攻略》在这个专栏里重新再写一遍。这些东西一定会让你有醍醐灌顶的感觉。\n\n# 成长\n\n在过去这 20 年中，我感觉到，很多人都非常在意自己的成长。所以，我会分享一堆我亲身经历的，也是我自己实验的与个人发展相关的文章。\n\n比如，如何利用技术变现、如何面试、如何选择新的技术、如何学习、如何管理自己的时间、如何管理自己的老板和工作、如何成为一个 Leader……这些东西一定会对你有用。（但是，我这里一定不会有速成的东西。一切都是要花时间和精力的。如果你想要速成，你不应该来订阅我的专栏。）\n\n# 管理\n\n这 20 年，我觉得做好技术工作的前提是，得做好技术的管理工作。只有管理好了软件工程和技术团队，技术才能发挥出最大的潜力。大多数的技术问题都是管理上的问题。\n\n所以，我会写上一系列的和管理相关的文章，涵盖管理三个要素：团队、项目和管理者自己。比如，人员招聘、绩效考核、提升士气、解决冲突、面对变化、沟通说服、项目管理、任务排期、会议、远程管理，等等。\n\n这些内容都是我在外企工作时，接受到的世界顶级管理培训机构培训内容，我会把我的实践写出来分享给你。这其中一定少不了亚马逊相关的各种实践。这些东西，我和很多公司和大佬都讲过，到目前为止还没有人不赞的。\n\n\n\n为了对付费用户负责，保证文章能够达到收费的质量，我承诺这个专栏的每一篇文章一定是用心创作的，而且是可以让你从中受益的。\n\n但因为是第一次做全年专栏，收费也让我有一定的压力，所以，我非常希望你能够跟我分享你的感受和体会。\n\n我会根据你的反馈及时做出调整和修正，并不断努力提高文章的质量和思想高度，以满足你对有价值、有营养的文章的需求。\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/181\" > </iframe>","categories":["左耳听风"]},{"title":"001丨程序员如何用技术变现（上）","url":"/posts/540365869.html","content":"\n\n\n程序员用自己的技术变现，其实是一件天经地义的事儿。写程序是一门“手艺活儿”，那么作为手艺人，程序员当然可以做到靠自己的手艺和技能养活自己。\n\n然而，现在很多手艺人程序员却说自己是“码农”，编码的农民工，在工作上被各种使唤，各种加班，累得像个牲口。在职业发展上各种迷茫和彷徨，完全看不到未来的希望，更别说可以成为一个手艺人用自己的技能变现了。\n\n从大学时代帮人打字挣点零花钱，到逐渐通过自己的技能帮助别人，由此获得相对丰厚的收入，我在很早就意识到，从事编程这个事可以做到，完全靠自己的手艺、不依赖任何人或公司去生活的。\n\n这对于程序员来说，本就应该是件天经地义的事，只是好像并不是所有的程序员都能意识到自己的价值。这里，我想结合我的一些经历来跟你聊聊。当然，我的经历有限，也不一定全对，只希望能给你一个参考。\n\n# 学生时代\n\n我是 1994 年上的大学，计算机科学软件专业。在 1996 年上大二的时候，因为五笔学得好打字很快，我应征到教务处帮忙，把一些文档录入到电脑里。打了三个月的字，学校按照每千字 10 元，给了我 1000 元钱。\n\n由于我的五笔越打越快，还会用 CCED 和 WPS 排版，于是引起了别人的注意，叫我帮忙去他的打字工作室，一个月收入 400 元。我的大学是在昆明上的，这相当于那会当地收入的中上水平了。\n\n后来，1997 年的时候，我帮一个开公司的老师写一些 MIS 软件，用 Delphi 和 PowerBuilder 写一些办公自动化和酒店管理的软件。一年后，老师给了我 2000 元钱。\n\n因为动手能力比较强，当时系上的老师要干个什么事都让我帮忙。而且，因为当时的计算机人才太少太少了，所以一些社会上的人需要开发软件或是解决技术问题也都会到大学来。基本上老师们也都推荐给我。\n\n还记得 1997 年老师推荐一个人来找我，问我会不会做网页？5 个静态页，10000 元钱。当时学校没教怎样做网页，我去书店找书看，结果发现书店里一本讲 HTML 的书都没有，只好回绝说“不会做”。一年后，我才发现原来这事简单得要命。\n\n# 初入职场\n\n到了 1998 年，我毕业参加工作，在工商银行网络科。由于可以拨号上网，于是我做了一个个人主页，那时超级流行个人主页或个人网站。我一边收集网上的一些知识，一边学着做些花哨的东西，比如网页上的菜单什么的。\n\n在 2000 年时，机缘巧合我的网站被《电脑报》的编辑看到了，他写来邮件约我投稿。我就写了一些如何在网页上做菜单之类的小技术文章，每个月写个两三篇，这样每个月就有 300 元左右的稿费，当时我的月工资是 600 元。\n\n现在通过文章标题还能找到一两篇，比如《[抽屉式菜单的设计](http://www.yesky.com/251/142751all.shtml)》，已经是乱码一堆了。\n\n大学时代被人请去做事的经历对我影响很大，甚至在潜意识里完全影响了我如何规划自己的人生。虽然当时我还说不清楚，只是一种强烈的感觉——我完全可以靠自己的手艺、不依赖任何人或公司去生活。\n\n我想这种感觉，我现在可以说清楚了，这种潜意识就是——**我完全没有必要通过打工听人安排而活着，而是反过来通过在公司工作提高自己的技能，让自己可以更为独立和自由地生活**。\n\n因而，在工作当中，对于那些没什么技术含量的工作，我基本上就像是在学生时代那样交作业就好了。我想尽一切方法提高交作业的效率，比如，提高代码的重用度，能自动化的就自动化，和需求人员谈需求，简化掉需求，这样我就可以少干一些活了……\n\n这样一来，**我就可以有更多的时间，去研究公司里外那些更为核心更有技术含量的技术了**。\n\n在工作中，我总是能被别人和领导注意到，总是有比别人更多的时间去读书，去玩一些高技术含量的技术。当然，这种被“注意”，也不全然是一种好事。\n\n2002 年，我被外包到银行里做业务开发时，因为我完成项目的速度太快，所以，没事干，整天在用户那边看书，写别的代码练手，而被用户投诉“不务正业”。我当然对这样的投诉置之不理，还是我行我素，因为我的作业已交了，所以用户也就是说说罢了。\n\n同年，我到了一家新的很有技术含量的公司，他们在用 C 语言写一个可以把一堆 PC 机组成一个超级计算机，进行并行计算的公司项目。\n\n当我做完第一个项目时，有个公司里的牛人和我说，你用 Purify 测试一下你的代码有没有内存问题。Purify 是以前一个叫 Rational 的公司（后来被 IBM 收购）做的一个神器，有点像 Linux 开源的 Valgrind。\n\n用完以后，我觉得 Purify 太厉害了，于是把它的英文技术文档通读了一遍。经理看我很喜欢这个东西，就让我给公司里的人做个分享。我认真地准备了个 PPT，结果只来了一个 QA。\n\n我在一个大会议室就对着她一个人讲了一个半小时。这个 QA 对我说，“你的分享做得真好，条理性很强，也很清楚，我学到了很多东西”。\n\n有了这个正向反馈，我就把关于 Purify 的文章分享到了我的 CSDN 博客上，标题为《[C/C++ 内存问题检查利器—Purify](http://blog.csdn.net/haoel/article/details/2900)》。可能因为这个软件是收费的，用的人不多，这篇文章的读者反响并不大。\n\n但是，2003 年的一天我很意外地接到了一个电话，是一个公司请我帮忙去给客户培训 Purify 这个软件。IBM 的培训太贵了，所以代理这个软件的公司为了成本问题，想找一个便宜的讲师。\n\n他们搜遍整个中国的互联网，只看到我的这篇文章，便通过 CSDN 找到我的联系方式，给我打了电话。最终，两天的培训价格税后一共 10000 元，而我当时的月薪只有 6000 元，还是税前。\n\n这件事儿让我在入行的时候就明白了一些道理。\n\n- 要去经历大多数人经历不到的，要把学习时间花在那些比较难的地方。\n- 要写文章就要写没有人写过的，或是别人写过，但我能写得更好的。\n- 更重要的是，技术和知识完全是可以变现的。\n\n现在回想一下，技术和知识变现这件事儿，在 15 年前我就明白了，哈哈。\n\n随后，我在 CSDN 博客上发表了很多文章，有谈 C 语言编程修养的文章，也有一些 makefile/gdb 手册性的文章，还有在工作中遇到的各种坑。\n\n因为我分享的东西比较系统，也是独一份，所以，搜索引擎自然是最优化的（最好的 SEO 就是独一份）。我的文章经常因为访问量大被推到 CSDN 首页。因此，引来了各种培训公司和出版社，还有一些别的公司主动发来的招聘，以及其他一些程序员想伙同创业的各种信息。\n\n紧接着我了解到，出书作者收入太低（作者的收入有两种：一种是稿费，一页 30 元；一种是版税，也就 5% 左右），而培训公司的投入产出比明显高很多后，于是我开始接一些培训的事（频率不高），一年有个七八次。当时需求比较强的培训主要是在这几个技术方面，C/C++/Java、Unix 系统编程、多层软件架构、软件测试、软件工程等。\n\n我喜欢做企业内训，还有一个主要原因是，可以走到内部去了解各个企业在做的事和他们遇到的技术痛点，以及身在其中的工程师的想法。这极大地增加了我对社会的了解和认识。而同时，让我这个原本不善表达的技术人员，在语言组织和表达方面有了极大的提升。\n\n其间也有一些软件开发的私活儿，但我基本全部拒绝了。最主要的原因是，这些软件开发基本上都是功能性的开发，我从中无法得到成长。而且后期会有很多维护工作，虽然一个小项目可以挣十几万，但为此花费的时间都是我人生中最宝贵的时光，得不偿失。\n\n**25~35 岁是每个人最宝贵的时光，应该用在刀刃上**。\n\n# 职业上升期\n\n因为有了这些经历，我感受到了一个人知识和技能的价值。我开始把我的时间投在一些主流、高级和比较有挑战性的技术上，这可以让我保持两件事儿：一个是技术和技能的领先，二是对技术本质和趋势的敏感度。\n\n因此，我有强烈的意愿去前沿的公司经历和学习这些东西。比如，我在汤森路透学到了人员团队管理上的各种知识和技巧，而亚马逊是让我提升最快的公司。虽说，亚马逊也有很多不好的东西，但是它的一些理念，的确让我的思维方式和思考问题的角度有了质的飞跃。\n\n所以后来，我开始对外输出的不仅仅是技术了，还有一些技术价值观上的东西。\n\n而从亚马逊到阿里巴巴是我在互联网行业的工作经历，这两段经历让我对这两家看似类似但内部完全不同的成功大公司，有了更为全面的了解和看法。\n\n这两种完全不一样甚至有些矛盾的玩法让我时常在思考着，大脑里就像两个小人在扳手腕一样，这可能是我从小被灌输的“标准答案”的思维方式所致。其实，这个世界本来就没什么标准答案，或是说，一个题目本来就可以有若干个正确答案，而且这些“正确答案”还很矛盾。\n\n于是，在我把一些价值观和思考记录下来的同时，我自然又被很多人关注到了，还吸引很多不同的思路在其中交织讨论。而从另外一方面来说，这对我来说是一个很好地补充，无论别人骂我也好，教育我也罢，他们都对我有帮助，大大地丰富了我思考问题的角度。\n\n这些经历从质上改善了我的思考方式，让我思考技术问题的角度都随之有了一个比较大的转变。而这个转变让我有了更高的思维高度和更为开阔的视野。\n\n可能是因为我有一些“独特”的想法，而且经历比较丰富，基础也比较扎实，使得我对技术人的认识和理解会更为透彻和深入。所以，也有了一些小名气。来找我做咨询和帮助解决问题的人越来越多，而我也开始收费收得越来越贵了。这里需要注意的是，我完全是被动收费高的。\n\n因为父亲的身体原因，我没有办法全职，所以成了一个自由人。而也正因如此，我才得以有机会可以为更多公司解决技术问题。2015 年，有家公司的后端系统一推广就挂，性能有问题，请我去看。\n\n我花了两天时间跟他们的工程师一起简单处理了一下，直接在生产线上重构，性能翻了 10 倍。虽然这么做有点 low，但当时完全是为了救急。公司老板很高兴，觉得他投的几百万推广费用有救了，一下给了我 10 万元。我说不用这么多的，1 万元就好了，结果他说就是这么多。**我欣然接受了，当时心里有一种技术被尊重的感动**。\n\n2016 年，某个公司需要做一个高并发方案，大概需要 2000 万 QPS，但是他们只能实现到 1200 万 QPS 左右。\n\n我花了两天时间做调研，分析性能原因，然后一天写了 700 多行代码。因为不想进入业务，所以我主要是优化了网络数据传输，让数据包尽量小，确保一个请求的响应在一个 MTU 内就传完。\n\n测试的时候，达到了 2500 万 QPS。于是老板给了我 20 万。\n\n这样的例子还有很多。上面的例子，我连钱都没谈就去做了，本来想着，也就最多 1 万元左右，没想到给我的酬劳大大超出了我的期望。\n\n这里，我想说的是，**并不是社会不尊重程序员，只要你能帮上大忙，就一定会赢得别人的尊重**。\n\n所以，我和一些人开玩笑说，**我们可能都是在写一样的 for(int i=0; i<n; i++) 语句，但是，你写在那个地方一文不值，而我写在这个地方，这行代码就值 2000 元**。不要误会，我只是想用这种“鲜明的对比方式”来加强我的观点。\n\n上面就是我这 20 年来的经历。相信这类经历你也有过，或者你正在经历中，欢迎你也分享一下自己的经历和心得。\n\n那么，怎样能让自己的技术被尊重？如何通过技术和技能赚钱？下一篇文章中，我将对此做一些总结，希望对你有帮助。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/183\" > </iframe>\n\n\n\n","categories":["左耳听风"]},{"title":"003丨Equifax信息泄露始末","url":"/posts/4155117663.html","content":"\n\n\n相信你一定有所耳闻，9 月份美国知名征信公司 Equifax 出现了大规模数据泄露事件，致使 1.43 亿美国用户及大量的英国和加拿大用户受到影响。今天，我就来跟你聊聊 Equifax 信息泄露始末，并对造成本次事件的原因进行简单的分析。\n\n# Equifax 信息泄露始末\n\nEquifax 日前确认，黑客利用了其系统中未修复的 Apache Struts 漏洞（CVE-2017-5638，2017 年 3 月 6 日曝光）来发起攻击，导致了最近这次影响恶劣的大规模数据泄露事件。\n\n作为美国三大信用报告公司中历史最悠久的一家，Equifax 的主营业务是为客户提供美国、加拿大和其他多个国家的公民信用信息。保险公司就是其服务的主要客户之一，涉及生命、汽车、火灾、医疗保险等多个方面。\n\n此外，Equifax 还提供入职背景调查、保险理赔调查，以及针对企业的信用调查等服务。由于 Equifax 掌握了多个国家公民的信用档案，包括公民的学前、学校经历、婚姻、工作、健康、政治参与等大量隐私信息，所以这次的信息泄露，影响面积很大，而且性质特别恶劣。\n\n受这次信息泄露影响的美国消费者有 1.43 亿左右，另估计约有 4400 万的英国客户和大量加拿大客户受到影响。事件导致 Equifax 市值瞬间蒸发掉逾 30 亿美元。\n\n根据《华尔街日报》（The Wall Street Journal）的观察，自 Equifax 在 9 月 8 日披露黑客进入该公司部分系统以来，全美联邦法院接到的诉讼已经超过百起。针对此次事件，Equifax 首席执行官理查德·史密斯（Richard Smith）表示，公司正在对整体安全操作进行全面彻底的审查。\n\n事件发生之初，Equifax 在声明中指出，黑客是利用了某个“U.S. website application”中的漏洞获取文件。后经调查，黑客是利用了 Apache Struts 的 CVE-2017-5638 漏洞。\n\n戏剧性的是，该漏洞于今年 3 月份就已被披露，其危险系数定为最高分 10 分，Apache 随后发布的 Struts 2.3.32 和 2.5.10.1 版本特针对此漏洞进行了修复。而 Equifax 在漏洞公布后的两个月内都没有升级 Struts 版本，导致 5 月份黑客利用这个漏洞进行攻击，泄露其敏感数据。\n\n事实上，除了 Apache 的漏洞，黑客还使用了一些其他手段绕过 WAF（Web 应用程序防火墙）。有些管理面板居然位于 Shodan 搜索引擎上。更让人大跌眼镜的是，据研究人员分析，Equifax 所谓的“管理面板”都没有采取任何安保措施。安全专家布莱恩·克雷布斯（Brian Krebs）在其博客中爆料，Equifax 的一个管理面板使用的用户名和密码都是“admin”。\n\n由于管理面板能被随意访问，获取数据库密码就轻而易举了——虽然管理面板会加密数据库密码之类的东西，但是密钥却和管理面板保存在了一起。虽然是如此重要的征信机构，但 Equifax 的安全意识之弱可见一斑。\n\n据悉，Equifax 某阿根廷员工门户也泄露了 14000 条记录，包括员工凭证和消费者投诉。本次事件发生后，好事者列举了 Equifax 系统中的一系列漏洞，包括一年以前向公司报告的未修补的跨站脚本（XSS）漏洞，更将 Equifax 推向了风口浪尖。\n\n# Apache Struts 漏洞相关\n\nApache Struts 是世界上最流行的 Java Web 服务器框架之一，它最初是 Jakarta 项目中的一个子项目，并在 2004 年 3 月成为 Apache 基金会的顶级项目。\n\nStruts 通过采用 Java Servlet/JSP 技术，实现了基于 Java EE Web 应用的 MVC 设计模式的应用框架，也是当时第一个采用 MVC 模式的 Web 项目开发框架。随着技术的发展和认知的提升，Struts 的设计者意识到 Struts 的一些缺陷，于是有了重新设计的想法。\n\n2006 年，另外一个 MVC 框架 WebWork 的设计者与 Struts 团队一起开发了新一代的 Struts 框架，它整合了 WebWork 与 Struts 的优点，同时命名为“Struts 2”，原来的 Struts 框架改名为 Struts 1。\n\n因为两个框架都有强大的用户基础，所以 Struts 2 一发布就迅速流行开来。在 2013 年 4 月，Apache Struts 项目团队发布正式通知，宣告 Struts 1.x 开发框架结束其使命，并表示接下来官方将不会继续提供支持。自此 Apache Struts 1 框架正式退出历史舞台。\n\n同期，Struts 社区表示他们将专注于推动 Struts 2 框架的发展。从这几年的版本发布情况来看，Struts 2 的迭代速度确实不慢，仅仅在 2017 年就发布了 9 个版本，平均一个月一个。\n\n但从安全角度来看，Struts 2 可谓是漏洞百出，因为框架的功能基本已经健全，所以这些年 Struts 2 的更新和迭代基本也是围绕漏洞和 Bug 进行修复。仅从官方披露的安全公告中就可以看到，这些年就有 53 个漏洞预警，包括大家熟知的远程代码执行高危漏洞。\n\n根据网络上一份未被确认的数据显示，中国的 Struts 应用分布在全球范围内排名第一，第二是美国，然后是日本，而中国没有打补丁的 Struts 的数量几乎是其它国家的总和。特别是在浙江、北京、广东、山东、四川等地，涉及教育、金融、互联网、通信等行业。\n\n所以在今年 7 月，国家信息安全漏洞共享平台还发布过关于做好 Apache Struts 2 高危漏洞管理和应急工作的安全公告，大致意思是希望企业能够加强学习，提高安全认识，同时完善相关流程，协同自律。\n\n而这次 Equifax 中招的漏洞编号是 CVE-2017-5638，官方披露的信息见下图。简单来说，这是一个 RCE 的远程代码执行漏洞，最初是被安恒信息的 Nike Zheng 发现的，并于 3 月 7 日上报。\n\n\n\n![image-20230920171507391](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230920171507391.png)\n\n从介绍中可以看出，此次漏洞的原因是 Apache Struts 2 的 Jakarta Multipart parser 插件存在远程代码执行漏洞，攻击者可以在使用该插件上传文件时，修改 HTTP 请求头中的 Content-Type 值来触发漏洞，最后远程执行代码。\n\n说白了，就是在 Content-Type 注入 OGNL 语言，进而执行命令。代码如下（一行 Python 命令就可以执行服务器上的 shell 命令）：\n\n```python\nimport requests\nrequests.get(\"https://target\", headers={\"Connection\": \"close\", \"Accept\": \"*/*\", \"User-Agent\": \"Mozilla/5.0\", \"Content-Type\": \"%{(#_='multipart/form-data').(#dm=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).(#_memberAccess?(#_memberAccess=#dm):((#container=#context['com.opensymphony.xwork2.ActionContext.container']).(#ognlUtil=#container.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)).(#ognlUtil.getExcludedPackageNames().clear()).(#ognlUtil.getExcludedClasses().clear()).(#context.setMemberAccess(#dm)))).(#cmd='dir').(#iswin=(@java.lang.System@getProperty('os.name').toLowerCase().contains('win'))).(#cmds=(#iswin?{'cmd.exe','/c',#cmd}:{'/bin/bash','-c',#cmd})).(#p=new java.lang.ProcessBuilder(#cmds)).(#p.redirectErrorStream(true)).(#process=#p.start()).(#ros=(@org.apache.struts2.ServletActionContext@getResponse().getOutputStream())).(@org.apache.commons.io.IOUtils@copy(#process.getInputStream(),#ros)).(#ros.flush())}\"})\n```\n\n在 GitHub 上有相关的代码，链接为：https://github.com/mazen160/struts-pwn 或 https://github.com/xsscx/cve-2017-5638\n\n\n\n注入点是在 JakartaMultiPartRequest.java 的 buildErrorMessage 函数中，这个函数里的 localizedTextUtil.findText 会执行 OGNL 表达式，从而导致命令执行（注：可以参看 Struts 两个版本的补丁“2.5.10.1 版补丁”“2.3.32 版补丁”），使客户受到影响。\n\n因为默认情况下 Jakarta 是启用的，所以该漏洞的影响范围甚广。当时官方给出的解决方案是尽快升级到不受影响的版本，看来 Equifax 的同学并没有注意到，或者也没有认识到它的严重性。\n\n另外，在 9 月 5 日和 7 日，Struts 官方又接连发布了几个严重级别的安全漏洞公告，分别是 CVE-2017-9804、CVE-2017-9805、CVE-2017-9793 和 CVE-2017-12611。\n\n这里面最容易被利用的当属 CVE-2017-9805，它是由国外安全研究组织 lgtm.com 的安全研究人员发现的又一个远程代码执行漏洞。漏洞原因是 Struts 2 REST 插件使用带有 XStream 程序的 XStream Handler 进行未经任何代码过滤的反序列化操作，所以在反序列化 XML payloads 时就可能导致远程代码执行。\n\n![image-20230920171637075](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230920171637075.png)\n\n不过在 Apache 软件基金会的项目管理委员会的回应文章中，官方也对事故原因进行了分析和讨论。首先，依然不能确定泄露的源头是 Struts 的漏洞导致的。其次，如果确实是源于 Struts 的漏洞，那么原因“或是 Equifax 服务器未打补丁，使得一些更早期公布的漏洞被攻击者利用，或者是攻击者利用了一个目前尚未被发现的漏洞”。\n\n根据推测，该声明提出黑客所使用的软件漏洞可能就是 CVE-2017-9805 漏洞，该漏洞虽然是在 9 月 4 日才由官方正式公布，但早在 7 月时就有人公布在网络上了，并且这个漏洞的存在已有 9 年。\n\n相信通过今天的分享，你一定对 Equifax 的数据泄露始末及造成原因有了清楚的了解。欢迎您把你的收获和想法，分享给我。下篇文章中，我们将回顾一下互联网时代的! 其他大规模数据泄露事件，并结合这些事件给出应对方案和技术手段。\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/281\" > </iframe>\n\n\n\n\n\n\n\n\n\n\n\n","categories":["左耳听风"]},{"title":"002丨程序员如何用技术变现（下）","url":"/posts/1371351109.html","content":"\n\n\n我不算是聪明的人，经历也不算特别成功，但一步一步走来，我认为，我能做到的，你一定也能做到，而且应该还能做得比我更好。\n\n# 如何让自己的技能变现\n\n还是那句话，本质上来说，程序员是个手艺人，有手艺的人就能做出别人做不出来的东西，而付费也是一件很自然的事了。那么，这个问题就变成如何让自己的“手艺”更为值钱的问题了。\n\n第一，**千里之行，积于跬步**。任何一件成功的大事，都是通过一个一个的小成功达到的。所以，你得确保你有一个一个的小成功。\n\n具体说来，首先，你得让自己身边的人有求于你，或是向别人推荐你。这就需要你能够掌握大多数人不能掌握的技能或技术，需要你更多地学习，并要有更多的别人没有的经验和经历。\n\n一旦你身边的人开始有求于你，或是向别人推荐你，你就会被外部的人注意到，于是其他人就会付费来获取你的帮助。而一旦你的帮忙对别人来说有效果，那就会产生效益，无论是经济效益还是社会效益，都会为你开拓更大的空间。\n\n你也会因为这样的正向反馈而鼓励自己去学习和钻研更多的东西，从而得到一个正向的循环。而且这个正向循环，一旦开始就停不下来了。\n\n第二，**关注有价值的东西**。什么是有价值的东西？价值其实是受供需关系影响的，供大于求，就没什么价值，供不应求，就有价值。这意味着你不仅要看到市场，还要看到技术的趋势，能够分辨出什么是主流技术，什么是过渡式的技术。当你比别人有更好的嗅觉时，你就能启动得更快，也就比别人有先发优势。\n\n- **关于市场需求**。你要看清市场，就需要看看各个公司都在做什么，他们的难题是什么。简单来说，现在的每家公司无论大小都缺人。但是真的缺人吗？中国是人口大国，从不缺少写代码搬砖的人，真正缺的其实是有能力能够解决技术难题的人，能够提高团队人效的人。所以，从这些方面思考，你会知道哪些技能才是真正的“供不应求”，这样可以让你更有价值。\n- **关于技术趋势**。要看清技术趋势，你需要了解历史，就像一个球运动一样，你要知道这个球未来运动的地方，是需要观察球的已经完成运动的轨迹才知道的。因此，了解技术发展轨迹是一件很重要的事。要看一个新的技术是否顺应技术发展趋势，你需要将一些老技术的本质吃得很透。\n\n因此，在学习技术的过程一定要多问自己两个问题：“一，这个技术解决什么问题？为什么别的同类技术做不到？二，为什么是这样解决的？有没有更好的方式？”另外，还有一个简单的判断方法，如果一个新的技术顺应技术发展趋势，那么在这个新的技术出现时，后面一定会有大型的商业公司支持，这类公司支持得越多，就说明你越需要关注。\n\n第三，**找到能体现价值的地方**。**在一家高速发展的公司中，技术人员的价值可以达到最大化**。\n\n试想，在一家大公司中，技术架构和业务已经定型，基本上没有什么太多的事可以做的。而且对于已经发展起来的大公司来说，往往稳定的重要性超过了创新。此外，大公司的高级技术人员很多，多你一个不多，少你一个不少，所以你的价值很难被体现出来。\n\n而刚起步的公司，业务还没有跑顺，公司的主要精力会放在业务拓展上，这个时候也不太需要高精尖的技术，所以，技术人员的价值也体现不出来。\n\n只有那些在高速发展的公司，技术人员的价值才能被最大化地体现出来。比较好的成长路径是，先进入大公司学习大公司的技术和成功的经验方法，然后再找到高速成长的公司，这样你就可以实现自己更多的价值。当然，这里并不排除在大公司中找到高速发展的业务。\n\n第四，**动手能力很重要**。成为一个手艺人，动手能力是很重要的，因为在解决任何一个具体问题的时候，有没有动手能力就成为了关键。这也是我一直在写代码的原因，代码里全是细节，细节是魔鬼，只有了解了细节，你才能提出更好或是更靠谱、可以落地的解决方案。而不是一些笼统和模糊的东西。这太重要了。\n\n第五，**关注技术付费点**。技术付费点基本体现在两个地方，**一个是，能帮别人“挣钱”的地方；另一个是，能帮别人“省钱”的地方**。也就是说，能够帮助别人更流畅地挣钱，或是能够帮助别人提高效率，能节省更多的成本，越直接越好。而且这个技术或解决方案最好还是大多数人做不到的。\n\n第六，**提升自己的能力和经历**。付费的前提是信任，只有你提升自己的能力和经历后，别人才会对你有一定的信任，才会觉得你靠谱，才会给你机会。而这个信任需要用你的能力和经历来填补。比如，你是一个很知名的开源软件的核心开发人员，或是你是某知名公司核心项目的核心开发人员，等等。\n\n第七，**找到有价值的信息源**。信息社会，如果你比别人有更好的信息源，那么你就可以比别人成长得更快。对于技术人员来说，我们知道，几乎所有的技术都源自西方世界，所以，你应该走到信息的源头去。\n\n如果你的信息来自朋友圈、微博、知乎、百度或是今日头条，那么我觉得你完蛋了。因为这些渠道有价值的信息不多，有营养的可能只有 1%，而为了这 1%，你需要读完 99% 的信息，太不划算了。\n\n那么如何找到这些信息源呢？用好 Google 就是一个关键，比如你在 Google 搜索引擎里输入“XXX Best Practice”，或是“Best programming resource”……你就会找到很多。而用好这个更好的信息源需要你的英文能力，因此不断提升英文能力很关键。\n\n第八，**输出观点和价值观**。真正伟大的公司或是产品都是要输出价值观的。只有输出了更先进的价值观，才会获得真正的影响力。但是，你要能输出观点和价值观，并不是一件容易的事，这需要你的积累和经历，而不是一朝之功。因此，如果想要让你的技能变现，这本质上是一个厚积薄发的过程。\n\n第九，**朋友圈很重要**。一个人的朋友圈很重要，你在什么样的朋友圈，就会被什么样的朋友圈所影响。如果你的朋友圈比较优质，那么给你介绍过来的事儿和活儿也会好一些。\n\n优质的朋友圈基本上都有这样的特性。\n\n- 这些人都比较有想法、有观点，经验也比较丰富；\n- 这些人涉猎的面比较广；\n- 这些人都有或多或少的成功；\n- 这些人都是喜欢折腾喜欢搞事的人；\n- 这些人都对现状有些不满，并想做一些改变；\n- 这些人都有一定的影响力。\n\n最后有个关键的问题是，物以类聚，人以群分。如果你不做到这些，你怎么能进入到这样的朋友圈呢？\n\n总之，就一句话，**会挣钱的人一定是会投资的人**。我一直认为，**最宝贵的财富并不是钱，而是你的时间，时间比钱更宝贵，因为钱你不用还在那里，而时间你不用就浪费掉了。你把你的时间投资在哪些地方，就意味着你未来会走什么样的路。所以，利用好你的时间，投到一些有意义的地方吧**。\n\n我的经历有限，只能看到这些，还希望大家一起来讨论，分享你的经验和心得，也让我可以学习和提高。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/185\" > </iframe>","categories":["左耳听风"]},{"title":"005丨何为技术领导力？","url":"/posts/782015863.html","content":"\n\n\n我先说明一下，我们要谈的并不是“如何成为一名管理者”。我想谈的是技术上的领先，技术上的优势，而不是一个职称，一个人事组织者。另外，我不想在理论上泛泛而谈这个事，我想谈得更落地、更实际一些，所以，我需要直面一些问题。\n\n首先，要考虑的问题是——做技术有没有前途？我们在很多场合都能听到：技术做不长，技术无用商业才有用等这样的言论。所以，在谈技术领导力前，我需要直面这个问题，否则，技术领导力就成为一个伪命题了。\n\n# 技术重要吗？\n\n在中国，程序员把自己称做“码农”，说自己是编程的农民工，干的都是体力活，加班很严重，认为做技术没有什么前途，好多人都拼命地想转管理或是转行。这是中国技术人员的一个现实问题。\n\n与国外相比，似乎中国的程序员在生存上遇到的问题更多。为什么会有这样的问题？我是这么理解的，在中国，需要解决的问题很多，而且人口众多。也就是说，中国目前处于加速发展中，遍地机会，公司可以通过“野蛮开采”来实现自身业务的快速拓展和扩张。而西方发达国家人口少一些，相对成熟一些，竞争比较激烈，所以，更多的是采用“精耕细作”的方式。\n\n此外，中国的基础技术还正在发展中，技术能力不足，所以，目前的状态下，销售、运营、地推等简单快速的业务手段显得更为有效一些，需要比拼的是如何拿到更多的“地”。而西方的“精耕细作”需要比拼的是在同样大小的一块田里，如何才能更快更多地种出“粮食”，这完全就是在拼技术了。\n\n每个民族、国家、公司和个人都有自己的发展过程。而总体上来说，中国公司目前还处于“野蛮开采”阶段，所以，这就是为什么很多公司为了快速扩张，要获得更多的用户和市场 ，需要通过加班、加人、烧钱、并购、广告、运营、销售等这些相对比较“野蛮”的方式发展自己，而导致技术人员在其中跟从和被驱动。这也是为什么很多中国公司要用“狼性”、要用“加班”、要用“打鸡血”来驱动员工完成更多的工作。\n\n但是，这会成为常态吗？中国和中国的公司会这样一直走下去吗？我并不觉得。\n\n这就好像人类的发展史一样。在人类发展的初期，蛮荒民族通过野蛮地掠夺来发展自己的民族更为有效，但我们知道资源是有限的，一旦没有太多可以掠夺的资源，就需要发展“自给自主”的能力，这就是所谓的“发展文明”。所以，我们也能看到，一些比较“文明”的民族在初期搞不过“野蛮”的民族，但是，一旦“文明”发展起来，就可以从质上完全超过“野蛮”民族。\n\n从人类历史的发展规律中，我们可以看到，各民族基本都是通过“野蛮开采”来获得原始积累，然后有一些民族开始通过这些原始积累发展自己的“文明”，从而达到强大，吞并弱小的民族。\n\n所以，对于一个想要发展、想要变强大的民族或公司来说，野蛮开采绝不会是常态，否则，只能赢得一时，长期来说，一定会被那些掌握先进技术的民族或公司所淘汰。\n\n从人类社会的发展过程中来看，基本上可以总结为几个发展阶段。\n\n- **第一个阶段：野蛮开采**。这个阶段的主要特点是资源过多，只需要开采就好了。\n- **第二个阶段：资源整合**。在这个阶段，资源已经被不同的人给占有了，但是需要对资源整合优化，提高利用率。这时通过管理手段就能实现。\n- **第三个阶段：精耕细作**。这个阶段基本上是对第二阶段的精细化运作，并且通过科学的手段来达到。\n- **第四个阶段：发明创造**。 在这个阶段，人们利用已有不足的资源来创造更好的资源，并替代已有的马上要枯竭的资源。这就需要采用高科技来达到了。\n\n这也是为什么像亚马逊、Facebook 这样的公司，最终都会去发展自己的核心技术，提高自己的技术领导力，从早期的业务型公司转变成为技术型公司的原因。那些本来技术很好的公司，比如雅虎、百度，在发展到一定程度时，将自己定位成了一个广告公司，然后开始变味、走下坡路。\n\n同样，谷歌当年举公司之力不做技术做社交也是一个失败的案例。还好拉里·佩奇（Larry Page）看到苗头不对，重新掌权，把产品经理全部移到一边，让工程师重新掌权，于是才有了无人车和 AlphaGo 这样真正能够影响人类未来的惊世之作。\n\n微软在某段时间由一个做电视购物的销售担任 CEO，也出现了技术领导力不足的情况，导致公司走下坡路。苹果公司，在聘任了一个非技术的 CEO 后也几近破产。\n\n**尊重技术的公司和不尊重技术的公司在初期可能还不能显现，而长期来看，差距就很明显了**。\n\n所以，无论是一个国家，一个公司，还是一个人，在今天这样技术浪潮一浪高过一浪的形势下，拥有技术不是问题，而问题是有没有拥有技术领导力。\n\n说的直白一点，技术领导力就是，你还在用大刀长矛打战的时候，对方已经用上了洋枪大炮；你还在赶马车的时候，对方已经开上了汽车……\n\n# 什么是技术领导力？\n\n但是，这么说还是很模糊，还是不能清楚地说明什么是技术领导力。我认为，技术领导力不仅仅是呈现出来的技术，而是一种可以获得绝对优势的技术能力。所以，技术领导力也有一些特征，为了说清楚这些特征，先让我们来看一下人类历史上的几次工业革命。\n\n**第一次工业革命**。第一次工业革命开始于 18 世纪 60 年代，一直持续到 19 世纪 30 年代至 40 年代。在这段时间里，人类生产逐渐转向新的制造过程，出现了以机器取代人力、兽力的趋势，以大规模的工厂生产取代个体工厂手工生产的一场生产与科技革命。由于机器的发明及运用成为了这个时代的标志，因此历史学家称这个时代为机器时代（the Age of Machines）。\n\n这个时期的标志技术是——“蒸汽机”。在瓦特改良蒸汽机之前，生产所需的动力依靠人力、畜力、水力和风力。伴随蒸汽机的发明和改进，工厂不再依河或溪流而建，很多以前依赖人力与手工完成的工作逐渐被机械化生产取代。世界被推向了一个崭新的“蒸汽时代”。\n\n**第二次工业革命**。第二次工业革命指的是 1870 年至 1914 年期间的工业革命。英国、德国、法国、丹麦和美国以及 1870 年后的日本，在这段时间里，工业得到飞速发展。第二次工业革命紧跟着 18 世纪末的第一次工业革命，并且从英国向西欧和北美蔓延。\n\n第二次工业革命以电力的大规模应用为代表，以电灯、电报以及无线电通信的发明为标志。这些发明把人类推向了“电力”时代。电力和内燃技术的出现，让人类进入了真正的工业时代。随着这些技术的发展，工人阶级开始受到关注，并逐渐出现了有专业知识的中产阶级，而且人数众多。\n\n**第三次工业革命**。第三次工业革命又名信息技术革命或者数字化革命，指第二次世界大战后，因计算机和电子数据的普及和推广而在各行各业发生的从机械和模拟电路再到数字电路的变革。第三次技术革命使传统工业更加机械化、自动化。它降低了工作成本，彻底改变了整个社会的运作模式，也创造了电脑工业这一高科技产业。\n\n它是人类历史上规模最大、影响最深远的科技革命，至今仍未结束。主要技术是“计算机”。计算机的发明是人类智力发展道路上的里程碑，因为它可以代替人类进行一部分脑力活动。\n\n而且，我们还可以看到，科学技术推动生产力的发展，转化为直接生产力的速度在加快。而科学技术密切结合，相互促进，在各个领域相互渗透。\n\n近代这几百年的人类发展史，从蒸汽机时代，到电力时代，再到信息时代，我们可以看到这样的一些信息。\n\n- **关键技术**。蒸汽机、电、化工、原子能、炼钢、计算机，如果只看这些东西的话，似乎没什么用。但这些核心技术的突破，可以让我们建造很多更牛的工具，而这些工具能让人类干出以前干不出来的事。\n- **自动化**。这其中最重要的事就是自动化。三次革命中最重要的事就是用机器来自动化。通信、交通、军事、教育、金融等各个领域都是在拼命地自动化，以提高效率——用更低的成本来完成更多的事。\n- **解放生产力**。把人从劳动密集型的工作中解放出来，去做更高层次的知识密集型的工作。说得难听一点，就是取代人类，让人失业。值得注意的是，今天的 AI 在开始取代人类的知识密集型的工作……\n\n因此，我们可以看到的技术领导力是：\n\n- 尊重技术，追求核心基础技术。\n- 追逐自动化的高效率的工具和技术，同时避免无效率的组织架构和管理。\n- 解放生产力，追逐人效的提高。\n- 开发抽象和高质量的可以重用的技术组件。\n- 坚持高于社会主流的技术标准和要求。\n\n# 如何拥有技术领导力？\n\n前面这些说的比较宏大，并不是所有的人都可以发明或创造这样的核心技术，但这不妨碍我们拥有技术领导力。因为，我认为，这世界的技术有两种，一种是像从马车时代到汽车时代这样的技术，也就是汽车的关键技术——引擎，另一种则是工程方面的技术，而工程技术是如何让汽车更安全更有效率地行驶。对于后者来说**，我觉得所有的工程师都有机会**。\n\n那么作为一个软件工程师怎样才算是拥有“技术领导力”呢？我个人认为，是有下面的这些特质。\n\n- **能够发现问题**。能够发现现有方案的问题。\n- **能够提供解决问题的思路和方案，并能比较这些方案的优缺点**。\n- **能够做出正确的技术决定**。用什么样的技术、什么解决方案、怎样实现来完成一个项目。\n- **能够用更优雅，更简单，更容易的方式来解决问题**。\n- **能够提高代码或软件的扩展性、重用性和可维护性**。\n- **能够用正确的方式管理团队**。所谓正确的方式，一方面是，让正确的人做正确的事，并发挥每个人的潜力；另一方面是，可以提高团队的生产力和人效，找到最有价值的需求，用最少的成本实现之。并且，可以不断地提高自身和团队的标准。\n- **创新能力**。能够使用新的方法新的方式解决问题，追逐新的工具和技术。\n\n我们可以看到，要做到这些其实并不容易，尤其，在面对不同问题的时候，这些能力也会因此不同。但是，我们不难发现，在任何一个团队中，大多数人都是在提问题，而只有少数人在回答这些人的问题，或是在提供解决问题的思路和方案。\n\n是的，一句话，总是在提供解决问题的思路和方案的人才是有技术领导力的人。\n\n那么，作为一个软件工程师，我们怎么让自己拥有技术领导力呢？总体来说，是四个方面，具体如下：\n\n- **扎实的基础技术**；\n- **非同一般的学习能力**；\n- **坚持做正确的事**；\n- **不断得高对自己的要求标准**；\n\n好了。今天要聊的内容就是这些，希望你能从中有所收获。而对于如何才能拥有技术领导力，你不妨结合我上面分享的四个点来思考一下，欢迎在留言区给出你的想法，下一篇文章，我也将会和你继续聊这个话题。\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/288\" > </iframe>","categories":["左耳听风"]},{"title":"004丨从Equifax信息泄露看数据安全","url":"/posts/1945011386.html","content":"\n\n\n上篇文章中，我们讲了 Equifax 信息泄露始末，并对造成此次事件的漏洞进行了分析。今天，我们就来回顾一下互联网时代的其他几次大规模数据泄露事件，分析背后的原因，给出解决这类安全问题的技术手段和方法。\n\n# 数据泄露介绍以及历史回顾\n\n类似于 Equifax 这样的大规模数据泄露事件在互联网时代时不时地会发生。上一次如此大规模的数据泄露事件主角应该是雅虎。\n\n继 2013 年大规模数据泄露之后，雅虎在 2014 年又遭遇攻击，泄露出 5 亿用户的密码，直到 2016 年有人在黑市公开交易这些数据时才为大众所知。雅虎股价在事件爆出的第二天就下跌了 2.4%。而此次 Equifax 的股价下跌超过 30%，市值缩水约 53 亿。这让各大企业不得不警惕。\n\n类似的，LinkedIn 在 2012 年也泄露了 6500 万用户名和密码。事件发生后，LinkedIn 为了亡羊补牢，及时阻止被黑账户的登录，强制被黑用户修改密码，并改进了登录措施，从单步认证增强为带短信验证的两步认证。\n\n国内也有类似的事件。2014 年携程网安全支付日志存在漏洞，导致大量用户信息如姓名、身份证号、银行卡类别、银行卡号、银行卡 CVV 码等信息泄露。这意味着，一旦这些信息被黑客窃取，在网络上盗刷银行卡消费将易如反掌。\n\n如果说网络运维安全是一道防线，那么社会工程学攻击则可能攻破另一道防线——人。2011 年，RSA 公司声称他们被一种复杂的网络攻击所侵害，起因是有两个小组的员工收到一些钓鱼邮件。邮件的附件是带有恶意代码的 Excel 文件。\n\n当一个 RSA 员工打开该 Excel 文件时，恶意代码攻破了 Adobe Flash 中的一个漏洞。该漏洞让黑客能用 Poison Ivy 远程管理工具来取得对机器的管理权，并访问 RSA 内网中的服务器。这次攻击主要威胁的是 SecurID 系统，最终导致了其母公司 EMC 花费 6630 万美元来调查、加固系统，并最终召回和重新分发了 30000 家企业客户的 SecurID 卡片。\n\n# 数据泄露攻击\n\n以这些公司为例，我们来看看这些攻击是怎样实现的。\n\n1. 利用程序框架或库的已知漏洞。比如这次 Equifax 被攻击，就是通过 Apache Struts 的已知漏洞。RSA 被攻击，也利用了 Adobe Flash 的已知漏洞。还有之前的“心脏流血”也是使用了 OpenSSL 的漏洞……\n2. 暴力破解密码。利用密码字典库或是已经泄露的密码来“撞库”。\n3. 代码注入。通过程序员代码的安全性问题，如 SQL 注入、XSS 攻击、CSRF 攻击等取得用户的权限。\n4. 利用程序日志不小心泄露的信息。携程的信息泄露就是本不应该能被读取的日志没有权限保护被读到了。\n5. 社会工程学。RSA 被攻击，第一道防线是人——RSA 的员工。只有员工的安全意识增强了，才能抵御此类攻击。其它的如钓鱼攻击也属于此类。\n\n然后，除了表面的攻击之外，窃取到的信息也显示了一些数据管理上的问题。\n\n1. 只有一层安全。Equifax 只是被黑客攻破了管理面板和数据库，就造成了数据泄露。显然这样只有一层安全防护是不够的。\n2. 弱密码。Equifax 数据泄露事件绝对是管理问题。至少，密码系统应该不能让用户设置如此简单的密码，而且还要定期更换。最好的方式是通过数据证书、VPN、双因子验证的方式来登录。\n3. 向公网暴露了内部系统。在公司网络管理上出现了非常严重的问题。\n4. 对系统及时打安全补丁。监控业内的安全漏洞事件，及时做出响应，这是任何一个有高价值数据的公司都需要干的事。\n5. 安全日志被暴露。安全日志往往包含大量信息，被暴露是非常危险的。携程的 CVV 泄露就是从日志中被读到的。\n6. 保存了不必要保存的用户数据。携程保存了用户的信用卡号、有效期、姓名和 CVV 码，这些信息足以让人在网上盗刷信用卡。其实对于临时支付来说，这些信息完全可以不保存在磁盘上，临时在内存中处理完毕立即销毁，是最安全的做法。即便是快捷支付，也没有必要保存 CVV 码。安全日志也没有必要将所有信息都保存下来，比如可以只保存卡号后四位，也同样可以用于处理程序故障。\n7. 密码没有被合理地散列。以现代的安全观念来说，以明文方式保存密码是很不专业的做法。进一步的是只保存密码的散列值（用安全散列算法），LinkedIn 就是这样做的。但是，散列一则需要用目前公认安全的算法（比如 SHA-2 256），而已知被攻破的算法则最好不要使用（如 MD5，能人为找到碰撞，对密码验证来说问题不大），二则要加一个安全随机数作为盐（salt）。LinkedIn 的问题正在于没有加盐，导致密码可以通过预先计算的彩虹表（rainbow table）反查出明文。这些密码明文可以用来做什么事，就不好说了，撞库什么的都有可能了。对用户来说，最好是不同网站用不同密码。\n\n# 专家建议\n\nContrast Security 是一家安全公司，其 CTO 杰夫·威廉姆斯（ Jeff Williams）在博客中表示，虽说最佳实践是确保不使用有漏洞的程序库，但是在现实中并不容易做到这一点，因为安全更新来得比较频繁。\n\n“经常，为了做这些安全性方面的更改，需要重新编写、测试和部署整个应用程序，而整个周期可能要花费几个月。我最近和几个大的组织机构聊过，他们在应对 CVE-2017-5638 这件事上花了至少四个月的时间。即便是在运营得最好的组织机构中，也经常在漏洞被发布和应用程序被更新之间有几个月的时间差。”威廉姆斯写道。\n\nApache Struts 的副总裁雷内·吉伦（René Gielen）在 Apache 软件基金会的官方博客中写道，为了避免被攻击，对于使用了开源或闭源的支持性程序库的软件产品或服务，建议如下的 5 条最佳实践。\n\n1. 理解你的软件产品中使用了哪些支持性框架和库，它们的版本号分别是多少。时刻跟踪影响这些产品和版本的最新安全性声明。\n2. 建立一个流程，来快速地部署带有安全补丁的软件产品发布版，这样一旦需要因为安全方面的原因而更新支持性框架或库，就可以快速地发布。最好能在几个小时或几天内完成，而不是几周或几个月。我们发现，绝大多数被攻破的情况是因为几个月或几年都没有更新有漏洞的软件组件而引起的。\n3. 所有复杂的软件都有漏洞。不要基于“支持性软件产品没有安全性漏洞”这样的假设来建立安全策略。\n4. 建立多个安全层。在一个面向公网的表示层（比如 Apache Struts 框架）后面建立多级有安全防护的层次，是一种良好的软件工程实践。就算表示层被攻破，也不会直接提供出重要（或所有）后台信息资源的访问权。\n5. 针对公网资源，建立对异常访问模式的监控机制。现在有很多侦测这些行为模式的开源和商业化产品，一旦发现异常访问就能发出警报。作为一种良好的运维实践，我们建议针对关键业务的网页服务应用一定要有这些监控机制。\n\n在吉伦提的第二点中说到，理想的更新时间是在几个小时到几天。我们知道，作为企业，部署了一个版本的程序库，在更新前需要在测试系统上测试各个业务模块，确保兼容以后才能上线。否则，盲目上线一个新版本，一旦遇到不兼容的情况，业务会部分或全部停滞，给客户留下不良印象，经济损失将是不可避免的。因此，这个更新周期必须通过软件工程手段来保证。\n\n一个有力的解决方案是自动化测试。对以数据库为基础的程序库，设置专门的、初始时全空的测试用数据库来进行 API 级别的测试。对于 UI 框架，使用 UI 自动化测试工具进行自动化测试。测试在原则上必须覆盖上层业务模块所有需要的功能，并对其兼容性加以验证。业务模块要连同程序库一起做集成的自动化测试，同时也要有单元测试。\n\n升级前的人工测试也有必要，但由于安全性更新的紧迫性，覆盖主要和重要路径即可。\n\n如果测试发现不兼容性，无法立即升级，那么要考虑的第二点是缓解措施（mitigation）。比如，能否禁用有漏洞的部分而不影响业务？如果不可行，那么是否可以通过 WAF 的设置来把一定特征的攻击载荷挡在门外？这些都是临时解决方案，要到开发部门把业务程序更新为能用新版本库，才能上线新版本的应用程序。\n\n# 技术上的安全做法\n\n除了上面所说的，那些安全防范的方法，我想在这里再加入一些我自己的经验。\n\n从技术上来说，安全防范最好是做到连自己内部员工都能防，因为无论是程序的 BUG 还是漏洞，都是为了取得系统的权限而获得数据。如果我们能够连内部人都能防的话，那么就可以不用担心绝大多数的系统漏洞了。所谓“家贼难防”，如果要做到这一点，一般来说，有如下的一些方式。\n\n首先，我们需要把我们的关键数据定义出来，然后把这些关键数据隔离出来，隔离到一个安全级别非常高的地方。所谓安全级别非常高的地方，即这个地方需要有各种如安全审计、安全监控、安全访问的区域。\n\n一般来说，在这个区域内，这些敏感数据只入不出。通过提供服务接口来让别的系统只能在这个区域内操作这些数据，而不是把数据传出去，让别的系统在外部来操作这些数据。\n\n举个例子，用户的手机号是敏感信息。如果有外部系统需要使用手机号，一般来说是想发个短信，那么我们这个掌管手机号数据的系统就对外提供发短信的功能，而外部系统通过 UID 或是别的抽像字段来调用这个系统的发短信的 API。信用卡也一样，提供信用卡的扣款 API 而不是把卡号返回给外部系统。\n\n另外，如果业务必需返回用户的数据，一般来说，最终用户可能需要读取自己的数据，那么，对于像信用卡这样的关键数据是死也不能返回全部数据的，只能返回一个被“马赛克”了的数据（隐藏掉部分信息）。就算需要返回一些数据（如用户的地址），那么也需要在传输层上加密返回。\n\n而用户加密的算法一定要采用非对称加密的方式，而且还要加上密钥的自动化更换，比如：在外部系统调用 100 次或是第一个小时后就自动更换加密的密钥。这样，整个系统在运行时就完全是自动化的了，而就算黑客得到了密钥，密匙也会过期，这样可以控制泄露范围。\n\n通过上述手段，我们可以把数据控制在一个比较小的区域内。\n\n而在这个区域内，我们依然会有相关的内部员工可以访问，因此，这个区域中的数据也是需要加密存放的，而加密使用的密钥则需要放在另外一个区域中。\n\n也就是说，被加密的数据和用于加密的密钥是由不同的人来管理的，有密钥的人没有数据，有数据的人没有密钥，这两拨人可以有访问自己系统的权限，但是没有访问对方系统的权限。这样可以让这两拨人互相审计，互相牵制，从而提高数据的安全性。比如，这两拨人是不同公司的。\n\n而密钥一定要做到随机生成，最好是对于不同用户的数据有不同的密钥，并且时不时地就能自动化更新一下，这样就可以做到内部防范。注明一下，按道理来说，用户自己的私钥应该由用户自己来保管，而公司的系统是不存的。而用户需要更新密钥时，需要对用户做身份鉴别，可以通过双因子认证，也可以通过更为严格的物理身份验证。例如，到银行柜台拿身份证重置密码。\n\n最后，每当这些关键信息传到外部系统，需要做通知，最好是通知用户和自己的管理员。并且限制外部系统的数据访问量，超过访问量后，需要报警或是拒绝访问。\n\n上述的这些技术手段是比较常见的做法，虽然也不能确保 100% 防止住，但基本上来说已经将安全级别提得非常高了。\n\n不管怎么样，安全在今天是一个非常严肃的事，能做到绝对的安全基本上是不可能的，我们只能不断提高黑客入侵的门槛。当黑客的投入和收益大大不相符时，黑客也就失去了入侵的意义。\n\n此外，安全还在于“风控”，任何系统就算你做得再完美，也会出现数据泄露的情况，只是我们可以把数据泄露的范围控制在一个什么样的比例，而这个比例就是我们的“风控”。\n\n所谓的安全方案基本上来说就是能够把这个风险控制在一个很小的范围。对于在这个很小范围出现的一些数据安全的泄露，我们可以通过“风控基金”来做业务上的补偿，比如赔偿用户损失，等等。因为从经济利益上来说，如果风险可以控制在一个——我防范它的成本远高于我赔偿它的成本，那么，还不如赔偿了。\n\n最后，如果你还有什么样的问题或是心得，欢迎和我交流！\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/285\" > </iframe>","categories":["左耳听风"]},{"title":"006丨如何才能拥有技术领导力？","url":"/posts/268182706.html","content":"\n\n\n通过上篇文章，相信你现在已经理解了“什么才是技术领导力”。今天，我就要跟你继续聊聊，怎样才能拥有技术领导力。\n\n**第一，你要吃透基础技术。基础技术是各种上层技术共同的基础。**吃透基础技术是为了更好地理解程序的运行原理，并基于这些基础技术进化出更优化的产品。吃透基础技术，有很多好处，具体来说，有如下几点。\n\n1. 万丈高楼平地起。一栋楼能盖多高，一座大桥能造多长，重要的是它们的地基。同样对于技术人员来说，基础知识越扎实，走得就会越远。\n2. 计算机技术太多了，但是仔细分析你会发现，只是表现形式很多，而基础技术并不多。学好基础技术，能让你一通百通，更快地使用各种新技术，从而可以更轻松地与时代同行。\n3. 很多分布式系统架构，以及高可用、高性能、高并发的解决方案基本都可以在基础技术上找到它们的身影。所以，学习基础技术能让你更好地掌握更高维度的技术。\n\n那么，哪些才是基础技术呢？我在下面罗列了一些。老实说，这些技术你学起来可能会感到枯燥无味，但是，我还是鼓励你能够克服人性的弱点，努力啃完。\n\n具体来说，可以分成两个部分：**编程和系统**。\n\n## 编程部分\n\n- **C 语言**：相对于很多其他高级语言来说，C 语言更接近底层。在具备跨平台能力的前提下，它可以比较容易地被人工翻译成相应的汇编代码。它的内存管理更为直接，可以让我们直接和内存地址打交道。\n\n  学习好 C 语言的好处是能掌握程序的运行情况，并能进行应用程序和操作系统编程（操作系统一般是汇编和 C 语言）。要学好 C 语言，你可以阅读 C 语言的经典书籍《C 程序设计语言（第 2 版）》，同时，肯定也要多写程序，多读一些优秀开源项目的源代码。\n\n  除了让你更为了解操作系统之外，学习 C 语言还能让你更清楚地知道程序是怎么精细控制底层资源的，比如内存管理、文件操作、网络通信……\n\n  这里需要说明的是，我们还是需要学习汇编语言的。因为如果你想更深入地了解计算机是怎么运作的，那么你是需要了解汇编语言的。虽然我们几乎不再用汇编语言编程了，但是如果你需要写一些如 lock free 之类高并发的东西，那么了解汇编语言，就能有助于你更好地理解和思考。\n\n- **编程范式**：各种编程语言都有它们各自的编程范式，用于解决各种问题。比如面向对象编程（C++、Java）、泛型编程（C++、Go、C#）、函数式编程（JavaScript、 Python、Lisp、Haskell、Erlang）等。\n\n  学好编程范式，有助于培养你的抽象思维，同时也可以提高编程效率，提高程序的结构合理性、可读性和可维护性，降低代码的冗余度，进而提高代码的运行效率。要学习编程范式，你还可以多了解各种程序设计语言的功能特性。\n\n- **算法和数据结构**：算法（及其相应的数据结构）是程序设计的有力支撑。适当地应用算法，可以有效地抽象问题，提高程序的合理性和执行效率。算法是编程中最最重要的东西，也是计算机科学中最重要的基础。\n\n  任何有技术含量的软件中一定有高级的算法和数据结构。比如 epoll 中使用了红黑树，数据库索引使用了 B+ 树……而就算是你的业务系统中，也一定使用各种排序、过滤和查找算法。学习算法不仅是为了写出运转更为高效的代码，而且更是为了能够写出可以覆盖更多场景的正确代码。\n\n## 系统部分\n\n- **计算机系统原理**：CPU 的体系结构（指令集 [CISC/RISC]、分支预测、缓存结构、总线、DMA、中断、陷阱、多任务、虚拟内存、虚拟化等），内存的原理与性能特点（SRAM、DRAM、DDR-SDRAM 等），磁盘的原理（机械硬盘 [盘面、磁头臂、磁头、启停区、寻道等]、固态硬盘 [页映射、块的合并与回收算法、TRIM 指令等]），GPU 的原理等。\n\n  学习计算机系统原理的价值在于，除了能够了解计算机的原理之外，你还能举一反三地反推出高维度的分布式架构和高并发高可用的架构设计。\n\n  比如虚拟化内存就和今天云计算中的虚拟化的原理是相通的，计算机总线和分布式架构中的 ESB 也有相通之处，计算机指令调度、并发控制可以让你更好地理解并发编程和程序性能调优……这里，推荐书籍《深入理解计算机系统》（Randal E. Bryant）。\n\n- **操作系统原理和基础**：进程、进程管理、线程、线程调度、多核的缓存一致性、信号量、物理内存管理、虚拟内存管理、内存分配、文件系统、磁盘管理等。\n\n  学习操作系统的价值在于理解程序是怎样被管理的，操作系统对应用程序提供了怎样的支持，抽象出怎样的编程接口（比如 POSIX/Win32 API），性能特性如何（比如控制合理的上下文切换次数），怎样进行进程间通信（如管道、套接字、内存映射等），以便让不同的软件配合一起运行等。\n\n  要学习操作系统知识，一是要仔细观察和探索当前使用的操作系统，二是要阅读操作系统原理相关的图书，三是要阅读 API 文档（如 man pages 和 MSDN Library），并编写调用操作系统功能的程序。这里推荐三本书《UNIX 环境高级编程》、《UNIX 网络编程》和《Windows 核心编程》。\n\n  学习操作系统基础原理的好处是，这是所有程序运行的物理世界，无论上层是像 C/C++ 这样编译成机器码的语言，还是像 Java 这样有 JVM 做中间层的语言，再或者像 Python/PHP/Perl/Node.js 这样直接在运行时解释的语言，其在底层都逃离不了操作系统这个物理世界的“物理定律”。\n\n  所以，了解操作系统的原理，可以让你更能从本质理解各种语言或是技术的底层原理。一眼看透本质可以让你更容易地掌握和使用高阶技术。\n\n- **网络基础**：计算机网络是现代计算机不可或缺的一部分。需要了解基本的网络层次结构（ISO/OSI 模型、TCP/IP 协议栈），包括物理层、数据链路层（包含错误重发机制）、网络层（包含路由机制）、传输层（包含连接保持机制）、会话层、表示层、应用层（在 TCP/IP 协议栈里，这三层可以并为一层）。\n\n  比如，底层的 ARP 协议、中间的 TCP/UDP 协议，以及高层的 HTTP 协议。这里推荐书籍《TCP/IP 详解》，学习这些基础的网络协议，可以为我们的高维分布式架构中的一些技术问题提供很多的技术方案。比如 TCP 的滑动窗口限流，完全可以用于分布式服务中的限流方案。\n\n- **数据库原理**：数据库管理系统是管理数据库的利器。通常操作系统提供文件系统来管理文件数据，而文件比较适合保存连续的信息，如一篇文章、一个图片等。但有时需要保存一个名字等较短的信息。如果单个文件只保存名字这样的几个字节的信息的话，就会浪费大量的磁盘空间，而且无法方便地查询（除非使用索引服务）。\n\n  但数据库则更适合保存这种短的数据，而且可以方便地按字段进行查询。现代流行的数据库管理系统有两大类：SQL（基于 B+ 树，强一致性）和 NoSQL（较弱的一致性，较高的存取效率，基于哈希表或其他技术）。\n\n  学习了数据库原理之后便能了解数据库访问性能调优的要点，以及保证并发情况下数据操作原子性的方法。要学习数据库，你可以阅读各类数据库图书，并多做数据库操作以及数据库编程，多观察分析数据库在运行时的性能。\n\n- **分布式技术架构**：数据库和应用程序服务器在应对互联网上数以亿计的访问量的时候，需要能进行横向扩展，这样才能提供足够高的性能。为了做到这一点，要学习分布式技术架构，包括负载均衡、DNS 解析、多子域名、无状态应用层、缓存层、数据库分片、容错和恢复机制、Paxos、Map/Reduce 操作、分布式 SQL 数据库一致性（以 Google Cloud Spanner 为代表）等知识点。\n\n  学习分布式技术架构的有效途径是参与到分布式项目的开发中去，并阅读相关论文。\n\n注意，**上面这些基础知识通常不是可以速成的**。虽然说，你可以在一两年内看完相关的书籍或论文，但是，我想说的是，这些基础技术是需要你用一生的时间来学习的，因为基础上的技术和知识，会随着阅历和经验的增加而有不同的感悟。\n\n**第二，提高学习能力。所谓学习能力，就是能够很快地学习新技术，又能在关键技术上深入的能力。**只有在掌握了上述的基础原理之上，你才能拥有好的学习能力。\n\n下面是让你提升学习能力的一些做法。\n\n- **学习的信息源**。信息源很重要，有好的信息源就可以更快速地获取有价值的信息，并提升学习效率。常见的信息源有 Google 等搜索引擎，Stack Overflow、Quora 等社区，图书，API 文档，论文和博客等。\n\n  这么说吧，如果今天使用中文搜索就可以满足你的知识需求，那么你就远远落后于这个时代了。如果用英文搜索才能找到你想要的知识，那么你才能算跟得上这个时代。而如果说有的问题你连用英文搜索都找不到，只能到社区里去找作者或者其他人交流，那么可以说你已真正和时代同频了。\n\n- **与高手交流**。程序员可以通过技术社区以及参加技术会议与高手交流，也可以通过参加开源项目来和高手切磋。常闻“听君一席话，胜读十年书”便是如此。与高手交流对程序员的学习和成长很有益处，不仅有助于了解热门的技术方向及关键的技术点，更可以通过观察和学习高手的技术思维及解决问题的方式，提高自己的技术前瞻性和技术决策力。\n\n  我在 Amazon 的时候，就有人和我说，多和美国的 Principle SDE 以上的工程师交流，无论交流什么，你都会有收获的。其实，这里说的就是，学习这些牛人的思维方式和看问题的角度，这会让你有质的提高。\n\n- **举一反三的思考**。比如，了解了操作系统的缓存和网页缓存以后，你要思考其相同点和不同点。了解了 C++ 语言的面向对象特性以后，思考 Java 面向对象的相同点和不同点。遇到故障的时候，举一反三，把同类问题一次性地处理掉。\n\n- **不怕困难的态度**。遇到难点，有时不花一番力气，是不可能突破的。此时如果没有不怕困难的态度，你就容易打退堂鼓。但如果能坚持住，多思考，多下功夫，往往就能找到出路。绝大多数人是害怕困难的，所以，如果你能够不怕困难，并可以找到解决困难的方法和路径，时间一长，你就能拥有别人所不能拥有的能力。\n\n- **开放的心态**。实现一个目的通常有多种办法。带有开放的心态，不拘泥于一个平台、一种语言，往往能带来更多思考，也能得到更好的结果。而且，能在不同的方法和方案间做比较，比较它们的优缺点，那么你会知道在什么样的场景下用什么样的方案，你就会比一般人能够有更全面和更完整的思路。\n\n**第三，坚持做正确的事。做正确的事，比用正确的方式做事更重要，因为这样才始终会向目的地靠拢**。哪些是正确的事呢？下面是我的观点：\n\n- **提高效率的事**。你要学习和掌握良好的时间管理方式，管理好自己的时间，能显著提高自己的效率。\n- **自动化的事**。程序员要充分利用自己的职业特质，当看见有可以自动化的步骤时，编写程序来自动化操作，可以显著提高效率。\n- **掌握前沿技术的事**。掌握前沿的技术，有利于拓展自己的眼界，也有利于找到更好的工作。需要注意的是，有些技术虽然当下很火，但未必前沿，而是因为它比较易学易用，或者性价比高。由于学习一门技术需要花费不少时间，你应该选择自己最感兴趣的，有的放矢地去学习。\n- **知识密集型的事**。知识密集型是相对于劳动密集型来说的。基本上，劳动密集型的事都能通过程序和机器来完成，而知识密集型的事却仍需要人来完成，所以人的价值此时就显现出来了。虽然现在人工智能似乎能做一些知识密集型的事（包括下围棋的 AlphaGo），但是在开放领域中相对于人的智能来说还是相去甚远。掌握了领域知识的人的价值依然很高。\n- **技术驱动的事**。不仅是指用程序驱动的事，而且还包括一切技术改变生活的事。比如自动驾驶、火星登陆等。就算自己一时用不着，你也要了解这些，以便将来这些技术来临时能适应它们。\n\n**第四，高标准要求自己。只有不断地提高标准 ，你才可能越走越高，所以，要以高标准要求自己，不断地反思、总结和审视自己，才能够提升自己**。\n\n- **Google 的自我评分卡**。Google 的评分卡是在面试 Google 时，要求应聘人对自己的技能做出评估的工具，它可以看出应聘人在各个领域的技术水平。我们可以参考 Google 的这个评分卡来给自己做评估，并通过它来不断地提高对自己的要求。（该评分卡见文末附录）。\n- **敏锐的技术嗅觉**。这是一个相对综合的能力，你需要充分利用信息源，GET 到新的技术动态，并通过参与技术社区的讨论，丰富自己了解技术的角度。思考一下是否是自己感兴趣的，能解决哪些实际问题，以及其背后的原因，新技术也好，旧技术的重大版本变化也罢。\n- **强调实践，学以致用**。学习知识，一定要实际用一用，可以是工作中的项目，也可以是自己的项目，不仅有利于吸收理解，更有利于深入到技术的本质。并可以与现有技术对比一下，同样的问题，用新技术解决有什么不同，带来了哪些优势，还有哪些有待改进的地方。\n- **Lead by Example**。永远在编程。不写代码，你就对技术细节不敏感，你无法做出可以实践的技术决策和方案。\n\n不要小看这些方法和习惯，坚持下来很有益处。谁说下一个改进方向或者重大修改建议，不可以是你给出的呢，尤其是在一些开源项目中。何为领导力，能力体现之一不就是指明技术未来的发展方向吗？\n\n吃透基础技术、提高学习能力、坚持做正确的事、高标准要求自己，不仅会让你全面提升技术技能，还能很好地锻炼自己的技术思维，培养技术前瞻性和决策力，进而形成技术领导力。\n\n然而，仅有技术还不够。作为一名合格的技术领导者，还需要有解决问题的各种软技能。比如，良好的沟通能力、组织能力、驱动力、团队协作能力等等。《技术领导之路》、《卓有成效的管理者》等多本经典图书中均有细致的讲解，这里不展开讲述，我后面内容也会有涉及。\n\n## 附 Google 评分卡\n\n0 - you are unfamiliar with the subject area.\n\n1 - you can read / understand the most fundamental aspects of the subject area.\n\n2 - ability to implement small changes, understand basic principles and able to figure out additional details with minimal help.\n\n3 - basic proficiency in a subject area without relying on help.\n\n4 - you are comfortable with the subject area and all routine work on it:\nFor software areas - ability to develop medium programs using all basic language features w/o book, awareness of more esoteric features (with book).\n\nFor systems areas - understanding of many fundamentals of networking and systems administration, ability to run a small network of systems including recovery, debugging and nontrivial troubleshooting that relies on the knowledge of internals.\n\n5 - an even lower degree of reliance on reference materials. Deeper skills in a field or specific technology in the subject area.\n\n6 - ability to develop large programs and systems from scratch. Understanding of low level details and internals. Ability to design / deploy most large, distributed systems from scratch.\n\n7 - you understand and make use of most lesser known language features, technologies, and associated internals. Ability to automate significant amounts of systems administration.\n\n8 - deep understanding of corner cases, esoteric features, protocols and systems including “theory of operation”. Demonstrated ability to design, deploy and own very critical or large infrastructure, build accompanying automation.\n\n9 - could have written the book about the subject area but didn’t; works with standards committees on defining new standards and methodologies.\n\n10 - wrote the book on the subject area (there actually has to be a book). Recognized industry expert in the field, might have invented it.\n\n**Subject Areas:**\n\n- TCP/IP Networking (OSI stack, DNS etc)\n- Unix/Linux internals\n- Unix/Linux Systems administration\n- Algorithms and Data Structures\n- C\n- C++\n- Python\n- Java\n- Perl\n- Go\n- Shell Scripting (sh, Bash, ksh, csh)\n- SQL and/or Database Admin\n- Scripting language of your choice (not already mentioned)\n- People Management\n- Project Management\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/291\" > </iframe>\n\n","categories":["左耳听风"]},{"title":"008 | Go语言，Docker和新技术","url":"/posts/59599383.html","content":"\n\n\n上个月，作为 Go 语言的三位创始人之一，Unix 老牌黑客罗勃·派克（Rob Pike）在新文章“Go: Ten years and climbing”中，回顾了 Go 语言的发展历程。文章提到，Go 语言这十年的迅猛发展快到连他们自己都没有想到，并且还成为了云计算领域新一代的开发语言。另外，文中还说到，中国程序员对 Go 语言的热爱完全超出了他们的想象，甚至他们都不敢相信是真的。\n\n这让我想起我在 2015 年 5 月拜访 Docker 公司在湾区的总部时，Docker 负责人也和我表达了相似的感叹：他们完全没有想到中国居然有那么多人喜欢 Docker，而且还有这么多人在为 Docker 做贡献，这让他们感到非常意外。此外，他还对我说，中国是除了美国本土之外的另外一个如此喜欢 Docker 技术的国家，在其它国家都没有看到。\n\n的确如他们所说，Go 语言和 Docker 这两种技术已经成为新一代的云计算技术，而且可以看到他们的发展态势非常迅猛。而中国也成为了像美国一样在强力推动这两种技术的国家。这的确是一件让人感到高兴的事儿，因为中国在跟随时代潮流这件事上已经做得相当不错了。\n\n然而就是在这样的背景下，这几年，总还是有人会问我是否要学 Go 语言，是否要学 Docker，Go 和 Docker 能否用在生产环境等等。从这些问题来看，对于 Go 语言和 Docker 这两种技术，国内的技术圈中还有相当大的一部分人在观望。\n\n所以，我想写这篇文章，并从两个方面来论述一下我的观点和看法。\n\n- 一个方面，为什么 Go 语言和 Docker 会是新一代的云计算技术。\n- 另一个方面，作为技术人员，我们如何识别什么样的新技术会是未来的趋势。\n\n这两个问题是相辅相成的，所以我会把这两个问题揉在一起谈。\n\n虽然 Go 语言是在 2009 年底开源的，但我是从 2012 年才开始接触和学习 Go 语言的。当时，我只花了一个周末两天的时间就学完了，而且在这两天的时间里，我还很快地写出了一个能完美运行的网页爬虫程序，以及一个简单的高并发文件处理服务，用于提取前面抓取的网页关键内容。这两个程序都很简单，总共不到 500 行代码。\n\n综合下来，我对 Go 语言有如下几点体会。\n\n第一，**语言简单，上手快**。Go 语言的语法特性简直是太简单了，简单到你几乎玩不出什么花招，直来直去的，学习难度很低，容易上手。\n\n第二，**并行和异步编程几乎无痛点**。Go 语言的 Goroutine 和 Channel 这两个神器简直就是并发和异步编程的巨大福音。像 C、C++、Java、Python 和 JavaScript 这些语言的并发和异步的编程方式控制起来就比较复杂了，并且容易出错，但 Go 语言却用非常优雅和流畅的方式解决了这个问题。这对于编程多年受尽并发和异步折磨的我来说，完全就是眼前一亮的感觉。\n\n![image-20230922151531596](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230922151531596.png)\n\n（图片来自 Medium：Why should you learn Go?）\n\n第三，**Go 语言的 lib 库“麻雀虽小，五脏俱全”**。Go 语言的 lib 库中基本上有绝大多数常用的库，虽然有些库还不是很好，但我觉得这都不是主要问题，因为随着技术的发展和成熟，这些问题肯定也都会随之解决。\n\n第四，**C 语言的理念和 Python 的姿态**。C 语言的理念是信任程序员，保持语言的小巧，不屏蔽底层且对底层友好，关注语言的执行效率和性能。而 Python 的姿态是用尽量少的代码完成尽量多的事。于是我能够感觉到，Go 语言是想要把 C 和 Python 统一起来，这是多棒的一件事。\n\n![image-20230922151540548](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230922151540548.png)\n\n（图片来自 Medium：Why should you learn Go?）\n\n所以，即便 Go 语言存在诸多的问题，比如垃圾回收、异常处理、泛型编程等，但相较于上面这几个优势，我认为这些问题都是些小问题。于是就毫不犹豫地入坑了。\n\n当然，一个技术能不能发展起来，关键还要看三点。\n\n- **有没有一个比较好的社区**。像 C、C++、Java、Python 和 JavaScript 的生态圈都是非常丰富和火爆的。尤其是有很多商业机构参与的社区那就更是人气爆棚了，比如 Linux 社区。\n- **有没有一个工业化的标准**。像 C、C++、Java 这些编程语言都是有标准化组织的。尤其是 Java，它在架构上还搞出了像 J2EE 这样的企业级标准。\n- **有没有一个或多个杀手级应用**。C、C++ 和 Java 的杀手级应用不用多说了，就算是对于 PHP 这样还不能算是一个优秀的编程语言来说，因为是 Linux 时代的第一个杀手级解决方案 LAMP 中的关键技术，所以，也发展起来了。\n\n在我看来，上面提到的三点至关重要，新的技术只需要占到其中一到两点就已经很不错了，何况有的技术，比如 Java 三点全都满足，所以，Java 的蓬勃发展也在情理之中。当然，除了上面这三点重要的，还有一些其它的影响因素，比如：\n\n- **学习难度是否低，上手是否快**。这点非常重要，C++ 在这点上越做越不好了。\n- **有没有一个不错的提高开发效率的开发框架**。如：Java 的 Spring 框架，C++ 的 STL 等。\n- **是否有一个或多个巨型的技术公司作为后盾**。如：Java 和 Linux 后面的 IBM、Sun……\n- **有没有解决软件开发中的痛点**。如：Java 解决了 C 和 C++ 的内存管理问题。\n\n用这些标尺来衡量一下 Go 语言，我们可以清楚地看到：\n\n- Go 语言容易上手；\n- Go 语言解决了并发编程和底层应用开发效率的痛点；\n- Go 语言有 Google 这个世界一流的技术公司在后面；\n- Go 语言的杀手级应用是 Docker 容器，而容器的生态圈这几年可谓是发展繁荣，也是热点领域。\n\n所以，Go 语言的未来是不可限量的。当然，我个人觉得，Go 可能会吞食很多 C、C++、Java 的项目。不过，Go 语言所吞食的项目应该主要是中间层的项目，既不是非常底层也不会是业务层。\n\n也就是说，Go 语言不会吞食底层到 C 和 C++ 那个级别的，也不会吞食到上层如 Java 业务层的项目。Go 语言能吞食的一定是 PaaS 上的项目，比如一些消息缓存中间件、服务发现、服务代理、控制系统、Agent、日志收集等等，他们没有复杂的业务场景，也到不了特别底层（如操作系统）的软件项目或工具。而 C 和 C++ 会被打到更底层，Java 会被打到更上层的业务层。这是我的一个判断。\n\n好了，我们再用上面的标尺来衡量一下 Go 语言的杀手级应用 Docker，你会发现基本是一样的。\n\n- Docker 容易上手。\n- Docker 解决了运维中的环境问题以及服务调度的痛点。\n- Docker 的生态圈中有大公司在后面助力，比如 Google。\n- Docker 产出了工业界标准 OCI。\n- Docker 的社区和生态圈已经出现像 Java 和 Linux 那样的态势。\n- ……\n\n所以，早在三四年前我就觉得 Docker 一定会是未来的技术。虽然当时的坑儿还很多，但是，相对于这些大的因素来说，那些小坑都不是问题。只是需要一些时间，这些小坑在未来 5-10 年就可以完全被填平了。\n\n同样，我们可以看到 Kubernetes 作为服务和容器调度的关键技术一定会是最后的赢家。这点我在去年初就能够很明显地感觉到了。\n\n关于 Docker 我还想多说几句，这是云计算中 PaaS 的关键技术。虽然，这世上在出现 Docker 之前，几乎所有的要玩公有 PaaS 的公司和产品都玩不起来，比如：Google 的 GAE，国内的各种 XAE，如淘宝的 TAE，新浪的 SAE 等。但我还是想说，**PaaS 是一个被世界或是被产业界严重低估的平台**。\n\nPaaS 层是承上启下的关键技术，任何一个不重视 PaaS 的公司，其技术架构都不可能让这家公司成长为一个大型的公司。因为 PaaS 层的技术主要能解决下面这些问题。\n\n- **软件生产线的问题**。持续集成和持续发布，以及 DevOps 中的技术必须通过 PaaS。\n- **分布式服务化的问题**。分布式服务化的服务高可用、服务编排、服务调度、服务发现、服务路由，以及分布式服务化的支撑技术完全是 PaaS 的菜。\n- **提高服务的可用性 SLA**。提高服务可用性 SLA 所需要的分布式、高可用的技术架构和运维工具，也是 PaaS 层提供的。\n- **软件能力的复用**。软件工程中的核心就是软件能力的复用，这一点也完美地体现在 PaaS 平台的技术上。\n\n老实说，这些问题的关键程度已经到了能判断一家技术驱动公司的研发能力是否靠谱的程度。没有这些技术，我认为，依托技术拓展业务的公司机会就不会很大。\n\n在后面，我会另外写几篇文章给你详细地讲一下分布式服务化和 PaaS 平台的重要程度。\n\n最后，我还要说一下，为什么要早一点地进入这些新技术，而不是等待这些技术成熟了后再进入。原因有这么几个。\n\n- **技术的发展过程非常重要**。我进入 Go 和 Docker 的技术不能算早，但也不算晚，从 2012 年学习 Go，再到 2013 年学习 Docker 再到今天，我清楚地看到了这两种技术的生态圈发展过程。这个过程中，我收获最大的并不是这些技术本身，而是一个技术的变迁和行业的发展。\n\n从中，我看到了非常具体的各种浪潮和思路，这些东西比起 Go 和 Docker 来说更有价值。因为，这不但让我重新思考我已掌握的技术以及如何更好地解决已有的问题，而且还让我看到了未来。我不但有了技术优势，而且这些知识还让我的技术生涯有了更多的可能性。\n\n- **这些关键新技术，可以让你提前抢占技术的先机**。这一点对一个需要技术领导力的个人或公司来说都是非常重要的。\n\n如果一个公司或是个人能够占有技术先机，就会比其它公司或个人有更大的影响力。一旦未来行业需求引爆，那么这个公司或是个人的影响力就会形成一个比较大的护城河，并可以快速地从中获取经济利益。\n\n最近，在与中国移动、中国电信以及一些股份制银行交流的过程中，我看到通讯行业、金融行业对于 PaaS 平台的理解已经超过了互联网公司，而我近 3 年来在这些技术上的研究让我也从中受益匪浅。\n\n所以，Go 语言和 Docker 作为 PaaS 平台的关键技术前途是无限的，我很庆幸自己赶上了这波浪潮，也很庆幸自己在 3 年前就看到了这个趋势，所以现在我也在用这些技术开发相关的技术产品，并助力于为高速成长的公司提供这些关键技术。\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/294\" > </iframe>","categories":["左耳听风"]},{"title":"007丨推荐阅读：每个程序员都该知道的知识","url":"/posts/4126243316.html","content":"\n\n\n在整个为期一年的专栏内容中，我会逐步向你推荐一些有价值的内容，供你参考，这些内容有中文，有英文，也有视频，它们都是我认为对我非常有价值的信息，我也希望它们对你能有同样的帮助和启发。\n\n今天，我为你推荐的 5 篇文章，它们分别是：\n\n- Stack Overflow 上推荐的一个经典书单；\n- 美国某大学教授给计算机专业学生的一些建议，其中有很多的学习资源；\n- LinkedIn 的高效代码复查实践，很不错的方法，值得你一读；\n- 一份关于程序语言和 bug 数相关的有趣的报告，可以让你对各种语言有所了解；\n- 最后是一本关于 C++ 性能优化的电子书。\n\n#### 每个程序员都应该要读的书\n\n在 Stack Overflow 上有用户问了一个[问题](https://stackoverflow.com/questions/1711/what-is-the-single-most-influential-book-every-programmer-should-read)，大意是想让大家推荐一些每个程序员都应该阅读的最有影响力的图书。\n\n虽然这个问题已经被关闭了，但这真是一个非常热门的话题。排在第一位的用户给出了一大串图书的列表，看上去着实吓人，不过都是一些相当经典相当有影响力的书，在这里我重新罗列一些我觉得你必须要看的。\n\n- **《代码大全》** 虽然这本书有点过时了，而且厚到可以垫显示器，但是这绝对是一本经典的书。\n- **《程序员修练之道》** 这本书也是相当经典，我觉得就是你的指路明灯。\n- **《计算机的构造和解释》** 经典中的经典，必读。\n- **《算法导论》** 美国的本科生教材，这本书应该也是中国计算机学生的教材。\n- **《设计模式》** 这本书是面向对象设计的经典书籍。\n\n- **《重构》** 代码坏味道和相应代码的最佳实践。\n- **《人月神话》** 这本书可能也有点过时了。但还是经典书。\n- **《代码整洁之道》** 细节之处的效率，完美和简单。\n- **《Effective C++》/《More Effective C++》** C++ 中两本经典得不能再经典的书。也许你觉得 C++ 复杂，但这两本书中带来对代码稳定性的探索方式让人受益，因为这种思维方式同样可以用在其它地方。以至于各种模仿者，比如《Effective Java》也是一本经典书。\n- **《Unix 编程艺术》、《Unix 高级环境编程》**也是相关的经典。\n\n还有好多，我就不在这里一一列举了。你可以看看其它的答案，我发现自己虽然读过好多书，但同样还有好些书没有读过，这个问答对我也很有帮助。\n\n#### 每个搞计算机专业的学生应有的知识\n\n**[What every computer science major should know](http://matt.might.net/articles/what-cs-majors-should-know/)**，每个搞计算机专业的学生应有的知识。\n\n本文作者马修·迈特（Matthew Might）是美国犹他大学计算机学院的副教授，2007 年于佐治亚理工学院取得博士学位。计算机专业的课程繁多，而且随着时代的变化，科目的课程组成也在不断变化。\n\n如果不经过思考，直接套用现有的计算机专业课程列表，则有可能忽略一些将来可能变得重要的知识点。为此，马修力求从四个方面来总结，得出这篇文章的内容。\n\n1. 要获得一份好工作，学生需要知道什么？\n2. 为了一辈子都有工作干，学生需要知道什么？\n3. 学生需要知道什么，才能进入研究生院？\n4. 学生需要知道什么，才能对社会有益？\n\n这篇文章不仅仅对刚毕业的学生有用，对有工作经验的人同样有用，这里我把这篇文章的内容摘要如下。\n\n首先，对于我们每个人来说，作品集（Portfolio）会比简历（Resume）更有参考意义。所以，在自己的简历中应该放上自己的一些项目经历，或是一些开源软件的贡献，或是你完成的软件的网址等。最好有一个自己的个人网址，上面有一些你做的事、自己的技能、经历，以及你的一些文章和思考会比简历更好。\n\n其次，计算机专业工作者也要学会与人交流的技巧，包括如何写演示文稿，以及面对质疑时如何与人辩论的能力。\n\n最后，他就各个方面展开计算机专业人士所需要的硬技能：工程类数学、Unix 哲学和实践、系统管理、程序设计语言、离散数学、数据结构与算法、计算机体系结构、操作系统、网络、安全、密码学、软件测试、用户体验、可视化、并行计算、软件工程、形式化方法、图形学、机器人、人工智能、机器学习、数据库等等。详读本文可以了解计算机专业知识的全貌。\n\n这篇文章的第三部分简直就是一个知识资源向导库，给出了各个技能的方向和关键知识点，你可以跟随着这篇文章里的相关链接学到很多东西。\n\n# LinkedIn 高效的代码复查技巧\n\n**[LinkedIn’s Tips for Highly Effective Code Review](https://thenewstack.io/linkedin-code-review/)**，LinkedIn 的高效代码复查技巧。\n\n对于 Code Review，我曾经写过一篇文章 《[从 Code Review 谈如何做技术](https://coolshell.cn/articles/11432.html)》，讲述了为什么 Code Review 是一件很重要事情。今天推荐的这篇文章是 LinkedIn 的相关实践。\n\n这篇文章介绍了 LinkedIn 内部实践的 Code Review 形式。具体来说，LinkedIn 的代码复查有以下几个特点。\n\n- 从 2011 年开始，强制要求在团队成员之间做代码复查。Code Review 带来的反馈意见让团队成员能够迅速提升自己的技能水平，这解决了 LinkedIn 各个团队近年来因迅速扩张带来的技能不足的问题。\n\n- 通过建立公司范围的 Code Review 工具，这就可以做跨团队的 Code Review。既有利于消除 bug，提升质量，也有利于不同团队之间经验互通。\n\n- Code Review 的经验作为员工晋升的参考因素之一。\n\n- Code Review 的一个难点是，Reviewer 可能不了解某块代码修改的背景和目的。所以 LinkedIn 要求代码签入版本管理系统前，就对其做清晰的说明，以便复查者了解其目的，促进 Review 的进行。\n\n  我认为，这个方法实在太赞了。因为，我看到很多时候，Reviewer 都会说不了解对方代码的背景或是代码量比较大而无法做 Code Review，然而，他们却没有找到相应的方法解决这个问题。\n\n  LinkedIn 对提交代码写说明文档这个思路是一个非常不错的方法，因为代码提交人写文档的过程其实也是重新梳理的过程。我的个人经验是，写文档的时候通常会发现自己把事儿干复杂了，应该把代码再简化一下，于是就会回头去改代码。是的，写文档就是在写代码。\n\n- 有些 Code Review 工具所允许给出的反馈只是代码怎样修改以变得更好，但长此以往会让人觉得复查提出的意见都表示原先的代码不够好。为了提高员工积极性，LinkedIn 的代码复查工具允许提出“这段代码很棒”之类的话语，以便让好代码的作者得到鼓励。我认为，这个方法也很赞，正面鼓励的价值也不可小看。\n\n- 为 Code Review 的结果写出有目的性的注释。比如“消除重复代码”，“增加了测试覆盖率”，等等。长此以往也让团队的价值观得以明确。\n\n- Code Review 中，不但要 Review 提交者的代码，还要 Reivew 提交者做过的测试。除了一些单元测试，还有一些可能是手动的测试。提交者最好列出所有测试过的案例。这样可以让 Reviewer 可以做出更多的测试建议，从而提高质量。\n\n- 对 Code Review 有明确的期望，不过分关注细枝末节，也不要炫技，而是对要 Review 的代码有一个明确的目标。\n\n# 编程语言和代码质量的研究报告\n\n**[A Large-Scale Study of Programming Languages and Code Quality in GitHub](https://cacm.acm.org/magazines/2017/10/221326-a-large-scale-study-of-programming-languages-and-code-quality-in-github/)**，编程语言和代码质量的研究报告。\n\n这是一项有趣的研究。有四个人从 GitHub 上分析了 728 个项目，6300 万行代码，近 3 万个提交人，150 万次 commits，以及 17 种编程语言（如下图所示），他们想找到编程语言对软件质量的影响。\n\n其中分析的方法我不多说了。我们来看一下相关的结果。\n\n首先，他们得出来的第一个结果是，从查看 bug fix 的 commits 的次数情况来看，C、C++、Objective-C、PHP 和 Python 中有很多很多的 commits 都是和 bug fix 相关的，而 Clojure、Haskell、Ruby、Scala 在 bug fix 的 commits 的数上明显要少很多。\n\n第二个结论是，函数式编程语言的 bug 明显比大多数其它语言要好很多。有隐式类型转换的语言明显产生的 bug 数要比强类型的语言要少很多。函数式的静态类型的语言要比函数式的动态类型语言的程序出 bug 的可能性要小很多。\n\n第三，研究者想搞清是否 bug 数会和软件的领域相关。比如，业务型、中间件型、框架、lib，或是数据库。研究表明，并没有什么相关性。下面这个图是各个语言在不同领域的 bug 率。\n\n第四，研究人员想搞清楚 bug 的类型是否会和语言有关系。的确如此，bug 的类型和语言是强相关性的。下图是各个语言在不同的 bug 类型的情况。如果你看到的是正数，说明高于平均水平，如果你看到的是负数，则是低于平均水平。\n\n也许，这份报告可以在你评估编程语言时有一定的借鉴作用。\n\n# 电子书：《C++ 软件性能优化》\n\n**[Optimizing Software in C++ - Agner Fog](http://agner.org/optimize/optimizing_cpp.pdf)** - PDF，C++ 软件性能优化。\n\n这本书是所有 C++ 程序员都应该要读的一本书，它从事无巨细地从语言层面、编译器层面、内存访问层面、多线程层面、CPU 层面讲述了如何对软件性能调优。实在是一本经典的电子书。\n\nAgner Fog 还写了其它几本和性能调优相关的书，你可以到这个网址[下载](：http://www.agner.org/optimize/)。\n\n- Optimizing subroutines in assembly language: An optimization guide for x86 platforms\n- The microarchitecture of Intel, AMD and VIA CPUs: An optimization guide for assembly programmers and compiler makers\n- Instruction tables: Lists of instruction latencies, throughputs and micro-operation breakdowns for Intel, AMD and VIA CPUs\n- Calling conventions for different C++ compilers and operating systems\n\n我今天推荐的内容比较干，都需要慢慢吸收体会，当然最好是能到实践中用用，相信这样你会有更多的感悟和收获。另外，不知道你还对哪些方面的内容感兴趣，欢迎留言给我。我后面收集推荐内容的时候，会有意识地关注整理。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/471\" > </iframe>","categories":["左耳听风"]},{"title":"009丨答疑解惑：渴望、热情和选择","url":"/posts/3192932670.html","content":"\n\n\n自从专栏上线以来，我陆陆续续从专栏留言、微信、微博、公开演讲等多种途径收到了一些用户的提问。在这篇答疑文章中，我特意挑选了其中最有代表性的三个问题来回答，希望能对你有帮助。\n\n- 加班太严重完全没有时间学习，怎么办？\n- 为什么你能写出这么多东西？\n- 怎样选择自己的人生和职业发展？\n\n# 加班太严重完全没有时间学习，怎么办？\n\n过去的 7 年时间里，这个问题我已经被很多人问过无数遍了。我觉得有必要在这里统一回答一下。老实说，我真的很理解年轻人工作压力大这事儿，现在的公司加班都很厉害，尤其在大城市工作还要算上路上奔波的时间，这样一来，对于很多人来说，可能就完全没有时间学习和成长了。\n\n但是从另外一方面，我们在通宵打游戏，追美剧，泡妞的时候，从来不会给自己找借口说时间不够。我们总是能够挤得出时间来干这些“顺人性”的事，甚至做到废寝忘食，而不找任何借口。\n\n所以，我觉得，可能并不在于加班和工作强度大到没时间，关键看你对学习有多少的渴望程度，对要学的东西有多大的热情。这点是非常重要的，因为学习这事其实挺反人性的。反人性的事基本上都是要付出很多，而且还要坚持很久。所以，如果对学习没有渴望的话，或是不能从学习中找到快乐的话，那么其实是很难坚持的，无论你有没有时间。\n\n说两个发生在我身上的故事供大家参考。\n\n第一个故事，发生在 2001 年到 2002 年期间，那时我还是一个外包程序员，有一整年被当成劳动力外包进了某银行做软件开发，从早上 9 点工作到晚上 10 点，每周要从周一工作到周六。这么忙，但是我坚持每天晚上看半个小时到一个小时的书，看得不多，一天 2-3 页。一年后，我看完了两本经典书，一本是《TCP/IP 详解：卷 I》，另一本是《UNIX 环境高级编程》。\n\n第二个故事，是在 2002 年到 2003 年的时候，我到了一家做分布式系统的公司工作。因为那里的技术比较复杂，我有点跟不上，所以，周末和节假日的时候，我都会到公司来，不是工作，而是看书学习（因为那时我是一个北漂，完全没有个人电脑，只能去蹭公司的电脑）。后来公司的物管都认识了我，甚至经常在周末和节假日的时候打电话给我，让我帮物业做点小事。比如某空调漏水，让我帮他们把接水的桶倒一下……\n\n我真的不算聪明的人，但是，我对学习真的是有渴望的。说得好听一点，我希望自己在不停地成长，不辜负生活在这个信息化大变革的时代。说得不好一点，我从银行出来了，很多人要看我的笑话，我不能让他们看我的笑话，所以我必须努力。我的渴望就来自这两点。\n\n时间一定是能找得到的，就看你对你要干的事有多大的渴望程度和多大的热情。 只要你真的想做，你就一定能想出各种各样的招儿来为自己挤出时间。\n\n在后面的文章中，我还会写一些关于时间管理的主题，敬请关注。\n\n# 为什么你能够写出这么多东西？\n\n其实，还是上面的那个问题，就是你对写作这个事有多少的兴趣和热情。\n\n我还是先说一下，我对写东西这个事的热情是怎么来的。从 2002 年开始写东西到今天，我基本上经历了几个阶段。\n\n**第一个阶段，是学习的阶段**。因为在我刚入行的时候，软件公司对文档的要求还是比较高的，干什么事都要写个文档，所以，我就有了写文档的习惯。不过，这个阶段，对于我个人来说，我会把学习到的东西都以笔记的方式记录下来，方便我以后可以翻出来看看。所以，这个阶段主要还是学习的阶段。\n\n**第二个阶段，是有利益驱动的阶段**。正如《程序员如何用技术变现》一文中提到的，因为我写的一篇技术文章，让我接到了一个培训的私活，两天时间就挣了我一个月的工资。说实话，这件事给了我很大的鼓励，让我有了更多的热情来写文章。\n\n**第三个阶段，是记录自己观点打自己脸的阶段**。这个时候，我遇到了博客火爆的时代，我看到很多人写博客来记录自己的观点和想法，我也跟着写博客，记录一些自己的想法和观点。时间一长，我发现有个有趣的事——我看自己好几年前写的东西，发现要么是我以前记录的观点打了现在的脸，要么就是现在打了自己过去的脸。\n\n这种有点科幻色彩的跨时空打自己脸的方式，让我觉得很好，因为这里面，我能够看到自己成长的过程，并且可以及时修正，这真是太好了。\n\n**第四个阶段，是与他人交互的阶段**。这个阶段，我开始写一些观点鲜明，甚至看上去比较极端或是理想的文章了。而且我的文章开始有很多人转载和评论，还时不时地引发争论。我发现在这个过程中，我的收获也很大，因为一旦一件事被真正地讨论起来（而不是点赞和转发），就会有很多知识命中了我的认知盲区。虽然这会被别人批评或是指责，但是，我能从中收获到更多，因为我会从不同的观点，以及别人的批评中，让自己变得更加完善和成熟。\n\n而且，我从写作中还能训练自己的表达能力，这让我能够更好更漂亮地与别人交流和沟通。这一点对于我们整天面对电脑的技术人员来说，太重要了。\n\n因为我能从写作中得到这么多的好处，所以我当然就能坚持下来了。虽然，我近几年的文章更新频率比较低，但是，我还是在坚持，因为我能从中收获很多对我个人有帮助、有提升、有价值的东西。\n\n我相信，只要你坚持下来，你一定也会有和我一样的感受。\n\n# 怎样选择自己的人生和职业发展？\n\n这也是一个我经常被问到的问题。老实说，我因为这个问题写了好多文章，比如在 CoolShell 上的《技术人员的发展之路》、《算法与人生》，包括在知乎上的一些回答。不过，老实说，这个问题实在是太大了。而且不同的人有不同的想法和追求，所以，这是一个完全没有正确答案的问题。\n\n虽然我给不出具体的答案，但是我还是可以给出一些相关的思路。希望这些思想能对你有启发，能帮助你规划和思考自己的职业或是人生。\n\n总体来说，我把人生分为两个阶段。\n\n- **一个是在 20-30 岁，这是打基础的阶段**。在这个阶段，我们要的是开阔眼界，把基础打扎实，努力学习和成长。\n- **另一个是在 30-40 岁，这是人生发展的阶段**。因为整个社会一定会把社会的重担交给这群人，30-40 岁的人年富力强，既有经验又有精力，还敢想敢干，所以这群人才是整个社会的中流砥柱。在这个阶段，你需要明确自己奋斗的方向，需要做有挑战的事儿，需要提升自己的技术领导力（关于如何发展技术领导力，可以参看我在本专栏的相关文章）。\n\n而过了 40 岁，你的事业和人生就有可能会被定型，不过这也不是绝对的。我只是想说，20-40 岁这 20 年是我们每个人最黄金的发展阶段，我们每一个人都要好好把握。\n\n除此之外，我再从我的角度给大家一些建议。\n\n1. **客观地审视自己**。找到自己的长处，不断地在自己的长处上发展自我。知道自己几斤几两才能清楚自己适合干什么。不然，目标设置得过高自己达不到，反而让自己难受。在职场上，审视自己的最佳方式，就是隔三差五就出去面试一把，看看自己在市场上能够到什么样的级别。**如果你超过了身边的大多数人，你不妨选择得激进一些冒险一些，否则，还是按部就班地来吧**。\n2. **确定自己想要什么**。如果不确定这个事，你就会纠结，不知道自己要什么，也就不知道自己要去哪里。注意，你不可能什么都要，你需要极端地知道自己要什么。**所谓“极端”，就是自己不会受到其它东西或其他人的影响，不会因为这条路上有人退出你会开始怀疑或者迷茫，也不会因为别的路上有人成功了，你就会羡慕**。\n3. **注重长期的可能性，而不是短期的功利**。20-30 岁应该多去经历一些有挑战的事，多去选择能给自己带来更多可能性的事。多去选择能让自己成长的事，尤其是能让自己开阔眼界的事情。人最害怕的不是自己什么都不会，而是自己不知道自己不会。\n4. **尽量关注自己会得到的东西，而不是自己会失去的东西**。因为无论你怎么选，你都会有得有失。（绝大多数人都会考虑自己会失去的，而不是考虑自己会得到的。）\n5. **不要和大众的思维方式一样**。因为，绝大多数人都是平庸的，所以，如果你的思维方式和大众一样，这意味着你做出来的选择也会和大众一样平庸。如果你和大众不一样，那么只有两种情况，一个是你比大多数人聪明，一个是你比大多数人愚蠢。\n\n希望我的这些思考能给你一些启发和帮助。我最近有个感慨就是，很多事情能做到什么程度，其实在思想的源头就被决定了，因为它会绝大程度地受到思考问题的出发点、思维方式、格局观、价值观等因素影响。这些才是最本源的东西，甚至可以定义成思维的“基因”。就我们程序员而言，我认为，编码能力很重要，但是技术视野、技术洞察力，以及我们如何用技术解决问题的能力更为重要。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/540\" > </iframe>","categories":["左耳听风"]},{"title":"010丨如何成为一个大家愿意追随的Leader？","url":"/posts/553570751.html","content":"\n\n\n之前的文章，我们分享过技术领导力（Leadership）相关的话题，主要讨论了作为一个技术人，如何取得技术上的领先优势，而不是如何成为一个技术管理者。今天的文章中，我们着重聊聊如何成为一个大家愿意跟随的技术领导者（Leader）。注意，Leader 不是管理者，不是经理，更不是职称，而是一个领头人。\n\n所谓领头人和经理或管理者的最大差别就是，领头人（Leader）是大家愿意追随的，而经理或管理者（Boss）则是一种行政和职位上的威慑。说白了，Leader 的影响力来自大家愿意跟随的现象，而经理或管理者的领导力来自职位和震慑，这两者是完全不同的。\n\n# Leader 和 Boss 的不同\n\n再或者用通俗的话说，Leader 是大家跟我一起上，而 Boss 则是大家给我上，一个在团队的前面，一个在团队的后面。\n\n具体来说，这两者的不同点如下。\n\n- **Boss 是驱动员工，Leader 是指导员工**。在面对项目的时候，Boss 制定时间计划，并且推动（push）和鞭策员工完成工作，而 Leader 则是和员工一起讨论工作细节，指导员工关注工作的重点，和员工一起规划出（work out）工作的方向和计划，并且在工作中和员工一起解决细节难题，帮助员工完成工作。\n- **Boss 制造畏惧，Leader 制造热情**。Boss 在工作中是用工作职位级别压人，用你的绩效考核来制造威慑，让员工畏惧他，从而推行工作。而 Leader 是通过描绘远景，制造激动人心的目标来鼓舞和触发团队的热情和斗志。\n\n- **Boss 面对错误喜欢使用人事惩罚的手段，而 Leader 面对错误喜欢寻找解决问题的技术或管理方法**。惩罚员工和解决问题完全是两码事，Boss 因为并不懂技术也并不懂问题的细节，所以他们只能使用惩罚这样的手段，而 Leader 通常是喜欢解决问题的技术型人才，所以，他们会深入技术细节，从技术上找到既治标又治本的技术方案或管理方式。\n- **Boss 只是知道怎么做，而 Leader 则是展示怎么做**。一个好 Leader 的最大特点就是 Lead by Example，以身作则，用身教而不是言传。而 Boss 只是在说教，总是在大道理上说的一套又一套，但从来不管技术细节。\n- **Boss 是用人，而 Leader 是发展人**。Boss 不关心人的发展，把人当成劳动力。而 Leader 则会看到人的潜力和特长，通过授权、指导和给员工制定成长计划让员工成长，从而发展员工。所以，我们通常可以看到 Boss 总是说自己的员工有这个问题有那个问题，而 Leader 总是说，如何让员工成长以解决员工个人的各种问题。\n- **Boss 从团队收割成绩，而 Leader 则是给予团队成绩**。Boss 通常都会把团队的成绩占为己有，虽然 Boss 会说这是团队的功劳，但基本上是一句带过。而 Leader 则是让团队成功，让团队的成员站在台前，自己甘当绿叶和铺路石。Leader 知道只有团队的每个人成功了，团队才会成功，所以，Leader 会帮助团队中的每个人更好更流畅地走向成功。\n- **Boss 喜欢命令和控制（ Command + Control ），而 Leader 喜欢沟通和协作（ Communication + Cooperation ）**。Boss 喜欢通过命令来控制员工的行为，从而实现团队的有效运转，而 Leader 喜欢通过沟通和协作来增加员工的参与感，从而让员工觉得这是自己的事，愿意为之付出。\n- **Boss 喜欢说“给我上”，而 Leader 喜欢说“跟我上”**。Boss 总是躲在团队后面，让团队冲锋陷阵，而 Leader 总是冲在前面用自己的行动领着团队浴血奋战。\n\n![image-20230922151226417](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230922151226417.png)\n\n从上面这些比较，我们应该可以看到 Boss 和 Leader 的不同，相信你已经有了一些了解和认识到什么才是一个真正的 Leader，什么才是一个 Leader 应有的素质和行为。\n\n下面，我将结合我的一些经历和经验分享一下，如何才能成为一个大家愿意追随的人。\n\n# 如何成为众人愿意追随的 Leader\n\n说白了，要成为一个大家愿意追随的人，那么你需要有以下这些“征兆”。\n\n- **帮人解决问题**。团队或身边大多数人都在问：“这个问题怎么办？”，而你总是能站出来告诉大家该怎么办。\n- **被人依赖**。团队或身边大多数人在做比较关键的决定时，都会来找你咨询意见和想法。\n\n要有这样的现象，你需要有技术领导力。关于技术领导力，你可以参看本专栏主题为《如何才能拥有技术领导力？》的文章。有没有技术领导力（Leadership），是成为一个 Leader 非常关键的因素。因为人们想要跟随的人通常都是比自己强比自己出色的人，或是能够跟他学到东西，能够跟他成长的人。\n\n但是，有了技术领导力可能并不够，作为一个 Leader，你还需要有其它的一些能力和素质。比如，和我一起共事过的人和下属，他们会把我当成他们的朋友，他们会和我交流很多在员工和老板间比较禁忌的话题，比如：\n\n- 有猎头或是别的公司来挖我的下属，我的下属会告诉我，并会征求我的意见。除了帮他们分析利弊，有些时候，我还会帮他们准备面试。甚至，我有时候还会为我的下属介绍其它公司的工作机会。不要误会我（Don’t get me wrong），我并不是不站在公司利益的角度，我这样做完全是站在公司利益的角度。\n\n  你要知道这个世界很大，一个公司或是一个 Leader 很难做到把人一辈子留下来，因为人总是需要有不同经历的，优秀的人更是如此。既然做不到把人留一辈子，那么不妨把这件事做得漂亮一些，这样会让要离开的员工觉得这个 Leader 或是这个公司的胸怀不一般，可能是他再也碰不到的公司或 Leader，反而会想留下来，或是离开后又想回来。\n\n- 下属会来找我分享他的难处和让他彷徨的事情，包括吐槽公司。一般来说，下属是不会找老板吐槽公司的，因为这是办公室中的禁忌。但是作为老板和经理，其实我们都知道，员工是一定会吐槽老板和公司的。既然做不到不让员工吐槽公司，那么不妨让这件事做得更漂亮一些——可以公开透明地说，而不是在背后说，因为在背后说对公司或是团队的伤害更大。\n\n举了上面两个例子，我只是想告诉你一个 Leader 除了有技术领导力还需要有其它的素质和人格魅力。如果你的员工把这些看似禁忌的事和你分享向你倾吐，说明他们是何等信任你，何等看重你，这就说明你对他的价值已经非同寻常了，这份信任和托付对于一个 Leader 来说要小心呵护。\n\n下面是我罗列的一些比较关键的除了技术领导力之外的一个 Leader 需要的素质。\n\n- **赢得他人的信任**。信任是人类一切活动的基础，人与人之间的关系是否好，完全都是基于信任的。**对于信任来说，并不完全是别人相信你能做到某个事，还有别人愿意向你打开心扉，和你说他心里面最柔软的东西。而后者才是真正的信任**。这还需要你的人格魅力，你的真诚，你的可信，你的价值观和你的情怀等一些诸多因素，才会让别人愿意找你分享心中的想法和情绪。\n\n- **开放的心态 + 倾向性的价值观**。这两个好像太矛盾了，其实并不是。我想说的是，对于新生事物要有开放的心态，对于每个人的观点都有开放的心态，但并不是要认同所有的观点和事情，成为一个油腔滑调的人。\n\n  也就是说，我可以听进各种不同观点，并在讨论中根据自己的价值观对不同的观点做出相应的判断，而并不是不加判断全部采用。因为如果你要做一个 Leader，你需要有明确的方向和观点，而不是说一些放之四海皆准的完全正确的废话。我的经验告诉我，对于各种各样的技术都要持一种比较开放的态度，可以讨论优缺点，但不会争个是非对错，尤其对于新技术来说，更要开放。\n\n  然而，就价值观来说，还是需要有倾向性的，比如，我就倾向于不加班的文化，倾向于全栈，倾向于按职责分工而不是按技能分工，倾向于做一个 Leader 而不是 Boss，倾向于技术是第一生产力，倾向于 OKR 而不是 KPI……\n\n  **我的这些倾向性可以让别人更清楚地知道我是一个什么样的人，而不会对我琢磨不透，一会东一会西只会让人觉得你太油了，反而会产生距离感和厌恶感。我认为，倾向性的价值观是别人是否可以跟随你的一个基础**。\n\n- **Lead by Example**。用自己的示例来 Lead，用自己的行为来向大家展示你的 Leadership。这就是说，你需要给大家做示范。很多时候，道理人人都知道，但未必人人都会做，知易行难，以身示范，一个示例会比讲一万遍道理都管用。\n\n  所以我认为，对于软件开发来说，不写代码的架构师是根本不靠谱的。**要做一个有人愿意跟随的技术 Leader，你需要终身写代码，也就是所谓的 ABC – Always Be Coding。这样，你会得到更多的实际经验，能够非常明白一个技术方案的优缺点，实现复杂度，知道什么是 Best Practice，你的方案才会更具执行力和实践性。当有了执行力，你就会获得更多的成就，而这些成就反过来会让更多的人来跟随你**。\n\n- **保持热情和冲劲**。在这个世界上，有太多太多的东西会让人产生沮丧、不满、彷徨、迷茫、疲惫等这些负面情绪，但是几乎所有的人都不会喜欢在这样的情绪中生活，我们每个人都会去追求更为积极更为正面的生活方式。\n\n  所以，作为一个 Leader 无论在什么情况下，你都需要保持热情和冲劲，只有这样，你才会让别人有跟随的想法和冲动。\n\n  但是，**所谓的保持热情和冲劲，并不是自欺欺人，也不是文过饰非，因为掩耳盗铃、掩盖问题、强颜欢笑的方式根本不是热情。真正的热情和冲劲是，正视问题，正视不足，正视错误，从中进行反思和总结得到更好的解决方案，不怕困难，迎难而上**。\n\n  正如鲁迅先生在《记念刘和珍君》中所说的那句话——“真的猛士，敢于直面惨淡的人生，敢于正视淋漓的鲜血”。\n\n- **能够抓住重点，看透事物的本质**。这个世界太复杂，有太多的因素和杂音影响着我们的判断和决定。绝大多数人都会在多重因素中迷失或是纠结。作为一个 Leader，能够抓住主要矛盾，看清事物的本质，给出清楚的观点或方向，简化复杂的事情，传道解惑、开启民智，让人豁然开朗、醍醐灌顶，才会让人追随之。\n\n- **描绘令人激动的方向，提供令人向住的环境**。我相信，我们每个人心中都有激动和理想，就算是被现实摧残得最凶残的人，他们已经忘却了心中那些曾经的激动和理想，但我相信也只是暂时的。一个好的 Leader 一定会把每个人心中最真善美的东西呼唤出来，并且还能让人相信这是有机会有可能做到的。\n\n- **甘当铺路石，为他人创造机会**。别人愿意跟随你，愿意和你共事，有一部分原因是你能够给别人带来更多的可能性和机会，别人觉得和你在一起能够成长，能够进步，你能够带着大家到达更远的地方。帮助别人其实就是帮助自己，成就他人其实也是在成就自己，这就像一个好的足球队一样，球队中的人都互相给队友创造机会，整个团队成功了，球队的每个人也就成功了。作为一个好的 Leader，你一定要在团队中创造好这样的文化和风气。\n\n做一个好的 Leader 真的不容易，你需要比大家强很多，你需要比大家付出更多；你需要容天下难容之事，你还需要保持热情和朝气；你需要带领团队守护理想，你还需要直面困难迎刃而上……\n\n也许，你不必做一个 Leader，但是如果你有想跟随的人，你应该去跟随这样的 Leader！\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/297\" > </iframe>","categories":["左耳听风"]},{"title":"012丨程序中的错误处理：异步编程以及我的最佳实践","url":"/posts/832186276.html","content":"\n\n\n上一篇文章中，我们讨论了错误返回码和异常捕捉，以及在不同情况下该如何选择和使用。本文中会接着讲两个有趣的话题：异步编程世界里的错误处理方法，以及我在实战中总结出来的错误处理最佳实践。\n\n# 异步编程世界里的错误处理\n\n在异步编程的世界里，因为被调用的函数是被放到了另外一个线程里运行，这将导致：\n\n- **无法使用返回码**。因为函数在“被”异步运行中，所谓的返回只是把处理权交给下一条指令，而不是把函数运行完的结果返回。**所以，函数返回的语义完全变了，返回码也没有用了**。\n- **无法使用抛异常的方式**。因为除了上述的函数立马返回的原因之外，抛出的异常也在另外一个线程中，不同线程中的栈是完全不一样的，所以主线程的 `catch` 完全看不到另外一个线程中的异常。\n\n对此，在异步编程的世界里，我们也会有好几种处理错误的方法，最常用的就是 `callback` 方式。在做异步请求的时候，注册几个 `OnSuccess()`、 `OnFailure()` 这样的函数，让在另一个线程中运行的异步代码来回调过来。\n\n## JavaScript 异步编程的错误处理\n\n比如，下面这个 JavaScript 示例：\n\n```JavaScript\nfunction successCallback(result) {\n  console.log(\"It succeeded with \" + result);\n}\n \nfunction failureCallback(error) {\n  console.log(\"It failed with \" + error);\n}\n \ndoSomething(successCallback, failureCallback);\n```\n\n通过注册错误处理的回调函数，让异步执行的函数在出错的时候，调用被注册进来的错误处理函数，这样的方式比较好地解决了程序的错误处理。**而出错的语义从返回码、异常捕捉到了直接耦合错误出处函数的样子**，挺好的。\n\n但是， 如果我们需要把几个异步函数顺序执行的话（异步程序中，程序执行的顺序是不可预测的、也是不确定的，而有时候，函数被调用的上下文是有相互依赖的，所以，我们希望它们能按一定的顺序处理），就会出现了所谓的 Callback Hell 的问题。如下所示：\n\n```javascript\ndoSomething(function(result) {\n  doSomethingElse(result, function(newResult) {\n    doThirdThing(newResult, function(finalResult) {\n      console.log('Got the final result: ' + finalResult);\n    }, failureCallback);\n  }, failureCallback);\n}, failureCallback);\n```\n\n而这样层层嵌套中需要注册的错误处理函数也有可能是完全不一样的，而且会导致代码非常混乱，难以阅读和维护。\n\n所以，一般来说，在异步编程的实践里，我们会用 Promise 模式来处理。如下所示（箭头表达式）：\n\n```JavaScript\ndoSomething()\n.then(result => doSomethingElse(result))\n.then(newResult => doThirdThing(newResult))\n.then(finalResult => {\n  console.log(`Got the final result: ${finalResult}`);\n}).catch(failureCallback);\n```\n\n上面代码中的 `then()` 和 `catch()` 方法就是 Promise 对象的方法，`then()`方法可以把各个异步的函数给串联起来，而`catch()` 方法则是出错的处理。\n\n看到上面的那个级联式的调用方式，这就要我们的 `doSomething()` 函数返回 Promise 对象，下面是这个函数的相关代码示例：\n\n比如：\n\n```JavaScript\nfunction doSomething() {\n\tlet promise = new Promise();\n\tlet xhr = new XMLHttpRequest();\n\txhr.open('GET', 'http://coolshell.cn/....', true);\n \n\txhr.onload = function (e) {\n        if (this.status === 200) {\n            results = JSON.parse(this.responseText);\n            promise.resolve(results); // 成功时，调用 resolve() 方法\n        }\n    };\n \n    xhr.onerror = function (e) {\n        promise.reject(e); // 失败时，调用 reject() 方法\n    };\n \n    xhr.send();\n    return promise;\n}\n```\n\n从上面的代码示例中，我们可以看到，如果成功了，要调用\n`Promise.resolve()` 方法，这样 Promise 对象会继续调用下一个 `then()`。如果出错了就调用 `Promise.reject()` 方法，这样就会忽略后面的 `then()` 直到 `catch()` 方法。\n\n我们可以看到 `Promise.reject()` 就像是抛异常一样。这个编程模式让我们的代码组织方便了很多。\n\n另外，多说一句，Promise 还可以同时等待两个不同的异步方法。比如下面的代码所展示的方式：\n\n```JavaScript\npromise1 = doSomething();\npromise2 = doSomethingElse();\nPromise.when(promise1, promise2).then( function (result1, result2) {\n\t... // 处理 result1 和 result2 的代码\n}, handleError);\n```\n\n在 ECMAScript 2017 的标准中，我们可以使用`async`/`await`这两个关键字来取代 Promise 对象，这样可以让我们的代码更易读。\n\n比如下面的代码示例：\n\n```JavaScript\nasync function foo() {\n  try {\n    let result = await doSomething();\n    let newResult = await doSomethingElse(result);\n    let finalResult = await doThirdThing(newResult);\n    console.log(`Got the final result: ${finalResult}`);\n  } catch(error) {\n    failureCallback(error);\n  }\n}\n```\n\n如果在函数定义之前使用了 `async` 关键字，就可以在函数内使用 `await`。 当在 `await` 某个 `Promise` 时，函数暂停执行，直至该 `Promise` 产生结果，并且暂停不会阻塞主线程。 如果 `Promise` resolve，则会返回值。 如果 `Promise` reject，则会抛出拒绝的值。\n\n而我们的异步代码完全可以放在一个 `try - catch` 语句块内，在有语言支持了以后，我们又可以使用 `try - catch` 语句块了。\n\n下面我们来看一下 pipeline 的代码。所谓 pipeline 就是把一串函数给编排起来，从而形成更为强大的功能。这个玩法是函数式编程中经常用到的方法。\n\n比如，下面这个 pipeline 的代码（注意，其上使用了 `reduce()` 函数）：\n\n```JavaScript\n[func1, func2].reduce((p, f) => p.then(f), Promise.resolve());\n复制代码\n```\n\n其等同于：\n\n```JavaScript\nPromise.resolve().then(func1).then(func2);\n复制代码\n```\n\n我们可以抽象成：\n\n```JavaScript\nlet applyAsync = (acc,val) => acc.then(val);\nlet composeAsync = (...funcs) => x => funcs.reduce(applyAsync, Promise.resolve(x));\n```\n\n于是，可以这样使用：\n\n```JavaScript\nlet transformData = composeAsync(func1, asyncFunc1, asyncFunc2, func2);\ntransformData(data);\n```\n\n但是，在 ECMAScript 2017 的 `async`/`await` 语法糖下，这事儿就变得更简单了。\n\n```JavaScript\nfor (let f of [func1, func2]) {\n  await f();\n}\n```\n\n## Java 异步编程的 Promise 模式\n\n在 Java 中，在 JDK 1.8 里也引入了类似 JavaScript 的玩法 —— `CompletableFuture`。这个类提供了大量的异步编程中 Promise 的各种方式。下面我列举几个。\n\n链式处理：\n\n```Java\nCompletableFuture.supplyAsync(this::findReceiver)\n                 .thenApply(this::sendMsg)\n                 .thenAccept(this::notify);\n```\n\n上面的这个链式处理和 JavaScript 中的`then()`方法很像，其中的\n`supplyAsync()` 表示执行一个异步方法，而 `thenApply()` 表示执行成功后再串联另外一个异步方法，最后是 `thenAccept()` 来处理最终结果。\n\n下面这个例子是要合并两个异步函数的结果：\n\n```Java\nString result = CompletableFuture.supplyAsync(() -> {\n         return \"hello\";\n     }).thenCombine(CompletableFuture.supplyAsync(() -> {\n         return \"world\";\n     }), (s1, s2) -> s1 + \" \" + s2).join());\nSystem.out.println(result);\n \n```\n\n接下来，我们再来看一下，Java 这个类相关的异常处理：\n\n```Java\nCompletableFuture.supplyAsync(Integer::parseInt) // 输入: \"ILLEGAL\"\n\t\t\t     .thenApply(r -> r * 2 * Math.PI)\n\t\t\t     .thenApply(s -> \"apply>> \" + s)\n\t\t\t     .exceptionally(ex -> \"Error: \" + ex.getMessage());\n```\n\n我们要注意到上面代码里的 `exceptionally()` 方法，这个和 JavaScript Promise 中的 `catch()` 方法相似。\n\n运行上面的代码，会出现如下输出：\n\n```Java\nError: java.lang.NumberFormatException: For input string: \"ILLEGAL\"\n复制代码\n```\n\n也可以这样：\n\n```Java\nCompletableFuture.supplyAsync(Integer::parseInt) // 输入: \"ILLEGAL\"\n\t\t\t\t .thenApply(r -> r * 2 * Math.PI)\n\t\t\t\t .thenApply(s -> \"apply>> \" + s)\n\t\t\t\t .handle((result, ex) -> {\n\t\t\t\t \tif (result != null) {\n\t\t\t\t \t\treturn result;\n\t\t\t\t \t} else {\n\t\t\t\t \t\treturn \"Error handling: \" + ex.getMessage();\n\t\t\t\t \t}\n\t\t\t\t });\n```\n\n上面代码中，你可以看到，其使用了 `handle()` 方法来处理最终的结果，其中包含了异步函数中的错误处理。\n\n## Go 语言的 Promise\n\n在 Go 语言中，如果你想实现一个简单的 Promise 模式，也是可以的。下面的代码纯属示例，只为说明问题。如果你想要更好的代码，可以上 GitHub 上搜一下 Go 语言 Promise 的相关代码库。\n\n首先，先声明一个结构体。其中有三个成员：第一个 `wg` 用于多线程同步；第二个 `res` 用于存放执行结果；第三个 `err` 用于存放相关的错误。\n\n```Go\ntype Promise struct {\n\twg  sync.WaitGroup\n\tres string\n\terr error\n}\n```\n\n然后，定义一个初始函数，来初始化 Promise 对象。其中可以看到，需要把一个函数 `f` 传进来，然后调用 `wg.Add(1)` 对 waitGroup 做加一操作，新开一个 Goroutine 通过异步去执行用户传入的函数 `f()` ，然后记录这个函数的成功或错误，并把 waitGroup 做减一操作。\n\n```Go\nfunc NewPromise(f func() (string, error)) *Promise {\n\tp := &Promise{}\n\tp.wg.Add(1)\n\tgo func() {\n\t\tp.res, p.err = f()\n\t\tp.wg.Done()\n\t}()\n\treturn p\n}\n```\n\n然后，我们需要定义 Promise 的 Then 方法。其中需要传入一个函数，以及一个错误处理的函数。并且调用 `wg.Wait()` 方法来阻塞（因为之前被`wg.Add(1)`)，一旦上一个方法被调用了 `wg.Done()`，这个 Then 方法就会被唤醒。\n\n唤醒的第一件事是，检查一下之前的方法有没有错误。如果有，那么就调用错误处理函数。如果之前成功了，就把之前的结果以参数的方式传入到下一个函数中。\n\n```Go\nfunc (p *Promise) Then(r func(string), e func(error)) (*Promise){\n\tgo func() {\n\t\tp.wg.Wait()\n\t\tif p.err != nil {\n\t\t\te(p.err)\n\t\t\treturn \n\t\t}\n\t\tr(p.res)\n\t}()\n\treturn p\n}\n```\n\n下面，我们定义一个用于测试的异步方法。这个方面很简单，就是在数数，然后，有一半的机率会出错。\n\n```Go\nfunc exampleTicker() (string, error) {\n\tfor i := 0; i < 3; i++ {\n\t\tfmt.Println(i)\n\t\t<-time.Tick(time.Second * 1)\n\t}\n\t\n\trand.Seed(time.Now().UTC().UnixNano())\n\tr:=rand.Intn(100)%2\n\tfmt.Println(r)\n\tif  r != 0 {\n\t\treturn \"hello, world\", nil\n\t} else {\n\t\treturn \"\", fmt.Errorf(\"error\")\n\t}\n}\n \n```\n\n下面，我们来看看我们实现的 Go 语言 Promise 是怎么使用的。代码还是比较直观的，我就不做更多的解释了。\n\n```Go\nfunc main() {\n\tdoneChan := make(chan int)\n\t\n\tvar p = NewPromise(exampleTicker)\n\tp.Then(func(result string) { fmt.Println(result); doneChan <- 1 }, \n\t\t\tfunc(err error) { fmt.Println(err); doneChan <-1 })\n\t\t\t\n\t<-doneChan\n}\n```\n\n当然，如果你需要更好的 Go 语言 Promise，可以到 GitHub 上找，上面好些代码都是实现得很不错的。上面的这个示例，实现得比较简陋，仅仅是为了说明问题。\n\n# 错误处理的最佳实践\n\n下面是我个人总结的几个错误处理的最佳实践。如果你知道更好的，请一定告诉我。\n\n- **统一分类的错误字典**。无论你是使用错误码还是异常捕捉，都需要认真并统一地做好错误的分类。最好是在一个地方定义相关的错误。比如，HTTP 的 4XX 表示客户端有问题，5XX 则表示服务端有问题。也就是说，你要建立一个错误字典。\n- **同类错误的定义最好是可以扩展的**。这一点非常重要，而对于这一点，通过面向对象的继承或是像 Go 语言那样的接口多态可以很好地做到。这样可以方便地重用已有的代码。\n- **定义错误的严重程度**。比如，Fatal 表示重大错误，Error 表示资源或需求得不到满足，Warning 表示并不一定是个错误但还是需要引起注意，Info 表示不是错误只是一个信息，Debug 表示这是给内部开发人员用于调试程序的。\n- **错误日志的输出最好使用错误码，而不是错误信息**。打印错误日志的时候，应该使用统一的格式。但最好不要用错误信息，而应使用相应的错误码，错误码不一定是数字，也可以是一个能从错误字典里找到的一个唯一的可以让人读懂的关键字。这样，会非常有利于日志分析软件进行自动化监控，而不是要从错误信息中做语义分析。比如：HTTP 的日志中就会有 HTTP 的返回码，如：`404`。但我更推荐使用像`PageNotFound`这样的标识，这样人和机器都很容易处理。\n- **忽略错误最好有日志**。不然会给维护带来很大的麻烦。\n- **对于同一个地方不停的报错，最好不要都打到日志里**。不然这样会导致其它日志被淹没了，也会导致日志文件太大。最好的实践是，打出一个错误以及出现的次数。\n- **不要用错误处理逻辑来处理业务逻辑**。也就是说，不要使用异常捕捉这样的方式来处理业务逻辑，而是应该用条件判断。如果一个逻辑控制可以用 if - else 清楚地表达，那就不建议使用异常方式处理。异常捕捉是用来处理不期望发生的事情，而错误码则用来处理可能会发生的事。\n- **对于同类的错误处理，用一样的模式**。比如，对于`null`对象的错误，要么都用返回 null，加上条件检查的模式，要么都用抛 NullPointerException 的方式处理。不要混用，这样有助于代码规范。\n- **尽可能在错误发生的地方处理错误**。因为这样会让调用者变得更简单。\n- **向上尽可能地返回原始的错误**。如果一定要把错误返回到更高层去处理，那么，应该返回原始的错误，而不是重新发明一个错误。\n- **处理错误时，总是要清理已分配的资源**。这点非常关键，使用 RAII 技术，或是 try-catch-finally，或是 Go 的 defer 都可以容易地做到。\n- **不推荐在循环体里处理错误**。这里说的是 try-catch，绝大多数的情况你不需要这样做。最好把整个循环体外放在 try 语句块内，而在外面做 catch。\n- **不要把大量的代码都放在一个 try 语句块内**。一个 try 语句块内的语句应该是完成一个简单单一的事情。\n- **为你的错误定义提供清楚的文档以及每种错误的代码示例**。如果你是做 RESTful API 方面的，使用 Swagger 会帮你很容易搞定这个事。\n- **对于异步的方式，推荐使用 Promise 模式处理错误**。对于这一点，JavaScript 中有很好的实践。\n- **对于分布式的系统，推荐使用 APM 相关的软件**。尤其是使用 Zipkin 这样的服务调用跟踪的分析来关联错误。\n\n好了。关于程序中的错误处理，我主要总结了这些。如果你有更好的想法和经验，欢迎来跟我交流。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/693\" > </iframe>","categories":["左耳听风"]},{"title":"011丨程序中的错误处理：错误返回码和异常捕捉","url":"/posts/3680837885.html","content":"\n\n\n今天，我们来讨论一下程序中的错误处理。也许你会觉得这个事没什么意思，处理错误的代码并不难写。但你想过没有，要把错误处理写好，并不是件容易的事情。另外，任何一个稳定的程序中都会有大量的代码在处理错误，所以说，处理错误是程序中一件比较重要的事情。这里，我会用两篇文章来系统地讲一下错误处理的各种方式和相关实践。\n\n# 传统的错误检查\n\n首先，我们知道，处理错误最直接的方式是通过错误码，这也是传统的方式，在过程式语言中通常都是用这样的方式处理错误的。比如 C 语言，基本上来说，其通过函数的返回值标识是否有错，然后通过全局的`errno`变量并配合一个 `errstr` 的数组来告诉你为什么出错。\n\n为什么是这样的设计？道理很简单，除了可以共用一些错误，更重要的是这其实是一种妥协。比如：`read()`, `write()`, `open()` 这些函数的返回值其实是返回有业务逻辑的值。也就是说，这些函数的返回值有两种语义，一种是成功的值，比如 `open()` 返回的文件句柄指针 `FILE*` ，或是错误 `NULL`。这样会导致调用者并不知道是什么原因出错了，需要去检查 `errno` 来获得出错的原因，从而可以正确地处理错误。\n\n一般而言，这样的错误处理方式在大多数情况下是没什么问题的。但是也有例外的情况，我们来看一下下面这个 C 语言的函数：\n\n```\nint atoi(const char *str)\n复制代码\n```\n\n这个函数是把一个字符串转成整型。但是问题来了，如果一个要传的字符串是非法的（不是数字的格式），如 \"ABC\" 或者整型溢出了，那么这个函数应该返回什么呢？出错返回，返回什么数都不合理，因为这会和正常的结果混淆在一起。比如，返回 `0`，那么会和正常的对 “0” 字符的返回值完全混淆在一起。这样就无法判断出错的情况。你可能会说，是不是要检查一下 `errno`，按道理说应该是要去检查的，但是，我们在 C99 的规格说明书中可以看到这样的描述——\n\n> 7.20.1\n>\n> The functions atof, atoi, atol, and atoll need not affect the value of the integer expression errno on an error. If the value of the result cannot be represented, the behavior is undeﬁned.\n\n像`atoi()`, `atof()`, `atol()` 或是 `atoll()` 这样的函数是不会设置 `errno`的，而且，还说了，如果结果无法计算的话，行为是`undefined`。所以，后来，libc 又给出了一个新的函数`strtol()`，这个函数在出错的时会设置全局变量`errno` ：\n\n```\nlong strtol(const char *restrict str, char **restrict endptr, int base);\n复制代码\n```\n\n于是，我们就可以这样使用：\n\n```\nlong val = strtol(in_str, &endptr, 10);  //10 的意思是 10 进制\n \n// 如果无法转换\nif (endptr == str) {\n    fprintf(stderr, \"No digits were found\\n\");\n    exit(EXIT_FAILURE);\n}\n \n// 如果整型溢出了\nif ((errno == ERANGE && (val == LONG_MAX || val == LONG_MIN)) {\n    fprintf(stderr, \"ERROR: number out of range for LONG\\n\");\n    exit(EXIT_FAILURE);\n }\n \n// 如果是其它错误\nif (errno != 0 && val == 0) {\n    perror(\"strtol\");\n    exit(EXIT_FAILURE);\n}\n \n```\n\n虽然，`strtol()` 函数解决了 `atoi()` 函数的问题，但是我们还是能感觉到不是很舒服和自然。\n\n因为，这种用 `返回值` + `errno` 的错误检查方式会有一些问题:\n\n- 程序员一不小心就会忘记返回值的检查，从而造成代码的 Bug；\n- 函数接口非常不纯洁，正常值和错误值混淆在一起，导致语义有问题。\n\n所以，后来，有一些类库就开始区分这样的事情。比如，Windows 的系统调用开始使用 `HRESULT` 的返回来统一错误的返回值，这样可以明确函数调用时的返回值是成功还是错误。但这样一来，函数的 input 和 output 只能通过函数的参数来完成，于是出现了所谓的 `入参` 和 `出参` 这样的区别。\n\n然而，这又使得函数接入中参数的语义变得复杂，一些参数是入参，一些参数是出参，函数接口变得复杂了一些。而且，依然没有解决函数的成功或失败可以被人为忽略的问题。\n\n# 多返回值\n\n于是，有一些语言通过多返回值来解决这个问题，比如 Go 语言。Go 语言的很多函数都会返回 `result, err` 两个值，于是:\n\n- 参数上基本上就是入参，而返回接口把结果和错误分离，这样使得函数的接口语义清晰；\n- 而且，Go 语言中的错误参数如果要忽略，需要显式地忽略，用 `_` 这样的变量来忽略；\n- 另外，因为返回的 `error` 是个接口（其中只有一个方法 `Error()`，返回一个 `string` ），所以你可以扩展自定义的错误处理。\n\n比如下面这个 JSON 语法的错误：\n\n```\ntype SyntaxError struct {\n    msg    string // description of error\n    Offset int64  // error occurred after reading Offset bytes\n}\n \nfunc (e *SyntaxError) Error() string { return e.msg }\n```\n\n在使用上会是这个样子:\n\n```\nif err := dec.Decode(&val); err != nil {\n    if serr, ok := err.(*json.SyntaxError); ok {\n        line, col := findLine(f, serr.Offset)\n        return fmt.Errorf(\"%s:%d:%d: %v\", f.Name(), line, col, err)\n    }\n    return err\n}\n```\n\n上面这个示例来自 Go 的官方文档 《[Error Handling and Go](https://blog.golang.org/error-handling-and-go)》，如果你有时间，可以点进去链接细看。\n\n多说一句，如果一个函数返回了多个不同类型的 `error`，你也可以使用下面这样的方式：\n\n```\nif err != nil {\n\tswitch err.(type) {\n\t\tcase *json.SyntaxError:\n\t\t\t...\n\t\tcase *ZeroDivisionError:\n\t\t\t...\n\t\tcase *NullPointerError:\n\t\t\t...\n\t\tdefault:\n\t\t\t...\n\t}\n}\n```\n\n但即便像 Go 这样的语言能让错误处理语义更清楚，而且还有可扩展性，也有其问题。如果写过一段时间的 Go 语言，你就会明白其中的痛苦—— `if err != nil` 这样的语句简直是写到吐，只能在 IDE 中定义一个自动写这段代码的快捷键……而且，正常的逻辑代码会被大量的错误处理打得比较凌乱。\n\n# 资源清理\n\n程序出错时需要对已分配的一些资源做清理，在传统的玩法下，每一步的错误都要去清理前面已分配好的资源。于是就出现了 `goto fail` 这样的错误处理模式。如下所示：\n\n```c\n#define FREE(p) if(p) { \\\n                    free(p); \\\n                    p = NULL; \\\n                 }\nmain()\n{\n\tchar *fname=NULL, *lname=NULL, *mname=NULL;\n\tfname = ( char* ) calloc ( 20, sizeof(char) );\n\tif ( fname == NULL ){\n\t    goto fail;\n\t}\n\tlname = ( char* ) calloc ( 20, sizeof(char) );\n\tif ( lname == NULL ){\n\t    goto fail;\n\t}\n\tmname = ( char* ) calloc ( 20, sizeof(char) );\n\tif ( mname == NULL ){\n\t    goto fail;\n\t}\n    \n\t......\n \n    \nfail:\n\tFREE(fname);\n\tFREE(lname);\n\tFREE(mname);\n\tReportError(ERR_NO_MEMORY);\n} \n```\n\n这样的处理方式虽然可以，但是会有潜在的问题。最主要的一个问题就是你不能在中间的代码中有 `return` 语句，因为你需要清理资源。在维护这样的代码时需要格外小心，因为一不注意就会导致代码有资源泄漏的问题。\n\n于是，C++ 的 RAII（Resource Acquisition Is Initialization）机制使用面向对象的特性可以容易地处理这个事情。RAII 其实使用 C++ 类的机制，在构造函数中分配资源，在析构函数中释放资源。下面看个例子。\n\n我们先看一个不好的示例：\n\n```c++\nstd::mutex m;\n \nvoid bad() \n{\n    m.lock();                    // 请求互斥\n    f();                         // 若 f() 抛异常，则互斥绝不被释放\n    if(!everything_ok()) return; // 提早返回，互斥绝不被释放\n    m.unlock();                  // 若 bad() 抵达此语句，互斥才被释放\n}\n```\n\n上面这个例子，在函数的第三条语句提前返回了，直接导致 `m.unlock()` 没有被调用，这样会引起死锁问题。我们来看一下用 RAII 的方式是怎样解决这个问题的。\n\n```c++\n// 首先，先声明一个 RAII 类，注意其中的构造函数和析构函数\nclass LockGuard {\npublic:\n\tLockGuard(std::mutex &m):_m(m) { m.lock(); }\n\t~LockGuard() { m. unlock(); }\nprivate:\n\tstd::mutex& _m;\n}\n \n \n// 然后，我们来看一下，怎样使用的\nvoid good()\n{\n\tLockGuard lg(m); \t\t\t    // RAII 类：构造时，互斥量请求加锁\n\tf();                             // 若 f() 抛异常，则释放互斥\n\tif(!everything_ok()) return;     // 提早返回，LockGuard 析构时，互斥量被释放\n}                                    // 若 good() 正常返回，则释放互斥\n```\n\n在 Go 语言中，使用`defer`关键字也可以做到这样的效果。参看下面的示例：\n\n```go\nfunc Close(c io.Closer) {\n\terr := c.Close()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n \nfunc main() {\n\tr, err := Open(\"a\")\n\tif err != nil {\n\t\tlog.Fatalf(\"error opening 'a'\\n\")\n\t}\n\tdefer Close(r) // 使用 defer 关键字在函数退出时关闭文件。\n \n\tr, err = Open(\"b\")\n\tif err != nil {\n\t\tlog.Fatalf(\"error opening 'b'\\n\")\n\t}\n\tdefer Close(r) // 使用 defer 关键字在函数退出时关闭文件。\n}\n```\n\n不知道从上面这三个例子来看，不同语言的错误处理，你自己更喜欢哪个呢？就代码的易读和干净而言，我更喜欢 C++ 的 RAII 模式，然后是 Go 的 defer 模式，最后才是 C 语言的 goto fail 模式。\n\n# 异常捕捉处理\n\n上面，我们讲了错误检查和程序出错后对资源的清理这两个事。能把这个事做得比较好的其实是 `try - catch - finally` 这个编程模式。\n\n```\ntry {\n\t... // 正常的业务代码\n} catch (Exception1 e) {\n\t... // 处理异常 Exception1 的代码\n} catch (Exception2 e) {\n\t... // 处理异常 Exception2 的代码\n} finally {\n\t... // 资源清理的代码\n}\n```\n\n把正常的代码、错误处理的代码、资源清理的代码分门别类，看上去非常干净。\n\n有一些人明确表示不喜欢 `try - catch` 这种错误处理方式，比如著名的 软件工程师[Joel Spolsky](https://www.joelonsoftware.com/2005/05/11/making-wrong-code-look-wrong/)。\n\n但是，我想说一下，`try - catch - finally` 这样的异常处理方式有如下一些好处。\n\n- 函数接口在 input（参数）和 output（返回值）以及错误处理的语义是比较清楚的。\n- 正常逻辑的代码可以与错误处理和资源清理的代码分开，提高了代码的可读性。\n- 异常不能被忽略（如果要忽略也需要 catch 住，这是显式忽略）。\n- 在面向对象的语言中（如 Java），异常是个对象，所以，可以实现多态式的 catch。\n- 与状态返回码相比，异常捕捉有一个显著的好处是，函数可以嵌套调用，或是链式调用。比如：`int x = add(a, div(b,c));` 或 `Pizza p = PizzaBuilder().SetSize(sz) .SetPrice(p)...;` 。\n\n当然，你可能会觉得异常捕捉对程序的性能是有影响的，这句话也对也不对。原因是这样的。\n\n- 异常捕捉的确是对性能有影响的，那是因为一旦异常被抛出，函数也就跟着 return 了。而程序在执行时需要处理函数栈的上下文，这会导致性能变得很慢，尤其是函数栈比较深的时候。\n- 但从另一方面来说，异常的抛出基本上表明程序的错误。程序在绝大多数情况下，应该是在没有异常的情况下运行的，所以，有异常的情况应该是少数的情况，不会影响正常处理的性能问题。\n\n总体而言，我还是觉得 `try - catch - finally` 这样的方式是很不错的。而且这个方式比返回错误码在诸多方面都更好。\n\n但是，`try - catch - finally` 有个致命的问题，那就是在异步运行的世界里的问题。try 语句块里的函数运行在另外一个线程中，其中抛出的异常无法在调用者的这个线程中被捕捉。这个问题就比较大了。\n\n# 错误返回码 vs 异常捕捉\n\n是返回错误状态，还是用异常捕捉的方式处理错误，可能是一个很容易引发争论的问题。有人说，对于一些偏底层的错误，比如：空指针、内存不足等，可以使用返回错误状态码的方式，而对于一些上层的业务逻辑方面的错误，可以使用异常捕捉。这么说有一定道理，因为偏底层的函数可能用得更多一些。但是我并不这么认为。\n\n**前面也比较过两者的优缺点，总体而言，似乎异常捕捉的优势更多一些。但是，我觉得应该从场景上来讨论这个事才是正确的姿势**。\n\n要讨论场景，我们需要先把要处理的错误分好类别，这样有利于简化问题。\n\n因为，错误其实是很多的，不同的错误需要有不同的处理方式。但错误处理是有一些通用规则的。为了讲清楚这个事，我们需要把错误来分个类。我个人觉得错误可以分为三个大类。\n\n- **资源的错误**。当我们的代码去请求一些资源时导致的错误，比如打开一个没有权限的文件，写文件时出现的写错误，发送文件到网络端发现网络故障的错误，等等。**这一类错误属于程序运行环境的问题。对于这类错误，有的我们可以处理，有的我们则无法处理。比如，内存耗尽、栈溢出或是一些程序运行时关键性资源不能满足等等这些情况，我们只能停止运行，甚至退出整个程序。**\n\n- **程序的错误**。比如：空指针、非法参数等。**这类是我们自己程序的错误，我们要记录下来，写入日志，最好触发监控系统报警**。\n\n- **用户的错误**。比如：Bad Request、Bad Format 等这类由用户不合法输入带来的错误。**这类错误基本上是在用户的 API 层上出现的问题**。比如，解析一个 XML 或 JSON 文件，或是用户输入的字段不合法之类的。\n\n  **对于这类问题，我们需要向用户端报错，让用户自己处理修正他们的输入或操作。然后，我们正常执行，但是需要做统计，统计相应的错误率，这样有利于我们改善软件或是侦测是否有恶意的用户请求。**\n\n我们可以看到，这三类错误中，有些是我们希望杜绝发生的，比如程序的 Bug，有些则是我们杜绝不了的，比如用户的输入。而对于程序运行环境中的一些错误，则是我们希望可以恢复的。也就是说，我们希望可以通过重试或是妥协的方式来解决这些环境的问题，比如重建网络连接，重新打开一个新的文件。\n\n所以，是不是我们可以这样来在逻辑上分类：\n\n- 对于我们并不期望会发生的事，我们可以使用异常捕捉；\n- 对于我们觉得可能会发生的事，使用返回码。\n\n比如，如果你的函数参数传入的对象不应该是一个 null 对象，那么，一旦传入 null 对象后，函数就可以抛异常，因为我们并不期望总是会发生这样的事。\n\n而对于一个需要检查用户输入信息是否正确的事，比如：电子邮箱的格式，我们用返回码可能会好一些。所以，对于上面三种错误的类型来说，程序中的错误，可能用异常捕捉会比较合适；用户的错误，用返回码比较合适；而资源类的错误，要分情况，是用异常捕捉还是用返回值，要看这事是不应该出现的，还是经常出现的。\n\n当然，这只是一个大致的实践原则，并不代表所有的事都需要符合这个原则。\n\n除了用错误的分类来判断是否用返回码还是用异常捕捉之外，我们还要从程序设计的角度来考虑哪种情况下使用异常捕捉更好，哪种情况下使用返回码更好。\n\n因为异常捕捉在编程上的好处比函数返回值好很多，所以很多使用异常捕捉的代码会更易读也更健壮一些。而返回码容易被忽略，所以，使用返回码的代码需要做好测试才能得到更好的软件质量。\n\n不过，我们也要知道，在某些情况下，你只能使用其中的一个，比如：\n\n- 在 C++ 重载操作符的情况下，你就很难使用错误返回码，只能抛异常；\n- 异常捕捉只能在同步的情况下使用，在异步模式下，抛异常这事就不行了，需要通过检查子进程退出码或是回调函数来解决；\n- 在分布式的情况下，调用远程服务只能看错误返回码，比如 HTTP 的返回码。\n\n所以，在大多数情况下，我们会混用这两种报错的方式，有时候，我们还会把异常转成错误码（比如 HTTP 的 RESTful API），也会把错误码转成异常（比如对系统调用的错误）。\n\n总之，“报错的类型” 和 “错误处理” 是紧密相关的，错误处理方法多种多样，而且会在不同的层面上处理错误。有些底层错误就需要自己处理掉（比如：底层模块会自动重建网络连接），而有一些错误需要更上层的业务逻辑来处理（比如：重建网络连接不成功后只能让上层业务来处理怎么办？降级使用本地缓存还是直接报错给用户？）。\n\n所以，不同的错误类型再加上不同的错误处理会导致我们代码组织层面上的不同，从而会让我们使用不同的方式。也就是说，**使用错误码还是异常捕捉主要还是看我们的错误处理流程以及代码组织怎么写会更清楚**。\n\n通过学习今天的内容，你是不是已经对如何处理程序中的错误，以及在不同情况下怎样选择错误处理方法，有了一定的认知和理解呢？然而，这些知识和经验仅在同步编程世界中适用。因为在异步编程世界里，被调用的函数是被放到另外一个线程里运行的，所以本文中的两位主角，不管是错误返回码，还是异常捕捉，都难以发挥其威力。\n\n那么异步编程世界中是如何做错误处理的呢？我们将在下篇文章中讨论。同时，还会给你讲讲我在实战中总结出来的错误处理最佳实践。\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/675\" > </iframe>","categories":["左耳听风"]},{"title":"015丨时间管理：同扭曲时间的事儿抗争","url":"/posts/2979708671.html","content":"\n\n\n我一直说，时间是人生中最宝贵的财富，今天我就来跟你聊聊时间管理方面的话题。\n\n关于时间管理，我以前在外企工作时，受过一个专门的培训，后来我也在工作中总结过自己的方式。时间管理是非常重要的，因为时间过得实在是太快了，快得让你有点受不了，而看似忙碌的我们似乎在这一年中也没有做太多事，尤其是让自己能成长的事情。\n\n有那么一句话是这么说，老天很公平，给了所有人同样多的时间，而有的人能够把时间用好，有的人则没有把时间用好。日积月累，人和人的差距就越来越大了。\n\n之前的文章和你讲过，我在工作强度很大的情况下，依然可以找到时间来学习和提升自己，主要是我自己很渴望学习。今天我就想和你聊一下，除了自己对某件事情的热情外，我们还有什么方法可以管理好自己的时间。\n\n不过，说实话，在安排时间方面，我成长于一个相对于今天算是比较好的环境，举几个例子。\n\n- 那个年代，没有智能手机，工作中也不用实时聊天工具。而现在，很多公司都会有若干个聊天群，所有人都可以把信息发给所有的人，而不管这个事是否与你相关。但这些信息无法像邮件那样根据邮件标题聚合，或是通过设置规则自动分类……于是你工作在了一个信息杂乱无章的环境里，而且还在不断地被人打扰，不断地被人打断。\n\n- 那个年代，别人要来找我开会，需要先给我发会议邀请，而且发会议邀请的时候，会找我日历上空闲的时间段来确定会议时间。所以，我可以把很多工作安排在我的日历上，通过邮箱（Outlook 或是 Gmail 都有这样的功能）共享出去。这样，别人都会自觉地绕开我有安排的时间段来找我。\n\n  而今天，我看到很多公司直接在微信上联系。你要是回复慢了，电话直接打过来，直接叫你去开会。不像我那个年代，老板临时给员工开会也要问一下员工有没有时间，但现在的工作环境连问都不问，直接一句，你来一下。\n\n- 那个年代，我们喜欢有计划地安排工作，然后按此执行。还记得在路透工作的时候，管理者们都说，你工作时如果有 70% 的时间能花在项目开发上，算是很高效了，一般来说，正常值也就是 50% 左右。在亚马逊的时候，每次开会都会把会议中要讨论的事打印出来，前 10 分钟大家都在读文档，然后直接讨论，所以基本上会议都保持在半小时左右。\n\n  这可能是外企的好处吧，从上到下都知道时间管理是很重要的事，所以，从管理层到执行层都会想方设法帮助程序员专注地做好开发工作。包括尽可能的不开会，不开长会，需求和设计都是要论证很久才会决定做不做，项目管理会帮你把你处理额外工作的时间也算进去，还会把你在学习上花的时间也计算进去。所以，时间在整个组织上能够被有效地管理和安排着。完全不像今天国内的互联网公司。\n\n  所以，我以前管理自己的时间还是比较容易的，然而，现在人的工作环境的确是非常不利于管理。不过，我还是想在这里谈一下如何管理自己的时间，希望对你有帮助。\n\n# 主动管理\n\n无论什么事情，如果你发现你持续处于被动的状态下，那么你一定要停下来想一想如何把被动变为主动。因为在被动的方式下工作，你是不可能做好工作的，无论什么事。我是一个非常不喜欢被动的人，所以，对于任何被动状态，我都要“反转控制”，想尽一切方式变成主动。\n\n如果你发现你的时间老是被别人打断，那么你就要告诉大家，我什么时间段在做什么事，请大家不要打扰我。我以前在国外看到有个老外就在自己的工位上挂了一个条幅，上面写着“正在努力写代码中，请勿打断……”而我在亚马逊工作时，亚马逊也允许员工想沉浸于工作时不用来公司而是可以在家办公（work from home）。我在阿里工作那会，有时候也怕被人打断，所以，我会跑到别的楼里找个空的工位工作。\n\n在今天，我觉得你也可以这么干，你可以在群里事先告诉大家，我在几点到几点要无间断地做某个事，这个期间不会看任何微信或是钉钉的群聊，也不会接任何的电话，请大家不要来打扰我。而且还可以学习一下那个我见过的老外，在自己的工位上挂一个不要打扰我的条幅。人肉 Mute 掉所有的打扰。\n\n另外，可以仿照一下以前在 Outlook 里设置工作日程的方式，把你的工作安排预先设置到一个可以共享的日历上，然后分享给大家，让大家了解你的日程。这样，可以让你的同事和老板能事先有个谱儿，而不至于想打断你就打断你。\n\n你甚至可以要求你的同事，重要的事，不要发微信，而是要发邮件，因为微信会有很大概率看不到。这样一来，你就再也不用在一大堆聊天信息中做人肉的大数据挖掘，来找到和你有关的信息。\n\n信息管理真的非常重要，因为将信息做好分类，才方便检索，方便你通过自己的优先级来处理信息。而目前看来，这些只有邮件才能够更好地完成（邮件可以帮你通过邮件标题聚合，你可以设置很多规则来自动化分类邮件，还可以帮你设置自动化回复）。\n\n换句话说，**你要主动管理的不是你的时间，而是管理你的同事，管理你的信息**。\n\n# 学会说“不”\n\n上面说了如何主动地管理你的时间。但是，那只是能让你有大块可以专注于工作的时间。然而，这并不能帮助你解决时间不够的问题。比如，现在的很多公司总是把工作安排得非常紧，今天提的需求，恨不得明天就上线，这也就是为什么今天加班的严重程度比我那个时候还更为严重。\n\n我认为，现在的很多公司已经不尊重科学和客观规律了，如果让他来管理孕妇，我觉得他们恨不得要把 10 个月的产期缩短成 2 个月。\n\n所以，在这种情况下，你要学会对某些事说“不”，甚至是要学习对老板说不。这其实是一种“向上管理”的能力。\n\n以前在外企接受到的管理方面的培训，有这么一条“Never Say No”——永不说不。的确是这样，说“不”会让人产生距离和不信任。所以，真是这样的，永远不要说不。但是，你明明做不到，还不能说不，这应该怎么办呢？这里面的诀窍如下。\n\n1. 当你面对做不到的需求时，你不要说这个需求做不到。尤其是，你不要马上说做不到，你要先想一下，这样让别人觉得你是想做的，但是，在认真思考过后，你觉得做不到，并且给出一个你觉得能做到的方案。这里的诀窍是——**给出另一个你可以做到的方案，而不是把对方的方案直接回绝掉**。\n2. 当你面对过于复杂的需求时，你不要说不。你要反问一下，为什么要这样做？这样做的目的是什么？当了解完目的以后，你可以给出一个自己的方案，或是和对方讨论一个性价比更好的方案。你可以回复说，这个需求好复杂，我们能不能先干这个，再做那个，这样会更经济一些。这里的诀窍是——**我不说我不能完全满足你，但我说我可以部分满足你**。\n3. 当你面对时间完全不够的需求时，你也不要说不。既然对方把压力给你，你要想办法把这个压力还回去，或是让对方来和你一同分担这个压力。\n\n这个时候，我惯用的方式是给回三个选择：a. 我可以加班加点完成，但是我不保证好的质量，有 bug 你得认，而且事后你要给我 1 个月的时间还债。b. 我可以加班加点，还能保证质量，但我没办法完成这么多需求，能不能减少一些？c. 我可以保质保量地完成所有的需求，但是，能不能多给我 2 周时间？\n\n这里的诀窍是——**我不能说不，但是我要有条件地说是。而且，我要把你给我的压力再反过来还给你，看似我给了需求方选择，实际上，我掌握了主动**。\n\n这就是学会说“不”的方法。说白了，你要学会在**“积极主动的态度下对于不合理的事讨价还价”。只有学会了说“不”，你才能够控制好你的时间**。\n\n# 加班和开会\n\n国内的公司和国外公司还有一个很不同的事情，就是大量的加班和大量冗长的会议。我见过很多国内的公司，无论大公司还是小的创业公司，都是这个样子的。\n\n老实说，我对这个事情也能理解也不能理解。一方面，我能理解为什么会有这么多的加班和会议，主要原因还是管理者在管理上只会使用低级的通过劳动密集型的方式来做事。\n\n另一方面，我不能理解的是，国外公司的加班和会议长度根本不像国内的公司，人家做的也比中国的公司好得多。在国内的公司，老板们看到团队在拼命加班，会很高兴，而在国外的公司，老板看到团队在拼命加班，会觉得这个团队一定是哪里出了问题，老板会比较焦虑。\n\n那么，对于身处于这样环境中的我们，应该怎样管理好自己的时间，或是为自己争取时间呢？老实说，在恶劣的环境中优雅的行动，基本上是一件不可能的事情。我也经历过这样的事，但我也没有太好的办法。不过，我还是可以跟你分享几个我的实践方式。\n\n对于加班的事，除了像上面说的那样，学会如何说“不”外，我发现很多时候造成加班的原因就是恶性循环。也就是说，因为加班干出来了质量不好的软件，于是线上故障很多，要花时间处理，而后面的需求也过来了，发现复杂代码的扩展性很差，越干越慢，越干越烂，越干故障越多。于是，你会被抱怨得越来越多。\n\n这里，我觉得，**如果怎么做都要受伤害，那么两害相权取其轻**。你要学会比较是项目延期的伤害大，还是线上故障的伤害大，是先苦后甜好，还是积压问题好，聪明的你应该能做出正确的判断。\n\n对于开会，我觉得今天大多数的会都开错了。在会上抛出问题，还是开放性的问题，然后公说公有理，婆说婆有理，任大家自由发挥，各种跑题跑偏，最后还没有任何的答案。**开会，不是讨论问题，而是讨论方案，开会不是要有议题，而是要有议案**。\n\n所以，作为与会者，如果你发现没有议案，大家海了去说，那么你有两种选择，跳出来帮大家理一理，或者也可以说一下，如果会上讨论不清，要不先线下讨论，有了方案再来评审。也许在一些会上你不敢这么干，但是有些会你是可以这么干的。能影响的这些都能为你争取到很多时间。\n\n好了，总结一下。今天我主要跟你分享了几个能为自己争取更多时间的方法，比如主动管理时间、学会说“不”，以及面对高强度的加班和冗长的会议时，该如何应对和解决等。因为我认为，只有将使用时间的主动权掌握在自己手上，才能更好地利用时间，才能更为高效率的工作。所以，**这才是时间管理的关键点。**\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/995\" > </iframe>","categories":["左耳听风"]},{"title":"014丨推荐阅读：机器学习101","url":"/posts/3490295019.html","content":"\n\n\n自从 2012 年在亚马逊第一次接触机器学习（一个关于预测商品需求的 Demand Forecasting 的项目）以来，我一直在用一些零星的时间学习机器学习相关的东西。所以，说实话，在机器学习方面，我也只是一个新手，也在入门阶段。\n\n在前面文章的评论中，有网友希望我写一篇有关大数据和机器学习的文章，老实说，有点为难我了。所以，我只能结合自己的学习过程写一篇入门级的文章，希望能看到高手的指教和指正。\n\n首先，简单介绍一下机器学习的一些原理。机器学习主要来说有两种方法，监督式学习（Supervised Learning）和非监督式学习（Unsupervised Learning）。\n\n# 监督式学习\n\n所谓监督式学习，也就是说，我们需要提供一组学习样本，包括相关的特征数据以及相应的标签。程序可以通过这组样本来学习相关的规律或是模式，然后通过得到的规律或模式来判断没有被打过标签的数据是什么样的数据。\n\n举个例子，假设需要识别一些手写的数字，那么我们就需要找到尽可能多的手写体数字的图像样本，然后人工或是通过某种算法来明确地标注什么是这些手写体的图片，谁是 1，谁是 2，谁是 3……这组数据就叫样本数据，又叫训练数据（training data）。\n\n通过机器学习的算法，我们可以找到每个数字在不同手写体下的特征，进而找到规律和模式。然后通过得到的规律或模式来识别那些没有被打过标签的手写数据，以此完成识别手写体数字的目标。\n\n一种比较常见的监督式学习，就是从历史数据中获得数据的走向趋势，来预测未来的走向。比如，我们使用历史上的股票走势数据来预测接下来的股价涨跌，或者通过历史上的一些垃圾邮件的样本来识别新的垃圾邮件。\n\n在监督式学习下，需要有样本数据或是历史数据来进行学习，这种方式会有一些问题。比如\n\n- 如果一个事物没有历史数据，那么就不好做了。变通的解决方式是通过一个和其类似事物的历史数据。我以前做过的需求预测，就属于这种情况。对于新上市的商品来说，完全没有历史数据，比如，iPhone X，那么就需要从其类似的商品上找历史数据，如 iPhone 7 或是别的智能手机。\n\n- 历史数据中可能会有一些是噪音数据，需要把这些噪音数据给过滤掉。一般这样的过滤方式要通过人工判断和标注。举两个例子，某名人在其微博或是演讲上推荐了一本书，于是这本书的销量就上升了。这段时间的历史数据不是规律性的，所以就不能成为样本数据，需要去掉。同样，如果某名人（如 Michael Jackson）去世导致和其有关的商品销售量很好，那么，这个事件所产生的数据则不属于噪音数据。因为每年这个名人忌日的时候出现销量上升的可能性非常高，所以，需要标注一下，这是有规律的样本，可以放入样本进行学习。\n\n# 非监督式学习\n\n对于非监督式学习，也就是说，数据是没有被标注过的，所以相关的机器学习算法需要找到这些数据中的共性。因为大量的数据是没有被标识过的，所以这种学习方式可以让大量未标识的数据能够更有价值。\n\n而且，非监督式的学习，可以为我们找到人类很难发现的数据里的规律或模型。所以，也有人将这种学习称为“特征点学习”。其可以让我们自动地为数据进行分类，并找到分类的模型。\n\n一般来说，非监督式学习会应用在一些交易型的数据中。比如，有一堆的用户购买数据，但是对于人类来说，我们很难找到用户属性和购买商品类型之间的关系，而非监督式学习算法可以帮助我们找到他们之间的关系。\n\n比如，一个在某一年龄段区间的女生购买了某种肥皂，有可能说明这个女生在怀孕期，或是某人购买儿童用品，有可能说明这个人的关系链中有孩子，等等。于是这些信息会被用作一些所谓的精准市场营销活动，从而可以增加商品销量。\n\n我们这么来说吧，监督式学习是在被告诉过正确的答案之后的学习，而非监督式学习是在没有被告诉正确答案时的学习，所以说，非监督式的学习是在大量的非常混乱的数据中找寻一些潜在的关系，这个成本也比较高。\n\n这种非监督式学习也会经常被用来检测一些不正常的事情发生，比如信用卡的诈骗或是盗刷。也有被用在推荐系统中，比如买了这个商品的人又买了别的什么东西，或是如果某个人喜欢某篇文章、某个音乐、某个餐馆，那么可能他会喜欢某款车、某个明星，或某个地方。\n\n在监督式的学习的算法下，我们可以用一组“狗”的照片来确定某个照片中的物体是不是狗。而在非监督式的学习算法下，我们可以通过一个照片来找到与其相似事物的照片。这两种学习方式都有各自适用的场景。\n\n# 如何找到数据的规律和关联\n\n机器学习基本就是在已知的样本数据中寻找数据的规律，在未知的数据中找数据的关系。所以，这就需要一定的数学知识了，但对于刚入门的人来说，学好高数、线性代数、概率论、数据建模等大学本科的数学知识应该就够用了。以前上大学时，总觉得这些知识没什么用处，原来只不过是自己太 low，还没有从事会运用到这些知识的工作。\n\n总之，机器学习中的基本方法论是这样的。\n\n1. 要找到数据中的规律，你需要找到数据中的特征点。\n2. 把特征点抽象成数学中的向量，也就是所谓的坐标轴。一个复杂的学习可能会有成十上百的坐标轴。\n3. 抽象成数学向量后，就可以通过某种数学公式来表达这类数据（就像 y=ax+b 是直线的公式），这就是数据建模。\n\n这个数据公式就是我们找出来的规律。通过这个规律，我们才可能关联类似的数据。\n\n当然，也有更为简单粗暴的玩法。\n\n1. 把数据中的特征点抽象成数学中的向量。\n2. 每个向量一个权重。\n3. 写个算法来找各个向量的权重是什么。\n\n有人把这个事叫“数据搅拌机”。据说，这种简单粗暴的方式超过了那些所谓的明确的数学公式或规则。这种“土办法”有时候会比高大上的数学更有效，哈哈。\n\n关于机器学习这个事，你可以读一读 [Machine Learning is Fun!](https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471) 这篇文章，以及它的[中文翻译版](https://zhuanlan.zhihu.com/p/24339995)。\n\n# 相关算法\n\n对于监督式学习，有如下经典算法。\n\n1. 决策树（Decision Tree）。比如自动化放贷、风控。\n2. 朴素贝叶斯分类（Naive Bayesian classification）。可以用于判断垃圾邮件，对新闻的类别进行分类，比如科技、政治、运动，判断文本表达的感情是积极的还是消极的，以及人脸识别等。\n3. 最小二乘法（Ordinary Least Squares Regression）。算是一种线性回归。\n4. 逻辑回归（Logisitic Regression）。一种强大的统计学方法，可以用一个或多个变量来表示一个二项式结果。它可以用于信用评分、计算营销活动的成功率、预测某个产品的收入等。\n5. 支持向量机（Support Vector Machine，SVM）。可以用于基于图像的性别检测，图像分类等。\n6. 集成方法（Ensemble methods）。通过构建一组分类器，然后根据它们的预测结果进行加权投票来对新的数据点进行分类。原始的集成方法是贝叶斯平均，但是最近的算法包括纠错输出编码、Bagging 和 Boosting。\n\n对于非监督式的学习，有如下经典算法。\n\n1. 聚类算法（Clustering Algorithms）。聚类算法有很多，目标是给数据分类。\n2. 主成分分析（Principal Component Analysis，PCA）。PCA 的一些应用包括压缩、简化数据，便于学习和可视化等。\n3. 奇异值分解（Singular Value Decomposition，SVD）。实际上，PCA 是 SVD 的一个简单应用。在计算机视觉中，第一个人脸识别算法使用 PCA 和 SVD 来将面部表示为“特征面”的线性组合，进行降维，然后通过简单的方法将面部匹配到身份。虽然现代方法更复杂，但很多方面仍然依赖于类似的技术。\n4. 独立成分分析（Independent Component Analysis，ICA）。ICA 是一种统计技术，主要用于揭示随机变量、测量值或信号集中的隐藏因素。\n\n上面的这些相关算法来源自博文《[The 10 Algorithms Machine Learning Engineers Need to Know](https://www.kdnuggets.com/2016/08/10-algorithms-machine-learning-engineers.html)》。\n\n# 相关推荐\n\n学习机器学习有几个课是必须要上的，具体如下。\n\n- 吴恩达教授（Andrew Ng）在 [Coursera 上的机器学习课程](https://www.coursera.org/learn/machine-learning)非常棒。我强烈建议从此入手。对于任何拥有计算机科学学位的人，或是还能记住一点点数学的人来说，都非常容易入门。这个斯坦福大学的课程后面是有作业的，请尽量拿满分。另外，[网易公开课上也有该课程](http://open.163.com/special/opencourse/machinelearning.html)。\n- 卡内基梅隆大学计算机科学学院汤姆·米切尔（Tom Mitchell）教授的机器学习课程，这里有[英文原版视频和课件 PDF](http://www.cs.cmu.edu/~tom/10701_sp11/lectures.shtml) 。汤姆·米切尔是全球 AI 界顶级大牛，在机器学习、人工智能、认知神经科学等领域都有建树，撰写了机器学习方面最早的教科书之一[《机器学习》](http://item.jd.com/10131321.html)，被誉为入门必读图书。\n- 加利福尼亚理工学院亚瑟·阿布·穆斯塔法（Yaser Abu-Mostafa）教授的 [Learning from Data 系列课程](http://work.caltech.edu/lectures.html) 。本课程涵盖机器学习的基本理论和算法，并将理论与实践相结合，更具实践指导意义，适合进阶。\n\n除了上述的那些课程外，下面这些资源也很不错。\n\n- YouTube 上的 Google Developers 的 [Machine Learning Recipes with Josh Gordon](https://www.youtube.com/playlist?list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal) 。这 9 集视频，每集不到 10 分钟，从 Hello World 讲到如何使用 TensorFlow，值得一看。\n- 还有 [Practical Machine Learning Tutorial with Python Introduction](https://pythonprogramming.net/machine-learning-tutorial-python-introduction/) 上面一系列的用 Python 带着你玩 Machine Learning 的教程。\n- Medium 上的 [Machine Learning - 101](https://medium.com/machine-learning-101) 讲述了好多我们上面提到过的经典算法。\n- 还有，Medium 上的 [Machine Learning for Humans](https://medium.com/machine-learning-for-humans)，不仅提供了入门指导，更介绍了各种优质的学习资源。\n- [杰森·布朗利（Jason Brownlee）博士的博客](https://machinelearningmastery.com/blog/) 也是非常值得一读，其中好多的 “How-To”，会让你有很多的收获。\n- [i am trask](http://iamtrask.github.io) 也是一个很不错的博客。\n- 关于 Deep Learning 中神经网络的学习，推荐 YouTube 介绍视频 [Neural Networks](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)。\n- 用 Python 做自然语言处理[Natural Language Processing with Python](http://www.nltk.org/book/)。\n- 以及 GitHub 上的 [Machine Learning 和 Deep Learning](https://github.com/ujjwalkarn/Machine-Learning-Tutorials) 的相关教程列表。\n\n此外，还有一些值得翻阅的图书。\n\n- [《机器学习》](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/MLbook2016.htm)，南京大学周志华教授著。它是一本机器学习方面的入门级教科书，适合本科三年级以上的学生学习。这本书如同一张地图一般，让你能“观其大略”，了解机器学习的各个种类、各个学派，其覆盖面与同类英文书籍相较不遑多让。\n- [A Course In Machine Learning](http://ciml.info/)，马里兰大学哈尔·道姆（Hal Daumé III）副教授著。 这本书讲述了几种经典机器学习算法，包括决策树、感知器神经元、kNN 算法、K-means 聚类算法、各种线性模型（包括对梯度下降、支持向量机等的介绍）、概率建模、神经网络、非监督学习等很多主题，还讲了各种算法使用时的经验技巧，适合初学者学习。此外，官网还提供了免费电子版。\n- [Deep Learning](http://www.deeplearningbook.org/)，麻省理工学院伊恩·古德费洛（Ian Goodfellow）、友华·本吉奥（Yoshua Benjio）和亚伦·考维尔（Aaron Courville）著。这本书是深度学习专题的经典图书。它从历史的角度，将读者带进深度学习的世界。深度学习使用多层的（深度的）神经元网络，通过梯度下降算法来实现机器学习，对于监督式和非监督式学习都有大量应用。如果读者对该领域有兴趣，可以深入阅读本书。本书官网提供免费电子版，但不提供下载。实体书（英文原版或中文翻译版）可以在网上买到。\n- [Reinforcement Learning](http://www.freetechbooks.com/reinforcement-learning-an-introduction-second-edition-draft-t1282.html)，安德鲁·巴托（Andrew G.Barto）和理查德·萨顿（Richard S. Sutton）著。这本书是强化学习（Reinforcement Learning）方面的入门书。它覆盖了马尔可夫决策过程（MDP）、Q-Learning、Sarsa、TD-Lamda 等方面。这本书的作者是强化学习方面的创始人之一。强化学习（结合深度学习）在围棋程序 AlphaGo 和自动驾驶等方面都有着重要的应用。\n- [Pattern Recognition and Machine Learning](https://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738) ，微软剑桥研究院克里斯托夫·比肖普（Christoph M. Bishop）著。这本书讲述了模式识别的技术，包括机器学习在模式识别中的应用。模式识别在图像识别、自然语言处理、控制论等多个领域都有应用。日常生活中扫描仪的 OCR、平板或手机的手写输入等都属于该领域的研究。\n\n好了，今天推荐的内容就这些。我目前也在学习中，希望能够跟你一起交流探讨，也期望能得到你的指教和帮助。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/862\" > </iframe>\n\n","categories":["左耳听风"]},{"title":"016丨时间管理：如何利用好自己的时间？","url":"/posts/3815558183.html","content":"\n\n\n前面我们讨论了如何争取到更多自己可以控制的时间，今天，我们接着再来聊另外一个话题——如何利用好自己的时间。对此，我有下面的这些心得和方法，如果你有更好的方法，也欢迎告诉我。\n\n# 投资自己的时间\n\n其实，时间就像金钱一样，你得学会投资时间，把时间投资在有价值有意义的地方，你就会有“更多的时间”。\n\n- **花时间学习基础知识，花时间读文档**。在参加工作的这 20 年时间里，我发现，很多程序员都把时间都浪费在了查错上。究其根本原因就是基础知识不完整，没有好好地把技术相关的用户文档读完就仓促上手做事情了。其实只要把基础打扎实，认真读一下文档，你会省出很多很多的时间。**系统地学习一门技术是非常关键的，所以这个时间是值得投资的**。\n\n- **花时间在解放自己生产力的事上**。在自动化、可配置、可重用、可扩展上要多花时间。对于软件开发来说，能自动化的事，就算多花点时间也要自动化，因为下次就不用花时间了。让自己的软件模块可以更灵活地配置和扩展，这样如果有需求变更或是有新需求的时候，可以不用改代码，或者就算要改代码也很容易。\n\n  这里，可能很多人会说不要过度设计，对于这个观点，我既同意，也反对。的确，过度设计不好，但是只要是能在未来节省时间的，宁可这个项目延期，我也会做的。**花时间在解放自己的事上是最有意义的了**。\n\n- **花时间在让自己成长的事上**。注意，晋升并不代表成长，成长不应该只看在一个公司内，而是要看在行业内，在行业内的成长才是真正的成长。所以，把时间花在能让自己成长，能让自己有更强的竞争力，能让自己有更大的视野，能让自己有更多可能性的事情上。这样的时间投资才是有价值的。\n\n- **花时间在建立高效的环境上**。我相信你和我会有一样的一个习惯，那就“工欲善其事，必先利其器”。我们程序员在做事之前都喜欢把自己的工作环境整理到自己喜欢的状态下。比如使用趁手的开发工具，使用趁手的设备。\n\n  这里，我想把这个事扩大一下，花些时间在影响你身边的人上，比如你的同事，你的产品经理，你的老板，去影响他们，让他们理解你，让他们配合你来建立更好的流程和管理方法。在这个方向上花时间也是很值得的。\n\n# 规划自己的时间\n\n**定义好优先级**。无论你写不写出来，你一定都会有一个自己的 to-do list。有 to-do list 并不是什么高深的事。更重要的是，你要知道什么事是重要的，什么事是紧急的，什么事重要但不紧急，什么事又重要又紧急。这有利于你划分优先级。\n\n**最短作业优先**。对于相同优先级的事，我个人喜欢的是“最短作业优先”的调度算法。理由是，先把可以快速做完的事做完，看到 to-do list 上划掉一个任务，看到任何的数据在减少，对于自己也好，对于老板也好。老板可以看到你的工作进度飞快，一方面有利于为后面复杂的工作争取更多的时间（老板只有在你有 Deliver 的时候才愿意给你更多的时间），另一方面，看到任务列表的减少会让你的心态更为积极。\n\n而反过来，你花太多的时间在长作业上，长作业通常很容易出现“意外情况”让你花更多的时间，但此时你发现还有很多别的事没有做，这会让你产生焦虑感，产生更多的压力，进而导致更慢的生产效率。\n\n**想清楚再做**。我发现很多时候，我们没有想清楚就开干了，边干边想，这样的工作方式其实很糟糕。你会发现，如果你没有想清楚，你总是要对已完成的工作进行返工，返工好几次，其实是非常浪费时间的。\n\n所以，对于一些没想清楚的事，或是自己不太有信心的事，还是先看看有没有已有的成熟解决方案，或是找更牛的人来给你把把关，帮你出出主意，看看有没有更好、更简单的方式。\n\n**关注长期利益规划**。要多关注长远可以节省多少时间，而不是当前会花费多少时间。长期成本会比短期成本大得多。所以，宁可在短期延期，也不要透支未来。这里的逻辑是，工作上的事你永远也做不完的，长痛不如短痛。\n\n我一年要做 10 个项目，我宁可第 1 或第 2 个项目被老板骂，但是我可以赢得后面 8 个项目，从后面 8 个项目上把之前失去的找回来。而如果反过来的话，我虽然一开始得到了老板的信任，但是后面越来越玩不动，最终搬起一块大石头砸了自己的脚。而且，不关注长远利益的人，基本上来说也是很难有成长的。\n\n也就是说，**你要学会规划自己的行动计划，不是短期的，而是一个中长期的。我个人建议是按季度来规划，这个季度做什么，达到什么目标，一年往前走四步，而不是只考虑眼下**。\n\n# 用好自己的时间\n\n**将军赶路不追小兔**。这个世界有太多的东西会让我们分心和跑偏。能专注地把时间投入到一个有价值的事上是非常重要的。确定自己的目标，专注达到这个目标，而不是分心。将军的目标是要攻城，而不是追兔子。所以，你要学会过滤掉与自己目标无关的事，不要让那些无关的事控制自己。\n\n比如，不要让别人来影响自己的心情，心情被影响了，你一下就会什么都不想干了。做自己心情的主人，不要让别人 hack 了你的心情。再比如，知道哪些是自己可以控制的事，哪些是自己控制不了的事，在自己能控制的地方花时间。\n\n再比如，知道哪些是更有效的路径，是花时间改变别人，还是花时间去寻找志同道合的人。不与不如自己的人争论，也不要尝试花时间去叫醒那些装睡的人，这些都是非常浪费时间的事。多花时间在有产出的事上，少花时间在说服别人的事上。\n\n**形成习惯**。再好的方法，如果没有形成习惯，不能在实际的工作和生活中解决实际问题，都将成为空谈。如果你是个追求上进的人，我相信一定看过很多时间管理方法的文章和书籍，并且看的时候还会有些振奋，内心有时还会不自觉地想，“嗯，嗯！这个方法不错，正是我需要的，可以解决我的问题……”但很多时候都坚持不了几天就抛之脑后了。\n\n所以，在讲述完如何争取时间，及如何使用时间之后，我想分享一下如何将这些时间管理方法形成习惯，因为我坚信：“做”比“做好”更重要。养成一个好习惯通常需要 30 天左右的时间，尤其在最初的几天就更为重要了。这时，不妨将文章中提到的方法和几个要点，写在某本书或者笔记本的扉页上，方便查看，时刻提醒自己。\n\n而且，你可以结合自己的实际情况，适当做出调整。我的方法是我根据自己的情况总结的，不一定完全适合你，你完全可以基于我说的几个原则，发掘其他更适合自己的方法，这样才能更有利于形成习惯，对你更有帮助。\n\n**形成正反馈**。在前面的文章中，我提到过，要有正反馈，也就是成就感，有助于完成一些看似难以完成的事儿。比如，我们说过，学习是逆人性的事儿，但如果在学习过程中不断地有正反馈，就更利于我们坚持下去。要让自己有正反馈，那就需要把时间花在有价值的地方，比如，解决自己和他人的痛点，这样你会收获别人的赞扬和鼓励。\n\n**反思和举一反三**。可以尝试每周末花上点时间思考一下，本周做了哪些事儿？时间安排是否合理？还有哪些可以优化提高的地方？有点儿类似于我们常说的“复盘”。然后思考一下，下周的主要任务是什么？并根据优先级规划一下完成这些任务的顺序，也就是做一些下周的工作规划。\n\n这样每周都能及时得到自己做时间管理之后的反馈，并有助于持续优化。通常坚持做时间管理一段时间以后，你都能在每次复盘时得到正反馈，这是有利于我们形成时间管理习惯的。但我这里也想强调一点，我们也要允许偶尔的“负反馈”，因为人的状态总是会有高潮和低谷的，控制好一个合理的度就可以了。\n\n人最宝贵的财富就是时间，把时间用在刀刃上，必将让你的人生有更多收获。\n\n# 其他\n\n写了这么多，还是让你来开心一下吧。下面这个图是我在某国内互联网公司工作的时候和我老板的聊天记录。是的，就只有这些信息，每次看到这个聊天记录时，我都会有一种莫明的喜感。结合这篇文章的主题，也给你开心开心。\n\n\n\n![image-20231018145030705](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20231018145030705.png)\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/997\" > </iframe>","categories":["左耳听风"]},{"title":"018丨故障处理最佳实践：故障改进","url":"/posts/4258323358.html","content":"\n\n\n在上篇文章中，我跟你分享了在故障发生时，我们该怎样做，以及在故障前该做些什么准备。只要做到我提到的那几点，你基本上就能游刃有余地处理好故障了。然而，在故障排除后，如何做故障复盘及整改优化则更为重要。在这篇文章中，我就跟你聊聊这几个方面的内容。\n\n# 故障复盘过程\n\n对于故障，复盘是一件非常重要的事情，因为我们的成长基本上就是从故障中总结各种经验教训，从而可以获得最大的提升。在亚马逊和阿里，面对故障的复盘有不一样的流程，虽然在内容上差不多，但细节上有很多不同。\n\n亚马逊内部面对 S1 和 S2 的故障复盘，需要那个团队的经理写一个叫 COE（Correction of Errors）的文档。这个 COE 文档，基本上包括以下几方面的内容。\n\n- **故障处理的整个过程**。就像一个 log 一样，需要详细地记录几点几分干了什么事，把故障从发生到解决的所有细节过程都记录下来。\n- **故障原因分析**。需要说明故障的原因和分析报告。\n- **Ask 5 Whys**。需要反思并反问至少 5 个为什么，并为这些“为什么”找到答案。\n- **故障后续整改计划**。需要针对上述的“Ask 5 Whys”说明后续如何举一反三地从根本上解决所有的问题。\n\n然后，这个文档要提交到管理层，向公司的 VP 级的负责人进行汇报，并由他们来审查。\n\n阿里的故障复盘会会把所有的相关人员都叫到现场进行复盘。我比较喜欢这样的方式，而不是亚马逊的由经理来操作这个事的方式。虽然阿里的故障复盘会会开很长时间，但是把大家叫在一起复盘的确是一个很好的方式。一方面信息是透明的，另一方面，也是对大家的一次教育。\n\n阿里的故障处理内容和亚马逊的很相似，只是没有“Ask 5 Whys”，但是加入了“故障等级”和“故障责任人”。对于比较大的故障，责任人基本上都是由 P9/M4 的人来承担。而且对于引发故障的直接工程师，阿里是会有相关的惩罚机制的，比如，全年无加薪无升职，或者罚款。\n\n**老实说，我对惩罚故障责任人的方式非常不认同。**\n\n- 首先，惩罚故障责任人对于解决故障完全没有任何帮助。因为它们之间没有因果关系，既不是充分条件，也不是必要条件，更不是充要条件。这是逻辑上的错误。\n- 其次，做得越多，错得越多。如果不想出错，最好什么也不要做。所以，惩罚故障责任人只会让大家都很保守，也会让大家都学会保守，而且开始推诿，营造一种恐怖的气氛。\n\n说个小插曲。有一次和一个同学一起开发一个系统，我们两个人的代码在同一个代码库中，而且也会运行在同一个进程里。这个系统中有一个线程池模型，我想直接用了。结果因为这个线程池是那个同学写的，他死活不让我用，说是各用各的分开写，以免出了问题后，说不清楚，引起不必要的麻烦。最后，在一个代码库中实现了两个线程池模型，我也是很无语。\n\n另外，亚马逊和阿里的故障整改内容不太一样。亚马逊更多的是通过技术手段来解决问题，几乎没有增加更复杂的流程或是把现有的系统复杂化。\n\n阿里的故障整改中会有一些复杂化问题的整改项，比如，对于误操作的处理方式是，以后线上操作需要由两个人来完成，其中一个人操作，另一个人检查操作过程。或是对于什么样的流程需要有审批环节。再比如：不去把原有的系统改好，而是加入一个新的系统来看（kān，第一声）着原来的那个不好的系统。当然，也有一些整改措施是好的，比如，通过灰度发布系统来减少故障面积。\n\n# 故障整改方法\n\n就故障整改来说，我比较喜欢亚马逊的那个 Ask 5 Whys 玩法，这个对后面的整改会有非常大的帮助。最近一次，在帮一家公司做一个慢 SQL 的故障复盘时，我一共问了近 9 个为什么。\n\n1. 为什么从故障发生到系统报警花了 27 分钟？为什么只发邮件，没有短信？\n2. 为什么花了 15 分钟，开发的同学才知道是慢 SQL 问题？\n3. 为什么监控系统没有监测到 Nginx 499 错误，以及 Nginx 的 upstream_response_time 和 request_time？\n4. 为什么在一开始按 DDoS 处理？\n5. 为什么要重启数据库？\n6. 为什么这个故障之前没有发生？因为以前没有上首页，最近上的。\n7. 为什么上首页时没有做性能测试？\n8. 为什么使用这个高危的 SQL 语句？\n9. 上线过程中为什么没有 DBA 评审？\n\n通过这 9 个为什么，我为这家公司整理出来很多不足的地方。提出这些问题的大致逻辑是这样的。\n\n第一，优化故障获知和故障定位的时间。\n\n- 从故障发生到我们知道的时间是否可以优化得更短？\n- 定位故障的时间是否可以更短？\n- 有哪些地方可以做到自动化？\n\n第二，优化故障的处理方式。\n\n- 故障处理时的判断和章法是否科学，是否正确？\n- 故障处理时的信息是否全透明？\n- 故障处理时人员是否安排得当？\n\n第三，优化开发过程中的问题。\n\n- Code Review 和测试中的问题和优化点。\n- 软件架构和设计是否可以更好？\n- 对于技术欠债或是相关的隐患问题是否被记录下来，是否有风险计划？\n\n第四，优化团队能力。\n\n- 如何提高团队的技术能力？\n- 如何让团队有严谨的工程意识？\n\n具体采取什么样的整改方案会和这些为什么有很大关系。\n\n总之还是那句话，解决一个故障可以通过技术和管理两方面的方法。如果你喜欢技术，是个技术范，你就更多地用技术手段；如果你喜欢管理，那么你就会使用更多的管理手段。**我是一个技术人员，我更愿意使用技术手段。**\n\n# 根除问题的本质\n\n最后，对于故障处理，我能感觉得到，**一个技术问题，后面隐藏的是工程能力问题，工程能力问题后面隐藏的是管理问题，管理问题后面隐藏的是一个公司文化的问题，公司文化的问题则隐藏着创始人的问题……**\n\n所以，这里给出三条我工作这 20 年总结出来的原则（Principle），供你参考。\n\n1. **举一反三解决当下的故障**。为自己赢得更多的时间。\n2. **简化复杂、不合理的技术架构、流程和组织**。你不可能在一个复杂的环境下根本地解决问题。\n3. **全面改善和优化整个系统，包括组织**。解决问题的根本方法是改善和调整整体结构。而只有简单优雅的东西才有被改善和优化的可能。\n\n换句话说，我看到很多问题出了又出，换着花样地出，大多数情况下是因为这个公司的系统架构太过复杂和混乱，以至于你不可能在这样的环境下干干净净地解决所有的问题。\n\n所以，你要先做大扫除，简化掉现有的复杂和混乱。如果你要从根本上改善一个事，那么首先得把它简化了。这就是这么多年来我得到的认知。\n\n但是，很不幸，我们就是生活在这样一个复杂的世界，有太多的人喜欢把简单的问题复杂化。所以，要想做到简化，基本上来说是非常非常难的。（下面这个小视频很有意思，非常形象地说明了，想在一个烂摊子中解决问题，几乎是不可能的事儿。）\n\n![image-20231020092548248](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20231020092548248.png)\n\n路漫漫其修远兮……\n\n在这篇文章的末尾，我想发个邀请给你。请你来聊聊，在处理好故障之后，你所在的企业会采取什么样的复盘方式。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/1064\" > </iframe>","categories":["左耳听风"]},{"title":"017丨故障处理最佳实践：应对故障","url":"/posts/1242831614.html","content":"\n\n\n或多或少我们都会经历线上的故障。在我的职业生涯中，就经历过很多的线上故障。老实说，线上故障是我们技术人员成长中必须要经历的事。从故障中我们可以吸取到很多教训，也能让我们学到很多书本上学不到的知识。坑踩多了，我们会变得越来越有经验，也就成为老司机了。\n\n不过，我看到很多公司处理线上故障的方式并不科学，而且存在很多问题，所以，今天这篇文章就来分享一些我的经验。这些经验主要来自亚马逊和阿里这两家互联网公司，以及我个人的经验总结。希望这套方法能够对你有帮助。\n\n# 故障发生时\n\n在故障发生时，最重要的是快速恢复故障。而快速恢复故障的前提是快速定位故障源。因为在很多分布式系统中，一旦发生故障就会出现“多米诺骨牌效应”。也就是说，系统会随着一个故障开始一点一点地波及到其它系统，而且这个过程可能会很快。一旦很多系统都在报警，要想快速定位到故障源就不是一件简单的事了。\n\n在亚马逊内部，每个开发团队至少都会有一位 oncall 的工程师。在 oncall 的时候，工程师要专心处理线上故障，轮换周期为每人一周。一旦发生比较大的故障，比如，S1 全部不可用，或 S2 某功能不可用，而且找不到替代方案，那么这个故障就会被提交到一个工单系统里。几乎所有相关团队 oncall 的工程师都会被叫到线上处理问题。\n\n工作流是这样的，工程师先线上签到，然后自查自己的服务，如果自己的服务没有问题，那么就可以在旁边待命（standby），以备在需要时进行配合。如果问题没有被及时解决，就会自动升级到高层，直到 SVP 级别。\n\n大家都知道，在亚马逊，不是按技能分工，而是按职责分工，也就是一个团队不是按前端、后端、运维等来分工，而是按所负责的 Service 来分工。\n\n所以，亚马逊的开发人员都是前端、后端、测试、运维全部都要干的。而亚马逊内部有很多的服务，一旦出现问题，为了避免一个工单在各个团队流转，需要所有团队上线处理，这样是最快的。\n\n如果我们的系统架构是分布式服务化的，那么一个用户的请求可能会经过很多的服务，开发和运维起来是非常麻烦的。此时，跨团队跨部门的开发和运维就变得非常重要了。\n\n就我的经历而言，在故障发生时，亚马逊的处理过程是比较有效和快速的，尤其是能够快速地定位故障源。对于被影响的其他团队也可以做一定的处理，比如做降级处理，这样可以控制故障的范围不被扩散。\n\n故障源团队通常会有以下几种手段来恢复系统。\n\n- **重启和限流**。重启和限流主要解决的是可用性的问题，不是功能性的问题。重启还好说，但是限流这个事就需要相关的流控中间件了。\n- **回滚操作**。回滚操作一般来说是解决新代码的 bug，把代码回滚到之前的版本是快速的方式。\n- **降级操作**。并不是所有的代码变更都是能够回滚的，如果无法回滚，就需要降级功能了。也就是说，需要挂一个停止服务的故障公告，主要是不要把事态扩大。\n- **紧急更新**。紧急更新是常用的手段，这个需要强大的自动化系统，尤其是自动化测试和自动化发布系统。假如你要紧急更新 1000 多台服务器，没有一个强大的自动化发布系统是很难做到的。\n\n也就是说，出现故障时，**最重要的不是 debug 故障，而是尽可能地减少故障的影响范围，并尽可能快地修复问题**。\n\n国内的很多公司，都是由专职的运维团队来处理线上问题的。然而，运维团队通常只能处理一些基础设施方面的问题，或是非功能性的问题。对于一些功能性的问题，运维团队是完全没有能力处理的，只能通过相应的联系人，把相关的开发人员叫到线上来看。\n\n而可能这个开发人员看到的是别的系统有问题，又会叫上其它团队的人来。所以，一级一级地传递下去，会浪费很多时间。\n\n# 故障前的准备工作\n\n为了能够在面临故障时做得有条不紊，我们需要做一些前期的准备工作。这些准备工作做得越细，故障处理起来也就越有条理。我们知道，故障来临时，一切都会变得混乱。此时，对于需要处理故障的我们来说，事可以乱，但人不能乱。如果人跟着事一起乱，那就是真正的混乱了。\n\n所以，我们需要做一些故障前的准备工作。在这里，我给出一些我的经验。\n\n- **以用户功能为索引的服务和资源的全视图**。首先，我们需要一个系统来记录前端用户操作界面和后端服务，以及服务使用到的硬件资源之间的关联关系。这个系统有点像 CMDB（配置管理数据库），但是比 CMDB 要大得多，是以用户端的功能来做索引的。然后，把后端的服务、服务的调用关系，以及服务使用到的资源都关联起来做成一个视图。\n\n  这个视图最好是由相应的自动化监控系统生成。有了这个资源图后，我们就可以很容易地找到处理故障的路径了。**这就好像一张地图，如果没有地图，我们只能像个无头苍蝇一样乱试了**。\n\n- **为地图中的各个服务制定关键指标，以及一套运维流程和工具，包括应急方案**。以用户功能为索引，为每个用户功能的服务都制定一个服务故障的检测、处理和恢复手册，以及相关的检测、查错或是恢复的运维工具。对于基础层和一些通用的中间件，也需要有相应的最佳实践的方法。\n\n  比如 Redis，怎样检查其是否存在问题，怎样查看其健康和运行状态？哪些是关键指标，面对常见的故障应该怎么应对，服务不可用的服务方案是什么，服务需要回滚了应该怎么操作，等等。**这就好像一个导航仪，能够告诉你怎么做。而没有导航仪，就没有章法，会导致混乱**。\n\n- **设定故障的等级**。还要设定不同故障等级的处理方式。比如，亚马逊一般将故障分为 4 级：1 级是全站不可用；2 级是某功能不可用，且无替代方案；3 级是某功能不可用，但有替代方案；4 级是非功能性故障，或是用户不关心的故障。阿里内的分类更多样一些，有时会根据影响多少用户来定故障等级。\n\n  制定故障等级，主要是为了确定该故障要牵扯进多大规模的人员来处理。故障级别越高，牵扯进来的人就越多，参与进来的管理层级别也就越高。就像亚马逊的全员上线 oncall 一样。**这就好像是我们社会中常用的“红色警报”、“橙色警报”、“黄色警报”之类的，会触发不同的处理流程**。\n\n- **故障演练**。故障是需要演练的。因为故障并不会时常发生，但我们又需要不断提升处理故障的能力，所以需要经常演练。一些大公司，如 Netflix，会有一个叫 Chaos Monkey 的东西，随机地在生产线上乱来。Facebook 也会有一些故障演习，比如，随机关掉线上的一些服务器。总之，要提升故障处理水平，最好的方式就是实践。见得多了，处理得多了，才能驾轻就熟。**故障演练是一个非常好的实践**。\n\n- **灰度发布系统**。要减少线上故障的影响范围，通过灰度发布系统来发布是一个很不错的方式。毕竟，我们在测试环境中很难模拟出线上环境的所有情况，所以，在生产线上进行灰度发布或是 A/B 测试是一件很好的事。\n\n在亚马逊，发布系统中有一个叫 Weblab 的系统，就是用来做灰度发布的。另外，亚马逊全球会有多个站点。一般来说，会先发中国区。如果中国区没什么问题了，就发日本区，然后发欧洲区，最后是美国区。而如果没有很多站点的话，那么你就需要一个流量分配系统来做这个事了。\n\n好了。今天就分享这么多。我觉得，只要能做好上面的几点，你处理起故障来就一定会比较游刃有余了。\n\n在这篇文章的末尾，我想发个邀请给你。请你来聊聊，你所经历过的线上故障，以及有哪些比较好的故障处理方法。\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/1059\" > </iframe>","categories":["左耳听风"]},{"title":"019丨答疑解惑：我们应该能够识别的表象和本质","url":"/posts/2098821550.html","content":"\n\n\n前两天，我以前在亚马逊（Amazon）团队的一个小伙伴从西雅图打来电话，和我主要聊了一下他最近的一些想法和动向。他在最近几个月面试了很多美国的本土公司，从大公司到创业公司都有，比如 Facebook、Snapchat、Oracle、微软、谷歌、Netflix、Uber 等。他今年 30 岁出头，到美国那边也有 3 年多时间了，所以想要多一些经历，到不同的公司看一下。\n\n我觉得他这个想法挺好的。于是我们聊了一些对这些公司的看法，进而聊到他想要什么，感兴趣什么，想要经历什么，以及擅长什么，未来如何发展等话题……在两个多小时交谈的过程中，我们谈论到了一些关于他个人发展以及技术上的东西。他听我的建议后，说很有价值。于是，我想既然有价值，那么就把这些分享出来，供更多的人参考吧。\n\n首先，我觉得在美国做技术真的比国内幸福好多，有那么多很不错的不同类别的公司可供选择。这与国内相比，选择空间实在是太大了，真是幸福。所以，在如此纷乱和多样化的地方，真是需要确定自己的发展方向和目标。不然就会像这个小伙儿一样，当 offer 像雪片一样飞过来的时候，却有点不知所措了。\n\n我直接和他说，你现在不愁工作了，可以规划自己的职业生涯了，那么问题是你想走哪条路，对什么方向有兴趣，或是自己的长项是什么？结果，他说他也不知道，说就是想多看看多经历一些事情，也不知道自己最终会对什么事有兴趣，也不知道哪个方向更适合自己，可能再来个 5 年就能明确了。不过，他明确表示对前端技术不感兴趣。\n\n我对他的这些思考没有任何异议，因为我觉得他的能力没有问题，我无非就是想和他说说我的一些认识和看法，希望可以帮他开阔开阔思路。我基本上是给了他如下的这些看法和观点。\n\n# 关于兴趣和投入\n\n兴趣是学习的助燃剂。对一件事有兴趣是是否愿意对这件事投入更多时间或者资源的前提条件。因此，找到自己的兴趣点的确是非常关键的。不过，我们也能看到下面几点。\n\n- **一方面，兴趣是需要保持的**。有的人有的事就是三分钟的兴趣。刚开始兴趣十足，然而时间一长，兴趣因为各种原因不能保持，就会很快地“移情别恋”了。所以，不能持久的兴趣，或是一时兴起的兴趣，都无法让人投入下去。\n- **另一方面，兴趣其实也是可以培养出来的**。我高考时，对计算机软件毫无兴趣，反而对物理世界里的很多东西感兴趣，比如无线电、原子能，或是飞行器之类的。但阴差阳错，我最终考了个计算机软件专业，然后发现，自己越来越喜欢编程了，于是就到了今天。\n\n我发现，一个可以持久的兴趣，或是可以培养出来的兴趣，后面都有一个比较本质的东西，其实就是成就感，他是你坚持或者努力的最直接的正反馈。也就是说，**兴趣只是开始，而能让人不断投入时间和精力的则是正反馈，是成就感**。\n\n带娃的父母可能对此比较好理解。比如，我家小孩 3 岁的时候，我买了一桶积木给她。她一开始只喜欢把积木胡乱堆放，没玩一会就对这种抽象的玩具失去了兴趣，去玩别的更形象的玩具去了。\n\n于是，我就搭了一个小城堡给她看，她看完后兴趣就来了，也想自己搭一个。但是，不一会儿，她就受挫了，因为没有掌握好物体在构建时的平衡和支点的方法，所以搭出来的东西会倒。\n\n我能看到，有时积木倒了之后，她会从中有一点点的学习总结，但更多的时候总结不出来。于是，我就上前帮她做调整，她很快就学会了，并且每一次都比上一次搭得更好……如此反复，最终，我家小孩玩积木上花的时间大大超过了其它的玩具，直到她无法从中得到成就感。\n\n很显然，我把孩子从“天性喜欢破坏的兴趣点”上拉到了“喜欢创造的兴趣点”上。因为创造能带来更多的成就感，不是吗？\n\n所以，我对这个朋友说，你对一件事的兴趣只是一种表象，而内在更多的是你做这件事的成就感是否可以持续。**你需要找到让自己能够更有成就感的事情，兴趣总是可以培养的**。\n\n# 关于学习和工作\n\n后面，我们又谈到了工作，他觉得只有找到与兴趣相匹配的工作才是能否学好一个技术的关键。对此，我给了他如下一些回应。\n\n我觉得，学好一项技术和是否找到与之相匹配的工作有关联，但它们之间并不是强关联的。但之所以，我们都觉得通过工作才让我们学习和成长得更快，主要有这些原因。\n\n- 工作能为我们带来相应的场景和实际的问题，而不是空泛的学习。带着问题去学习，带着场景去解决问题，的确是一种高效的学习方式。\n- 在工作当中，有同事和高手帮助。和他们的交互和讨论，可以让你更快地学习和成长。\n\n**本质上来说，并不是只有找到了相应的工作我们才可以学好一项技术，而是，我们在通过解决实际问题，在和他人讨论，获得高手帮助的环境中，才能更快更有效率地学习和成长。**\n\n有时候，在工作中你反而学不到东西，那是因为你找的这个工作能够提供的场景不够丰富，需要解决的实际问题太过简单，以及你的同事对你的帮助不大。这时，这个工作反而限制了你的学习和成长。\n\n所以，我给了这个小伙子两点建议。\n\n- 找工作不只是找用这个技术的工作，更是要找场景，找实际问题，找团队。这些才是本质。一项技术很多公司都在用，然而，只有进入到有更多的场景、有挑战性的问题、有靠谱团队的公司，才对学习和成长更有帮助。\n- 不要完全把自己的学习寄希望于找一份工作，才会学得好。我给他的建议是，在一些开源社区内，有助于学习的场景会更多，要解决的实际问题也更多，同时你能接触到的牛人也更多。特别是一些有大量公司和几万、几十万甚至上百万的开发人员在贡献代码的项目，我认为可以让人成长很快。\n\n我入行前十年并没有生活在一个开源软件爆发的年代，也没有生活在一个场景像今天这么丰富的年代，所以也走了很多弯路。不过，比较幸运的是，我还是在一些关键时期找到了靠谱的工作，为我带来了一般人看不到的实际问题，也为我提供了很不错的团队和实际场景。\n\n今天的年轻人有比我更好的环境和条件，应该能比我成长得更好、更快。当然，和我的成长一样，都需要小心地鉴别和甄选。\n\n**总之，找到学习的方法，提升自己对新事物学习的能力，才是学习和成长的关键。**\n\n# 关于技术和价值\n\n后面，我们又聊到了什么样的技术会是属于未来的技术，以及应该把时间花在什么样的技术上。我问了他这样一个问题：“你觉得，让人登月探索宇宙的技术价值大，还是造高铁的技术价值大？或者是科学种田的技术价值大？……”\n\n是的，对于这个问题，从不同的角度上看，就会得到不同的结论。似乎，我们无法说明白哪项技术创造的价值更大，因为完全没法比较。\n\n于是我又说了一个例子，在第一次工业革命的时候，也就是蒸汽机时代，除了蒸汽机之外还有其它一些技术含量更高的技术，比如化学、冶金、水泥、玻璃……但是，这么一个不起眼的技术引发了人类社会的变革。也许，那个时候，在技术圈中，很多技术专家还鄙视蒸汽机的技术含量太低呢。\n\n我并不是想说高大上的技术无用，我想说的是，技术无贵贱，很多伟大的事就是通过一些不起眼的技术造就的。所以，我们应该关注的是：\n\n- 要用技术解决什么样的问题，场景非常重要；\n- 如何降低技术的学习成本，提高易用性，从而可以让技术更为普及。\n\n另外，我又说了一个例子。假设，我们今天没有电，忽然，有人说他发明了电。我相信，这个世界上的很多人都会觉得“电”这个东西没什么用，而只有等到“电灯”的发明，人们才明白发明“电”是多么牛。\n\n所以，对于一些“基础技术”来说，通常会在某段时间内会被人类社会低估。就像国内前几年低估“云计算”技术一样。基础技术就像是创新的引擎，其不断地成熟和完善会引发更上层的技术不断地衍生，越滚越大。\n\n而在一个基础技术被广泛应用的过程中，如何规模化也会成为一个关键。这就好像发电厂一样，没有发电厂，电力就无法做到规模化。记得汽车发明的时候，要组装一个汽车的时间成本、人力成本、物力成本都非常高，所以完全无法做到规模化，而通过模块化分工、自动化生产等技术手段才释放了产能，从而普及。\n\n所以，我个人觉得一项有价值的技术，并不在于这项技术是否有技术含量，而是在于：\n\n- 能否低成本高效率地解决实际问题；\n- 是不是众多产品的基础技术；\n- 是不是可以支持规模化的技术。\n\n对于我们搞计算机软件的人来说，也可以找到相对应的技术点。比如：\n\n- 低成本高效率地解决实际问题的技术，一定是自动化的技术。软件天生就是用来完成重复劳动的，天生就是用来做自动化的。而未来的 AI 和 IoT 也是在拼命数字化和自动化还没有自动化的领域。\n- 基础技术总是枯燥和有价值的。数学、算法、网络、存储等基础技术吃得越透，就越容易服务上层的各种衍生技术或产品。\n- 支持规模化的技术也是很有价值的。在软件行业中，也就是 PaaS 的相关技术。\n\n当然，我的意思并不是别的技术都没有价值了。重申一下，**技术无贵贱。我只是想说，能规模化低成本高效率解决实际问题的技术及其基础技术，就算是很 low，也是很有价值的。**\n\n# 关于趋势和未来\n\n好像每次跟人聊天的时候都会扯到这个事上来。老实说，真的没人可以预测未来会是什么样的。不过，似乎有些规律也是有迹可寻的。\n\n我一直认为，**这个世界的技术趋势和未来其实是被人控制的**。就是被那些有权有势有钱的公司或国家来控制的。当然，他们控制的不是长期的未来，但短期的未来（3-5 年）一定是他们控制着的。\n\n也就是说，技术的未来要去哪，主要是看这个世界的投入会到哪。基本上就是这个世界上的有钱有势的人把财富投到哪个领域，也就是这个世界的大公司或大国们的规划。\n\n一旦他们把大量的金钱投到某个领域，这个领域就会得到发展，那么发展之后，这个领域也就成为未来了。只要是有一堆公司在往一个方向上不间断地投资或者花钱，这个方向不想成为未来似乎都不可能。\n\n听上去多少有点儿令人沮丧，但我个人觉得世界就是如此简单粗暴运作着的。\n\n所以，对于我们这些在这个世界里排不上号的人来说，只能默默地跟随着这些大公司所引领的趋势和未来。对一些缺钱缺人的创业公司，唯一能够做的，也许只是两条路，一是用更为低的成本来提供和大公司相应的技术，另一条路是在细分垂直市场上做得比大公司更专更精。等着自己有一天长大后，也能加入第一梯队从而“引领”未来。\n\n# 小结\n\n今天的这个主题，我其实观察和酝酿了很久，正好结合跟这位小伙伴的交流，总结整理出来。在我们的生活和工作中，总是会有很多人混淆一些看似有联系，实则关系不大的词和概念，分辨不清事物的表象和本质。\n\n比如文中提到的兴趣和投入。表面上，兴趣是决定一件事儿能否做持久的关键因素。而反观我们自己和他人的经历不难发现，兴趣扮演的角色通常是敲门砖，它引发我们关注到某事某物。而真正能让我们坚持下去的，实际上是做一件事之后从中收获到的正反馈，也就是成就感。\n\n同样，人们也经常搞错学习和工作之间的关系。多数人都会认为，在工作中学习和成长速度更快。而仔细观察下来，你会发现，工作不过是提供了一个能够解决实际问题，能跟人讨论，有高手帮助的环境。\n\n所以说，让我们成长的并不是工作本身，而是有利于学习的环境。也就是说，如果我们想学习，除了可以选择有助于学习的工作机会，开源社区提供的环境同样有助于我们的学习和提高，那里高手更多，实际问题不少。\n\n还有，技术和价值。人们通常认为技术含量高的技术其价值会更高，而历史上无数的事实却告诉我们，能规模化、低成本、高效率地解决实际问题的技术及其基础技术，才发挥出了更为深远的影响，甚至其价值更是颠覆性的，难以估量。\n\n趋势和未来也是被误解得很深的一对“孪生兄弟”。虽然大家通常会认为有什么样的技术趋势，必然带来什么样的未来。殊不知，所谓的趋势和未来，其实都是可以由人为控制的，特别是哪些有钱有势的人和公司。也就是，社会的资金和资源流向什么领域，这个领域势必会得到成长和发展，会逐渐形成趋势，进而成为未来。我们遵循这样的规律，就能很容易地判断出未来的，最起码是近几年的，技术流向了。\n\n再如，加班和产出，努力和成功，速度和效率……加班等于高产出吗？显然不是。很努力就一定会成功吗？当然不是。速度快就是效率高吗？更加不是。可以枚举的还有很多，如干得多就等于干得好吗？等等。\n\n读完这篇文章，你是不是不再混淆一些现象和本质，是不是能将一些事情看得更加清晰了呢？欢迎来跟我交流。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/865\" > </iframe>","categories":["左耳听风"]},{"title":"069丨程序员练级攻略：开篇词","url":"/posts/2876477423.html","content":"\n\n\n2011 年，我在 [CoolShell](https://coolshell.cn/) 上发表了 《[程序员技术练级攻略](https://coolshell.cn/articles/4990.html)》一文，收到了很多读读者的追捧，同时，这几年时间里，我还陆续收到了一些人的反馈，说跟着这篇文章找到了不错的工作，他们希望我把这篇文章更新一下，因为毕竟行业的变化很快。\n\n是的，**老实说，抛开这几年技术的更新迭代不说，那篇文章写得也不算特别系统，同时标准也有点低，当时是给一个想要入门的朋友写的。所以，非常有必要从头更新一下《程序员练级攻略》这一主题**。\n\n# 前言导读\n\n升级版的《程序员练级攻略》会比 Coolshell 上的内容更多，也更专业。这篇文章有【入门篇】、【修养篇】、【专业基础篇】、【软件设计篇】、【高手成长篇】五大篇章。它们会帮助你从零开始，一步步地，系统地，完成从陌生到熟悉，到理解掌握，从编码到设计再到架构，从码农到程序员再到工程师再到架构师的进阶，实现从普通到精通到卓越的完美转身……\n\n在**入门篇**中，我先推荐的是把 Python 和 JavaScript 作为入门语言，并给出了相应的学习资源和方法。Python 语法比较简单，有大量的库和语法糖，是零基础的人学习编程的不二之选。而 JavaScript 是前端语言，更容易让你获得编程的成就感。\n\n随后，我们需要学习使用操作系统 Linux、编程工具 Visual Studio Code 等入门必学内容。Web 互联网作为第三次工业革命信息化浪潮中最大的发明，也是每个程序员都不能错过的。而学习编程还是要多多动手，因此我给出了 Web 编程入门的学习要点，并给出了一个实践项目，帮助你理解和巩固所学的内容。\n\n如果你跟着我的这个教程走过来，并能自己去解决遇到的问题，那么，我相信你能够做一点东西了，而且你还可能会对编程非常感兴趣了。但是你千万不要以为自己已经入门了。我只是用这些内容给你一些成就感，并激发你持续学习的兴趣。\n\n正式入门，我推荐的语言是 Java，因为我认为，它是所有语言里综合实力最强的。随后，推荐了更为专业实用的编程工具，如编程的 IDE、版本管理工具 Git、调试前端程序和数据库设计工具等，并且给出了一个实践项目。我同时设置了业务和技术两方面的需求，跟着做一遍，相信你对学习编程会有更多的理解和感悟。\n\n接下来，我要带你进入更为专业更为复杂的编程世界中。进入之前，我们需要树立正确的三观和心态，这对于程序员来说至关重要。这就好像民工建筑队和专业的工程队的区别，就好像小作坊和工厂的差别，他们并不仅仅是差别在技能和技术上，更是差别在做事的心态和三观上。\n\n因此，在学习专业的软件开发知识之前，我们来谈谈**程序员修养**。它看似与程序员练级关系不大，实际上却能反映出程序员的工程师特质和价值观，决定了这条路你到底能走多远，是精髓所在。**有修养的程序员才可能成长为真正的工程师和架构师，而没有修养的程序员只能沦为码农，这是码农和工程师的关键区分点。**\n\n在“修养篇”，我给出了一些相关的学习资料，并指出了我认为比较重要的几个方面：英文能力、提问的能力、写代码的修养、安全防范意识、软件工程和上线规范、编程规范等。这些能力的训练和培养将为后续的学习和发展夯实基础。\n\n此时，相信你已经迫不及待地想进入**专业基础篇**了。这部分内容主要涵盖编程语言、理论学科和系统知识三方面知识。在编程语言方面，推荐学习 C、C++ 和 Java 这三个工业级的编程语言。理论学科方面，需要学习算法、数据结构、网络模型、计算机原理等内容。系统知识方面会讲述 Unix/Linux、TCP/IP、C10K 挑战等专业的系统知识。最后给出了你可以选择的几大从业方向。\n\n- 如果你对操作系统、文件系统、数据库、网络等比较感兴趣，那么可以考虑从事底层方面的工作。\n- 如果对分布式系统架构、微服务、DevOps、Cloud Native 等有热情，那么可以从事架构方面的工作。\n- 如果是对大数据、机器学习、人工智能等比较关注，那么数据领域可以成为你一展身手的地方。\n- 如果你对用户体验或者交互等更感兴趣，那么前端工程师也是个不错的选择。\n- 此外，安全开发、运维开发、嵌入式开发等几大方向中，也为你提供了丰富多彩的发展空间。\n\n以我之见，该如何选择应该完全遵从于你的本心，你更愿意在哪个领域里持续奋斗和学习。这个答案，在你的手中，在你的心中。**这里我只想和你说两个观点：各种技术方向不是鱼和熊掌，是可以兼得的；很多技术是相通的，关键是你是学在表面还是深入本质。**\n\n**软件设计**能力是每个程序员都需要具备的基本素质。我结合各主流语言讲述了泛型编程、函数式编程、面向对象编程等多种编程范式，分享了 DRY- 避免重复原则、KISS- 简单原则、迪米特法则（又称“最少知识原则”）、 面向对象的 S.O.L.I.D 原则等等多个经典的软件设计原则。\n\n同时，给出了软件设计领域的一些重要的学习资料。**软件设计是工程师非常重要的能力，这里描述了软件工程自发展以来的各种设计方法，这是从工程师通往架构师的必备技能。**\n\n登峰造极，是每个武林高手都渴望达到的境界，对于每个有理想有追求的程序员也是如此。因此，我特意在《程序员练级攻略（2018）》这一系列内容的最后设置了**高手成长篇**。\n\n相较前面的内容，这部分内容相当全面和丰富，涵盖系统、数据库、分布式架构、微服务、容器化和自动化运维、机器学习、前端方向和技术论文等几方面内容，而且深度一下子拔高了好几个数量级。\n\n同时，这也是我留给你的再一次做选择的机会，平凡还是卓越？自在悠闲，还是猛啃书本，不破楼兰终不还？还是遵循你内心的选择吧。偷偷地告诉你，我选择的是后者。\n\n你应该不难看出这一系列文章比我在 CoolShell 上的那一篇更为专业，标准也会更高，当然，难度也会更大。但是，也会让你有更坚固的技术基础，并能有更高更广泛的提高。\n\n通过这一系列文章，我主要想回答以下几个问题。\n\n- **理论和现实的差距**。你是否觉得自己从学校毕业的时候只做过小玩具一样的程序？走入职场后哪怕没有什么经验也可以把文中提到的这些课外练习走一遍。学校课程总是从理论出发，作业项目都看不出有什么实际作用，到了工作上发现自己什么也不会干。\n\n- **技术能力的瓶颈**。你又是否觉得，在工作当中需要的技术只不过是不断地堆业务功能，完全没有什么技术含量。而你工作一段时间后，自己都感觉得非常地迷茫和彷徨，感觉到达了提高的瓶颈，完全不知道怎么提升了。\n- **技术太多学不过来**。你是否又觉得，要学的技术多得都不行了，完全不知道怎么学？感觉完全跟不上。有没有什么速成的方法？\n\n对此，我有如下的一些解释，以端正一下你的态度。\n\n- 并不是理论和现实的差距大，而是你还没有找到相关的场景，来感受到那些学院派知识的强大威力。算法与数据结构、操作系统原理、编译原理、数据库原理、计算机原理……这些原理上的东西，是你想要成为一个专家必须要学的东西。**这就是“工人”和“工程师”的差别，是“建筑工人”和“建筑架构师”的差别**。如果你觉得这些理论上的东西无用，那么只能说明，你只不过在从事工人的工作，而不是工程师的工作。\n- **技术能力的瓶颈，以及技术太多学不过来，只不过是你为自己的能力不足或是懒惰找的借口罢了**。技术的东西都是死的，这些死的知识只要努力就是可以学会的。只不过聪明的人花得时间少，笨点的人花得时间多点罢了。这其中的时间差距主要是由学习方法的不同，基础知识储备的不同决定的。只要你方法得当，多花点时间在基础知识上，会让你未来学习应用知识的时间大大缩短。**以绝大多数人努力的程度，和为自己不努力找借口的程度为参考，只要你坚持正常的学习就可以超过大多数人了**。\n- **这里没有学习技术的速成的方法，真正的牛人不是能够培训出来的，一切都是要靠你自己去努力和持续地付出**。如果你觉得自己不是一个能坚持的人，也不是一个想努力的人，而是一个想找捷径的人，那么，这篇文章并不适合你。**这篇文章中的成长路径是需要思考、精力和相关的经验的，这都需要时间，而且是不短的时间。你先问问自己有没有花十年磨一剑的决心，如果没有，那这篇文章对你没有任何作用。**\n\n这里有一篇传世之文《[Teach Yourself Programming in Ten Years](http://norvig.com/21-days.html)》（[中英对照版](https://liuyandong.com/archives/1244)）。还有在我 Cooslhell 上的这篇《[程序员的荒谬之言还是至理名言？](https://coolshell.cn/articles/4235.html)》。\n\n我希望你在学习编程之前先读一读这两篇文章。如果你觉得可以坚持的话，那么，我这一系列文章会对你很有帮助。否则，我相信你只要大致浏览一下目录及其中的某些章节，就会选择放弃走这条路的。是的，这个系列的文内容也会让一些想入行但又不愿意付出努力的同学早点放弃。\n\n最后，给出我的几点**学习建议**。\n\n- 一定要坚持，要保持长时间学习，甚至终生学习的态度。\n- 一定要动手，不管例子多么简单，建议至少自己动手敲一遍看看是否理解了里头的细枝末节。\n- 一定要学会思考，思考为什么要这样，而不是那样。还要举一反三地思考。\n- 不要乱买书，不要乱追新技术新名词，基础的东西经过很长时间积累，会在未来至少 10 年通用。\n- 回顾一下历史，看看历史时间线上技术的发展，你才能明白明天会是什么样的。\n\n另外，这篇文章的标准会非常高。希望不会把你吓坏了。《易经》有云：“**取法其上，得乎其中，取法其中，得乎其下，取法其下，法不得也**”。所以，我这里会给你立个比较高标准，你要努力达到。相信我，就算是达不到，也会比你一开始期望的要高很多……\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/8136\" > </iframe>\n\n","categories":["左耳听风"]},{"title":"070丨程序员练级攻略：零基础启蒙","url":"/posts/2791059186.html","content":"\n\n\n如果你从来没有接触过程序语言，这里给你两个方面的教程，一个偏后端，一个偏前端。对从零基础开始的人来说，最重要的是能够对编程有兴趣，而要对编程有兴趣，就要有成就感。而成就感又来自于用程序打造东西，所以，我推荐下面这份不错的入门教程。\n\n第一份入门教程，主要是让你体会到编程是什么。\n\n- [《与孩子一起学编程》](https://book.douban.com/subject/5338024/) ，这本书以 Python 语言教你如何写程序，是一本老少咸宜的编程书。其中会教你编一些小游戏，还会和你讲基本的编程知识，相当不错。\n- 两个在线编程入门的网站：[Codecademy: Learn Python](https://www.codecademy.com/learn) 和 [People Can Program](https://www.peoplecanprogram.com/) ，你也可以在这两个网站上学习 Python，只不过是英文的。\n\n然后，你可以到 [CodeAbbey](http://www.codeabbey.com/index/task_list) 上去做一些在线编程的小练习。\n\n第二份入门教程，主要是让你做点实际有用的东西。嗯，做个网页吧。\n\n- [MDN 的 Web 开发入门](https://developer.mozilla.org/zh-CN/docs/Learn/Getting_started_with_the_web) ，MDN 全称是 Mozilla Developer Network，你可以认为是 Web 方面的官方技术网站。这个教程会带着你建立一个网站。然后，你可以把你的网页发布在 GitHub 上。\n\n这两份教程都很不错，都是从零开始，带着你从环境准备开始，一点一点地从一些简单又有意思的东西入手，让你感觉一下编程世界是什么样的，相信这两个教程可以让零基础的你喜欢上编程。\n\n# 编程入门\n\n在这时，我们使用 Python 和 JavaScript 作为入门语言。Python 就不用多说了，语法比较简单，有大量的库和语法糖，是零基础的人学习编程的不二之选。而 JavaScript 则是前端的语言，为了让你更有编程的成就感，所以，这也成了一门要学习的语言。（注意：对于计算机专业的学生来说，一般会使用 Pascal 做为入门的编程语言，但我觉得编程入门还是要以培养兴趣为主，所以，还是选一些能让人有成就感的语言会更好）。\n\n## 入门语言 Python\n\n如果你想更为系统地学习一下 Python 编程，我强烈推荐你阅读下面这两本书。它们是零基础入门非常不错的图书，里面有大量的更为实用的示例和项目，可以快速给你正反馈。\n\n- [Python 编程快速上手](https://book.douban.com/subject/26836700/)\n- [Python 编程：从入门到实践](https://book.douban.com/subject/26829016/)\n\n这两本书除了编程语法方面的讲述有所不同之外，其他都差不多，主要是通过书中的示例来强化你对编程的学习。第一本偏文本处理，包括处理 Word、Excel 和 PDF，第二本中有一些 Web 项目和代码部署方面的内容。如果可能的话，你可以把两本书中的示例都跑一遍。如果你时间有限的话，我推荐你看第二本。\n\n[编辑植入：极客时间上也有 Python 入门的视频课程。]\n\n## 入门语言 JavaScript\n\n如果想入门学习 JavaScript，我主要推荐以下在线教程。\n\n- [MDN JavaScript 教程](https://developer.mozilla.org/zh-CN/docs/Web/JavaScript)，你可以认为这是最权威的 JavaScript 官方教程了，从初级到中级再到高级。\n- [W3School JavaScript 教程](http://www.w3school.com.cn/js/)，这个教程比较偏 Web 方面的编程。\n- [JavaScript 全栈教程（廖雪峰）](https://www.liaoxuefeng.com/wiki/001434446689867b27157e896e74d51a89c25cc8b43bdb3000)，这是廖雪峰的一个比较偏应用的教程，也是偏 Web 方面的编程，同时包括涉及后端的 Node.js 方面的教程。\n\n## 操作系统入门 Linux\n\n学习编程你还需要会玩 Linux，虽然 Windows 占据着更多的桌面市场，但是你还是要了解 Linux。这里，你可以看一下，W3CSchool 上的在线教程 [Linux 教程](https://www.w3cschool.cn/linux/)。\n\n## 编程工具 Visual Studio Code\n\n这里主要推荐时下最流行也是最好用的 Visual Studio Code，这个工具潜力十足，用它开发 Python、JavaScript、Java、Go、C/C++ 都能得心应手（[教程](https://www.gitbook.com/book/jeasonstudio/vscode-cn-doc/details) - 本文发布时还基本没怎么翻译完）。\n\n## Web 编程入门\n\n如果玩到这里，你觉得有趣的话，可以学习一下 Web 方面的入门知识。**为什么是 Web 而不是别的其他技术呢？因为你正身处于第三次工业革命的信息化浪潮中，在这个浪潮中，Web 互联网是其中最大的发明，所以，这是任何一个程序员都不能错过的**。\n\n关于 Web 编程，有下面几个方向你要学习一下。\n\n- **前端基础**。要系统地学习一下前端的知识，也就是 CSS、HTML 和 JavaScript 这三个东西。这里还是给出 MDN 的相关的技术文档页面 [CSS 文档](https://developer.mozilla.org/zh-CN/docs/Web/CSS) 和 [HTML 文档](https://developer.mozilla.org/zh-CN/docs/Web/HTML) 。**文档很大，你要学习的并不是所有的东西，而是了解 CSS 和 HTML 是怎么相互作用来展示数据的，然后，不用记忆文档中的内容，这两个文档是用来查找知识的。** 另外，你可以简单地学习使用 JavaScript 操纵 HTML。理解 DOM 和动态网页（可以参看 [W3Schools 的 JavaScript HTML DOM 的教程](https://www.w3schools.com/js/js_htmldom.asp)）。\n- **后端基础**。如果你想省点事，不想再学一门新的语言了，那么你可以直接用 Python 或者 Node.js，这两个技术在前面提到的廖雪峰的那个教程里提到过。当然，如果你想试试另外一种脚本型的也是比较主流的编程语言，那么可以搞搞 PHP，它也是很快就可以上手的语言。学习 PHP 语言，你可以先跟着 [W3School 的 PHP 教程](http://www.w3school.com.cn/php/index.asp) 玩玩（其中有连接数据库的 MySQL 的教程）。然后，以 [PHP 的官网文档](http://php.net/manual/zh/) 作为更全的文档来学习或查找相关的技术细节。\n\n下面是一些学习要点：\n\n- 学习 HTML 基本语法。\n- 学习 CSS 如何选中 HTML 元素并应用一些基本样式。\n- 学会用 Firefox + Firebug 或 Chrome 查看你觉得很炫的网页结构，并动态修改。\n- 在一台 Linux 机器上配置 LEMP - Ubuntu/Nginx/PHP/MySQL 这个环境。\n- 学习 PHP，让后台 PHP 和前台 HTML 进行数据交互，对服务器相应浏览器请求形成初步认识。实现一个表单提交和反显的功能。\n- 把 PHP 连接本地或者远程数据库 MySQL（MySQL 和 SQL 现学现用够了）。\n\n这里，你可能会问我，入门时有三个后端语言，一个是 Python，一个是 Node.js，一个是 PHP，你对这三门语言怎么看？老实说，Python 我还看好一些，PHP 次之，Node.js 最后。原因是：\n\n- Python 语言的应用面还是很广的。（当然，性能可能会有一些问题，但是用于一些性能不敏感的和运维或是一些小工具相关的，还是非常好用的。另外，Python 的应用场景其实还是很多的，包括机器学习和 AI 也有 Python 的身影。用 Python 来做一些爬虫、简单的中间件、应用或是业务服务也是很不错的。）\n- PHP 也是一个比较主流的简单的语言（PHP 在目前来说还是一个比较主流的语言，但其发展潜力有限，虽然可以让你找得到工作，但是一般玩玩就行了）。\n- Node.js 号称 JavaScript 的后端版，但从目前发展来说，在后端的世界里，并不能承担大任，而且问题很多。一些前端程序员用它来做后端的粘合层，我个人觉得这样做法只是掩盖前后端配合有问题，或是接口设计思维上的懒惰，我还是希望前端程序员应该认真学习一门真正的后端语言。\n\n当然，这里只是让你感觉一下，**Web 前端编程的感觉，只是为了入门而已。所以，对于这些语言你也不用学得特别精通，感觉一下这几个不同的语言就可以了，然后知道相关的文档和知识在哪里，这样有助于你查阅相应的知识点**。\n\n# 实践项目\n\n无论你用 Python，还是 Node.js，还是 PHP，我希望你能做一个非常简单的 Blog 系统，或是 BBS 系统，需要支持如下功能：\n\n- 用户登录和注册（不需密码找回）。\n- 用户发贴（不需要支持富文本，只需要支持纯文本）。\n- 用户评论（不需要支持富文本，只需要支持纯文本）。\n\n你需要从前端一直做到后端，也就是说，从 HTML/CSS/JavaScript，到后面的 PHP（Python/Node.js），再到数据库。这其中需要你查阅很多的知识。\n\n这里有几个技术点你需要关注一下。\n\n1. 用户登录时的密码不应该保存为明文，应该用 MD5+Salt 来保存（关于这个是什么，希望你能自行 Google）。\n2. 用户登录后，对于用户自己的贴子可以有“重新编辑”或 “删除”的功能，但是无权编辑或删除其它用户的贴子。\n3. 数据库的设计，你需要三张表：用户表、文章表和评论表，它们之间是怎么关联的，你需要学习一下。这里有个 PHP 的 blog 教你怎么建表，你可以 [前往一读](https://code.tutsplus.com/tutorials/how-to-create-a-phpmysql-powered-forum-from-scratch--net-10188)。\n\n如果你有兴趣，你可以顺着这个小项目，研究一下下面这几个事。\n\n- 图片验证码。\n- 上传图片。\n- 阻止用户在发文章或评论时输入带 HTML 或 JavaScript 的内容。\n- 防范 SQL 注入。参看[PHP 官方文档](http://php.net/manual/zh/security.database.sql-injection.php) 或 [微软官方文档](https://technet.microsoft.com/zh-cn/library/ms161953(v=sql.105).aspx?f=255&MSPPError=-2147217396)，或者你自己 Google 一下。\n\n上面这些东西，不是什么高深的东西，但是可以让你从中学到很多。相信你只需要自己 Google 一下就能搞定。\n\n## 小结\n\n接下来，我总结下今天的内容。首先，我推荐了 Python 和 JavaScript 作为入门语言，以让你尽快上手，获得成就感，从而激发你想持续学习的热情。随后介绍了 Linux 操作系统、Visual Studio Code 编程工具、Web 编程入门等方面的学习资料，并给出了学习要点。最后，我给出了一个实践项目，帮助你理解和巩固今天所学的内容。\n\n消化好了今天的内容，就准备好精力迎接后面的挑战吧。下篇文章中，我们将正式入门学习该如何编程。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/8216\" > </iframe>","categories":["左耳听风"]},{"title":"071丨程序员练级攻略：正式入门","url":"/posts/4219119099.html","content":"\n\n\n学习了前面文章中的入门级经验和知识后，你可能会有两种反应。\n\n- 一种反应可能是，你对编程有一点的兴趣了，甚至有一点点小骄傲，可能还会四处炫耀。我想说，请保持这种感觉，但是你也要清醒一下，上面的那些东西，还不算真正的入门，你只是入门了一条腿。\n- 另一种反应也可能是，你被吓着了，觉得太难了。感觉不是一般人能玩的，如果是这样的话，我想鼓励你一下–“**无论你做什么事，你都会面对各式各样的困难，这对每个人来说都是一样的，而只有兴趣、热情和成就感才能让你不畏惧这些困难**”。所以，你问问你自己，是否从中收获了成就感，如果没有的话，可能这条路并不适合你。如果有的话，哪怕一丁点儿，你也应该继续坚持下来。\n\n这篇文章，我主要是让你成为更为专业的入门程序员。请注意，此时，你可能需要读一些比较枯燥的书，但我想说，这些是非常非常重要的。你一定要坚持住。\n\n# 编程技能\n\n在系统地学习编程技能之前，我希望你能先看一下 \" [The Key To Accelerating Your Coding Skills](http://blog.thefirehoseproject.com/posts/learn-to-code-and-be-self-reliant/)\"， 这篇文章会告诉你如何有效地快速提高自己的编程能力。\n\n然后接下来是下面几大块内容，但还只是入门级的。\n\n- **编程技巧方面** - 你可以开始看怎么把程序写好的书了，这里推荐的是《[代码大全](https://book.douban.com/subject/1477390/)》。这本书好多年没有更新了，其中有一些内容可能有点过时，但还是一本非常好的书，有点厚，你不需要马上就看完。在你的编程路上，这本书可以陪你走很久，因为当你有更多的编程经验时，踩过更多的坑后，再把这本书拿出来看看，你会有更多的体会。**好的书和不好的书最大的区别就是，好的书在你不同的阶段来读，你会有不同的收获，而且还会产生更多的深层次的思考！** 《代码大全》就是这样的一本书。\n- **编程语言方面** - 这个阶段，你可以开始了解一下 Java 语言了，我个人觉得 Java 是世界上目前为止综合排名最好的语言。你一定要学好这门语言。推荐《[Java 核心技术（卷 1）](https://book.douban.com/subject/26880667/)》，除了让你了解 Java 的语法，它还会让你了解面向对象编程是个什么概念（如果你觉得这本书有点深，那么，你可以降低难度看更为基础的《[Head First Java](https://book.douban.com/subject/2000732/)》）。然后，既然开始学习 Java 了，那就一定要学 Spring，推荐看看《[Spring in Action](https://book.douban.com/subject/26767354/)》或是直接从最新的 Spring Boot 开始，推荐看看《[Spring Boot 实战](https://book.douban.com/subject/26857423/)》。关于 Spring 的这两本书，里面可能会有很多你从来没有听说过的东西，比如，IoC 和 AOP 之类的东西，能看懂多少就看懂多少，没事儿。\n\n- **操作系统** - 这里你可以看看《[鸟哥的 Linux 私房菜](https://book.douban.com/subject/4889838/)》，这本书会让你对计算机和操作系统，以及 Linux 有一个非常全面的了解，并能够管理或是操作好一个 Linux 系统。当然，这本书有很多比较专业的知识，你可能会看不懂，没关系，就暂时略过就好了。这本书的确并不适合初学者，你能看多少就看多少吧。\n- **网络协议** - 你需要系统地了解一下 HTTP 协议，请到 MDN 阅读一下其官方的 [HTTP 的文档](https://developer.mozilla.org/zh-CN/docs/Web/HTTP)。你需要知道 HTTP 协议的几个关键点：1）HTTP 头，2）HTTP 的请求方法，3）HTTP 的返回码。还有，HTTP 的 Cookie、缓存、会话，以及链接管理，等等，在 MDN 的这个文档中都有了。对于 HTTP 协议，你不需要知道所有的东西，你只需要了解这个协议的最关键的那些东西就好了。\n- **数据库设计** - 你需要系统地了解一下数据库设计中的那些东西，这里推荐慕课网的一个在线课程：数据库设计的那些事。每个小课程不过 5-6 分钟，全部不到 2 个小时，我相信你一定能跟下来。你需要搞清楚数据的那几个范式，还有 SQL 语句的一些用法。当然，你还要学习和使用一下数据库，这里推荐学习开源的 MySQL。你可以看官方文档，也可以看一下这本书《[MySQL 必知必会](https://book.douban.com/subject/3354490/)》。\n- **前端方面** - 前端的东西不算复杂，你需要学习几个东西。一个是和 JavaScript 相关的 [jQuery](https://jquery.com/)，另一个是和 CSS 相关的 [Bootstrap](https://getbootstrap.com/)，学习这两个东西都不复杂，直接上其官网看文档就好了。最重要的是，你要学习一下如何使用 JavaScript Ajax 请求后端的 API 接口，而不是再像前面那样用后端来向前端返回 HTML 页面的形式了。这里，你需要学习一下，JavaScript 的 Promise 模式。[阮一峰翻译的 ES6 的教程中有相关的内容](http://es6.ruanyifeng.com/#docs/promise)。当然，你 Google 一下，也可以找到一堆学习资料。\n- **字符编码方面** - 在你处理中文时有时会发现有乱码出现，此时需要了解 ASCII 和 Unicode 这样的字符编码。这里推荐一篇文章 - “[关于字符编码，你所需要知道的（ASCII,Unicode,Utf-8,GB2312…）](http://www.imkevinyang.com/2010/06/关于字符编码，你所需要知道的.html)” 或是英文文章 “[The history of Character Encoding](http://www.developerknowhow.com/1091/the-history-of-character-encoding)” 以及 [Wikipedia - Character encoding](https://en.wikipedia.org/wiki/Character_encoding)。还有 GitHub 上的这两个 Awesome 仓库：[Awesome Unicode](https://github.com/jagracey/Awesome-Unicode) 和 [Awesome Code Points](https://github.com/Codepoints/awesome-codepoints)。\n\n# 为什么转成 Java 语言？\n\n相信你可能会问，为什么之前学习的 Python 和 JavaScript 不接着学，而是直接切到 Java 语言上来，这样会不会切得太快了。这是一个好问题，这里需要说明一下，为什么我会切到 Java 这个语言上来，主要是有以下几方面考虑。\n\n1. Java 是所有语言里面综合实力最强的，这也是为什么几乎所有大型的互联网或是分布式架构基本上都是 Java 技术栈。所以，这是一个工业级的编程语言（Python 和 JavaScript 还达不到这样的水准）。\n2. 之所以没有用 Java 来做入门语言而是用了 Python，这是因为编程是一件比较费脑子的事，一开始学习时，兴趣的培养很重要。Python 比较简单，容易上手，能够比较容易地提起兴趣，而用 Java 则可能比较难。\n3. 在你有了一些编程语言的基础后，有了一些代码的逻辑后，切到工业级的编程语言上来，更为专业地学习编程，是非常有帮助的。像 Python 和 JavaScript 这样的动态语言用着是很爽，但是，只有像 C、C++ 和 Java 这样的静态语言才可以让你真正地进阶。\n4. 对于一个合格的程序员，掌握几门语言是非常正常的事情。一方面，这会让你对不同的语言进行比较，让你有更多的思考。另一方面，这也是一种学习能力的培养。很多时候，一些程序员只在自己熟悉的技术而不是合适的技术上工作，这其实并不好，这会让你的视野受限，而视野会决定你的高度。综上所述，这就是在入门的时候我故意让你多学几门语言的原因。\n\n# 编程工具\n\n编程工具方面，你需要开始学习使用下面这些工具了。\n\n- **编程的 IDE**。传统一点的，你可以使用 Eclipse（[教程](http://www.runoob.com/eclipse/eclipse-tutorial.html)）。当然，我推荐你使用 Intellij IDEA（[教程](https://www.gitbook.com/book/dancon/intellij-idea/details)）。这两个工具都可以开发各种语言，但是主要用在 Java。**如果你想玩得更时髦一些的话，使用 Visual Studio Code 也不错，这个工具潜力十足**，用其开发 Python、JavaScript、Java、Go、C 和 C++ 都能得心应手（[教程](https://www.gitbook.com/book/jeasonstudio/vscode-cn-doc/details)）。\n- **版本管理工具**。版本管理工具是非常重要的编程工具。传统的有 P4、 SVN、CVS 等，但都会被 Git 取代，所以，你就只用学习 Git 就好了。学习 Git 的教程网上有很多，这里我推荐非常系统的 [Pro Git 第二版](https://git-scm.com/book/zh/v2/) （如果你觉得 Pro Git 比较枯燥的话，备选[猴子都能懂的 Git 入门](https://backlog.com/git-tutorial/cn/)），然后你要学会使用 GitHub。关于一些 Git 环境安装和准备以及 GitHub 使用，你可以自行 Google（比如：这篇[GitHub and Git 图文教程 ](https://github.com/JiapengLi/GitTutorial)或是这篇[Git 图文教程及详解](https://www.jianshu.com/p/1b65ed31da97)）。\n- **调试前端程序**。你需要学会使用 Chrome 调试前端程序，Google 一下会有很多文章，你可以看看 [超完整的 Chrome 浏览器客户端调试大全](http://www.igeekbar.com/igeekbar/post/156.htm)。\n- **数据库设计工具**。你需要学会使用 MySQL WorkBench，这个工具很容易使用。相关的手册，你可以看一下[官方文档](https://dev.mysql.com/doc/refman/5.7/en/)。\n\n# 实践项目\n\n这回我们需要设计一个投票系统的项目。\n\n业务上的需求如下：\n\n- 用户只有在登录后，才可以生成投票表单。\n- 投票项可以单选，可以多选。\n- 其它用户投票后显示当前投票结果（但是不能刷票）。\n- 投票有相应的时间，页面上需要出现倒计时。\n- 投票结果需要用不同颜色不同长度的横条，并显示百分比和人数。\n\n技术上的需求如下：\n\n- 这回要用 Java Spring Boot 来实现了，然后，后端不返回任何的 HTML，只返回 JSON 数据给前端。\n- 由前端的 JQuery 来处理并操作相关的 HTML 动态生成在前端展示的页面。\n- 前端的页面还要是响应式的，也就是可以在手机端和电脑端有不同的呈现。 这个可以用 Bootstrap 来完成。\n\n如果你有兴趣，还可以挑战以下这些功能。\n\n- 在微信中，通过微信授权后记录用户信息，以防止刷票。\n- 可以不用刷页面，就可以动态地看到投票结果的变化。\n- Google 一些画图表的 JavaScript 库，然后把图表画得漂亮一些。\n\n# 小结\n\n上面那些书和知识你要看完，还要能理解并掌握，我估计你最少也要花 1-2 年左右的时间。如果你能够走到这里，把前面的那些知识都了解了，不用精通，能独立地做出上面的那些实践项目，那么，你就算是真正的入门了。\n\n而且，你已经是一个“全栈工程师”的样子了，在这里我要给你一个大大的赞。如果这个时候，你对编程还有很大的热情，那么我要恭喜你了，你可能会是一个非常不错的程序员。加油啊！\n\n上面的那些技术已经算是比较专业的了。如果你已经大致掌握了，我相信你可以找到至少年薪 20 万以上的工作了，而且你的知识面算是有不错的广度了。但是深度还不够，这个时候，是一个比较关键点了。\n\n你可能已经沉醉在沾沾自喜的骄傲的情绪中，那么你也可以就此止步，加入一些公司，在那里按部就班地完成一些功能性的开发，成为一个搬砖的码农。你也可以开始选择一个方向开始深入。\n\n我给你的建议是选择一个方向开始深入。**因为你并不知道你未来会有多大的可能性，也不知道你会成为什么样的人，所以为什么不再更努力一把呢？**\n\n后面，我们就开始非常专业的程序员之路了。这也是一般程序员和高级程序员的分水岭了，能不能过去就看你的了。\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/8217\" > </iframe>","categories":["左耳听风"]},{"title":"074丨程序员练级攻略：理论学科","url":"/posts/163837357.html","content":"\n\n\n进入专业的编程领域，算法、数据结构、网络模型、计算机原理等这样的计算机科学专业需要学习的理论知识是必须要学习的。下面我们先来看看数据结构和算法。\n\n# 数据结构和算法\n\n算法是比较难学习的，而且学习“算法”是需要智商的。数组、链表、哈希表、二叉树、排序算法等一些基础知识，对大多数人来说是没什么问题的。但是一旦进入到路径规划、背包问题、字符串匹配、动态规划、递归遍历等一些比较复杂的问题上，就会让很多人跟不上了，不但跟不上，而且还会非常痛苦。是的，解决算法问题的确是可以区分人类智商的一个比较好的方式，这也是为什么好些公司用算法题当面试题来找到智商比较高的程序员。\n\n然而，在很多时候，我们在工作中却发现根本用不到算法，或是一些基本的算法也没有必要实现，只需要使用一下第三方的库就好了。于是，导致社会上出现很多“算法无用论”的声音。\n\n对此，我想说，算法真的很重要。我这 20 年的经历告诉我，无论是做业务还是做底层系统，经常需要使用算法处理各种各样的问题。比如，业务上我需要用算法比较两个数组中差异的布隆过滤器，或是在做监控系统时实时计算过去一分钟的 P99 统计时的蓄水池算法，或是数据库的 B+ 树索引，还有 Linux 内核中的 epoll 的红黑树，还有在做服务调度里的“背包问题”等都会用算法，真的是会本质上帮助到你，也是会让你瞬间会产生成就感的事情。\n\n虽然算法很难，需要智商，但我还是想鼓励你，这其中是有很多的套路是可以学习的，一旦学会这些套路，你会受益无穷的。\n\n这里有几本书着重推荐一下。\n\n- **基础知识**。《[算法](https://book.douban.com/subject/10432347/)》，是算法领域经典的参考书，不但全面介绍了关于算法和数据结构的必备知识，还给出了每位程序员应知应会的 50 个算法，并提供了实际代码。最不错的是，其深入浅出的算法介绍，让一些比较难的算法也变得容易理解，尤其是书中对红黑树的讲解非常精彩。其中，还有大量的图解，详尽的代码和讲解，也许是最好的数据结构入门图书。不好的是不深，缺乏进一步的算法设计内容，甚至连动态规划都未提及。另外，如果你觉得算法书比较枯燥的话，你可以看看这本有趣的《[算法图解](https://book.douban.com/subject/26979890/)》。\n- **理论加持**。如果说上面这本书偏于实践和工程，而你看完后，对算法和数据结构的兴趣更浓了，那么你可以再看看另一本也是很经典的偏于理论方面的书——《[算法导论](https://book.douban.com/subject/20432061/)》。虽然其中的一些理论知识在《算法》那本书中也有提过，但《算法导论》这本书更为专业一些，是美国计算机科学本科生的教科书。\n- **思维改善**。还有一本叫《[编程珠玑](https://book.douban.com/subject/3227098/)》的书，写这本书的人是世界著名计算机科学家乔恩·本特利（Jon Bentley），被誉为影响算法发展的十位大师之一。你可能不认识这个人，但是你知道他的学生有多厉害吗？我例举几个，一个是 Tcl 语言设计者约翰·奥斯德奥特（John Ousterhout），另一个是 Java 语言设计者詹姆斯·高斯林（James Gosling），还有一个是《算法导论》作者之一查尔斯·雷斯尔森（Charles Leiserson），还有好多好多。这本书也是很经典的算法书，其中都是一些非常实际的问题，并以其独有的洞察力和创造力，来引导读者理解并学会解决这些问题的方法，也是一本可以改善你思维方式的书。\n\n然后，你需要去做一些题来训练一下自己的算法能力，这里就要推荐 [LeetCode](https://leetcode.com/) 这个网站了。它是一个很不错的做算法训练的地方。现在也越做越好了。基本上来说，这里会有两类题。\n\n- **基础算法题**。其中有大量的算法题，解这些题都是有套路的，不是用递归（深度优先 DFS、广度优先 BFS），就是要用动态规划（Dynamic Programming），或是折半查找（Binary Search），或是回溯（Back tracing），或是分治法（Divide and Conquer），还有大量的对树、数组、链表、字符串和 hash 表的操作。通过做这些题能让你对这些最基础的算法的思路有非常扎实的了解和训练。对我而言，Dynamic Programming 是我的短板，尤其是一些比较复杂的问题，在推导递推公式上总是有思维的缺陷（数学是我的硬伤）。做了这些题后，我能感到我在动态编程的思路上受到了很大的启发。\n- **编程题**。比如：atoi、strstr、add two nums、括号匹配、字符串乘法、通配符匹配、文件路径简化、Text Justification、反转单词等，这些题的 Edge Case 和 Corner Case 有很多。这些题需要你想清楚了再干，只要你稍有疏忽，就会有几个 case 让你痛不欲生，而且一不小心就会让你的代码写得又臭又长，无法阅读。通过做这些题，可以非常好地训练你对各种情况的考虑，以及你对程序代码组织的掌控（其实就是其中的状态变量）。\n\n我觉得每个程序员都应该花时间和精力做这些题，因为你会从这些题中得到很大的收益。我在 Leetcode 上做的一些题的代码在这——我的 [GitHub](https://github.com/haoel/leetcode) 上，可以给你一些参考。\n\n如果能够把这些算法能力都掌握了，那么你就有很大的概率可以很容易地通过这世界上最优的公司的面试，比如：Google、Amazon、Facebook 之类的公司。对你来说，如果能够进入到这些公司里工作，那么你未来的想像空间也会大很多。\n\n最后，我们要知道这个世界上的数据结构和算法有很多，下面给出了两个网站。\n\n- **[List of Algorithms](https://www.wikiwand.com/en/List_of_algorithms)** ，这个网站罗列了非常多的算法，完全可以当成一个算法字典，或是用来开阔眼界。\n- 还有一个数据结构动画图的网站 [Data Structure Visualizations](https://www.cs.usfca.edu/~galles/visualization/Algorithms.html)。\n\n# 其它理论基础知识\n\n下面这些书，基本上是计算机科学系的大学教材。如果你想有科班出身的理论基础，那么这些书是必读的。当然，这些理论基础知识比较枯燥，但我觉得如果你想成为专业的程序员，那么应该要找时间读一下。\n\n- 《[数据结构与算法分析](https://book.douban.com/subject/1139426/)》，这本书曾被评为 20 世纪顶尖的 30 部计算机著作之一，作者 Mark Allen Weiss 在数据结构和算法分析方面卓有建树，他在数据结构和算法分析等方面的著作尤其畅销，并广受好评，已被世界 500 余所大学用作教材。\n- 《[数据库系统概念](https://book.douban.com/subject/1929984/)》，它是数据库系统方面的经典教材之一。国际上许多著名大学包括斯坦福大学、耶鲁大学、德克萨斯大学、康奈尔大学、伊利诺伊大学、印度理工学院等都采用本书作为教科书。这本书全面介绍了数据库系统的各种知识，透彻阐释数据库管理的基本概念。不仅讨论了数据库查询语言、模式设计、数据仓库、数据库应用开发、基于对象的数据库和 XML、数据存储和查询、事务管理、数据挖掘与信息检索以及数据库系统体系结构等方面的内容，而且对性能评测标准、性能调整、标准化以及空间与地理数据、事务处理监控等高级应用主题进行了广泛讨论。\n- 《[现代操作系统](https://book.douban.com/subject/3852290/)》，这本书是操作系统领域的经典之作，书中集中讨论了操作系统的基本原理，包括进程、线程、存储管理、文件系统、输入 / 输出、死锁等，同时还包含了有关计算机安全、多媒体操作系统、掌上计算机操作系统、微内核、多核处理机上的虚拟机以及操作系统设计等方面的内容。\n- 《[计算机网络](https://book.douban.com/subject/1391207/)》，这本书采用了独创的自顶向下方法，即从应用层开始沿协议栈向下讲解计算机网络的基本原理，强调应用层范例和应用编程接口，内容深入浅出，注重教学方法，理论与实践相结合。新版中还增加了无线和移动网络一章，并扩充了对等网络、BGP、MPLS、网络安全、广播选路和因特网编址及转发方面的材料。是一本不可多得的教科书。\n- 《[计算机程序的构造和解释](https://book.douban.com/subject/1148282/)》，这本书也很经典，是 MIT 的计算机科学系的教材。这本书中主要证实了很多程序是怎么构造出来的，以及程序的本质是什么。整本书主要是使用 Scheme/Lisp 语言，从数据抽象、过程抽象、迭代、高阶函数等编程和控制系统复杂性的思想，到数据结构和算法，到编译器 / 解释器、编程语言设计。\n- 《[编译原理](https://book.douban.com/subject/3296317/)》，这本书又叫 \" 龙书 \"，其全面、深入地探讨了编译器设计方面的重要主题，包括词法分析、语法分析、语法制导定义和语法制导翻译、运行时刻环境、目标代码生成、代码优化技术、并行性检测以及过程间分析技术，并在相关章节中给出大量的实例。与上一版相比，本书进行了全面的修订，涵盖了编译器开发方面的最新进展。每章中都提供了大量的系统及参考文献。\n\n# 小结\n\n好了，最后我们来总结一些今天分享的内容。在这篇文章中，我建议想进入专业编程领域的人，一定要学习算法、数据结构、网络模型、计算机原理等理论知识，并推荐了相应的学习素材，给出了我的思考和建议。\n\n我认为，虽然这些理论知识枯燥难学，而且通常学完了在工作中也并不是马上就能用上，但这些知识是必须要学好的。**这些理论知识可以说是计算机科学这门学科最精华的知识了，认真学习，理解其背后的逻辑和思维方式，会让你受益匪浅**。不管是未来你是要学习新技能，还是解决什么疑难问题，都能在这些知识中获得灵感或者启发。\n\n下篇文章中，我们将分享每个程序员都需要掌握的系统知识。敬请期待。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/8887\" > </iframe>\n\n\n\n","categories":["左耳听风"]},{"title":"072丨程序员练级攻略：程序员修养","url":"/posts/1018932928.html","content":"\n\n\n在完成上述的入门知识学习之后，我们要向专业的计算机软件开发进军了。但是在学习那些专业的知识前，我们先要抽一部分的篇幅来说一下程序员的修养。这是程序员的工程师文化，也就是程序员的价值观，因为我觉得如果你的技术修养不够的话，你学再多的知识也是没有用的。\n\n要了解程序员的修养，你可以先从 Quora 上的这个贴子开始 “[What are some of the most basic things every programmer should know?](https://www.quora.com/What-are-some-of-the-most-basic-things-every-programmer-should-know)”，我摘录一些在这里供你参考。\n\n- Bad architecture causes more problems than bad code.\n- You will spend more time thinking than coding.\n- The best programmers are always building things.\n- There’s always a better way.\n- Code reviews by your peers will make all of you better.\n- Fewer features for better code is always the right answer in the end.\n- If it’s not tested, it doesn’t work.\n- Don’t reinvent the wheel, library code is there to help.\n- Code that’s hard to understand is hard to maintain.\n- Code that’s hard to maintain is next to useless.\n- Always know how your business makes money, that determines who gets paid what.\n- If you want to feel important as a software developer, work at a tech company.\n\n然后是 《[97 Things Every Programmer Should Know](https://97-things-every-x-should-know.gitbooks.io/97-things-every-programmer-should-know/content/en/index.html)》，其中有 97 个非常不错的编程方面的建议。这篇文章是比较经典的，别被“97”这个数字吓住，你可以快速浏览一下，会让你有不同的感觉的。另外，在工作一段时间后再来读，你会更有感觉。\n\n# 英文能力\n\n必须指出，再往下走，有一个技能非常重要，那就是英文。如果对这个技能发怵的话，那么你可能无缘成为一个程序员高手了。因为我们所有的计算机技术全部来自于西方国家，所以如果你要想成为一个高手的话，那么必须到信息的源头去。英文的世界真是有价值的信息的集散地。你可以在那里，到官网上直接阅读手册，到 StackOverflow 上问问题，到 YouTube 上看很多演讲和教学，到 GitHub 上参与社区，用 Google 查询相关的知识，到国际名校上参加公开课……\n\n如果你的英文能力有问题的话，那么基本上来说，你无法成为一个高手。因此，学好英文是非常有必要的，我说的不只是读写，还有听和说。相信你在学校里学过英文，有一定的基础。所以，我给你下面的这些建议。\n\n1. 坚持 Google 英文关键词，而不是在 Google 里搜中文。\n2. 在 GitHub 上只用英文。用英文写代码注释，写 Code Commit 信息，用英文写 Issue 和 Pull Request，以及用英文写 Wiki。\n3. 坚持到 YouTube 上每天看 5 分钟的视频。YouTube 上有相关的机器字幕，实在不行就打开字幕。\n4. 坚持用英文词典而不是中文的。比如：[剑桥英语词典](https://dictionary.cambridge.org/) 或是 [Dictionary.com](http://www.dictionary.com/) 。你可以安装一个 Chrome 插件 [Google Dictionary](https://chrome.google.com/webstore/detail/google-dictionary-by-goog/mgijmajocgfcbeboacabfgobmjgjcoja)。\n5. 坚持用英文的教材而不是中文的。比如：[BBC 的 Learning English](http://www.bbc.co.uk/learningenglish/) ，或是到一些 ESL 网站上看看，如 [ESL: English as a Second Language](https://www.rong-chang.com/) 上有一些课程。\n6. 花钱参加一些线上的英文课程，用视频和老外练习。\n\n# 问问题的能力\n\n提问的智慧（[How To Ask Questions The Smart Way](http://www.catb.org/~esr/faqs/smart-questions.html)）一文最早是由 Eric Steven Raymond 所撰写的，详细描述了发问者事前应该做好什么，而什么又是不该做的。作者认为这样能让问题容易令人理解，而且发问者自己也能学到较多东西。\n\n此文一经发出，就广受好评，被广泛转载并奉为经典。该文也有 [简体中文翻译版](http://doc.zengrong.net/smart-questions/cn.html) 被流传着，所以在华人界也是篇很有名的文章。有两个著名的缩写 STFW（Search the fxxking web）以及 RTFM（Read the fxxking manual）就是出自本文。\n\n另外，还有一个经典的问题叫 [X-Y Problem](http://xyproblem.info/)。对我来说，这是一个很容易犯的错误，所以，你也要小心避免（我曾经在我的 Coolshell 上写过这个事《[X-Y 问题](https://coolshell.cn/articles/10804.html)》）。\n\n然后，你可以到 StackOverflow 上看看如何问问题的一些提示 -- “[FAQ for StackExchange Site](https://meta.stackexchange.com/questions/7931/faq-for-stack-exchange-sites)”。\n\n作为一个程序员，不做伸手党，你必须要读一读这几篇文章，并努力践行。\n\n# 写代码的修养\n\n除了《代码大全》外，你还需要补充一些如何写好代码的知识，有以下几本书推荐。\n\n- 《[重构：改善既有代码的设计](https://book.douban.com/subject/4262627/)》，这本书是 Martin Fowler 的经典之作。这本书的意义不仅仅在于 \" 改善既有代码的设计 \"，也指导了我们如何从零开始构建代码的时候避免不良的代码风格。这是一本程序员必读的书。\n- 《[修改代码的艺术](https://book.douban.com/subject/2248759/)》，这本书是继《重构》之后探讨修改代码技术的又一里程碑式的著作，而且从涵盖面和深度上都超过了前两部经典（《代码大全》和《重构》）。作者将理解、测试和修改代码的原理、技术和最新工具（自动化重构工具、单元测试框架、仿对象、集成测试框架等），与解依赖技术和大量开发和设计优秀代码的原则、最佳实践相结合，许多内容非常深入。这本书不仅可以帮你掌握最顶尖的修改代码技术，还可以大大提高你对代码和软件开发的领悟力。\n- 《[代码整洁之道](https://book.douban.com/subject/4199741/)》，这本书提出一种观念：代码质量与其整洁度成正比。干净的代码，既在质量上较为可靠，也为后期维护和升级奠定了良好基础。本书作者给出了一系列行之有效的整洁代码操作实践。这些实践在本书中体现为一条条规则，并辅以来自现实项目正反两面的范例。\n- 《[程序员的职业素养](https://book.douban.com/subject/11614538/)》，这本书是编程大师 Bob 大叔 40 余年编程生涯的心得体会，讲解成为真正专业的程序员需要什么样的态度、原则，需要采取什么样的行动。作者以自己以及身边的同事走过的弯路、犯过的错误为例，意在为后来人引路，助其职业生涯迈上更高台阶。\n\n另外，作为一个程序员，Code Review 是非常重要的程序员修养。 Code Review 对我的成长非常有帮助，我认为没有 Code Review 的公司都没有必要呆（因为不做 Code Review 的公司一定是不尊重技术的）。下面有几篇我觉得还不错的 Code Review 的文章，供你参考。\n\n- [Code Review Best Practices](https://medium.com/@palantir/code-review-best-practices-19e02780015f)\n- [How Google Does Code Review](https://dzone.com/articles/how-google-does-code-review)\n- [LinkedIn’s Tips for Highly Effective Code Review](https://thenewstack.io/linkedin-code-review/)\n\n除了 Code Review 之外，Unit Test 也是程序员的一个很重要的修养。写 Unit Test 的框架一般来说都是从 JUnit 衍生出来的，比如 CppUnit 之类的。学习 JUnit 使用的最好方式就是到其官网上看 [JUnit User Guide](https://junit.org/junit5/docs/current/user-guide/)（[中文版](http://sjyuan.cc/junit5/user-guide-cn/)）。然后，有几篇文章你可以看看（也可以自行 Google）：\n\n- [You Still Don’t Know How to Do Unit Testing](https://stackify.com/unit-testing-basics-best-practices/)\n- [Unit Testing Best Practices: JUnit Reference Guide](https://dzone.com/articles/unit-testing-best-practices)\n- [JUnit Best Practices](http://www.kyleblaney.com/junit-best-practices/)\n\n# 安全防范\n\n在代码中没有最基本的安全漏洞问题，也是我们程序员必须要保证的重要大事，尤其是对外暴露 Web 服务的软件，其安全性就更为重要了。对于在 Web 上经常出现的安全问题，有必要介绍一下 [OWASP - Open Web Application Security Project](https://www.owasp.org/index.php/Main_Page)。\n\nOWASP 是一个开源的、非盈利的全球性安全组织，致力于应用软件的安全研究。其被视为 Web 应用安全领域的权威参考。2009 年，国际信用卡数据安全技术 PCI 标准将其列为必要组件，美国国防信息系统局、欧洲网络与信息安全局、美国国家安全局等政府机构所发布的美国国家和国际立法、标准、准则和行业实务守则参考引用了 OWASP。\n\n美国联邦贸易委员会（FTC）强烈建议所有企业需遵循 OWASP 十大 Web 弱点防护守则。所以，对于[https://www.owasp.org/index.php/Category:OWASP_T]( op_Ten_Project\">OWASP Top 10 项目 是程序员非常需要关注的最基本的也是最严重的安全问题，现在其已经成了一种标准，这里是其中文版《[OWASP Top 10 2017 PDF 中文版](https://www.owasp.org/images/d/dc/OWASP_Top_10_2017_中文版v1.3.pdf)》。\n\n下面是安全编程方面的一些 Guideline。\n\n- [伯克立大学的 Secure Coding Practice Guidelines](https://security.berkeley.edu/secure-coding-practice-guidelines)。\n- [卡内基梅隆大学的 SEI CERT Coding Standards](https://wiki.sei.cmu.edu/confluence/display/seccode/SEI+CERT+Coding+Standards)。\n\n此外，有一篇和 HTTP 相关的安全文章也是每个程序员必须要读的——《[Hardening Your HTTP Security Headers](https://www.keycdn.com/blog/http-security-headers/)》。\n\n最后想说的是 \" 防御性编程 \"，英文叫[Defensive Programming](https://en.wikipedia.org/wiki/Defensive_programming)，它是为了保证对程序的不可预见的使用，不会造成程序功能上的损坏。它可以被看作是为了减少或消除墨菲定律效力的想法。防御式编程主要用于可能被滥用，恶作剧或无意地造成灾难性影响的程序上。下面是一些文章。\n\n- [The Art of Defensive Programming](https://medium.com/web-engineering-vox/the-art-of-defensive-programming-6789a9743ed4)。\n- 当然，也别太过渡了，这篇文章可以看看，[Overly defensive programming](https://medium.com/@cvitullo/overly-defensive-programming-e7a1b3d234c2)。\n\n# 软件工程和上线\n\n系统上线是一件比较严肃的事，这表明你写的软件不是跑在自己的机器上的玩具，或是实验室里的实验品，而是交付给用户使用的，甚至是用户付费的软件。对于这样的软件或系统，我们需要遵守一些上线规范，比如，需要认真测试，并做上线前检查，以及上线后监控。下面是几个简单的规范，供你参考。\n\n- 关于测试，推荐两本书。\n  - 《[完美软件：对软件测试的各种幻想](https://book.douban.com/subject/4187479/)》，这本书重点讨论了与软件测试有关的各种心理问题及其表现与应对方法。作者首先阐述软件测试之所以如此困难的原因–人的思维不是完美的，而软件测试的最终目的就是发现对改善软件产品和软件开发过程有益的信息，故软件测试是一个信息获取的过程。\n  - 《[Google 软件测试之道](https://book.douban.com/subject/25742200/)》，描述了测试解决方案，揭示了测试架构是如何设计、实现和运行的，介绍了软件测试工程师的角色；讲解了技术测试人员应该具有的技术技能；阐述了测试工程师在产品生命周期中的职责；讲述了测试管理，并对在 Google 的测试历史上或者主要产品上发挥了重要作用的工程师的访谈，这令那些试图建立类似 Google 的测试流程或团队的人受益很大。\n- 当你的系统要上线时，你是不是已经做好上线的准备了？这里有两个 Checklist 供你做上线前的一些检查。\n  - [Server Side checklist](https://github.com/mtdvio/going-to-production/blob/master/serverside-checklist.md)\n  - [Single Page App Checklist](https://github.com/mtdvio/going-to-production/blob/master/spa-checklist.md)\n- 《[Monitoring 101](https://www.datadoghq.com/blog/monitoring-101-collecting-data/)》这是一篇运维方面的入门文章，告诉你最基本的监控线上运行软件的方法和实践。\n\n# 小结\n\n好了，总结一下今天分享的主要内容。程序员修养看似与程序员练级关系不大，实际上却能反映出程序员的工程师特质和价值观，决定了这条路你到底能走多远。**有修养的程序员才可能成长为真正的工程师和架构师，而没有修养的程序员只能沦为码农**。\n\n因此，在这篇文章中，我指出了我认为比较重要的几个方面：英文能力、问问题的能力、写代码的修养、安全防范意识、软件工程和上线规范等。这些能力的训练和培养将为后续的学习和发展夯实基础。\n\n# 附录：编程规范\n\n我们在写代码时，最好参考一些已有的最佳实践。为什么要有编程规范和最佳实践，要让所有人按一定的规范来编程呢？有下面几个主要原因。\n\n- 可以让你的代码很规整，这有利于代码易读性，从而可以更容易地维护。\n- 提升开发效率，我们知道，效率来自于结构化，而不是杂乱。\n- 可以让你的软件避免一些容易掉坑的陷阱，也让 Bug 更少，质量更高。\n- 可以让团队成员更高效率地协作。\n\n如果一个程序员没有这类规范和最佳实践的沉淀，那么是很难成为真正的程序员，只能沦为码农。\n\n当然，对于一些代码风格方面的东西，比如左大括号是否要换行，缩进是用 tab 还是空格等等，我觉得没有对错，只要团队统一就好了。\n\n下面，我罗列了一堆各种语言的编程规范，供你参考。\n\n## 编程语言相关\n\n**C 语言**\n\n- [NASA C Style](http://homepages.inf.ed.ac.uk/dts/pm/Papers/nasa-c-style.pdf)。\n- [C Coding Standard](https://users.ece.cmu.edu/~eno/coding/CCodingStandard.html)。\n- [C Programming/Structure and style](https://en.wikibooks.org/wiki/C_Programming/Structure_and_style)。\n- [Linux kernel coding style](https://www.kernel.org/doc/html/latest/process/coding-style.html)。\n- [GNU Coding Standard](https://www.gnu.org/prep/standards/html_node/Writing-C.html)，GNU 的编码规范。\n\n**C++ 语言**\n\n- [C++ Core Guidelines](http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines)，这个文档是各种 C++ 的大拿包括原作者在内在持续讨论更新的和 C++ 语言相关的各种最佳实践。\n- [Google C++ Style Guide](https://google.github.io/styleguide/cppguide.html)。\n\n**Go 语言**\n\n- [Effective Go](https://golang.org/doc/effective_go.html) ，Go 的语法不复杂，所以，Go 语言的最佳实践只需要看这篇官方文档就够了。\n\n**Java 语言**\n\n- [Code Conventions for the Java™ Programming Language](http://www.oracle.com/technetwork/java/codeconvtoc-136057.html) ，Java 官方的编程规范。\n- [Google Java Style Guide](https://google.github.io/styleguide/javaguide.html)，Google 的 Java 编码规范。\n\n**JavaScript 语言**\n\n- [JavaScript The Right Way](http://jstherightway.org) ，一个相对比较容读的 JavaScript 编程规范，其中不但有代码规范，还有设计模式，测试工具，编程框架，游戏引擎……\n- [Google JavaScript Style Guide](https://google.github.io/styleguide/jsguide.html)，Google 公司的 JavaScript 的编码规范，一个非常大而全的编程规范。\n- [Airbnb JavaScript Style Guide](https://github.com/airbnb/javascript)，Airbnb 的 JavaScript 编程规范。没 Google 的这么大而全，但是也很丰富了。\n- [jQuery Core Style Guide](http://contribute.jquery.org/style-guide/js/)，jQuery 的代码规范。\n- [JavaScript Clean Code](https://github.com/ryanmcdermott/clean-code-javascript)，前面推荐过的《代码整洁之道》一书中的 JavaScript 的实践 。\n\n还有一些其它相对比较简单的 JavaScript 编程规范。\n\n- [JavaScript Style Guides And Beautifiers](https://addyosmani.com/blog/javascript-style-guides-and-beautifiers/) ，这是一篇推荐 JavaScript 编程规范的文章，你可以看看。\n- [JavaScript Style Guide and Coding Conventions](https://www.w3schools.com/js/js_conventions.asp)，这是 W3Schools 的 JavaScript。\n- [Code Conventions for the JavaScript](http://crockford.com/javascript/code.html)。\n\n**PHP 语言**\n\n- [PHP FIG](http://www.php-fig.org/psr/)，PHP 编码规范及标准推荐。\n- [PHP The Right Way](http://www.phptherightway.com)，除了编码规范之外的各种 PHP 的最佳实践，还包括一些设计模式，安全问题，以及服务部署，Docker 虚拟化以及各种资源。\n- [Clean Code PHP](https://github.com/jupeter/clean-code-php)，《代码整洁之道》的 PHP 实践。\n\n**Python 语言**\n\n- [Style Guide for Python Code](https://www.python.org/dev/peps/pep-0008/)，Python 官方的编程码规范。\n- [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html)，Google 公司的 Python 编码规范。\n- [The Hitchhiker’s Guide to Python](http://docs.python-guide.org/en/latest/)，这不只是 Python 的编程规范，还是 Python 资源的集散地，强烈推荐。\n\n**Ruby 语言**\n\n- [Ruby Style Guide](https://github.com/airbnb/ruby)，Airbnb 公司的 Ruby 编程规范。\n- [Ruby Style Guide](https://github.com/bbatsov/ruby-style-guide) 。\n\n**Rust 语言**\n\n- [Rust Style Guide](https://github.com/rust-lang-nursery/fmt-rfcs/blob/master/guide/guide.md)。\n- [Rust Guidelines](http://aturon.github.io) 开源社区里最好的 Rust 编程规范。\n\n**Scala 语言**\n\n- [Scala Style Guide](http://docs.scala-lang.org/style/)，Scala 官方的编程规范。\n- [Databricks Scala Guide](https://github.com/databricks/scala-style-guide) - Databricks 的 Scala 编程规范。\n- [Scala Best Practices](https://github.com/alexandru/scala-best-practices)。\n\n**Shell 语言**\n\n- [Google Shell Style Guide](https://google.github.io/styleguide/shell.xml)，Google 的 Shell 脚本编程规范。\n\n**Node.js 相关**\n\n- [npm-coding-style](https://docs.npmjs.com/misc/coding-style)。\n- [Microsoft + Node.js Guidelines](https://github.com/Microsoft/nodejs-guidelines)。\n- [Node.js Style Guide](https://github.com/felixge/node-style-guide)。\n\n**Mozilla 的编程规范**\n\n- [Mozilla Coding Style Guide](https://developer.mozilla.org/en-US/docs/Mozilla/Developer_guide/Coding_Style)，其中包括 C、C++、Java、Python、JavaScript、Makefile 和 SVG 等编程规范。\n\n## 前端开发相关\n\n- [CSS Guidelines](https://cssguidelin.es)，CSS 容易学，但是不好写，这篇规范会教你如何写出一个健全的、可管理的，并可以扩展的 CSS。\n- [Scalable and Modular Architecture for CSS](https://smacss.com/)，这是一本教你如何写出可扩展和模块化的 CSS 的电子书，非常不错。\n- [Frontend Guidelines](https://github.com/bendc/frontend-guidelines)，一些和 HTML、CSS、JavaScript 相关的最佳实践。\n- [Sass Guidelines](https://sass-guidelin.es)，Sass 作为 CSS 的补充，其要让 CSS 变得更容易扩展。然而，也变得更灵活，这意味着可以被更容易滥用。这里这篇 \" 富有主见 \" 的规范值得你一读。\n- [Airbnb CSS / Sass Styleguide](https://github.com/airbnb/css)， Airbnb 的 CSS/Sass 规范。\n- 说了 Sass 就不得不说 LESS，这里有几篇和 LESS 相关的：[LESS Coding Guidelines](https://gist.github.com/radermacher/f84b24af816111faf0ef)、[LESS Coding Guidelines](https://github.com/odoo/odoo/wiki/LESS-coding-guidelines)、[LESS coding standard](http://devdocs.magento.com/guides/v2.0/coding-standards/code-standard-less.html)。\n- [HTML Style Guide](https://github.com/marcobiedermann/html-style-guide)，一个教你如何写出性能更高，结构更好，容易编程和扩展的 HTML 的规范。\n- [HTML + CSS Code Guide](http://codeguide.co)，如何写出比较灵活、耐用、可持续改进的 HTML 和 CSS 的规范。\n- [CoffeeScript Style Guide](https://github.com/polarmobile/coffeescript-style-guide)，CoffeeScript 的最佳实践和编程规范。\n- [Google HTML/CSS Style Guide](https://google.github.io/styleguide/htmlcssguide.html)，Google 的 HTML/CSS 的编程规范。\n- [Guidelines for Responsive Web Design](https://www.smashingmagazine.com/2011/01/guidelines-for-responsive-web-design/) ，响应式 Web 设计的规范和最佳实践。\n- [U.S. Web Design Standards](https://standards.usa.gov)，这是美国政府网端要求的一些 UI 交互可视化的一些规范。\n\n最后是一个前端开发的各种注意事项列表，非常有用。\n\n- [Front-End Checklist](https://github.com/thedaviddias/Front-End-Checklist) ，一个前端开发的 Checklist，其中包括 HTML、CSS 和 JavaScript，还和图片、字体、SEO、性能相关，还包括关一些和安全相关的事项，这个列表真的是太好了。\n\n## 移动端相关\n\n**Kotlin**\n\n- [Coding Conventions](https://kotlinlang.org/docs/reference/coding-conventions.html)。\n\n**Objective-C 语言**\n\n- [Objective-C Style guide](https://github.com/github/objective-c-style-guide)，Style guide & coding conventions for Objective-C projects。\n- [Google Objective-C Style Guide](https://google.github.io/styleguide/objcguide.xml)。\n- [NYTimes Objective-C Style Guide](https://github.com/NYTimes/objective-c-style-guide) ，The Objective-C Style Guide used by The New York Times。\n\n**Swift 语言**\n\n- [API Design Guidelines](https://swift.org/documentation/api-design-guidelines/)。\n- [Swift](https://github.com/github/swift-style-guide) - 一个 Swift 的相关编程规范的教程。\n- [Swift style guide](https://github.com/raywenderlich/swift-style-guide)。\n- [Swift Style Guide](https://github.com/linkedin/swift-style-guide) - LinkedIn 的官方 Swift 编程规范。\n- [Metova’s Swift style guide](https://github.com/metova/swift-style-guide)。\n- [Xmartlabs Swift Style Guide](https://github.com/xmartlabs/Swift-Style-Guide)，Xmartlabs 的 Swift 编程规范。\n\n## API 相关\n\n- [HAL](http://stateless.co/hal_specification.html)，一个简单的 API 规范教程。\n- [Microsoft REST API Guidelines](https://github.com/Microsoft/api-guidelines)，微软软的 Rest API 规范。\n- [API Design Guide](http://apiguide.readthedocs.io/en/latest/)。\n- [RESTful API Designing guidelines - The best practices](https://hackernoon.com/restful-api-designing-guidelines-the-best-practices-60e1d954e7c9)。\n- [JSON API - Recommendations](http://jsonapi.org/recommendations)，JSON 相关的 API 的一些推荐实践。\n- [API Security Checklist](https://github.com/shieldfy/API-Security-Checklist) ，API 的安全问题的检查列表。\n\n## 开发工具相关\n\n**Markdown 相关**\n\n- [Google Markdown Style Guide](https://github.com/google/styleguide/blob/gh-pages/docguide/style.md)。\n- [Markdown Style Guide](http://www.cirosantilli.com/markdown-style-guide/)。\n\n**JSON**\n\n- [Google JSON Style Guide](https://google.github.io/styleguide/jsoncstyleguide.xml)。\n- [JSON Style Guide](http://www.w3resource.com/slides/json-style-guide.php)。\n\n**Git 相关**\n\n- [Git Style Guide](https://github.com/agis/git-style-guide)。\n- [Few Rules from Git Documentation](https://github.com/git/git/blob/master/Documentation/CodingGuidelines)。\n\n**正则表达式相关**\n\n- [RegexHQ](https://github.com/regexhq)。\n- [Learn regex the easy way](https://github.com/zeeshanu/learn-regex)。\n\n下面是《程序员练级攻略》系列文章的目录。\n\n- [开篇词](https://time.geekbang.org/column/article/8136)\n- 入门篇\n  - [零基础启蒙](https://time.geekbang.org/column/article/8216)\n  - [正式入门](https://time.geekbang.org/column/article/8217)\n- 修养篇\n  - [程序员修养](https://time.geekbang.org/column/article/8700)\n- 专业基础篇\n  - [编程语言](https://time.geekbang.org/column/article/8701)\n  - [理论学科](https://time.geekbang.org/column/article/8887)\n  - [系统知识](https://time.geekbang.org/column/article/8888)\n- 软件设计篇\n  - [软件设计](https://time.geekbang.org/column/article/9369)\n- 高手成长篇\n  - [Linux 系统、内存和网络（系统底层知识）](https://time.geekbang.org/column/article/9759)\n  - [异步 I/O 模型和 Lock-Free 编程（系统底层知识）](https://time.geekbang.org/column/article/9851)\n  - [Java 底层知识](https://time.geekbang.org/column/article/10216)\n  - [数据库](https://time.geekbang.org/column/article/10301)\n  - [分布式架构入门（分布式架构）](https://time.geekbang.org/column/article/10603)\n  - [分布式架构经典图书和论文（分布式架构）](https://time.geekbang.org/column/article/10604)\n  - [分布式架构工程设计 (分布式架构)](https://time.geekbang.org/column/article/11232)\n  - [微服务](https://time.geekbang.org/column/article/11116)\n  - [容器化和自动化运维](https://time.geekbang.org/column/article/11665)\n  - [机器学习和人工智能](https://time.geekbang.org/column/article/11669)\n  - [前端基础和底层原理（前端方向）](https://time.geekbang.org/column/article/12271)\n  - [前端性能优化和框架（前端方向）](https://time.geekbang.org/column/article/12389)\n  - [UI/UX 设计（前端方向）](https://time.geekbang.org/column/article/12486)\n  - [技术资源集散地](https://time.geekbang.org/column/article/12561)\n\n\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/8700\" > </iframe>\n\n\n\n","categories":["左耳听风"]},{"title":"073丨程序员练级攻略：编程语言","url":"/posts/3091156493.html","content":"\n\n\n为了进入专业的编程领域，我们需要认真学习以下三方面的知识。\n\n**编程语言**。你需要学习 C、C++ 和 Java 这三个工业级的编程语言。为什么说它们是工业级的呢？主要是，C 和 C++ 语言规范都由 ISO 标准化过，而且都有工业界厂商组成的标准化委员会来制定工业标准。次要原因是，它们已经在业界应用于许多重要的生产环境中。\n\n- C 语言不用多说，现今这个世界上几乎所有重要的软件都跟 C 有直接和间接的关系，操作系统、网络、硬件驱动等等。说得霸气一点儿，这个世界就是在 C 语言之上运行的。\n- 而对于 C++ 来说，现在主流的浏览器、数据库、Microsoft Office、主流的图形界面、著名的游戏引擎等都是用 C++ 编写的。而且，很多公司都用 C++ 开发核心架构，如 Google、腾讯、百度、阿里云等。\n- 而金融电商公司则广泛地使用 Java 语言，因为 Java 的好处太多了，代码稳定性超过 C 和 C++，生产力远超 C 和 C++。有 JVM 在，可以轻松地跨平台，做代码优化，做 AOP 和 IoC 这样的高级技术。以 Spring 为首的由庞大的社区开发的高质量的各种轮子让你只需关注业务，是能够快速搭建企业级应用的不二之选。\n\n此外，我推荐学习 Go 语言。一方面，Go 语言现在很受关注，它是取代 C 和 C++ 的另一门有潜力的语言。C 语言太原始了，C++ 太复杂了，Java 太高级了，所以 Go 语言就在这个夹缝中出现了。这门语言已经 10 多年了，其已成为云计算领域事实上的标准语言，尤其是在 Docker/Kubernetes 等项目中。Go 语言社区正在不断地从 Java 社区移植各种 Java 的轮子过来，Go 社区现在也很不错。\n\n如果你要写一些 PaaS 层的应用，Go 语言会比 C 和 C++ 更好，目前和 Java 有一拼。而且，Go 语言在国内外一些知名公司中有了一定的应用和实践，所以，是可以学习的（参看：《[Go 语言、Docker 和新技术](https://coolshell.cn/articles/18190.html)》一文）。此外，Go 语言语法特别简单，你有了 C 和 C++ 的基础，学习 Go 的学习成本基本为零。\n\n**理论学科**。你需要学习像算法、数据结构、网络模型、计算机原理等计算机科学专业需要学习的知识。为什么要学好这些理论上的知识呢？\n\n- 其一，这些理论知识可以说是计算机科学这门学科最精华的知识了。说得大一点，这些是人类智慧的精华。你只要想成为高手，这些东西是你必需要掌握和学习的。\n- 其二，当你在解决一些很复杂或是很难的问题时，这些基础理论知识可以帮到你很多。我过去这 20 年从这些基础理论知识中受益匪浅。\n- 其三，这些理论知识的思维方式可以让你有触类旁通，一通百通的感觉。虽然知识比较难啃，但啃过以后，你将获益终生。\n\n另外，你千万不要觉得在你的日常工作或是生活当中根本用不上，学了也白学，这样的思维方式千万不要有，因为这是平庸的思维方式。如果你想等我用到了再学也不晚，那么你有必要看一下这篇文章《[程序员的荒谬之言还是至理名言？](https://coolshell.cn/articles/4235.html)》。\n\n**系统知识**。系统知识是理论知识的工程实践，这里面有很多很多的细节。比如像 Unix/Linux、TCP/IP、C10K 挑战等这样专业的系统知识。这些知识是你能不能把理论应用到实际项目当中，能不能搞定实际问题的重要知识。\n\n当你在编程的时候，如何和系统进行交互或是获取操作系统的资源，如何进行通讯，当系统出了性能问题，当系统出了故障等，你有大量需要落地的事需要处理和解决。这个时候，这些系统知识就会变得尤为关键和重要了。\n\n这些东西，你可以认为是计算机世界的物理世界，上层无论怎么玩，无论是 Java NIO，还是 Nginx，还是 Node.js，它们都逃脱不掉最下层的限制。所以，你要好好学习这方面的知识。\n\n# 编程语言\n\n## Java 语言\n\n学习 Java 语言有以下**入门级的书**（注意：下面一些书在入门篇中有所提及，但为了完整性，还是要在这里提一下，因为可能有朋友是跳着看的）。\n\n- 《[Java 核心技术：卷 1 基础知识](https://book.douban.com/subject/26880667/)》，这本书本来是 Sun 公司的官方用书，是一本 Java 的入门参考书。对于 Java 初学者来说，是一本非常不错的值得时常翻阅的技术手册。书中有较多地方进行 Java 与 C++ 的比较，因为当时 Java 面世的时候，又被叫作 \"C++ Killer\"。而我在看这本书的时候，发现书中有很多 C++ 的东西，于是又去学习了 C++。学习 C++ 的时候，发现有很多 C 的东西不懂，又顺着去学习了 C。然后，C -> C++ -> Java 整条线融汇贯通，这对我未来的技术成长有非常大的帮助。\n- 有了上述的入门后，Java 的 Spring 框架是你玩 Java 所无法回避的东西，所以接下来是两本 Spring 相关的书，《[Spring 实战](https://book.douban.com/subject/26767354/)》和《[Spring Boot 实战](https://book.douban.com/subject/26857423/)》。前者是传统的 Spring，后者是新式的微服务的 Spring。如果你只想看一本的话，那么就看后者吧。\n\n前面推荐的几本书可以帮你成功入门 Java，但想要进一步成长，就要看下面我推荐的几本进阶级别的书了。\n\n- 接下来，你需要了解了一下如何编写高效的代码，于是必需看一下《[Effective Java](https://book.douban.com/subject/27047716/)》（注意，这里我给的引用是第三版的，也是 2017 年末出版的书），这本书是模仿 Scott Meyers 的经典图书《Effective C++》的。Effective 这种书基本上都是各种经验之谈，所以，这是一本非常不错的书，你一定要读。这里需要推荐一下 [Google Guava 库](https://github.com/google/guava) ，这个库不但是 JDK 的升级库，其中有如：集合（collections）、缓存（caching）、原生类型支持（primitives support）、并发库（concurrency libraries）、通用注解（common annotations）、字符串处理（string processing）、I/O 等库，其还是 Effective Java 这本书中的那些经验的实践代表。\n- 《[Java 并发编程实战](https://book.douban.com/subject/10484692/)》，是一本完美的 Java 并发参考手册。书中从并发性和线程安全性的基本概念出发，介绍了如何使用类库提供的基本并发构建块，用于避免并发危险、构造线程安全的类及验证线程安全的规则，如何将小的线程安全类组合成更大的线程安全类，如何利用线程来提高并发应用程序的吞吐量，如何识别可并行执行的任务，如何提高单线程子系统的响应性，如何确保并发程序执行预期任务，如何提高并发代码的性能和可伸缩性等内容。最后介绍了一些高级主题，如显式锁、原子变量、非阻塞算法以及如何开发自定义的同步工具类。\n- 了解如何编写出并发的程序，你还需要了解一下如何优化 Java 的性能。我推荐《[Java 性能权威指南](https://book.douban.com/subject/26740520/)》。通过学习这本书，你可以比较大程度地提升性能测试的效果。其中包括：使用 JDK 中自带的工具收集 Java 应用的性能数据，理解 JIT 编译器的优缺点，调优 JVM 垃圾收集器以减少对程序的影响，学习管理堆内存和 JVM 原生内存的方法，了解如何最大程度地优化 Java 线程及同步的性能，等等。看完这本书后，如果你还有余力，想了解更多的底层细节，那么，你有必要去读一下《[深入理解 Java 虚拟机](https://book.douban.com/subject/24722612/)》。\n- 《[Java 编程思想](https://book.douban.com/subject/2130190/)》，真是一本透着编程思想的书。上面的书让你从微观角度了解 Java，而这本书则可以让你从一个宏观角度了解 Java。这本书和 Java 核心技术的厚度差不多，但这本书的信息密度比较大。所以，读起来是非常耗大脑的，因为它会让你不断地思考。对于想学好 Java 的程序员来说，这是一本必读的书。\n- 《[精通 Spring 4.x](https://book.douban.com/subject/26952826/)》，也是一本很不错的书，就是有点厚，一共有 800 多页，都是干货。我认为其中最不错的是在分析原理，尤其是针对前面提到的 Spring 技术，应用与原理都讲得很透彻，IOC 和 AOP 也分析得很棒，娓娓道来。其对任何一个技术都分析得很细致和全面，不足之处就是内容太多了，所以导致很厚，但这并不影响它是一本不错的工具书。\n\n当然，学 Java 你一定要学面向对象的设计模式，这里就只有一本经典的书《[设计模式](https://book.douban.com/subject/1052241/)》。如果你觉得有点儿难度了，那么可以看一下《[Head First 设计模式](https://book.douban.com/subject/2243615/)》。学习面向对象的设计模式时，你不要迷失在那 23 个设计模式中，你一定要明白这两个原则：\n\n- **Program to an ‘interface’, not an 'implementation’**\n  - 使用者不需要知道数据类型、结构、算法的细节。\n  - 使用者不需要知道实现细节，只需要知道提供的接口。\n  - 利于抽象、封装，动态绑定，多态。符合面向对象的特质和理念。\n- **Favor ‘object composition’ over 'class inheritance’**\n  - 继承需要给子类暴露一些父类的设计和实现细节。\n  - 父类实现的改变会造成子类也需要改变。\n  - 我们以为继承主要是为了代码重用，但实际上在子类中需要重新实现很多父类的方法。\n  - 继承更多的应该是为了多态。\n\n至此，如果你把上面的这些知识都融汇贯通的话，那么，你已是一个高级的 Java 程序员了，我保证你已经超过了绝大多数程序员了。基本上来说，你在技术方面是可以进入到一线公司的，而且还不是一般的岗位，至少是高级程序员或是初级架构师的级别了。\n\n## C/C++ 语言\n\n不像我出道那个时候，几乎所有的软件都要用 C 语言来写。现在，可能不会有多少人学习 C 语言了，因为一方面有 Java、Python 这样的高级语言为你屏蔽了很多的底层细节，另一方面也有像 Go 语言这样的新兴语言可以让你更容易地写出来也是高性能的软件。但是，我还是想说，C 语言是你必须学习的语言，因为这个世界上绝大多数编程语言都是 C-like 的语言，也是在不同的方面来解决 C 语言的各种问题。**这里，我想放个比较武断话——如果你不学 C 语言，你根本没有资格说你是一个合格的程序员！**\n\n- 这里尤其推荐，已故的 C 语言之父 Dennis M. Ritchie 和著名科学家 Brian W. Kernighan 合作的圣经级的教科书《[C 程序设计语言](https://book.douban.com/subject/1139336/)》。注意，这本书是 C 语言原作者写的，其 C 语言的标准不是我们平时常说的 ANSI 标准，而是原作者的标准，又被叫作 K&R C。但是这本书很轻薄，也简洁，不枯燥，是一本你可以拿着躺在床上看还不会看着看着睡着的书。\n- 然后，还有一本非常经典的 C 语言的书《[C 语言程序设计现代方法](https://book.douban.com/subject/2280547/)》。有人说，这本书配合之前的 [The C Programming Language](https://en.wikipedia.org/wiki/The_C_Programming_Language) 那本书简真是无敌。我想说，这本书更实用，也够厚，完整覆盖了 C99 标准，习题的质量和水准也比较高。更好的是，探讨了现代编译器的实现，以及和 C++ 的兼容，还揭穿了各种古老的 C 语言的神话和信条……是相当相当干的一本学习 C 语言的书。\n\n**对了，千万不要看谭浩强的 C 语言的书。各种误导，我大学时就是用这本书学的 C，后来工作时被坑得不行**。\n\n在学习 C 语言的过程中，你一定会感到，C 语言这么底层，而且代码经常性地崩溃，经过一段时间的挣扎，你才开始觉得你从这个烂泥坑里快要爬出来了。但你还需要看看《[C 陷阱与缺陷](https://book.douban.com/subject/2778632/)》这本书，你会发现，这里面的坑不是一般大。\n\n此时，如果你看过我的《编程范式游记》那个系列文章，你可能会发现 C 语言在泛型编程上的各种问题，这个时候我推荐你学习一下 C++ 语言。可能会有很多人觉得我说的 C++ 是个大坑。是的，这是世界目前来说最复杂也是最难的编程语言了。但是，**C++ 是目前世界上范式最多的语言了，其做得最好的范式就是 \" 泛型编程 \"，这在静态语言中，是绝对地划时代的一个事**。\n\n所以，你有必要学习一下 C++，看看 C++ 是如何解决 C 语言中的各种问题的。你可以先看看我的这篇文章 “[C++ 的坑真的多吗？](https://coolshell.cn/articles/7992.html)” ，有个基本认识。下面推荐几本 C++ 的书。\n\n- 《[C++ Primer 中文版](https://book.douban.com/subject/25708312/)》，这本书是久负盛名的 C++ 经典教程。书是有点厚，前面 1/3 讲 C 语言，后面讲 C++。C++ 的知识点实在是太多了，而且又有点晦涩。但是你主要就看几个点，一个是面向对象的多态，一个是模板和重载操作符，以及一些 STL 的东西。看看 C++ 是怎么玩泛型和函数式编程的。\n- 如果你想继续研究，你需要看另外两本更为经典的书《[Effective C++](https://book.douban.com/subject/5387403/)》和《[More Effective C++](https://book.douban.com/subject/5908727/)》。 这两本书不厚，但是我读了 10 多年，每过一段时间再读一下，就会发现有更多的收获。这两本书的内容会随着你经历的丰富而变得丰富，这也是对我影响最大的两本书，其中影响最大的不是书中的那些 C++ 的东西，而是作者的思维方式和不断求真的精神，这真是太赞了。\n- 学习 C/C++ 都是需要好好了解一下编译器到底干了什么事的。就像 Java 需要了解 JVM 一样，所以，这里还有一本非常非常难啃的书你可以挑战一下《[深度探索 C++ 对象模型\n  ](https://book.douban.com/subject/10427315/)》。这本书是非常之经典的，看完后，C++ 对你来说就再也没有什么秘密可言。我以前写过的《[C++ 虚函数表解析](https://coolshell.cn/articles/12165.html)》，还有《[C++ 对象内存布局](https://coolshell.cn/articles/12176.html)》属于这个范畴。\n- 还有 C++ 的作者 Bjarne Stroustrup 写的 [C++ FAQ](http://www.stroustrup.com/bs_faq.html) （[中文版](http://www.stroustrup.com/bsfaqcn.html)），也是非常值得一读的。\n\n## 学习 Go 语言\n\nC 语言太原始了，C++ 太复杂了，Go 语言是不二之选。有了 C/C++ 的功底，学习 Go 语言非常简单。\n\n首推 [Go by Example](https://gobyexample.com/) 作为你的入门教程。然后，[Go 101](https://go101.org/article/101.html) 也是一个很不错的在线电子书。如果你想看纸书的话，[The Go Programming Language](https://book.douban.com/subject/26337545/) 一书在豆瓣上有 9.2 分，但是国内没有卖的。（当然，我以前也写过两篇入门的供你参考 “[GO 语言简介（上）- 语法](https://coolshell.cn/articles/8460.html)” 和 “[GO 语言简介（下）- 特性](https://coolshell.cn/articles/8489.html)”）。\n\n另外，Go 语言官方的 [Effective Go](https://golang.org/doc/effective_go.html) 是必读的，这篇文章告诉你如何更好地使用 Go 语言，以及 Go 语言中的一些原理。\n\nGo 语言最突出之处是并发编程，Unix 老牌黑客罗勃·派克（Rob Pike）在 Google I/O 上的两个分享，可以让你学习到一些并发编程的模式。\n\n- Go Concurrency Patterns（ [幻灯片](https://talks.golang.org/2012/concurrency.slide)和[演讲视频](https://www.youtube.com/watch?v=f6kdp27TYZs)）。\n- Advanced Go Concurrency Patterns（[幻灯片](https://talks.golang.org/2013/advconc.slide)、[演讲视频](https://youtu.be/QDDwwePbDtw)）。\n\n然后，Go 在 GitHub 的 wiki 上有好多不错的学习资源，你可以从中学习到多。比如：\n\n- [Go 精华文章列表](https://github.com/golang/go/wiki/Articles)。\n- [Go 相关博客列表](https://github.com/golang/go/wiki/Blogs)。\n- [Go Talks](https://github.com/golang/go/wiki/GoTalks)。\n\n此外，还有个内容丰富的 Go 资源列表 [Awesome Go](https://github.com/avelino/awesome-go)，推荐看看。\n\n# 小结\n\n好了，最后我们来总结一些今天分享的内容。在编程语言方面，我推荐学习 C、C++、Java 和 Go 四门语言，并分别阐释了推荐的原因。\n\n- 我认为，C 语言是必须学习的语言，因为这个世界上绝大多数编程语言都是 C-like 的语言，也是在不同的方面来解决 C 语言的各种问题。\n- 而 C++ 虽然复杂难学，但它几乎是目前世界上范式最多的语言了，其做得最好的范式就是 \" 泛型编程 \"，这在静态语言中，是绝对地划时代的一个事。尤其要看看 C++ 是如何解决 C 语言中的各种问题的。\n- Java 是我认为综合能力最强的语言。其实我是先学了 Java，然后又去学了 C++，之后去学了 C 语言的。C -> C++ -> Java 整条线融汇贯通，这对我未来的技术成长有非常大的帮助。\n- 在文章最末，我推荐了 Go 语言，并给出了相关的学习资料。\n\n我认为，一个合格的程序员应该掌握几门语言。一方面，这会让你对不同的语言进行比较，让你有更多的思考。另一方面，这也是一种学习能力的培养，会让你对于未来的新技术学习得更快。\n\n下篇文章中，我们将分享每个程序员都需要掌握的理论知识。敬请期待。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/8701\" > </iframe>\n\n","categories":["左耳听风"]},{"title":"075丨程序员练级攻略：系统知识","url":"/posts/2522467552.html","content":"\n\n\n进入专业的编程领域，学习系统知识是非常关键的一部分。\n\n首先推荐的是翻译版图书《[深入理解计算机系统](https://book.douban.com/subject/5333562/)》，原书名为《Computer Systems A Programmer’s Perspective》。不过，这本书叫做《程序员所需要了解的计算机知识》更为合适。\n\n本书的最大优点是为程序员描述计算机系统的实现细节，帮助其在大脑中构造一个层次型的计算机系统。从最底层的数据在内存中的表示到流水线指令的构成，到虚拟存储器，到编译系统，到动态加载库，到最后的用户态应用。通过掌握程序是如何映射到系统上，以及程序是如何执行的，你能够更好地理解程序的行为为什么是这样的，以及效率低下是如何造成的。\n\n**再强调一下，这本书是程序员必读的一本书！**\n\n然后就是美国计算机科学家 [理查德·史蒂文斯（Richard Stevens）](https://zh.wikipedia.org/wiki/理查德·史蒂文斯) 的三套巨经典无比的书。（理查德·史蒂文斯于 1999 年 9 月 1 日离世，终年 48 岁。死因不详，有人说是滑雪意外，有人说是攀岩意外，有人说是滑翔机意外。总之，家人没有透露。大师的 [个人主页](http://www.kohala.com/start/) 今天还可以访问。）\n\n- 《[Unix 高级环境编程](https://book.douban.com/subject/1788421/)》。\n- 《Unix 网络编程》 [第 1 卷 套接口 API](https://book.douban.com/subject/1500149/) 、[第 2 卷 进程间通信](https://book.douban.com/subject/4118577/) 。\n- 《[TCP/IP 详解 卷 I 协议](https://book.douban.com/subject/1088054/)》。\n\n这几本书的地位我就不多说了，你可以自己看相关的书评。但是，这三本书可能都不容易读，一方面是比较厚，另一方面是知识的密度太大了，所以，读起来有点枯燥和乏味。但是，这没办法，你得忍住。\n\n这里要重点说一下《TCP/IP 详解》这本书，是一本很奇怪的书。这本书迄今至少被 [近五百篇学术论文引用过](http://portal.acm.org/citation.cfm?id=161724) 。这本写给工程师看的书居然被各种学院派的论文来引用，也是很神奇的一件事了。而且，虽然理查德·史蒂文斯不是 TCP 的发明人，但是这本书中把这个协议深入浅出地讲出来，还画了几百张时序图，也是令人叹为观止了。\n\n如果你觉得上面这几本经典书比较难啃，你可以试试下面这些通俗易懂的（当然，如果读得懂上面那三本的，下面的这些也就不需要读了）。\n\n- 《[Linux C 编程一站式学习](https://book.douban.com/subject/4141733/)》。\n- 《[TCP/IP 网络编程](https://book.douban.com/subject/25911735/)》。\n- 《[图解 TCP/IP](https://book.douban.com/subject/24737674/)》，这本书其实并不是只讲了 TCP/IP，应该是叫《计算机网络》才对，主要是给想快速入门的人看的。\n- 《[The TCP/IP Guide](http://www.tcpipguide.com/free/index.htm)》，这本书在豆瓣上的评分 9.2，这里给的链接是这本书的 HTML 英文免费版的，里面的图画得很精彩。\n\n另外，学习网络协议不单只是看书，你最好用个抓包工具看看这些网络包是什么样的。所以，这里推荐一本书《[Wireshark 数据包分析实战](https://book.douban.com/subject/21691692/)》。在这本书中，作者结合一些简单易懂的实际网络案例，图文并茂地演示使用 Wireshark 进行数据包分析的技术方法，可以让我们更好地了解和学习网络协议。当然，也拥有了一定的黑客的技能。\n\n看完《Unix 高级环境编程》后，你可以趁热打铁看看《[Linux/Unix 系统编程手册](https://book.douban.com/subject/25809330/)》或是罗伯特·拉姆（Robert Love）的 [Linux System Programming 英文电子版](http://igm.univ-mlv.fr/~yahya/progsys/linux.pdf) 。其中文翻译版[Linux 系统编程](https://book.douban.com/subject/25828773/) 也值得一读，虽然和《Unix 高级环境编程》很像，不过其主要突出的是 Linux 的一些关键技术和相关的系统调用。\n\n关于 TCP 的东西，你还可以看看下面这一系列的文章。\n\n- [Let’s code a TCP/IP stack, 1: Ethernet & ARP](http://www.saminiir.com/lets-code-tcp-ip-stack-1-ethernet-arp/)\n- [Let’s code a TCP/IP stack, 2: IPv4 & ICMPv4](http://www.saminiir.com/lets-code-tcp-ip-stack-2-ipv4-icmpv4/)\n- [Let’s code a TCP/IP stack, 3: TCP Basics & Handshake](http://www.saminiir.com/lets-code-tcp-ip-stack-3-tcp-handshake/)\n- [Let’s code a TCP/IP stack, 4: TCP Data Flow & Socket API](http://www.saminiir.com/lets-code-tcp-ip-stack-4-tcp-data-flow-socket-api/)\n- [Let’s code a TCP/IP stack, 5: TCP Retransmission](http://www.saminiir.com/lets-code-tcp-ip-stack-5-tcp-retransmission/)\n\n**对于系统知识，我认为主要有以下一些学习要点。**\n\n- 用这些系统知识操作一下文件系统，实现一个可以拷贝目录树的小程序。\n- 用 fork / wait / waitpid 写一个多进程的程序，用 pthread 写一个多线程带同步或互斥的程序。比如，多进程购票的程序。\n- 用 signal / kill / raise / alarm / pause / sigprocmask 实现一个多进程间的信号量通信的程序。\n- 学会使用 gcc 和 gdb 来编程和调试程序（参看我的《**用 gdb 调试程序**》[一](https://blog.csdn.net/haoel/article/details/2879)、[二](https://blog.csdn.net/haoel/article/details/2880)、[三](https://blog.csdn.net/haoel/article/details/2881)、[四](https://blog.csdn.net/haoel/article/details/2882)、[五](https://blog.csdn.net/haoel/article/details/2883)、[六](https://blog.csdn.net/haoel/article/details/2884)、[七](https://blog.csdn.net/haoel/article/details/2885)）。\n- 学会使用 makefile 来编译程序（参看我的《**跟我一起写 makefile**》[一](https://blog.csdn.net/haoel/article/details/2886)、[二](https://blog.csdn.net/haoel/article/details/2887)、[三](https://blog.csdn.net/haoel/article/details/2888)、[四](https://blog.csdn.net/haoel/article/details/2889)、[五](https://blog.csdn.net/haoel/article/details/2890)、[六](https://blog.csdn.net/haoel/article/details/2891)、[七](https://blog.csdn.net/haoel/article/details/2892)、[八](https://blog.csdn.net/haoel/article/details/2893)、[九](https://blog.csdn.net/haoel/article/details/2894)、[十](https://blog.csdn.net/haoel/article/details/2895)、[十一](https://blog.csdn.net/haoel/article/details/2896)、[十二](https://blog.csdn.net/haoel/article/details/2897)、[十三](https://blog.csdn.net/haoel/article/details/2898)、[十四](https://blog.csdn.net/haoel/article/details/2899)）。\n- Socket 的进程间通信。用 C 语言写一个 1 对 1 的聊天小程序，或是一个简单的 HTTP 服务器。\n\n# C10K 问题\n\n然后，当你读完《Unix 网络编程》后，千万要去读一下 “[C10K Problem](http://www.kegel.com/c10k.html) （[中文翻译版](https://www.oschina.net/translate/c10k)）”。提出这个问题的人叫丹·凯格尔（Dan Kegel），目前在 Google 任职。\n\n他从 1978 年起开始接触计算机编程，是 Winetricks 的作者，也是 Wine 1.0 的管理员，同时也是 Crosstool（ 一个让 gcc/glibc 编译器更易用的工具套件）的作者。还是 Java JSR 51 规范的提交者并参与编写了 Java 平台的 NIO 和文件锁，同时参与了 RFC 5128 标准中有关 NAT 穿越（P2P 打洞）技术的描述和定义。\n\nC10K 问题本质上是**操作系统处理大并发请求的问题**。对于 Web 时代的操作系统而言，对于客户端过来的大量的并发请求，需要创建相应的服务进程或线程。这些进程或线程多了，导致数据拷贝频繁（缓存 I/O、内核将数据拷贝到用户进程空间、阻塞）， 进程 / 线程上下文切换消耗大，从而导致资源被耗尽而崩溃。这就是 C10K 问题的本质。\n\n了解这个问题，并了解操作系统是如何通过多路复用的技术来解决这个问题的，有助于你了解各种 I/O 和异步模型，这对于你未来的编程和架构能力是相当重要的。\n\n另外，现在，整个世界都在解决 C10M 问题，推荐看看 [The Secret To 10 Million Concurrent Connections -The Kernel Is The Problem, Not The Solution](http://highscalability.com/blog/2013/5/13/the-secret-to-10-million-concurrent-connections-the-kernel-i.html) 一文。\n\n# 实践项目\n\n我们已经学习完了编程语言、理论学科和系统知识三部分内容，下面就来做几个实践项目，小试牛刀一下。实现语言可以用 C、C++ 或 Java。\n\n实现一个 telnet 版本的聊天服务器，主要有以下需求。\n\n- 每个客户端可以用使用`telnet ip:port`的方式连接到服务器上。\n- 新连接需要用用户名和密码登录，如果没有，则需要注册一个。\n- 然后可以选择一个聊天室加入聊天。\n- 管理员有权创建或删除聊天室，普通人员只有加入、退出、查询聊天室的权力。\n- 聊天室需要有人数限制，每个人发出来的话，其它所有的人都要能看得到。\n\n实现一个简单的 HTTP 服务器，主要有以下需求。\n\n- 解释浏览器传来的 HTTP 协议，只需要处理 URL path。\n- 然后把所代理的目录列出来。\n- 在浏览器上可以浏览目录里的文件和下级目录。\n- 如果点击文件，则把文件打开传给浏览器（浏览器能够自动显示图片、PDF，或 HTML、CSS、JavaScript 以及文本文件）。\n- 如果点击子目录，则进入到子目录中，并把子目录中的文件列出来。\n\n实现一个生产者 / 消费者消息队列服务，主要有以下需求。\n\n- 消息队列采用一个 Ring-buffer 的数据结构。\n- 可以有多个 topic 供生产者写入消息及消费者取出消息。\n- 需要支持多个生产者并发写。\n- 需要支持多个消费者消费消息（只要有一个消费者成功处理消息就可以删除消息）。\n- 消息队列要做到不丢数据（要把消息持久化下来）。\n- 能做到性能很高。\n\n# 小结\n\n到今天，我们已经学习完了专业编程方面最为重要的三部分内容：编程语言、理论学科和系统知识，我们针对这些内容做个小结。如果想看完我推荐的那些书和知识，并能理解和掌握，我估计怎么也得需要 4-5 年的时间。嗯，是的，就是一个计算机科学系科班出身的程序员需要学习的一些东西。这其中，最重要的是下面这几点。\n\n**编程语言**。以工业级的 C、C++、Java 这三门语言为主，这三门语言才是真正算得上工业级的编程语言，因为有工业级的标准化组织在控制着这几门语言，而且也有工业级的企业应用。尤其是 Java，还衍生出了大量的企业级架构上的开源生态。你至少需要掌握 C 语言和 Java 语言，这对你以后面对各式各样的编程语言是非常重要的。\n\n此外，还推荐学习 Go 语言，它已成为云计算领域事实上的标准语言，尤其是在 Docker、Kubernetes 等项目中。而且，Go 语言在国内外一些知名公司中有了一定的应用和实践，并且其生态圈也越来越好。\n\n**算法和数据结构**。这个太重要了，尤其是最基础的算法和数据结构，这是任何一个称职的程序员都需要学习和掌握的。你必需要掌握。\n\n**计算机的相关系统**。你至少要掌握三个系统的基础知识，一个是操作系统，一个是网络系统，还有一个是数据库系统。它们分别代表着计算机基础构架的三大件——计算、存储、网络。\n\n如果你能够走到这里，把前面的那些知识都了解了（不用精通，因为精通是需要时间和实践来慢慢锤炼出来的，所以，你也不用着急），那么你已经是一个合格的程序员了，而且你的潜力和可能性是非常非常高的。\n\n如果经历过这些比较枯燥的理论知识，而且你还能有热情和成就感，那么我要恭喜你了。因为你已经超过了绝大多数人，而且还是排在上游的比较抢手的程序员了。我相信你至少可以找到年薪 50 万以上的工作了。\n\n但是，你还需要很多的经验或是一些实践，以及一些大系统大项目的实际动手的经验。没关系，我们后面会有教你怎么实操的方法和攻略。\n\n但是，往后面走，你需要开始需要术业有专攻了。下面给一些建议的方向。\n\n- **底层方向**：操作系统、文件系统、数据库、网络……\n- **架构方向**：分布式系统架构、微服务、DevOps、Cloud Native……\n- **数据方向**：大数据、机器学习、人工智能……\n- **前端方向**：你对用户体验或是交互更感兴趣，那么你走前端的路吧。\n- **其它方向**：比如，安全开发、运维开发、嵌入式开发……\n\n这些方向你要仔细选择，因为一旦选好，就要勇往直前地走下去，当然，你要回头转别的方向也没什么问题，因为你有前面的这些基础知识在身，所以，不用害怕。只是不同的方向上会有不同的经验积累，经验积累是看书看不来的，这个是转方向的成本。\n\n下篇文章，我们将进入《软件设计篇》。敬请期待。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/8888\" > </iframe>","categories":["左耳听风"]},{"title":"076丨程序员练级攻略：软件设计","url":"/posts/2280971856.html","content":"\n\n\n学习软件设计的方法、理念、范式和模式，是让你从一个程序员通向工程师的必备技能。如果你不懂这些设计方法，那么你将无法做出优质的软件。这就好像写作文一样，文章人人都能写，但是能写得有条理，有章法，有血有肉，就不简单了。软件开发也一样，实现功能，做出来并不难，但是要做漂亮，做优雅，就非常不容易了。\n\nLinus 说过，这世界程序员之所有高下之分，最大的区别就是程序员的“品味”不一样。有品位的程序员和没有品位的程序员写出来的代码，做出来的软件，差距非常大。**所以，如果你想成为一名优秀的程序员，软件设计定是你的必修课**。\n\n然而，软件设计这个事，并不是一朝一夕就能学会的，也不是别人能把你教会的，很多东西需要你自己用实践、用时间、用错误、用教训、用痛苦才能真正体会其中的精髓。所以，除了学习理论知识外，你还需要大量的工程实践，然后每过一段时间就把这些设计的东西重新回炉一下。你会发现这些软件设计的东西，就像饮茶一样，一开始是苦的，然后慢慢回甘，最终你会喝出真正的滋味。\n\n**要学好这些软件开发和设计的方法，你真的需要磨练和苦行，反复咀嚼，反复推敲，在实践和理论中螺旋式地学习，才能真正掌握。** 所以，你需要有足够的耐心和恒心。\n\n# 编程范式\n\n学习编程范式可以让你明白编程的本质和各种语言的编程方式。因此，我推荐以下一些资料，以帮助你系统化地学习和理解。\n\n- 一个是我在极客时间写的《编程范式游记》系列文章，目录如下。\n\n  - [编程范式游记（1）- 起源](https://time.geekbang.org/column/article/301)\n  - [编程范式游记（2）- 泛型编程](https://time.geekbang.org/column/article/303)\n  - [编程范式游记（3）- 类型系统和泛型的本质](https://time.geekbang.org/column/article/2017)\n  - [编程范式游记（4）- 函数式编程](https://time.geekbang.org/column/article/2711)\n  - [编程范式游记（5）- 修饰器模式](https://time.geekbang.org/column/article/2723)\n  - [编程范式游记（6）- 面向对象编程](https://time.geekbang.org/column/article/2729)\n  - [编程范式游记（7）- 基于原型的编程范式](https://time.geekbang.org/column/article/2741)\n  - [编程范式游记（8）- Go 语言的委托模式](https://time.geekbang.org/column/article/2748)\n  - [编程范式游记（9）- 编程的本质](https://time.geekbang.org/column/article/2751)\n  - [编程范式游记（10）- 逻辑编程范式](https://time.geekbang.org/column/article/2752)\n  - [编程范式游记（11）- 程序世界里的编程范式](https://time.geekbang.org/column/article/2754)\n\n- [Wikipedia: Programming paradigm](https://en.wikipedia.org/wiki/Programming_paradigm) ，维基百科上有一个编程范式的页面，顺着这个页面看下去，你可以看到很多很多有用的和编程相关的知识。这些东西对你的编程技能的提高会非常非常有帮助。\n\n- [Six programming paradigms that will change how you think about coding](https://www.ybrikman.com/writing/2014/04/09/six-programming-paradigms-that-will/)，中文翻译版为 [六个编程范型将改变你对编程的看法](https://my.oschina.net/editorial-story/blog/890965)。这篇文章讲了默认支持并发（Concurrent by default）、依赖类型（Dependent types）、连接性语言（Concatenative languages）、声明式编程（Declarative programming）、符号式编程（Symbolic programming）、基于知识的编程（Knowledge-based programming）等六种不太常见的编程范式，并结合了一些你没怎么听说过的语言来分别进行讲述。\n\n  比如在讲 Concatenative languages 时，以 Forth、cat 和 joy 三种语言为例讲述这一编程范式背后的思想——语言中的所有内容都是一个函数，用于将数据推送到堆栈或从堆栈弹出数据；程序几乎完全通过功能组合来构建（concatenation is composition）。作者认为，这些编程范式背后的思想十分有魅力，能够改变对编程的思考。我看完此文，对此也深信不疑。虽然这些语言和编程范式不常用到，但确实能在思想层面给予人很大的启发。这也是我推荐此文的目的。\n\n- [Programming Paradigms for Dummies: What Every Programmer Should Know](https://www.info.ucl.ac.be/~pvr/VanRoyChapter.pdf) ，这篇文章的作者彼得·范·罗伊（Peter Van Roy）是比利时鲁汶大学的计算机科学教师。他在这篇文章里分析了编程语言在历史上的演进，有哪些典型的、值得研究的案例，里面体现了哪些值得学习的范式。\n\n  比如，在分布式编程领域，他提到了 Erlang、E、Distributed Oz 和 Didactic Oz 这四种编程语言。虽然它们都是分布式编程语言，但各有特色，各自解决了不同的问题。通过这篇文章能学到不少在设计编程语言时要考虑的问题，让你重新审视自己所使用的编程语言应该怎样用才能用好，有什么局限性，这些局限性能否被克服等。\n\n- [斯坦福大学公开课：编程范式](http://open.163.com/special/opencourse/paradigms.html)，这是一门比较基础且很详细的课程，适合学习编程语言的初学者。它通过讲述 C、C++、并发编程、Scheme、Python 这 5 门语言，介绍了它们各自不同的编程范式。以 C 语言为例，它解释了 C 语言的基本要素，如指针、内存分配、堆、C 风格的字符串等，并解释了为什么 C 语言会在泛型编程、多态等方面有局限性。通过学习这门课程，你会对一些常用的编程范式有所了解。\n\n# 一些软件设计的相关原则\n\n- **[Don’t Repeat Yourself (DRY) ](http://en.wikipedia.org/wiki/Don't_repeat_yourself)**，DRY 是一个最简单的法则，也是最容易被理解的。但它也可能是最难被应用的（因为要做到这样，我们需要在泛型设计上做相当的努力，这并不是一件容易的事）。它意味着，当在两个或多个地方发现一些相似代码的时候，我们需要把它们的共性抽象出来形成一个唯一的新方法，并且改变现有地方的代码让它们以一些合适的参数调用这个新的方法。\n\n- **[Keep It Simple, Stupid(KISS)](http://en.wikipedia.org/wiki/KISS_principle)** ，KISS 原则在设计上可能最被推崇，在家装设计、界面设计和操作设计上，复杂的东西越来越被众人所鄙视了，而简单的东西越来越被人所认可。宜家（IKEA）简约、高效的家居设计和生产思路；微软（Microsoft）“所见即所得”的理念；谷歌（Google）简约、直接的商业风格，无一例外地遵循了“KISS”原则。也正是“KISS”原则，成就了这些看似神奇的商业经典。而苹果公司的 iPhone 和 iPad 将这个原则实践到了极至。\n\n- **Program to an interface, not an implementation**，这是设计模式中最根本的哲学，注重接口，而不是实现，依赖接口，而不是实现。接口是抽象是稳定的，实现则是多种多样的。在面向对象的 S.O.L.I.D 原则中会提到我们的依赖倒置原则，就是这个原则的另一种样子。还有一条原则叫 Composition over inheritance（喜欢组合而不是继承），这两条是那 23 个经典设计模式中的设计原则。\n\n- **[You Ain’t Gonna Need It (YAGNI)](http://en.wikipedia.org/wiki/You_Ain't_Gonna_Need_It)** ，这个原则简而言之为——只考虑和设计必须的功能，避免过度设计。只实现目前需要的功能，在以后你需要更多功能时，可以再进行添加。如无必要，勿增复杂性。软件开发是一场 trade-off 的博弈。\n\n- **[Law of Demeter](http://en.wikipedia.org/wiki/Principle_of_Least_Knowledge)**，迪米特法则 (Law of Demeter)，又称“最少知识原则”（Principle of Least Knowledge），其来源于 1987 年荷兰大学的一个叫做 Demeter 的项目。克雷格·拉尔曼（Craig Larman）把 Law of Demeter 又称作“不要和陌生人说话”。在《程序员修炼之道》中讲 LoD 的那一章将其叫作“解耦合与迪米特法则”。\n\n  关于迪米特法则有一些很形象的比喻：1) 如果你想让你的狗跑的话，你会对狗狗说还是对四条狗腿说？2) 如果你去店里买东西，你会把钱交给店员，还是会把钱包交给店员让他自己拿？和狗的四肢说话？让店员自己从钱包里拿钱？这听起来有点儿荒唐，不过在我们的代码里这几乎是见怪不怪的事情了。对于 LoD，正式的表述如下：\n\n  对于对象 ‘O’ 中一个方法’M’，M 应该只能够访问以下对象中的方法：\n\n  1. 对象 O；\n  2. 与 O 直接相关的 Component Object；\n  3. 由方法 M 创建或者实例化的对象；\n  4. 作为方法 M 的参数的对象。\n\n- **[面向对象的 S.O.L.I.D 原则](\">http://en.wikipedia.org/wiki/Solid_(object-oriented_design)**：\n\n  - **SRP（Single Responsibility Principle）- 职责单一原则**。关于单一职责原则，其核心的思想是：一个类，只做一件事，并把这件事做好，其只有一个引起它变化的原因。单一职责原则可以看作是低耦合、高内聚在面向对象原则上的引申，将职责定义为引起变化的原因，以提高内聚性来减少引起变化的原因。\n\n  职责过多，可能引起它变化的原因就越多，这将导致职责依赖，相互之间就产生影响，从而极大地损伤其内聚性和耦合度。单一职责，通常意味着单一的功能，因此不要为一个模块实现过多的功能点，以保证实体只有一个引起它变化的原因。\n\n  - **OCP（Open/Closed Principle）- 开闭原则**。关于开发封闭原则，其核心的思想是：模块是可扩展的，而不可修改的。也就是说，对扩展是开放的，而对修改是封闭的。对扩展开放，意味着有新的需求或变化时，可以对现有代码进行扩展，以适应新的情况。对修改封闭，意味着类一旦设计完成，就可以独立完成其工作，而不要对类进行任何修改。\n  - **LSP（Liskov substitution principle）- 里氏代换原则**。软件工程大师罗伯特·马丁（Robert C. Martin）把里氏代换原则最终简化为一句话：“Subtypes must be substitutable for their base types”。也就是，子类必须能够替换成它们的基类。即子类应该可以替换任何基类能够出现的地方，并且经过替换以后，代码还能正常工作。另外，不应该在代码中出现 if/else 之类对子类类型进行判断的条件。里氏替换原则 LSP 是使代码符合开闭原则的一个重要保证。正是由于子类型的可替换性才使得父类型的模块在无需修改的情况下就可以扩展。\n  - **ISP（Interface Segregation Principle ）- 接口隔离原则**。接口隔离原则的意思是把功能实现在接口中，而不是类中，使用多个专门的接口比使用单一的总接口要好。举个例子，我们对电脑有不同的使用方式，比如：写作、通讯、看电影、打游戏、上网、编程、计算和数据存储等。\n\n  如果我们把这些功能都声明在电脑的抽象类里面，那么，我们的上网本、PC 机、服务器和笔记本的实现类都要实现所有的这些接口，这就显得太复杂了。所以，我们可以把这些功能接口隔离开来，如工作学习接口、编程开发接口、上网娱乐接口、计算和数据服务接口，这样，我们的不同功能的电脑就可以有所选择地继承这些接口。\n\n  - **DIP（Dependency Inversion Principle）- 依赖倒置原则**。高层模块不应该依赖于低层模块的实现，而是依赖于高层抽象。举个例子，墙面的开关不应该依赖于电灯的开关实现，而是应该依赖于一个抽象的开关的标准接口。这样，当我们扩展程序的时候，开关同样可以控制其它不同的灯，甚至不同的电器。也就是说，电灯和其它电器继承并实现我们的标准开关接口，而开关厂商就可以不需要关于其要控制什么样的设备，只需要关心那个标准的开关标准。这就是依赖倒置原则。\n\n- [CCP（Common Closure Principle） - 共同封闭原则](http://c2.com/cgi/wiki?CommonClosurePrinciple)，一个包中所有的类应该对同一种类型的变化关闭。一个变化影响一个包，便影响了包中所有的类。一个更简短的说法是：一起修改的类，应该组合在一起（同一个包里）。如果必须修改应用程序里的代码，那么我们希望所有的修改都发生在一个包里（修改关闭），而不是遍布在很多包里。\n\n  CCP 原则就是把因为某个同样的原因而需要修改的所有类组合进一个包里。如果两个类从物理上或者从概念上联系得非常紧密，它们通常一起发生改变，那么它们应该属于同一个包。CCP 延伸了开闭原则（OCP）的“关闭”概念，当因为某个原因需要修改时，把需要修改的范围限制在一个最小范围内的包里。\n\n- [CRP（Common Reuse Principle）- 共同重用原则](http://c2.com/cgi/wiki?CommonReusePrinciple) ，包的所有类被一起重用。如果你重用了其中的一个类，就重用全部。换个说法是，没有被一起重用的类不应该组合在一起。CRP 原则帮助我们决定哪些类应该被放到同一个包里。依赖一个包就是依赖这个包所包含的一切。\n\n  当一个包发生了改变，并发布新的版本，使用这个包的所有用户都必须在新的包环境下验证他们的工作，即使被他们使用的部分没有发生任何改变。因为如果包中包含未被使用的类，即使用户不关心该类是否改变，但用户还是不得不升级该包并对原来的功能加以重新测试。CCP 则让系统的维护者受益。CCP 让包尽可能大（CCP 原则加入功能相关的类），CRP 则让包尽可能小（CRP 原则剔除不使用的类）。它们的出发点不一样，但不相互冲突。\n\n- [好莱坞原则 - Hollywood Principle](http://en.wikipedia.org/wiki/Hollywood_Principle) ，好莱坞原则就是一句话——“don’t call us, we’ll call you.”。意思是，好莱坞的经纪人不希望你去联系他们，而是他们会在需要的时候来联系你。也就是说，所有的组件都是被动的，所有的组件初始化和调用都由容器负责。\n\n  简单来讲，就是由容器控制程序之间的关系，而非传统实现中，由程序代码直接操控。这也就是所谓“控制反转”的概念所在：1) 不创建对象，而是描述创建对象的方式。2）在代码中，对象与服务没有直接联系，而是容器负责将这些联系在一起。控制权由应用代码中转到了外部容器，控制权的转移，是所谓反转。好莱坞原则就是[IoC（Inversion of Control）](http://en.wikipedia.org/wiki/Inversion_of_Control) 或[DI（Dependency Injection）](https://martinfowler.com/articles/injection.html)的基础原则。\n\n- [高内聚， 低耦合 & - High Cohesion & Low/Loose coupling](http://en.wikipedia.org/wiki/Coupling_(computer_science))，这个原则是 UNIX 操作系统设计的经典原则，把模块间的耦合降到最低，而努力让一个模块做到精益求精。内聚，指一个模块内各个元素彼此结合的紧密程度；耦合指一个软件结构内不同模块之间互连程度的度量。内聚意味着重用和独立，耦合意味着多米诺效应牵一发动全身。对于面向对象来说，你也可以看看马萨诸塞州戈登学院的面向对象课中的这一节讲义[High Cohesion and Low Coupling](http://www.math-cs.gordon.edu/courses/cs211/lectures-2009/Cohesion,Coupling,MVC.pdf)。\n\n- [CoC（Convention over Configuration）- 惯例优于配置原则](http://en.wikipedia.org/wiki/Convention_over_Configuration) ，简单点说，就是将一些公认的配置方式和信息作为内部缺省的规则来使用。例如，Hibernate 的映射文件，如果约定字段名和类属性一致的话，基本上就可以不要这个配置文件了。你的应用只需要指定不 convention 的信息即可，从而减少了大量 convention 而又不得不花时间和精力啰里啰嗦的东东。\n\n  配置文件在很多时候相当影响开发效率。Rails 中很少有配置文件（但不是没有，数据库连接就是一个配置文件）。Rails 的 fans 号称其开发效率是 Java 开发的 10 倍，估计就是这个原因。Maven 也使用了 CoC 原则，当你执行 `mvn -compile` 命令的时候，不需要指定源文件放在什么地方，而编译以后的 class 文件放置在什么地方也没有指定，这就是 CoC 原则。\n\n- [SoC (Separation of Concerns) - 关注点分离](http://sulong.me/archives/99) ，SoC 是计算机科学中最重要的努力目标之一。这个原则，就是在软件开发中，通过各种手段，将问题的各个关注点分开。如果一个问题能分解为独立且较小的问题，就是相对较易解决的。问题太过于复杂，要解决问题需要关注的点太多，而程序员的能力是有限的，不能同时关注于问题的各个方面。\n\n  正如程序员的记忆力相对于计算机知识来说那么有限一样，程序员解决问题的能力相对于要解决的问题的复杂性也是一样的非常有限。在我们分析问题的时候，如果我们把所有的东西混在一起讨论，那么就只会有一个结果——乱。实现关注点分离的方法主要有两种，一种是标准化，另一种是抽象与包装。标准化就是制定一套标准，让使用者都遵守它，将人们的行为统一起来，这样使用标准的人就不用担心别人会有很多种不同的实现，使自己的程序不能和别人的配合。\n\n  就像是开发镙丝钉的人只专注于开发镙丝钉就行了，而不用关注镙帽是怎么生产的，反正镙帽和镙丝钉按照标准来就一定能合得上。不断地把程序的某些部分抽象并包装起来，也是实现关注点分离的好方法。一旦一个函数被抽象出来并实现了，那么使用函数的人就不用关心这个函数是如何实现的。同样的，一旦一个类被抽象并实现了，类的使用者也不用再关注于这个类的内部是如何实现的。诸如组件、分层、面向服务等这些概念都是在不同的层次上做抽象和包装，以使得使用者不用关心它的内部实现细节。\n\n- [DbC（Design by Contract）- 契约式设计](http://en.wikipedia.org/wiki/Design_by_contract) ，DbC 的核心思想是对软件系统中的元素之间相互合作以及“责任”与“义务”的比喻。这种比喻从商业活动中“客户”与“供应商”达成“契约”而得来。如果在程序设计中一个模块提供了某种功能，那么它要：\n\n  - 期望所有调用它的客户模块都保证一定的进入条件：这就是模块的先验条件（客户的义务和供应商的权利，这样它就不用去处理不满足先验条件的情况）。\n  - 保证退出时给出特定的属性：这就是模块的后验条件（供应商的义务，显然也是客户的权利）。\n  - 在进入时假定，并在退出时保持一些特定的属性：不变式。\n\n- [ADP（Acyclic Dependencies Principle）- 无环依赖原则](http://c2.com/cgi/wiki?AcyclicDependenciesPrinciple) ，包（或服务）之间的依赖结构必须是一个直接的无环图形，也就是说，在依赖结构中不允许出现环（循环依赖）。如果包的依赖形成了环状结构，怎么样打破这种循环依赖呢？\n\n  有两种方法可以打破这种循环依赖关系：第一种方法是创建新的包，如果 A、B、C 形成环路依赖，那么把这些共同类抽出来放在一个新的包 D 里。这样就把 C 依赖 A 变成了 C 依赖 D 以及 A 依赖 D，从而打破了循环依赖关系。第二种方法是使用 DIP（依赖倒置原则）和 ISP（接口分隔原则）设计原则。无环依赖原则（ADP）为我们解决包之间的关系耦合问题。在设计模块时，不能有循环依赖。\n\n# 一些软件设计的读物\n\n- 《[领域驱动设计](https://book.douban.com/subject/26819666/)》 ，本书是领域驱动设计方面的经典之作。全书围绕着设计和开发实践，结合若干真实的项目案例，向读者阐述如何在真实的软件开发中应用领域驱动设计。书中给出了领域驱动设计的系统化方法，并将人们普遍接受的一些实践综合到一起，融入了作者的见解和经验，展现了一些可扩展的设计新实践、已验证过的技术以及便于应对复杂领域的软件项目开发的基本原则。\n- 《[UNIX 编程艺术](https://book.douban.com/subject/1467587/)》 ，这本书主要介绍了 Unix 系统领域中的设计和开发哲学、思想文化体系、原则与经验，由公认的 Unix 编程大师、开源运动领袖人物之一埃里克·雷蒙德（Eric S. Raymond）倾力多年写作而成。包括 Unix 设计者在内的多位领域专家也为本书贡献了宝贵的内容。本书内容涉及社群文化、软件开发设计与实现，覆盖面广、内容深邃，完全展现了作者极其深厚的经验积累和领域智慧。\n- 《[Clean Architecture](https://8thlight.com/blog/uncle-bob/2012/08/13/the-clean-architecture.html)》，如果你读过 《[Clean Code](https://book.douban.com/subject/5442024/)》 和 《[The Clean Coder](https://book.douban.com/subject/11614538/)》这两本书。你就能猜得到这种 Clean 系列一定也是出自“Bob 大叔”之手。没错，就是 Bob 大叔的心血之作。除了这个网站，《[Clean Architecture](https://book.douban.com/subject/26915970/)》也是一本书，这是一本很不错的架构类图书。对软件架构的元素、方法等讲得很清楚。示例都比较简单，并带一些软件变化历史的讲述，很开阔视野。\n- [The Twelve-Factor App](https://12factor.net/) ，如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建 SaaS 应用提供了方法论，这也是架构师必读的文章。（[中译版](https://12factor.net/zh_cn/)） 这篇文章在业内的影响力很大，必读！\n- [Avoid Over Engineering](https://medium.com/@rdsubhas/10-modern-software-engineering-mistakes-bc67fbef4fc8) ，有时候，我们会过渡设计我们的系统，过度设计会把我们带到另外一个复杂度上，所以，我们需要一些工程上的平衡。这篇文章是一篇非常不错地告诉你什么是过度设计的文章。\n- [Instagram Engineering’s 3 rules to a scalable cloud application architecture](https://medium.com/@DataStax/instagram-engineerings-3-rules-to-a-scalable-cloud-application-architecture-c44afed31406) ，Instagram 工程的三个黄金法则：1）使用稳定可靠的技术（迎接新的技术）；2）不要重新发明轮子；3）Keep it very simple。我觉得这三条很不错。其实，Amazon 也有两条工程法则，一个是自动化，一个是简化。\n- [How To Design A Good API and Why it Matters - Joshua Bloch](https://www.infoq.com/presentations/effective-api-design) ，Google 的一个分享，关于如何设计好一个 API。\n- 关于 Restful API 的设计，你可以学习并借鉴一下下面这些文章。\n  - [Best Practices for Designing a Pragmatic RESTful API](https://www.vinaysahni.com/best-practices-for-a-pragmatic-restful-api)\n  - [Ideal REST API design](https://betimdrenica.wordpress.com/2015/03/09/ideal-rest-api-design/)\n  - [HTTP API Design Guide](https://github.com/interagent/http-api-design)\n  - [Microsoft REST API Guidelines](https://github.com/Microsoft/api-guidelines/blob/vNext/Guidelines.md)\n  - [IBM Watson REST API Guidelines](https://github.com/watson-developer-cloud/api-guidelines)\n  - [Zalando RESTful API and Event Scheme Guidelines](https://opensource.zalando.com/restful-api-guidelines/)\n- [The Problem With Logging](https://blog.codinghorror.com/the-problem-with-logging/) ，一篇关于程序打日志的短文，可以让你知道一些可能以往不知道的打日志需要注意的问题。\n- [Concurrent Programming for Scalable Web Architectures](http://berb.github.io/diploma-thesis/community/index.html) ，这是一本在线的免费书，教你如何架构一个可扩展的高性能的网站。其中谈到了一些不错的设计方法和知识。\n\n# 小结\n\n好了，总结一下今天分享的内容。我认为，“品位”不同，是各层次程序员之间最大的区别，这也决定了他们所做出来的软件的质量和价值。因此，我特意撰写了软件设计这一篇章，帮助那些想成长为软件工程师、设计师或架构师的程序员，提高软件设计的品位，进而实现自己的目标。\n\n虽然很多程序员都忽略了对编程范式的学习，但我觉得学习编程范式其实是非常非常重要的事，能够明白编程的本质和各种语言的编程方式。为此，我推荐了好几份学习资料，帮助你系统化地学习和理解。随后我介绍了 DRY- 避免重复原则、KISS- 简单原则、迪米特法则（又称“最少知识原则”）、 面向对象的 S.O.L.I.D 原则等多个经典的软件设计原则。\n\n最后，我精选并推荐了软件设计方面的学习资料，如《领域驱动设计》、《UNIX 编程艺术》和《Clean Architecture》等必读好书，以及如何构建 SaaS，如何避免过度设计，如何设计 API，如何用程序打日志等方面的资料。\n\n希望这些内容对你有帮助。从下一篇文章开始，我们将进入《程序员练级攻略》的第五个篇章——高手成长篇。敬请期待。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/9369\" > </iframe>","categories":["左耳听风"]},{"title":"077丨程序员练级攻略：Linux系统、内存和网络","url":"/posts/2788417582.html","content":"\n\n\n这一篇章，是本系列中最长的一篇，其中包括了如下的内容。\n\n- **系统底层相关**。 主要是以 Linux 系统为主，其中有大量的文章可以让你学习到 Linux 内核，以及内存、网络、异步 I/O 模型、Lock-free 的无锁编程，还有其它和系统底层相关的东西。注意，系统底层要是深下去是可以完全不见底的。而且内存方面的知识也是比较多的，所以，这里还是主要给出一些非常有价值的基础性的知识和技术。学好这些东西，你会对系统有很深的理解，而且可以把这些知识反哺到架构设计上来。\n- **数据库相关**。数据库方面主要是 MySQL 和各种开源 NoSQL 的一些相关的有价值的文章和导读，主要是让你对这些数据库的内在有一定的了解，但又不会太深。真正的深入是需要扎入到源代码中的。需要说明的是，这块技术不是我的长项，但又是每个架构师需要知道的，所以，我在这里给的学习资源可能会比较浅，这点还希望你来补充和指正。\n- **分布式架构**。这一部分是最长最多的。其中有架构入门、分布式理论中各种非常有价值的经典论文，然后是一些分布式工程设计方面的文章，其中包括设计模式和工程应用，最后还有各大公司的架构供参考。\n- **微服务**。有了分布式架构理论和工程的基础，接下来是对微服务的学习。在这部分内容中，我会罗列几个介绍微服务架构非常系统的文章，然后比较一下微服务和 SOA 的差别，最后则是一些工程实践和最佳实践。\n- **容器化和自动化运维**。在容器化和自动化运维中，主要是学习 Docker 和 Kubernetes 这两个自动化运维的杀手型技术。而不是 Salt、Puppet、Chef 和 Ansible 这样比较传统的工具。原因很简单，因为自动化部署根本不够，还需要对环境和运行时的管理和运维才够，而只有 Docker 和 Kubernetes 才是未来。所以，这里重点让你学习这两个技术，其中有很多文章需要一些系统底层的知识。\n- **机器学习和人工智能**。机器学习和人工智能，也不是我的长项，我也只是一个入门者。这里，我主要给了一些基础性的知识，其中包括基本原理、图书、课程、文章和相关的算法。你顺着我画的这路走，不能说能成为一个人工智能专家，但成为一个机器学习的高级工程师甚至准专家还是可能的。\n- **前端开发**。这里的前端主要是 HTML 5 的前端了，这一节会带你学习一下前端开发所需要知道的基础知识，尤其是对前端开发语言 JavaScript 的学习，我花费了相当的篇幅列出了很多很经典的学习资料，必定会让你成为一个 JavaScript 高手。然后你还需要了解浏览器是怎样工作的，还有相关的网络协议和一些性能优化的技巧。最后则是 JavaScript 框架的学习，这里我只给了 React.js 和 Vue.js，并通过 React.js 带出来函数式编程的学习。我虽然不是一个前端程序员，但是，我相信我这个后端程序员给出来的这组前端开发的学习资料和路径会比前端程序员更靠谱一些。\n- **信息源**。最后，则是一些信息源，其中包括各大公司的技术 Blog，还有相关的论文集散地。\n\n另外，这里需要说明几点。\n\n- 我假设你在前面已经打下了非常扎实的基础，但是要成为一个高手，基础知识只是一个地基，你还需要很多更为具体的技术。对我来说，就是看各种各样的文章、手册、论文、分享…… 其实，学习到一定程度，就是要从书本中走出去，到社区里和大家一起学习，而且还需要自己找食吃了。所以，对于这里面的文章，有很多都是在罗列各种文章和资源，只是为你梳理信息源，而不是喂你吃饭。\n- **老实说，我已经为你梳理并过滤掉了很多的信息，这里只留下了 30% 我觉得最经济也最有价值的信息**。虽然对于不同定位和不同需求的人还可以再对这些信息进行删减，但是觉得我这么一做就会对其它人不公平了。所以，这也是我觉得最小数量集的信息和资源吧。**你也可以把我这里的东西当成一个索引来对待**。\n- 这些内容，不能说是隔离开来的，应该说是相辅相成的。也没什么顺序，可以各取所需。虽然看上去内容很多，但你也别害怕，真的不用害怕，你会越学越快，越实践越有感觉，也越有效率。在一开始可能会很慢，但是坚持住，积累一段时间后就会越来越快的。 而且，我要告诉你，绝大多数人是坚持不下来的。只要你能坚持下来，我保证，你一定会成为各个大公司的抢手货，这点你一定要相信我。**你不需要特别努力，只需要日进一步，3-5 年后，你就会发现，绝大多数人都在你身后很远的地方了。**\n\n今天分享的内容为系统底层知识中的 Linux 系统、内存和网络等方面的相关知识及推荐的学习资料。\n\n# Linux 系统相关\n\n学习 Linux 操作系统的原理是通向系统工程师的必经之路。我觉得，Unix/Linux 操作系统里的东西并不难学。你千万不要一下子扎到源代码里去，那样没用——你还是要在上层先通过读一些不错的文档来学习。下面我罗列了一些很不错的站点，其中有很多内容供你去钻研和探索。\n\n我在这里默认你前面已经读过并读懂了我推荐的那些和 Unix/Linux 相关的图书了。所以，我相信你对 Unix/Linux 下的编程已经是有一些基础了，因此，你继续深挖 Linux 下的这些知识应该也不是很难的事了。\n\n- [Red Hat Enterprise Linux 文档](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/?version=7) 。Red Hat Enterprise Linux（RHEL）是老牌 Linux 厂商 Red Hat 出品的面向商业的 Linux 发行版。Red Hat 网站上的这个文档中有很多很有价值的内容，值得一看。\n- [Linux Insides](https://github.com/0xAX/linux-insides) ，GitHub 上的一个开源电子书，其中讲述了 Linux 内核是怎样启动、初始化以及进行管理的。\n- [LWN’s kernel page](http://lwn.net/Kernel/Index/) ，上面有很多非常不错的文章来解释 Linux 内核的一些东西。\n- [Learn Linux Kernel from Android Perspective](http://learnlinuxconcepts.blogspot.com/2014/10/this-blog-is-to-help-those-students-and.html) ，从 Android 的角度来学习 Linux 内核，这个站点上的 Blog 相对于前面的比较简单易读一些。\n- [Linux Kernel Doc](https://www.kernel.org/doc/)， Linux 的内核文档也可以浏览一下。\n- [Kernel Planet](http://planet.kernel.org/) ，Linux 内核开发者的 Blog，有很多很不错的文章和想法。\n- [Linux Performance and Tuning Guidelines](https://lenovopress.com/redp4285.pdf) ，这是 IBM 出的红皮书，虽然有点老了，但还是非常值得一读的。\n- [TLK: The Linux Kernel](http://tldp.org/LDP/tlk/tlk.html) ，这是一本相对比较老的书了，Linux 内核版本为 2.0.33，但了解一下前人的思路，也是很有帮助的。\n- [Linux Performance](http://www.brendangregg.com/linuxperf.html) ，这个网站上提供了和 Linux 系统性能相关的各种工具和文章收集，非常不错。\n- [Optimizing web servers for high throughput and low latency](https://blogs.dropbox.com/tech/2017/09/optimizing-web-servers-for-high-throughput-and-low-latency/) ，这是一篇非常底层的系统调优的文章，来自 DropBox，从中你可以学到很多底层的性能调优的经验和知识。\n\n# 内存相关\n\n计算机内存管理是每一个底层程序员需要了解的非常重要的事儿。当然，这里我们重点还是 Linux 操作系统相关的内存管理上的知识。\n\n首先，LWN.net 上有一系列的 “**What every programmer should know about memory**” 文章你需要读一下。当然，你可以直接访问一个完整的 [PDF 文档](http://futuretech.blinkenlights.nl/misc/cpumemory.pdf)。下面是这个系列文章的网页版列表。读完这个列表的内容，你基本上就对内存有了一个比较好的知识体系了。\n\n- [Part 1: Introduction](https://lwn.net/Articles/250967/) ，中译版为 “[每个程序员都应该了解的内存知识【第一部分】](https://www.oschina.net/translate/what-every-programmer-should-know-about-memory-part1)”\n- [Part 2: CPU caches](https://lwn.net/Articles/252125/)\n- [Part 3 (Virtual memory)](http://lwn.net/Articles/253361/)\n- [Part 4 (NUMA systems)](http://lwn.net/Articles/254445/)\n- [Part 5 (What programmers can do - cache optimization)](http://lwn.net/Articles/255364/)\n- [Part 6 (What programmers can do - multi-threaded optimizations)](http://lwn.net/Articles/256433/)\n- [Part 7 (Memory performance tools)](http://lwn.net/Articles/257209/)\n- [Part 8 (Future technologies)](https://lwn.net/Articles/258154/)\n- [Part 9 (Appendices and bibliography)](https://lwn.net/Articles/258188/)\n\n然后是几篇和内存相关的论文。下面这三篇论文是我个人觉得能对你非常有帮助的文章，尤其是你要做一些程序的性能优化方面。\n\n- [Memory Barriers: a Hardware View for Software Hackers](http://irl.cs.ucla.edu/~yingdi/web/paperreading/whymb.2010.06.07c.pdf)。内存的读写屏障是线程并发访问共享的内存数据时，从程序本身、编译器到 CPU 都必须遵循的一个规范。有了这个规范，才能保证访问共享的内存数据时，一个线程对该数据的更新能被另一个线程以正确的顺序感知到。在 SMP（对称多处理）这种类型的多处理器系统（包括多核系统）上，这种读写屏障还包含了复杂的缓存一致性策略。这篇文章做了详细解释。\n- [A Tutorial Introduction to the ARM and POWER Relaxed Memory Models](http://www.cl.cam.ac.uk/~pes20/ppc-supplemental/test7.pdf)，对 ARM 和 POWER 的宽松内存模型的一个教程式的简介。本篇文章的焦点是 ARM 和 POWER 体系结构下多处理器系统内存并发访问一致性的设计思路和使用方法。与支持较强的 TSO 模型的 x86 体系结构不同，ARM 和 POWER 这两种体系结构出于对功耗和性能的考虑，使用了一种更为宽松的内存模型。本文详细讨论了 ARM 和 POWER 的模型。\n- [x86-TSO: A Rigorous and Usable Programmer’s Model for x86 Multiprocessors](http://www.cl.cam.ac.uk/~pes20/weakmemory/cacm.pdf)，介绍 x86 的多处理器内存并发访问的一致性模型 TSO。\n\n接下来是开发者最关心的内存管理方面的 lib 库。通常来说，我们有三种内存分配管理模块。就目前而言，BSD 的 jemalloc 有很大的影响力。后面我们可以看到不同公司的实践性文章。\n\n- [ptmalloc](http://www.malloc.de/en/) 是 glibc 的内存分配管理。\n- [tcmalloc](https://github.com/gperftools/gperftools) 是 Google 的内存分配管理模块，全称是 Thread-Caching malloc，基本上来说比 glibc 的 ptmalloc 快两倍以上。\n- [jemalloc](http://jemalloc.net/) 是 BSD 提供的内存分配管理。其论文为 [A Scalable Concurrent malloc(3) Implementation for FreeBSD](https://people.freebsd.org/~jasone/jemalloc/bsdcan2006/jemalloc.pdf)，这是一个可以并行处理的内存分配管理器。\n\n关于 C 的这些内存分配器，你可以参看 Wikipedia 的 “[C Dynamic Memory Allocation](https://en.wikipedia.org/wiki/C_dynamic_memory_allocation#Thread-caching_malloc_(tcmalloc))”这个词条。\n\n下面是几篇不错的文章，让你感觉一下上面那三种内存分配器的一些比较和工程实践。\n\n- [ptmalloc，tcmalloc 和 jemalloc 内存分配策略研究](https://owent.net/2013/867.html)\n- [内存优化总结：ptmalloc、tcmalloc 和 jemalloc](http://www.cnhalo.net/2016/06/13/memory-optimize/)\n- [Scalable memory allocation using jemalloc](https://www.facebook.com/notes/facebook-engineering/scalable-memory-allocation-using-jemalloc/480222803919)\n- [Decreasing RAM Usage by 40% Using jemalloc with Python & Celery](https://zapier.com/engineering/celery-python-jemalloc/)\n\n# 计算机网络\n\n## 网络学习\n\n首先，推荐一本书——《[计算机网络（第五版）](https://book.douban.com/subject/10510747/)》，这本“计算机网络”和前面推荐的那本计算机网络不一样，前面那本偏扫盲，这本中有很多细节。这本书是国内外使用最广泛、最权威的计算机网络经典教材。全书按照网络协议模型自下而上（物理层、数据链路层、介质访问控制层、网络层、传输层和应用层）有系统地介绍了计算机网络的基本原理，并结合 Internet 给出了大量的协议实例。\n\n这本书还与时俱进地引入了最新的网络技术，包括无线网络、3G 蜂窝网络、RFID 与传感器网络、内容分发与 P2P 网络、流媒体传输与 IP 语音，以及延迟容忍网络等。另外，本书针对当前网络应用中日益突出的安全问题，用了一整章的篇幅对计算机网络的安全性进行了深入讨论，而且把相关内容与最新网络技术结合起来阐述。这本书读起来并不枯燥，因为其中有很多小故事和小段子。\n\n然后，有两个网上的教程和讲义也可以让人入门。\n\n- 渥汰华大学的一个课程讲义你也可以一看 [Computer Network Design](http://www.site.uottawa.ca/~shervin/courses/ceg4185/lectures/) 。\n- GeeksforGeeks 上也有一个简单的 [Computer Network Tutorials](https://www.geeksforgeeks.org/computer-network-tutorials/) 。\n\n## 网络调优\n\n接下来，你可能需要一些非常实用的可以操作的技术，下面的几篇文章相信可以帮助到你。\n\n- 《Linux 的高级路由和流量控制 HowTo》（[Linux Advanced Routing & Traffic Control HOWTO](http://lartc.org/) ），这是一个非常容易上手的关于 iproute2、流量整形和一点 netfilter 的指南。\n- 关于网络调优，你可以看一下这个文档 [Red Hat Enterprise Linux Network Performance Tuning Guide](https://access.redhat.com/sites/default/files/attachments/20150325_network_performance_tuning.pdf)。\n- 还有一些网络工具能够帮上你的大忙，这里有一个网络工具的 Awesome 列表 [Awesome Pcap Tools](https://github.com/caesar0301/awesome-pcaptools) ，其中罗列了各种网络工具，能够让你更从容地调试网络相关的程序。\n- [Making Linux TCP Fast](https://netdevconf.org/1.2/papers/bbr-netdev-1.2.new.new.pdf) ，一篇非常不错的 TCP 调优的论文。\n- 下面是在 PackageCloud 上的两篇关于 Linux 网络栈相关的底层文章，非常值得一读。\n  - [Monitoring and Tuning the Linux Networking Stack: Receiving Data](https://blog.packagecloud.io/eng/2016/06/22/monitoring-tuning-linux-networking-stack-receiving-data/)\n  - [Monitoring and Tuning the Linux Networking Stack: Sending Data](https://blog.packagecloud.io/eng/2017/02/06/monitoring-tuning-linux-networking-stack-sending-data/)\n\n## 网络协议\n\n接下来，想要学习网络协议最好的方式就是学习通讯相关的 RFC。所以，在这里我会推荐一系列值得读的 RFC 给你。读 RFC 有几个好处，一方面可以学习技术，另一方面，你可以通过 RFC 学习到一个好的技术文档是怎么写的，还能看到各种解决问题的方案和思路。\n\n对于第 2 层链路层，你可能需要了解一下 ARP：\n\n- [RFC 826 - An Ethernet Address Resolution Protocol](https://tools.ietf.org/html/rfc826)\n\n以及 Tunnel 相关的协议：\n\n- [RFC 1853 - IP in IP Tunneling](https://tools.ietf.org/html/rfc1853)\n- [RFC 2784 - Generic Routing Encapsulation (GRE)](https://tools.ietf.org/html/rfc2784)\n- [RFC 2661 - Layer Two Tunneling Protocol “L2TP”](https://tools.ietf.org/html/rfc2661)\n- [RFC 2637 - Point-to-Point Tunneling Protocol (PPTP)](https://tools.ietf.org/html/rfc2637)\n\n对于第 4 层，你最需要了解的是 TCP/IP 了。和 TCP 相关的 RFC 相当多，这里给一系列经典的 RFC。这些 RFC 我都引用在了我在 CoolShell 上的《[TCP 的那些事儿（上）](https://coolshell.cn/articles/11564.html)》和《[TCP 的那些事儿（下）](https://coolshell.cn/articles/11609.html)》两篇文章中。如果你看不懂 RFC，你也可以去看我上述的文章。\n\n- [RFC 793 - Transmission Control Protocol](https://tools.ietf.org/html/rfc793) - 最初的 TCP 标准定义，但不包括 TCP 相关细节。\n- [RFC 813 - Window and Acknowledgement Strategy in TCP](https://tools.ietf.org/html/rfc813) - TCP 窗口与确认策略，并讨论了在使用该机制时可能遇到的问题及解决方法。\n- [RFC 879 - The TCP Maximum Segment Size and Related Topics](https://tools.ietf.org/html/rfc879) - 讨论 MSS 参数对控制 TCP 分组大小的重要性，以及该参数与 IP 分段大小的关系等。\n- [RFC 896 - Congestion Control in IP/TCP Internetworks](https://tools.ietf.org/html/rfc896) - 讨论拥塞问题和 TCP 如何控制拥塞。\n- [RFC 2581 - TCP Congestion Control](https://tools.ietf.org/html/rfc2581) - 描述用于拥塞控制的四种机制：慢启动、拥塞防御、快重传和快恢复。后面这个 RFC 被 [RFC 5681](https://tools.ietf.org/html/rfc5681) 所更新。还有 [RFC 6582 - The NewReno Modification to TCP’s Fast Recovery Algorithm](https://tools.ietf.org/html/rfc6582) 中一个改进的快速恢复算法。\n- [RFC 2018 - TCP Selective Acknowledgment Options](https://tools.ietf.org/html/rfc2018) - TCP 的选择确认。\n- [RFC 2883 - An Extension to the Selective Acknowledgement (SACK) Option for TCP](https://tools.ietf.org/html/rfc2883) - 对于 RFC 2018 的改进。\n- [RFC 2988 - Computing TCP’s Retransmission Timer](https://tools.ietf.org/html/rfc2988) - 讨论与 TCP 重传计时器设置相关的话题，重传计时器控制报文在重传前应等待多长时间。也就是经典的 TCP Karn/Partridge 重传算法。\n- [RFC 6298 - Computing TCP’s Retransmission Timer](https://tools.ietf.org/html/rfc6298) - TCP Jacobson/Karels Algorithm 重传算法。\n\n我个人觉得 TCP 最牛的不是不丢包，而是拥塞控制。对此，如果你感兴趣，可以读一下经典论文《[Congestion Avoidance and Control](http://ee.lbl.gov/papers/congavoid.pdf)》。\n\n关于 Linux 下的 TCP 参数，你需要仔仔细细地读一下[TCP 的 man page](http://man7.org/linux/man-pages/man7/tcp.7.html) 。\n\n对于第 7 层协议，HTTP 协议是重点要学习的。\n\n首先推荐的是《[HTTP 权威指南](https://book.douban.com/subject/10746113/) 》，这本书有点厚，可以当参考书来看。这本书中没有提到 HTTP/2 的事，但是可以让你了解到 HTTP 协议的绝大多数特性。\n\nHTTP 1.1 的原始 RFC 是 1999 年 6 月的 [RFC 2616](https://tools.ietf.org/html/rfc2616)，但其在 2014 后很快被下面这些 RFC 给取代了。\n\n- [RFC 7230 - Hypertext Transfer Protocol (HTTP/1.1): Message Syntax and Routing](https://tools.ietf.org/html/rfc7230)\n- [RFC 7231 - Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content](https://tools.ietf.org/html/rfc7231)\n- [RFC 7232 - Hypertext Transfer Protocol (HTTP/1.1): Conditional Requests](https://tools.ietf.org/html/rfc7232)\n- [RFC 7233 - Hypertext Transfer Protocol (HTTP/1.1): Range Requests](https://tools.ietf.org/html/rfc7233)\n- [RFC 7234 - Hypertext Transfer Protocol (HTTP/1.1): Caching](https://tools.ietf.org/html/rfc7234)\n- [RFC 7235 - Hypertext Transfer Protocol (HTTP/1.1): Authentication](https://tools.ietf.org/html/rfc7235)\n\n关于[HTTP/2](https://en.wikipedia.org/wiki/HTTP/2)，这是 HTTP 的一个比较新的协议，它于 2015 年被批准通过，现在基本上所有的主流浏览器都默认启用这个协议。所以，你有必要学习一下这个协议。下面是相关的学习资源。\n\n- [Gitbook - HTTP/2 详解](https://legacy.gitbook.com/book/ye11ow/http2-explained/details)\n- [http2 explained](http://daniel.haxx.se/http2/)（[中译版](https://www.gitbook.com/book/ye11ow/http2-explained/details)）\n- [HTTP/2 for a Faster Web](https://cascadingmedia.com/insites/2015/03/http-2.html)\n- [Nginx HTTP/2 白皮书](https://www.nginx.com/wp-content/uploads/2015/09/NGINX_HTTP2_White_Paper_v4.pdf)\n- HTTP/2 的两个 RFC：\n  - [RFC 7540 - Hypertext Transfer Protocol Version 2 (HTTP/2)](https://httpwg.org/specs/rfc7540.html) ，HTTP/2 的协议本身\n  - [RFC 7541 - HPACK: Header Compression for HTTP/2](https://httpwg.org/specs/rfc7541.html) ，HTTP/2 的压缩算法\n\n最后，你可以上 Wikipedia 的 [Internet Protocol Suite](https://en.wikipedia.org/wiki/Internet_protocol_suite) 上看看，这是一个很不错的网络协议的词条汇集地。顺着这些协议，你可以找到很多有用的东西。\n\n# 小结\n\n好了，总结一下今天的内容。这是程序员练级攻略 2018 版第五篇章——高手成长篇的第一篇文章。前面的内容先介绍了一些这一系列内容的总体构成，及每一部分的学习重点。后面是这一篇章第一个主题系统底层知识中的部分内容，即 Linux 系统、内存和计算机网络，并给出了相应的学习资料。\n\n我认为，学习到一定程度，就是要从书本中走出去，到社区里和大家一起学习，而且还需要自己找食吃了。所以，这篇文章中，我罗列了各种文章和资源，并给出了简短的推荐语言，就是在为你梳理信息源，而不是喂你吃饭。我更希望看到你自趋势地成长。\n\n下篇文章中，我们分享的内容为系统底层知识中的异步 I/O 模型、Lock-Free 编程以及其他一些相关的知识点和学习资源。敬请期待。\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/9759\" > </iframe>","categories":["左耳听风"]},{"title":"078丨程序员练级攻略：异步I-O模型和Lock-Free编程","url":"/posts/2957725591.html","content":"\n\n\n# 异步 I/O 模型\n\n异步 I/O 模型是我个人觉得所有程序员都必需要学习的一门技术或是编程方法，这其中的设计模式或是解决方法可以借鉴到分布式架构上来。再说一遍，学习这些模型，是非常非常重要的，你千万要认真学习。\n\n史蒂文斯（Stevens）在《[UNIX 网络编程](https://book.douban.com/subject/4859464/)》一书 6.2 I/O Models 中介绍了五种 I/O 模型。\n\n- 阻塞 I/O\n- 非阻塞 I/O\n- I/O 的多路复用（select 和 poll）\n- 信号驱动的 I/O（SIGIO）\n- 异步 I/O（POSIX 的 aio_functions）\n\n然后，在前面我们也阅读过了 - [C10K Problem](https://en.wikipedia.org/wiki/C10k_problem) 。相信你对 I/O 模型也有了一定的了解。 这里，我们需要更为深入地学习 I/O 模型，尤其是其中的异步 I/O 模型。\n\n首先，我们看一篇和 Java 相关的 I/O 模型的文章来复习一下之前的内容。[Thousands of Threads and Blocking I/O: The Old Way to Write Java Servers Is New Again (and Way Better)](https://www.slideshare.net/e456/tyma-paulmultithreaded1) ，这个 PPT 中不仅回顾和比较了各种 I/O 模型，而且还有各种比较细节的方案和说明，是一篇非常不错的文章。\n\n然后，你可以看一篇 Java 相关的 PPT - 道格·莱亚（Doug Lea）的 [Scalable IO in Java](http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf)，这样你会对一些概念有个了解。\n\n接下来，我们需要了解一下各种异步 I/O 的实现和设计方式。\n\n- [IBM - Boost application performance using asynchronous I/O](https://www.ibm.com/developerworks/library/l-async/) ，这是一篇关于 AIO 的文章。\n- [Lazy Asynchronous I/O For Event-Driven Servers](https://www.usenix.org/legacy/event/usenix04/tech/general/full_papers/elmeleegy/elmeleegy_html/html.html) ，这篇文章也很不错。\n- 另外，异步 I/O 模型中的 [Windows I/O Completion Ports](https://docs.microsoft.com/en-us/windows/desktop/FileIO/i-o-completion-ports) , 你也需要了解一下。如果 MSDN 上的这个手册不容易读，你可以看看这篇文章 [Inside I/O Completion Ports](http://sysinternals.d4rk4.ru/Information/IoCompletionPorts.html)。另外，关于 Windows，[Windows Internals](https://book.douban.com/subject/6935552/) 这本书你可以仔细读一下，非常不错的。其中有一节 I/O Processing 也是很不错的，这里我给一个网上免费的链接[I/O Processing](https://flylib.com/books/en/4.491.1.85/1/) 你可以看看 Windows 是怎么玩的。\n- 接下来是 Libevent。你可以看一下其主要维护人员尼克·马修森（Nick Mathewson）写的 [Libevent 2.0 book](http://www.wangafu.net/~nickm/libevent-book/)。还有一本国人写的电子书 《[Libevent 深入浅出](https://aceld.gitbooks.io/libevent/content/)》。\n- 再接下来是 Libuv。你可以看一下其官网的 [Libuv Design Overview](http://docs.libuv.org/en/v1.x/design.html) 了解一下。\n\n我简单总结一下，基本上来说，异步 I/O 模型的发展技术是： select -> poll -> epoll -> aio -> libevent -> libuv。Unix/Linux 用了好几十年走过这些技术的变迁，然而，都不如 Windows I/O Completion Port 设计得好（免责声明：这个观点纯属个人观点。相信你仔细研究这些 I/O 模型后，你会有自己的判断）。\n\n看过这些各种异步 I/O 模式的实现以后，相信你会看到一个编程模式——Reactor 模式。下面是这个模式的相关文章（读这三篇就够了）。\n\n- [Understanding Reactor Pattern: Thread-Based and Event-Driven](https://dzone.com/articles/understanding-reactor-pattern-thread-based-and-eve)\n- [Reactor Pattern](https://www.dre.vanderbilt.edu/~schmidt/PDF/Reactor2-93.pdf)\n- [The reactor pattern and non-blocking IO](https://www.celum.com/en/blog/technology/the-reactor-pattern-and-non-blocking-io)\n\n然后是几篇有意思的延伸阅读文章。\n\n- [The Secret To 10 Million Concurrent Connections -The Kernel Is The Problem, Not The Solution](http://highscalability.com/blog/2013/5/13/the-secret-to-10-million-concurrent-connections-the-kernel-i.html) - C10M 问题来了……\n- 还有几篇可能有争议的文章，让你从不同的角度思考。\n  - [Select is fundamentally broken](https://idea.popcount.org/2017-01-06-select-is-fundamentally-broken/)\n  - [Epoll is fundamentally broken 1/2](https://idea.popcount.org/2017-02-20-epoll-is-fundamentally-broken-12/)\n  - [Epoll is fundamentally broken 2/2](https://idea.popcount.org/2017-03-20-epoll-is-fundamentally-broken-22/)\n\n# Lock-Free 编程相关\n\nLock-Free - 无锁技术越来越被开发人员重视，因为锁对于性能的影响实在是太大了，所以如果想开发出一个高性能的程序，你就非常有必要学习 Lock-Free 的编程方式。\n\n关于无锁的数据结构，有几篇教程你可以看一下。\n\n- [Dr.Dobb’s: Lock-Free Data Structures](http://www.drdobbs.com/lock-free-data-structures/184401865)\n- [Andrei Alexandrescu: Lock-Free Data Structures](https://erdani.com/publications/cuj-2004-10.pdf)\n\n然后强烈推荐一本免费的电子书：[Is Parallel Programming Hard, And, If So, What Can You Do About It?](https://www.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html) ，这是大牛 [保罗·麦肯尼（Paul E. McKenney）](https://www.linkedin.com/in/paulmckenney/) 写的书。这本书堪称并行编程的经典书，必看。\n\n此时，Wikipedia 上有三个词条你要看一下，以此了解并发编程中的一些概念：[Non-blocking algorithm](https://en.wikipedia.org/wiki/Non-blocking_algorithm) 、[Read-copy-update](https://en.wikipedia.org/wiki/Read-copy-update) 和 [Seqlock](https://en.wikipedia.org/wiki/Seqlock)。\n\n接下来，读一下以下两篇论文 。\n\n- [Implementing Lock-Free Queues](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.8674&rep=rep1&type=pdf)， 这也是一篇很不错的论文，我把它介绍在了我的网站上 ，文章为“[无锁队列的实现](https://coolshell.cn/articles/8239.html)”。\n- [Simple, Fast, and Practical Non-Blocking and Blocking Concurrent Queue Algorithms](http://www.cs.rochester.edu/~scott/papers/1996_PODC_queues.pdf) ，这篇论文给出了一个无阻塞和阻塞的并发队列算法。\n\n最后，有几个博客你要订阅一下。\n\n- [1024cores](http://www.1024cores.net/) - 德米特里·伐由科夫（Dmitry Vyukov）的和 lock-free 编程相关的网站。\n- [Paul E. McKenney](http://paulmck.livejournal.com/) - 保罗（Paul）的个人网站。\n- [Concurrency Freaks](http://concurrencyfreaks.blogspot.com/) - 关于并发算法和相关模式的网站。\n- [Preshing on Programming](http://preshing.com/) - 加拿大程序员杰夫·普莱辛（Jeff Preshing）的技术博客，主要关注 C++ 和 Python 两门编程语言。他用 C++11 实现了类的反射机制，用 C++ 编写了 3D 小游戏 Hop Out，还为该游戏编写了一个游戏引擎。他还讨论了很多 C++ 的用法，比如 C++14 推荐的代码写法、新增的某些语言构造等，和 Python 很相似。阅读这个技术博客上的内容能够深深感受到博主对编程世界的崇敬和痴迷。\n- [Sutter’s Mill](http://herbsutter.com/) - 赫布·萨特（Herb Sutter）是一位杰出的 C++ 专家，曾担任 ISO C++ 标准委员会秘书和召集人超过 10 年。他的博客有关于 C++ 语言标准最新进展的信息，其中也有他的演讲视频。博客中还讨论了其他技术和 C++ 的差异，如 C# 和 JavaScript，它们的性能特点、怎样避免引入性能方面的缺陷等。\n- [Mechanical Sympathy](http://mechanical-sympathy.blogspot.com/) - 博主是马丁·汤普森（Martin Thompson），他是一名英国的技术极客，探索现代硬件的功能，并提供开发、培训、性能调优和咨询服务。他的博客主题是 Hardware and software working together in harmony，里面探讨了如何设计和编写软件使得它在硬件上能高性能地运行。非常值得一看。\n\n接下来，是一些编程相关的一些 C/C++ 的类库，这样你就不用从头再造轮子了（对于 Java 的，请参看 JDK 里的 Concurrent 开头的一系列的类）。\n\n- [Boost.Lockfree](http://www.boost.org/doc/libs/1_60_0/doc/html/lockfree.html) - Boost 库中的无锁数据结构。\n- [ConcurrencyKit](https://github.com/concurrencykit/ck) - 并发性编程的原语。\n- [Folly](https://github.com/facebook/folly) - Facebook 的开源库（它对 MPMC 队列做了一个很好的实现）。\n- [Junction](https://github.com/preshing/junction) - C++ 中的并发数据结构。\n- [MPMCQueue](https://github.com/rigtorp/MPMCQueue) - 一个用 C++11 编写的有边界的“多生产者 - 多消费者”无锁队列。\n- [SPSCQueue](https://github.com/rigtorp/SPSCQueue) - 一个有边界的“单生产者 - 单消费者”的无等待、无锁的队列。\n- [Seqlock](https://github.com/rigtorp/Seqlock) - 用 C++ 实现的 Seqlock。\n- [Userspace RCU](http://liburcu.org/) - liburcu 是一个用户空间的 RCU（Read-copy-update，读 - 拷贝 - 更新）库。\n- [libcds](https://github.com/khizmax/libcds) - 一个并发数据结构的 C++ 库。\n- [liblfds](https://liblfds.org/) - 一个用 C 语言编写的可移植、无许可证、无锁的数据结构库。\n\n# 其它\n\n- 关于 64 位系统编程，只要去一个地方就行了： [All about 64-bit programming in one place](https://software.intel.com/en-us/blogs/2011/07/07/all-about-64-bit-programming-in-one-place/)，这是一个关于 64 位编程相关的收集页面，其中包括相关的文章、28 节课程，还有知识库和相关的 blog。\n\n- [What Scalable Programs Need from Transactional Memory](https://dl.acm.org/citation.cfm?id=3037750) ，事务性内存（TM）一直是许多研究的重点，它在诸如 IBM Blue Gene/Q 和 Intel Haswell 等处理器中得到了支持。许多研究都使用 STAMP 基准测试套件来评估其设计。然而，我们所知的所有 TM 系统上的 STAMP 基准测试所获得的加速比较有限。\n\n  例如，在 IBM Blue Gene/Q 上有 64 个线程，我们观察到使用 Blue Gene/Q 硬件事务内存（HTM）的中值加速比为 1.4 倍，使用软件事务内存（STM）的中值加速比为 4.1 倍。什么限制了这些 TM 基准的性能？在本论文中，作者认为问题在于用于编写它们的编程模型和数据结构上，只要使用合适的模型和数据结构，程序的性能可以有 10 多倍的提升。\n\n- [Improving OpenSSL Performance](https://software.intel.com/en-us/articles/improving-openssl-performance) ，这篇文章除了教你如何提高 OpenSSL 的执行性能，还讲了一些底层的性能调优知识。\n\n- 关于压缩的内容。为了避免枯燥，主要推荐下面这两篇实践性很强的文章。\n\n  - [How eBay’s Shopping Cart used compression techniques to solve network I/O bottlenecks](https://www.ebayinc.com/stories/blogs/tech/how-ebays-shopping-cart-used-compression-techniques-to-solve-network-io-bottlenecks/) ，这是一篇很好的文章，讲述了 eBay 是如何通过压缩数据来提高整体服务性能的，其中有几个比较好的压缩算法。除了可以让你学到相关的技术知识，还可以让你看到一种比较严谨的工程师文化。\n  - [Linkedin: Boosting Site Speed Using Brotli Compression](https://engineering.linkedin.com/blog/2017/05/boosting-site-speed-using-brotli-compression) ，LinkedIn 在 2017 年早些时候开始使用 [Brotli](https://en.wikipedia.org/wiki/Brotli) 来替换 gzip，以此带来更快的访问，这篇文章讲述了什么是 Brotli 以及与其它压缩程序的比较和所带来的性能提升。\n\n- 这里有两篇关于 SSD 硬盘性能测试的文章。[Performance Testing with SSDs, Part 1](https://devs.mailchimp.com/blog/performance-testing-with-ssds-part-1/) 和 [Performance Testing with SSDs Part 2](https://devs.mailchimp.com/blog/performance-testing-with-ssds-pt-2/) ，这两篇文章介绍了测试 SSD 硬盘性能以及相关的操作系统调优方法。\n\n- [Secure Programming HOWTO - Creating Secure Software](https://www.dwheeler.com/secure-programs/) ，这是一本电子书，其中有繁体中文的翻译，这本电子书讲了 Linux/Unix 下的一些安全编程方面的知识。\n\n# 相关论文\n\n- [Hints for Computer System Design](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/acrobat-17.pdf) ，计算机设计的忠告，这是 ACM 图灵奖得主 [Butler Lampson](https://en.wikipedia.org/wiki/Butler_Lampson) 在 Xerox PARC 工作时的一篇论文。这篇论文简明扼要地总结了他在做系统设计时的一些想法，非常值得一读。（用他的话来说，“Studying the design and implementation of a number of computer has led to some general hints for system design. They are described here and illustrated by many examples, ranging from hardware such as the Alto and the Dorado to application programs such as Bravo and Star“。）\n\n- [The 5 minute rule for trading memory for disc accesses and the 5 byte rule for trading memory for CPU time](http://www.hpl.hp.com/techreports/tandem/TR-86.1.pdf) ，根据文章名称也可以看出，5 分钟法则是用来衡量内存与磁盘的，而 5 字节法则则是在内存和 CPU 之间的权衡。这两个法则是 Jim Gray 和 Franco Putzolu 在 1986 年的文章。\n\n  在该论文发表 10 年后的 1997 年，Jim Gray 和 Goetz Graefe 又在 [The Five-Minute Rule Ten Years Later and Other Computer Storage Rules of Thumb](http://research.microsoft.com/en-us/um/people/gray/5_min_rule_SIGMOD.pdf) 中对该法则进行了重新审视。2007 年，也就是该论文发表 20 年后，这年的 1 月 28 日，Jim Gray 驾驶一艘 40 英尺长的船从旧金山港出海，目的是航行到附近的费拉隆岛，在那里撒下母亲的骨灰。出海之后，他就同朋友和亲属失去了联系。为了纪念和向大师致敬，时隔 10 多年后的 2009 年 Goetz Graefe 又发表了 [The Five-Minute Rule 20 Years Later (and How Falsh Memory Changes the Rules)](http://cacm.acm.org/magazines/2009/7/32091-the-five-minute-rule-20-years-later/fulltext)。\n\n  注明一下，Jim Gray 是关系型数据库领域的大师。因在数据库和事务处理研究和实现方面的开创性贡献而获得 1998 年图灵奖。美国科学院、工程院两院院士，ACM 和 IEEE 两会会士。他 25 岁成为加州大学伯克利分校计算机科学学院第一位博士。在 IBM 工作期间参与和主持了 IMS、System R、SQL／DS、DB2 等项目的开发。后任职于微软研究院，主要关注应用数据库技术来处理各学科的海量信息。\n\n# 小结\n\n好了，总结一下今天的内容。异步 I/O 模型是我个人觉得所有程序员都必需要学习的一门技术或是编程方法，这其中的设计模式或是解决方法可以借鉴到分布式架构上来。而且我认为，学习这些模型非常重要，你千万要认真学习。\n\n接下来是 Lock-Free 方面的内容，由于锁对于性能的影响实在是太大了，所以它越来越被开发人员所重视。如果想开发出一个高性能的程序，你非常有必要学习 Lock-Free 的编程方式。随后，我给出系统底层方面的其它一些重要知识，如 64 位编程、提高 OpenSSL 的执行性能、压缩、SSD 硬盘性能测试等。最后介绍了几篇我认为对学习和巩固这些知识非常有帮助的论文，都很经典，推荐你务必看看。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/9851\" > </iframe>","categories":["左耳听风"]},{"title":"079丨程序员练级攻略：Java底层知识","url":"/posts/2094591746.html","content":"\n\n\n前两篇文章分享的是系统底层方面的内容，今天我们进入高手成长篇的第二部分——Java 底层知识。\n\n# Java 字节码相关\n\n首先，Java 最黑科技的玩法就是字节码编程，也就是动态修改或是动态生成 Java 字节码。Java 的字节码相当于汇编，其中的一些细节你可以从下面的这几个教程中学习。\n\n- [Java Zone: Introduction to Java Bytecode](https://dzone.com/articles/introduction-to-java-bytecode) ，这篇文章图文并茂地向你讲述了 Java 字节码的一些细节，是一篇很不错的入门文章。\n- [IBM DeveloperWorks: Java bytecode](https://www.ibm.com/developerworks/library/it-haggar_bytecode/index.html) ，虽然这篇文章很老了，但是这篇文章是一篇非常好的讲 Java 字节码的文章。\n- [Java Bytecode and JVMTI Examples](https://github.com/jon-bell/bytecode-examples)，这是一些使用 [JVM Tool Interface](http://docs.oracle.com/javase/7/docs/platform/jvmti/jvmti.html) 操作字节码的比较实用的例子。包括方法调用统计、静态字节码修改、Heap Taggin 和 Heap Walking。\n\n当然，一般来说，我们不使用 JVMTI 操作字节码，而是用一些更好用的库。这里有三个库可以帮你比较容易地做这个事。\n\n- [asmtools](https://wiki.openjdk.java.net/display/CodeTools/asmtools) - 用于生产环境的 Java .class 文件开发工具。\n- [Byte Buddy](http://bytebuddy.net/) - 代码生成库：运行时创建 Class 文件而不需要编译器帮助。\n- [Jitescript](https://github.com/qmx/jitescript) - 和 [BiteScript](https://github.com/headius/bitescript) 类似的字节码生成库。\n\n就我而言，我更喜欢 Byte Buddy，它在 2015 年还获了 Oracle 的 “[Duke’s Choice](https://www.oracle.com/corporate/pressrelease/dukes-award-102815.html)”大奖，其中说 Byte Buddy 极大地发展了 Java 的技术。\n\n使用字节码编程可以玩出很多高级玩法，最高级的还是在 Java 程序运行时进行字节码修改和代码注入。听起来是不是一些很黑客，也很黑科技的事？是的，这个方式使用 Java 这门静态语言在运行时可以进行各种动态的代码修改，而且可以进行无侵入的编程。\n\n比如， 我们不需要在代码中埋点做统计或监控，可以使用这种技术把我们的监控代码直接以字节码的方式注入到别人的代码中，从而实现对实际程序运行情况进行统计和监控。如果你看过我的《编程范式游记》，你就知道这种技术的威力了，其可以很魔法地把业务逻辑和代码控制分离开来。\n\n要做到这个事，你还需要学习一个叫 Java Agent 的技术。Java Agent 使用的是 “[Java Instrumentation API](https://stackoverflow.com/questions/11898566/tutorials-about-javaagents)”，其主要方法是实现一个叫 `premain()` 的方法（嗯，一个比 `main()` 函数还要超前执行的 main 函数），然后把你的代码编译成一个 jar 文件。\n\n在 JVM 启动时，使用这样的命令行来引入你的 jar 文件：`java -javaagent:yourAwesomeAgent.jar -jar App.jar`。更为详细的文章你可以参看：“[Java Code Geeks: Java Agents](https://www.javacodegeeks.com/2015/09/java-agents.html)”，你还可以看一下这个示例项目：[jvm-monitoring-agent](https://github.com/toptal/jvm-monitoring-agent) 或是 [EntryPointKR/Agent.java](https://gist.github.com/EntryPointKR/152f089f6f3884047abcd19d39297c9e)。如果想用 ByteBuddy 来玩，你可以看看这篇文章 “[通过使用 Byte Buddy，便捷地创建 Java Agent](http://www.infoq.com/cn/articles/Easily-Create-Java-Agents-with-ByteBuddy)”。如果你想学习如何用 Java Agent 做监控，你可以看一下这个项目 [Stage Monitor](http://www.stagemonitor.org/)。\n\n# JVM 相关\n\n接下来讲讲 Java 底层知识中另一个非常重要的内容——JVM。\n\n说起 JVM，你有必要读一下 JVM 的规格说明书，我在这里放一个 Java 8 的， [The Java Virtual Machine Specification Java SE 8 Edition](https://docs.oracle.com/javase/specs/jvms/se8/jvms8.pdf) 。对于规格说明书的阅读，我认为是系统了解 JVM 规范的最佳文档，这个文档可以让你对于搞不清楚或是诡异的问题恍然大悟。关于中文翻译，有人在 GitHub 上开了个 Repo - “[java-virtual-machine-specification](https://github.com/waylau/java-virtual-machine-specification)”。\n\n另外，也推荐一下 [JVM Anatomy Park](https://shipilev.net/jvm-anatomy-park/) JVM 解剖公园，这是一个系列的文章，每篇文章都不长，但是都很精彩，带你一点一点地把 JVM 中的一些技术解开。\n\n学习 Java 底层原理还有 Java 的内存模型，官方文章是 [JSR 133](http://www.jcp.org/en/jsr/detail?id=133)。还有马里兰大学的威廉·皮尤（William Pugh）教授收集的和 Java 内存模型相关的文献 - [The Java Memory Model](http://www.cs.umd.edu/~pugh/java/memoryModel/) ，你可以前往浏览。\n\n对于内存方面，道格·利（Doug Lea）有两篇文章也是很有价值的。\n\n- [The JSR-133 Cookbook for Compiler Writers](http://gee.cs.oswego.edu/dl/jmm/cookbook.html)，解释了怎样实现 Java 内存模型，特别是在考虑到多处理器（或多核）系统的情况下，多线程和读写屏障的实现。\n- [Using JDK 9 Memory Order Modes](http://gee.cs.oswego.edu/dl/html/j9mm.html)，讲了怎样通过 VarHandle 来使用 plain、opaque、release/acquire 和 volatile 四种共享内存的访问模式，并剖析了底层的原理。\n\n垃圾回收机制也是需要好好学习的，在这里推荐一本书 《[The Garbage Collection Handbook](https://book.douban.com/subject/6809987/)》，在豆瓣上的得分居然是 9.9（当然，评价人数不多）。这本书非常全面地介绍了垃圾收集的原理、设计和算法。但是这本书也是相当难啃的。中文翻译《[垃圾回收算法手册](https://book.douban.com/subject/26740958/)》翻译得很一般，有人说翻译得很烂。所以，如果可能，还是读英文版的。如果你对从事垃圾回收相关的工作有兴趣，那么你需要好好看一下这本书。\n\n当然，更多的人可能只需要知道怎么调优垃圾回收， 那么推荐读读 [Garbage Collection Tuning Guide](http://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/) ，它是 Hotspot Java 虚拟机的垃圾回收调优指南，对你很有帮助。\n\n[Quick Tips for Fast Code on the JVM](https://gist.github.com/djspiewak/464c11307cabc80171c90397d4ec34ef) 也是一篇很不错的文章，里面有写出更快的 Java 代码的几个小提示，值得一读。\n\n# 小结\n\n好了，总结一下今天学到的内容。Java 最黑科技的玩法就是字节码编程，也就是动态修改或是动态生成 Java 字节码。Java 的字节码相当于汇编，学习其中的细节很有意思，为此我精心挑选了 3 篇文章，供你学习。我们一般不使用 JVMTI 操作字节码，而是用一些更好用的库，如 asmtools、Byte Buddy 和 BiteScript 等。使用字节码编程可以玩出很多高级玩法，其中最高级的玩法是在 Java 程序运行时进行字节码修改和代码注入。同时，我介绍了 Java Agent 技术，帮助你更好地实现这种高级玩法。\n\nJVM 也是学习 Java 过程中非常重要的一部分内容。我推荐阅读一下 JVM 的规格说明书，我认为，它是系统了解 JVM 规范的最佳文档，可以让你对于搞不清楚或是诡异的问题恍然大悟。同时推荐了 [JVM Anatomy Park](https://shipilev.net/jvm-anatomy-park/) 系列文章，也非常值得一读。\n\n随后介绍的是 Java 的内存模型和垃圾回收机制，尤其给出了如何调优垃圾回收方面的资料。这些内容都很底层，但也都很重要。对于想成为高手的你来说，还是有必要花时间来啃一啃的。\n\n下篇文章是数据库方面的内容，我们将探讨各种类型的数据库，非常有意思。敬请期待。\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/10216\" > </iframe>","categories":["左耳听风"]},{"title":"080丨程序员练级攻略：数据库","url":"/posts/3292932205.html","content":"\n\n\n对于数据库方向，重点就是两种数据库，一种是以 SQL 为代表的关系型数据库，另一种是以非 SQL 为代表的 NoSQL 数据库。关系型数据库主要有三个：Oracle、MySQL 和 Postgres。\n\n在这里，我们只讨论越来越主流的 MySQL 数据库。首先，我们要了解数据库的一些实现原理和内存的一些细节，然后我们要知道数据的高可用和数据复制这些比较重要的话题，了解一下关系型数据库的一些实践和难点。然后，我们会进入到 NoSQL 数据库的学习。\n\nNoSQL 数据库千奇百怪，其主要是解决了关系型数据库中的各种问题。第一个大问题就是数据的 Schema 非常多，用关系型数据库来表示不同的 Data Schema 是非常笨拙的，所以要有不同的数据库（如时序型、键值对型、搜索型、文档型、图结构型等）。另一个大问题是，关系型数据库的 ACID 是一件很讨厌的事，这极大地影响了数据库的性能和扩展性，所以 NoSQL 在这上面做了相应的妥协以解决大规模伸缩的问题。\n\n对于一个程序员，你可能觉得数据库的事都是 DBA 的事，然而我想告诉你你错了，这些事才真正是程序员的事。因为程序是需要和数据打交道的，所以程序员或架构师不仅需要设计数据模型，还要保证整体系统的稳定性和可用性，数据是整个系统中关键中的关键。所以，作为一个架构师或程序员，你必须了解最重要的数据存储——数据库。\n\n# 关系型数据库\n\n今天，关系型数据库最主要的两个代表是闭源的 Oracle 和开源的 MySQL。当然，还有很多了，比如微软的 SQL Server，IBM 的 DB2 等，还有开源的 PostgreSQL。关系型数据库的世界中有好多好多产品。当然，还是 Oracle 和 MySQL 是比较主流的。所以，这里主要介绍更为开放和主流的 MySQL。\n\n如果你要玩 Oracle，我这里只推荐一本书《[Oracle Database 9i/10g/11g 编程艺术](https://book.douban.com/subject/5402711/)》，无论是开发人员还是 DBA，它都是必读的书。这本书的作者是 Oracle 公司的技术副总裁托马斯·凯特（Thomas Kyte），他也是世界顶级的 Oracle 专家。\n\n这本书中深入分析了 Oracle 数据库体系结构，包括文件、内存结构以及构成 Oracle 数据库和实例的底层进程，利用具体示例讨论了一些重要的数据库主题，如锁定、并发控制、事务等。同时分析了数据库中的物理结构，如表、索引和数据类型，并介绍采用哪些技术能最优地使用这些物理结构。\n\n- 学习 MySQL，首先一定是要看[MySQL 官方手册](https://dev.mysql.com/doc/)。\n\n- 然后，官方还有几个 PPT 也要学习一下。\n\n  - [How to Analyze and Tune MySQL Queries for Better Performance](https://www.mysql.com/cn/why-mysql/presentations/tune-mysql-queries-performance/)\n  - [MySQL Performance Tuning 101](https://www.mysql.com/cn/why-mysql/presentations/mysql-performance-tuning101/)\n  - [MySQL Performance Schema & Sys Schema](https://www.mysql.com/cn/why-mysql/presentations/mysql-performance-sys-schema/)\n  - [MySQL Performance: Demystified Tuning & Best Practices](https://www.mysql.com/cn/why-mysql/presentations/mysql-performance-tuning-best-practices/)\n  - [MySQL Security Best Practices](https://www.mysql.com/cn/why-mysql/presentations/mysql-security-best-practices/)\n  - [MySQL Cluster Deployment Best Practices](https://www.mysql.com/cn/why-mysql/presentations/mysql-cluster-deployment-best-practices/)\n  - [MySQL High Availability with InnoDB Cluster](https://www.mysql.com/cn/why-mysql/presentations/mysql-high-availability-innodb-cluster/)\n\n- 然后推荐《[高性能 MySQL](https://book.douban.com/subject/23008813/)》，这本书是 MySQL 领域的经典之作，拥有广泛的影响力。不但适合数据库管理员（DBA）阅读，也适合开发人员参考学习。不管是数据库新手还是专家，都能从本书中有所收获。\n\n- 如果你对 MySQL 的内部原理有兴趣的话，可以看一下这本书《[MySQL 技术内幕：InnoDB 存储引擎](https://book.douban.com/subject/24708143/)》。当然，还有官网的[MySQL Internals Manual](https://dev.mysql.com/doc/internals/en/) 。\n\n- 数据库的索引设计和优化也是非常关键的，这里还有一本书《[数据库的索引设计与优化](https://book.douban.com/subject/26419771/)》也是很不错的。虽然不是讲 MySQL 的，但是原理都是相通的。这也是上面推荐过的《高性能 MySQL》在其索引部分推荐的一本好书。\n\n  你千万不要觉得只有做数据库你才需要学习这种索引技术。不是的！在系统架构上，在分布式架构中，索引技术也是非常重要的。这本书对于索引性能进行了非常清楚的估算，不像其它书中只是模糊的描述，你一定会收获很多。\n\n下面还有一些不错的和 MySQL 相关的文章。\n\n- [MySQL 索引背后的数据结构及算法原理](http://blog.codinglabs.org/articles/theory-of-mysql-index.html)\n- [Some study on database storage internals](https://medium.com/@kousiknath/data-structures-database-storage-internals-1f5ed3619d43)\n- [Sharding Pinterest: How we scaled our MySQL fleet](https://medium.com/@Pinterest_Engineering/sharding-pinterest-how-we-scaled-our-mysql-fleet-3f341e96ca6f)\n- [Guide to MySQL High Availability](https://www.mysql.com/cn/why-mysql/white-papers/mysql-guide-to-high-availability-solutions/)\n- [Choosing MySQL High Availability Solutions](https://dzone.com/articles/choosing-mysql-high-availability-solutions)\n- [High availability with MariaDB TX: The definitive guide](https://mariadb.com/sites/default/files/content/Whitepaper_High_availability_with_MariaDB-TX.pdf)\n\n最后，还有一个 MySQL 的资源列表 [Awesome MySQL](https://shlomi-noach.github.io/awesome-mysql/)，这个列表中有很多的工具和开发资源，可以帮助你做很多事。\n\nMySQL 有两个比较有名的分支，一个是 Percona，另一个是 MariaDB，其官网上的 Resources 页面中有很多不错的资源和文档，可以经常看看。 [Percona Resources](https://www.percona.com/resources)、[MariaDB Resources](https://mariadb.com/resources) ，以及它们的开发博客中也有很多不错的文章，分别为 [Percona Blog](https://www.percona.com/blog/) 和 [MariaDB Blog](https://mariadb.com/resources/blog)。\n\n然后是关于 MySQL 的一些相关经验型的文章。\n\n- [Booking.com: Evolution of MySQL System Design](https://www.percona.com/live/mysql-conference-2015/sessions/bookingcom-evolution-mysql-system-design) ，Booking.com 的 MySQL 数据库使用的演化，其中有很多不错的经验分享，我相信也是很多公司会遇到的的问题。\n- [Tracking the Money - Scaling Financial Reporting at Airbnb](https://medium.com/airbnb-engineering/tracking-the-money-scaling-financial-reporting-at-airbnb-6d742b80f040) ，Airbnb 的数据库扩展的经验分享。\n- [Why Uber Engineering Switched from Postgres to MySQL](https://eng.uber.com/mysql-migration/) ，无意比较两个数据库谁好谁不好，推荐这篇 Uber 的长文，主要是想让你从中学习到一些经验和技术细节，这是一篇很不错的文章。\n\n关于 MySQL 的集群复制，下面有这些文章供你学习一下，都是很不错的实践性比较强的文章。\n\n- [Monitoring Delayed Replication, With A Focus On MySQL](https://engineering.imvu.com/2013/01/09/monitoring-delayed-replication-with-a-focus-on-mysql/)\n- [Mitigating replication lag and reducing read load with freno](https://githubengineering.com/mitigating-replication-lag-and-reducing-read-load-with-freno/)\n- 另外，Booking.com 给了一系列的文章，你可以看看：\n  - [Better Parallel Replication for MySQL](https://medium.com/booking-com-infrastructure/better-parallel-replication-for-mysql-14e2d7857813)\n  - [Evaluating MySQL Parallel Replication Part 2: Slave Group Commit](https://medium.com/booking-com-infrastructure/evaluating-mysql-parallel-replication-part-2-slave-group-commit-459026a141d2)\n  - [Evaluating MySQL Parallel Replication Part 3: Benchmarks in Production](https://medium.com/booking-com-infrastructure/evaluating-mysql-parallel-replication-part-3-benchmarks-in-production-db5811058d74)\n  - [Evaluating MySQL Parallel Replication Part 4: More Benchmarks in Production\n    ](https://medium.com/booking-com-infrastructure/evaluating-mysql-parallel-replication-part-4-more-benchmarks-in-production-49ee255043ab)\n  - [Evaluating MySQL Parallel Replication Part 4, Annex: Under the Hood](https://medium.com/booking-com-infrastructure/evaluating-mysql-parallel-replication-part-4-annex-under-the-hood-eb456cf8b2fb)\n\n对于 MySQL 的数据分区来说，还有下面几篇文章你可以看看。\n\n- [StackOverflow: MySQL sharding approaches?](https://stackoverflow.com/questions/5541421/mysql-sharding-approaches)\n- [Why you don’t want to shard](https://www.percona.com/blog/2009/08/06/why-you-dont-want-to-shard/)\n- [How to Scale Big Data Applications](https://www.percona.com/sites/default/files/presentations/How to Scale Big Data Applications.pdf)\n- [MySQL Sharding with ProxySQL](https://www.percona.com/blog/2016/08/30/mysql-sharding-with-proxysql/)\n\n然后，再看看各个公司做 MySQL Sharding 的一些经验分享。\n\n- [MailChimp: Using Shards to Accommodate Millions of Users\n  ](https://devs.mailchimp.com/blog/using-shards-to-accommodate-millions-of-users/)\n- [Uber: Code Migration in Production: Rewriting the Sharding Layer of Uber’s Schemaless Datastore](https://eng.uber.com/schemaless-rewrite/)\n- [Sharding & IDs at Instagram](https://instagram-engineering.com/sharding-ids-at-instagram-1cf5a71e5a5c)\n- [Airbnb: How We Partitioned Airbnb’s Main Database in Two Weeks](https://medium.com/airbnb-engineering/how-we-partitioned-airbnb-s-main-database-in-two-weeks-55f7e006ff21)\n\n# NoSQL 数据库\n\n关于 NoSQL 数据库，其最初目的就是解决大数据的问题。然而，也有人把其直接用来替换掉关系型数据库。所以在学习这个技术之前，我们需要对这个技术的一些概念和初衷有一定的了解。下面是一些推荐资料。\n\n- Martin Fowler 在 YouTube 上分享的 NoSQL 介绍 [Introduction To NoSQL](https://youtu.be/qI_g07C_Q5I)， 以及他参与编写的 [NoSQL Distilled - NoSQL 精粹](https://book.douban.com/subject/25662138/)，这本书才 100 多页，是本难得的关于 NoSQL 的书，很不错，非常易读。\n- [NoSQL Databases: a Survey and Decision Guidance](https://medium.com/baqend-blog/nosql-databases-a-survey-and-decision-guidance-ea7823a822d#.nhzop4d23)，这篇文章可以带你自上而下地从 CAP 原理到开始了解 NoSQL 的种种技术，是一篇非常不错的文章。\n- [Distribution, Data, Deployment: Software Architecture Convergence in Big Data Systems](https://resources.sei.cmu.edu/asset_files/WhitePaper/2014_019_001_90915.pdf)，这是卡内基·梅隆大学的一篇讲分布式大数据系统的论文。其中主要讨论了在大数据时代下的软件工程中的一些关键点，也说到了 NoSQL 数据库。\n- [No Relation: The Mixed Blessings of Non-Relational Databases](http://ianvarley.com/UT/MR/Varley_MastersReport_Full_2009-08-07.pdf)，这篇论文虽然有点年代久远。但这篇论文是 HBase 的基础，你花上一点时间来读读，就可以了解到，对各种非关系型数据存储优缺点的一个很好的比较。\n- [NoSQL Data Modeling Techniques](https://highlyscalable.wordpress.com/2012/03/01/nosql-data-modeling-techniques/) ，NoSQL 建模技术。这篇文章我曾经翻译在了 CoolShell 上，标题为 [NoSQL 数据建模技术](https://coolshell.cn/articles/7270.htm)，供你参考。\n  - [MongoDB - Data Modeling Introduction](https://docs.mongodb.com/manual/core/data-modeling-introduction/) ，虽然这是 MongoDB 的数据建模介绍，但是其很多观点可以用于其它的 NoSQL 数据库。\n  - [Firebase - Structure Your Database](https://firebase.google.com/docs/database/android/structure-data) ，Google 的 Firebase 数据库使用 JSON 建模的一些最佳实践。\n- 因为 CAP 原理，所以当你需要选择一个 NoSQL 数据库的时候，你应该看看这篇文档 [Visual Guide to NoSQL Systems](http://blog.nahurst.com/visual-guide-to-nosql-systems)。\n\n选 SQL 还是 NoSQL，这里有两篇文章，值得你看看。\n\n- [SQL vs. NoSQL Databases: What’s the Difference?](https://www.upwork.com/hiring/data/sql-vs-nosql-databases-whats-the-difference/)\n- [Salesforce: SQL or NoSQL](https://engineering.salesforce.com/sql-or-nosql-9eaf1d92545b)\n\n# 各种 NoSQL 数据库\n\n学习使用 NoSQL 数据库其实并不是一件很难的事，只要你把官方的文档仔细地读一下，是很容易上手的，而且大多数 NoSQL 数据库都是开源的，所以，也可以通过代码自己解决问题。下面我主要给出一些典型的 NoSQL 数据库的一些经验型的文章，供你参考。\n\n**列数据库 Column Database**\n\n- Cassandra 相关\n  - 沃尔玛实验室有两篇文章值得一读。\n    - [Avoid Pitfalls in Scaling Cassandra Cluster at Walmart](https://medium.com/walmartlabs/avoid-pitfalls-in-scaling-your-cassandra-cluster-lessons-and-remedies-a71ca01f8c04)\n    - [Storing Images in Cassandra at Walmart](https://medium.com/walmartlabs/building-object-store-storing-images-in-cassandra-walmart-scale-a6b9c02af593)\n  - [Yelp: How We Scaled Our Ad Analytics with Apache Cassandra](https://engineeringblog.yelp.com/2016/08/how-we-scaled-our-ad-analytics-with-cassandra.html) ，Yelp 的这篇博客也有一些相关的经验和教训。\n  - [Discord: How Discord Stores Billions of Messages](https://blog.discordapp.com/how-discord-stores-billions-of-messages-7fa6ec7ee4c7) ，Discord 公司分享的一个如何存储十亿级消息的技术文章。\n  - [Cassandra at Instagram](https://www.slideshare.net/DataStax/cassandra-at-instagram-2016) ，Instagram 的一个 PPT，其中介绍了 Instagram 中是怎么使用 Cassandra 的。\n  - [Netflix: Benchmarking Cassandra Scalability on AWS - Over a million writes per second](https://medium.com/netflix-techblog/benchmarking-cassandra-scalability-on-aws-over-a-million-writes-per-second-39f45f066c9e) ，Netflix 公司在 AWS 上给 Cassandra 做的一个 Benchmark。\n- HBase 相关\n  - [Imgur Notification: From MySQL to HBASE](https://medium.com/imgur-engineering/imgur-notifications-from-mysql-to-hbase-9dba6fc44183)\n  - [Pinterest: Improving HBase Backup Efficiency](https://medium.com/@Pinterest_Engineering/improving-hbase-backup-efficiency-at-pinterest-86159da4b954)\n  - [IBM : Tuning HBase performance](https://www.ibm.com/support/knowledgecenter/en/SSPT3X_2.1.2/com.ibm.swg.im.infosphere.biginsights.analyze.doc/doc/bigsql_TuneHbase.html)\n  - [HBase File Locality in HDFS](http://www.larsgeorge.com/2010/05/hbase-file-locality-in-hdfs.html)\n  - [Apache Hadoop Goes Realtime at Facebook](http://borthakur.com/ftp/RealtimeHadoopSigmod2011.pdf)\n  - [Storage Infrastructure Behind Facebook Messages: Using HBase at Scale](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.294.8459&rep=rep1&type=pdf)\n  - [GitHub: Awesome HBase](https://github.com/rayokota/awesome-hbase)\n\n针对于 HBase 有两本书你可以考虑一下。\n\n- 首先，先推荐两本书，一本是偏实践的《[HBase 实战](https://book.douban.com/subject/25706541/)》，另一本是偏大而全的手册型的《[HBase 权威指南](https://book.douban.com/subject/10748460/)》。\n- 当然，你也可以看看官方的 [The Apache HBase™ Reference Guide](http://hbase.apache.org/0.94/book/book.html)\n- 另外两个列数据库：\n  - [ClickHouse - Open Source Distributed Column Database at Yandex](https://clickhouse.yandex/)\n  - [Scaling Redshift without Scaling Costs at GIPHY](https://engineering.giphy.com/scaling-redshift-without-scaling-costs/)\n\n**文档数据库 Document Database - MongoDB, SimpleDB, CouchDB**\n\n- [Data Points - What the Heck Are Document Databases?](https://msdn.microsoft.com/en-us/magazine/hh547103.aspx)\n- [eBay: Building Mission-Critical Multi-Data Center Applications with MongoDB](https://www.mongodb.com/blog/post/ebay-building-mission-critical-multi-data-center-applications-with-mongodb)\n- [The AWS and MongoDB Infrastructure of Parse: Lessons Learned](https://medium.baqend.com/parse-is-gone-a-few-secrets-about-their-infrastructure-91b3ab2fcf71)\n- [Migrating Mountains of Mongo Data](https://medium.com/build-addepar/migrating-mountains-of-mongo-data-63e530539952)\n- [Couchbase Ecosystem at LinkedIn](https://engineering.linkedin.com/blog/2017/12/couchbase-ecosystem-at-linkedin)\n- [SimpleDB at Zendesk](https://medium.com/zendesk-engineering/resurrecting-amazon-simpledb-9404034ec506)\n- [Github: Awesome MongoDB](https://github.com/ramnes/awesome-mongodb)\n\n**数据结构数据库 Data structure Database - Redis**\n\n- [Learn Redis the hard way (in production) at Trivago](http://tech.trivago.com/2017/01/25/learn-redis-the-hard-way-in-production/)\n- [Twitter: How Twitter Uses Redis To Scale - 105TB RAM, 39MM QPS, 10,000+ Instances](http://highscalability.com/blog/2014/9/8/how-twitter-uses-redis-to-scale-105tb-ram-39mm-qps-10000-ins.html)\n- [Slack: Scaling Slack’s Job Queue - Robustly Handling Billions of Tasks in Milliseconds Using Kafka and Redis](https://slack.engineering/scaling-slacks-job-queue-687222e9d100)\n- [GitHub: Moving persistent data out of Redis at GitHub](https://githubengineering.com/moving-persistent-data-out-of-redis/)\n- [Instagram: Storing Hundreds of Millions of Simple Key-Value Pairs in Redis](https://engineering.instagram.com/storing-hundreds-of-millions-of-simple-key-value-pairs-in-redis-1091ae80f74c)\n- [Redis in Chat Architecture of Twitch (from 27:22)](https://www.infoq.com/presentations/twitch-pokemon)\n- [Deliveroo: Optimizing Session Key Storage in Redis](https://deliveroo.engineering/2016/10/07/optimising-session-key-storage.html)\n- [Deliveroo: Optimizing Redis Storage](https://deliveroo.engineering/2017/01/19/optimising-membership-queries.html)\n- [GitHub: Awesome Redis](https://github.com/JamzyWang/awesome-redis)\n\n**时序数据库 Time-Series Database**\n\n- [What is Time-Series Data & Why We Need a Time-Series Database](https://blog.timescale.com/what-the-heck-is-time-series-data-and-why-do-i-need-a-time-series-database-dcf3b1b18563)\n- [Time Series Data: Why and How to Use a Relational Database instead of NoSQL](https://blog.timescale.com/time-series-data-why-and-how-to-use-a-relational-database-instead-of-nosql-d0cd6975e87c)\n- [Beringei: High-performance Time Series Storage Engine @Facebook](https://code.facebook.com/posts/952820474848503/beringei-a-high-performance-time-series-storage-engine/)\n- [Introducing Atlas: Netflix’s Primary Telemetry Platform @Netflix](https://medium.com/netflix-techblog/introducing-atlas-netflixs-primary-telemetry-platform-bd31f4d8ed9a)\n- [Building a Scalable Time Series Database on PostgreSQL](https://blog.timescale.com/when-boring-is-awesome-building-a-scalable-time-series-database-on-postgresql-2900ea453ee2)\n- [Scaling Time Series Data Storage - Part I @Netflix](https://medium.com/netflix-techblog/scaling-time-series-data-storage-part-i-ec2b6d44ba39)\n- [Design of a Cost Efficient Time Series Store for Big Data](https://medium.com/@leventov/design-of-a-cost-efficient-time-series-store-for-big-data-88c5dc41af8e)\n- [GitHub: Awesome Time-Series Database](https://github.com/xephonhq/awesome-time-series-database)\n\n**图数据库 - Graph Platform**\n\n- 首先是 IBM Devloperworks 上的两个简介性的 PPT。\n  - [Intro to graph databases, Part 1, Graph databases and the CRUD operations](https://www.ibm.com/developerworks/library/cl-graph-database-1/cl-graph-database-1-pdf.pdf)\n  - [Intro to graph databases, Part 2, Building a recommendation engine with a graph database](https://www.ibm.com/developerworks/library/cl-graph-database-2/cl-graph-database-2-pdf.pdf)\n- 然后是一本免费的电子书《[Graph Database](http://graphdatabases.com)》。\n- 接下来是一些图数据库的介绍文章。\n  - [Handling Billions of Edges in a Graph Database](https://www.infoq.com/presentations/graph-database-scalability)\n  - [Neo4j case studies with Walmart, eBay, AirBnB, NASA, etc](https://neo4j.com/customers/)\n  - [FlockDB: Distributed Graph Database for Storing Adjacency Lists at Twitter](https://blog.twitter.com/engineering/en_us/a/2010/introducing-flockdb.html)\n  - [JanusGraph: Scalable Graph Database backed by Google, IBM and Hortonworks](https://architecht.io/google-ibm-back-new-open-source-graph-database-project-janusgraph-1d74fb78db6b)\n  - [Amazon Neptune](https://aws.amazon.com/neptune/)\n\n**搜索数据库 - ElasticSearch**\n\n- [Elasticsearch: The Definitive Guide](https://www.elastic.co/guide/en/elasticsearch/guide/master/index.html) 这是官网方的 ElasticSearch 的学习资料，基本上来说，看这个就够了。\n- 接下来是 4 篇和性能调优相关的工程实践。\n  - [Elasticsearch Performance Tuning Practice at eBay](https://www.ebayinc.com/stories/blogs/tech/elasticsearch-performance-tuning-practice-at-ebay/)\n  - [Elasticsearch at Kickstarter](https://kickstarter.engineering/elasticsearch-at-kickstarter-db3c487887fc)\n  - [9 tips on ElasticSearch configuration for high performance](https://www.loggly.com/blog/nine-tips-configuring-elasticsearch-for-high-performance/)\n  - [Elasticsearch In Production - Deployment Best Practices](https://medium.com/@abhidrona/elasticsearch-deployment-best-practices-d6c1323b25d7)\n- 最后是 GitHub 上的资源列表 [GitHub: Awesome ElasticSearch](https://github.com/dzharii/awesome-elasticsearch) 。\n\n# 小结\n\n好了，总结一下今天分享的内容。虽然有人会认为数据库与程序员无关，是 DBA 的事儿。但我坚信，数据库才真正是程序员的事儿。因为程序是需要和数据打交道的，所以程序员或架构师不仅需要设计数据模型，还要保证整体系统的稳定性和可用性，数据是整个系统中关键中的关键。\n\n对于数据库方向，重点就是两种数据库，一种是以 SQL 为代表的关系型数据库，另一种是以非 SQL 为代表的 NoSQL 数据库。因而，在这篇文章中，我给出了 MySQL 和各种开源 NoSQL 的一些相关的有价值的文章和导读，主要是让你对这些数据库的内在有一定的了解，但又不会太深。同时给出了一些知名企业使用数据库的工程实践，这对于了解各种数据库的优劣非常有帮助，值得认真读读。\n\n从下篇文章开始，我们将进入分布式系统架构方面的内容，里面不仅涵盖了大量的理论知识，更有丰富的入门指导和大量的工程实践。敬请期待。\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/10301\" > </iframe>","categories":["左耳听风"]},{"title":"081丨程序员练级攻略：分布式架构入门","url":"/posts/3350841020.html","content":"\n\n\n学习分布式系统跟学习其它技术非常不一样，分布式系统涵盖的面非常广，具体来说涵盖如下几方面：\n\n- **服务调度**，涉及服务发现、配置管理、弹性伸缩、故障恢复等。\n- **资源调度**，涉及对底层资源的调度使用，如计算资源、网络资源和存储资源等。\n- **流量调度**，涉及路由、负载均衡、流控、熔断等。\n- **数据调度**，涉及数据复本、数据一致性、分布式事务、分库、分表等。\n- **容错处理**，涉及隔离、幂等、重试、业务补偿、异步、降级等。\n- **自动化运维**，涉及持续集成、持续部署、全栈监控、调用链跟踪等。\n\n所有这些形成了分布式架构的整体复杂度，也造就了分布式系统中的很多很多论文、图书以及很多很多的项目。要学好分布式系统及其架构，我们需要大量的时间和实践才能真正掌握这些技术。\n\n这里有几点需要你注意一下。\n\n- **分布式系统之所以复杂，就是因为它太容易出错了**。这意味着，**你要把处理错误的代码当成正常功能的代码来处理**。\n- **开发一个健壮的分布式系统的成本是单体系统的几百倍甚至几万倍**。这意味着，**我们要自己开发一个，需要能力很强的开发人员**。\n- **非常健壮的开源的分布式系统并不多，或者说基本没有**。这意味着，**如果你要用开源的，那么你需要 hold 得住其源码**。\n- **管理或是协调多个服务或机器是非常难的**。这意味着，**我们要去读很多很多的分布式系统的论文**。\n- **在分布式环境下，出了问题是很难 debug 的**。这意味着，**我们需要非常好的监控和跟踪系统，还需要经常做演练和测试**。\n- **在分布式环境下，你需要更科学地分析和统计**。这意味着，**我们要用 P90 这样的统计指标，而不是平均值，我们还需要做容量计划和评估**。\n- **在分布式环境下，需要应用服务化**。这意味着，**我们需要一个服务开发框架，比如 SOA 或微服务**。\n- **在分布式环境下，故障不可怕，可怕的是影响面过大，时间过长**。这意味着，**我们需要花时间来开发我们的自动化运维平台**。\n\n总之，在分布式环境下，一切都变得非常复杂。要进入这个领域，你需要有足够多的耐性和足够强的心态来接受各式各样的失败。当拥有丰富的实践和经验后，你才会有所建树。这并不是一日之功，你可能要在这个领域花费数年甚至数十年的时间。\n\n# 分布式架构入门\n\n学习如何设计可扩展的架构将会有助于你成为一个更好的工程师。系统设计是一个很宽泛的话题。在互联网上，关于架构设计原则的资源也是多如牛毛。所以，你需要知道一些基本概念，对此，这里你先阅读下面两篇文章。\n\n- [Scalable Web Architecture and Distributed Systems](http://www.aosabook.org/en/distsys.html) ，这篇文章会给你一个大概的分布式架构是怎么来解决系统扩展性问题的粗略方法。\n- [Scalability, Availability & Stability Patterns](http://www.slideshare.net/jboner/scalability-availability-stability-patterns) ，这个 PPT 能在扩展性、可用性、稳定性等方面给你一个非常大的架构设计视野和思想，可以让你感受一下大概的全景图。\n\n然后，我更强烈推荐 GitHub 上的一篇文档 - [System Design Primer](https://github.com/donnemartin/system-design-primer) ，这个仓库主要组织收集分布式系统的一些与扩展性相关的资源，它可以帮助你学习如何构建可扩展的架构。\n\n目前这个仓库收集到了好些系统架构和设计的基本方法。其中包括：CAP 理论、一致性模型、可用性模式、DNS、CDN、负载均衡、反向代理、应用层的微服务和服务发现、关系型数据库和 NoSQL、缓存、异步通讯、安全等。\n\n我认为，上面这几篇文章基本足够可以让你入门了，因为其中基本涵盖了所有与系统架构相关的技术。这些技术，足够这世上 90% 以上的公司用了，只有超级巨型的公司才有可能使用更高层次的技术。\n\n# 分布式理论\n\n下面，我们来学习一下分布式方面的理论知识。\n\n首先，你需要看一下 [An introduction to distributed systems](https://github.com/aphyr/distsys-class)。 这只是某个教学课程的提纲，我觉得还是很不错的，几乎涵盖了分布式系统方面的所有知识点，而且辅以简洁并切中要害的说明文字，非常适合初学者提纲挈领地了解知识全貌，快速与现有知识结合，形成知识体系。这也是一个分布式系统的知识图谱，可以让你看到分布式系统的整体全貌。你可以根据这个知识图 Google 下去，然后你会学会所有的东西。\n\n然后，你需要了解一下拜占庭将军问题（[Byzantine Generals Problem](https://en.wikipedia.org/wiki/Byzantine_fault_tolerance)）。这个问题是莱斯利·兰波特（Leslie Lamport）于 1982 年提出用来解释一致性问题的一个虚构模型（[论文地址](https://www.microsoft.com/en-us/research/uploads/prod/2016/12/The-Byzantine-Generals-Problem.pdf)）。拜占庭是古代东罗马帝国的首都，由于地域宽广，守卫边境的多个将军（系统中的多个节点）需要通过信使来传递消息，达成某些一致的决定。但由于将军中可能存在叛徒（系统中节点出错），这些叛徒将努力向不同的将军发送不同的消息，试图会干扰一致性的达成。拜占庭问题即为在此情况下，如何让忠诚的将军们能达成行动的一致。\n\n对于拜占庭问题来说，假如节点总数为 `N`，叛变将军数为 `F`，则当 `N >= 3F + 1` 时，问题才有解，即拜占庭容错（Byzantine Fault Tolerant，BFT）算法。拜占庭容错算法解决的是，网络通信可靠但节点可能故障情况下一致性该如何达成的问题。\n\n最早由卡斯特罗（Castro）和利斯科夫（Liskov）在 1999 年提出的实用拜占庭容错（Practical Byzantine Fault Tolerant，PBFT）算法，是第一个得到广泛应用的 BFT 算法。只要系统中有 2/3 的节点是正常工作的，则可以保证一致性。PBFT 算法包括三个阶段来达成共识：预准备（Pre-Prepare）、准备（Prepare）和提交（Commit）。\n\n这里有几篇和这个问题相关的文章，推荐阅读。\n\n- [Dr.Dobb’s - The Byzantine Generals Problem](http://www.drdobbs.com/cpp/the-byzantine-generals-problem/206904396)\n- [The Byzantine Generals Problem](http://blog.jameslarisch.com/the-byzantine-generals-problem)\n- [Practicle Byzantine Fault Tolerance](http://pmg.csail.mit.edu/papers/osdi99.pdf)\n\n拜占庭容错系统研究中有三个重要理论：CAP、FLP 和 DLS。\n\n- [CAP 定理](https://en.wikipedia.org/wiki/CAP_theorem)，CAP 理论相信你应该听说过不下 N 次了。CAP 定理是分布式系统设计中最基础也是最为关键的理论。CAP 定理指出，分布式数据存储不可能同时满足以下三个条件：一致性（Consistency）、可用性（Availability）和 分区容忍（Partition tolerance）。 “在网络发生阻断（partition）时，你只能选择数据的一致性（consistency）或可用性（availability），无法两者兼得”。\n\n  论点比较直观：如果网络因阻断而分隔为二，在其中一边我送出一笔交易：“将我的十元给 A”；在另一半我送出另一笔交易：“将我的十元给 B”。此时系统要不是，a）无可用性，即这两笔交易至少会有一笔交易不会被接受；要不就是，b）无一致性，一半看到的是 A 多了十元而另一半则看到 B 多了十元。要注意的是，CAP 理论和扩展性（scalability）是无关的，在分片（sharded）或非分片的系统皆适用。\n\n- [FLP impossibility](http://the-paper-trail.org/blog/a-brief-tour-of-flp-impossibility/)，在异步环境中，如果节点间的网络延迟没有上限，只要有一个恶意的节点存在，就没有算法能在有限的时间内达成共识。但值得注意的是， [“Las Vegas” algorithms](https://en.wikipedia.org/wiki/Las_Vegas_algorithm)（这个算法又叫撞大运算法，其保证结果正确，只是在运算时所用资源上进行赌博，一个简单的例子是随机快速排序，它的 pivot 是随机选的，但排序结果永远一致）在每一轮皆有一定机率达成共识，随着时间增加，机率会越趋近于 1。而这也是许多成功的共识算法会采用的解决问题的办法。\n\n- 容错的上限，从[DLS 论文](http://groups.csail.mit.edu/tds/papers/Lynch/jacm88.pdf) 中我们可以得到以下结论：\n\n  - 在部分同步（partially synchronous）的网络环境中（即网络延迟有一定的上限，但我们无法事先知道上限是多少），协议可以容忍最多 1/3 的拜占庭故障（Byzantine fault）。\n  - 在异步（asynchronous）的网络环境中，具有确定性质的协议无法容忍任何错误，但这篇论文并没有提及 [randomized algorithms](http://link.springer.com/chapter/10.1007%2F978-3-540-77444-0_7)，在这种情况下可以容忍最多 1/3 的拜占庭故障。\n  - 在同步（synchronous）网络环境中（即网络延迟有上限且上限是已知的），协议可以容忍 100% 的拜占庭故障，但当超过 1/2 的节点为恶意节点时，会有一些限制条件。要注意的是，我们考虑的是\"具有认证特性的拜占庭模型（authenticated Byzantine）\"，而不是\"一般的拜占庭模型\"；具有认证特性指的是将如今已经过大量研究且成本低廉的公私钥加密机制应用在我们的算法中。\n\n当然，还有一个著名的“8 条荒谬的分布式假设（[Fallacies of Distributed Computing](http://en.wikipedia.org/wiki/Fallacies_of_distributed_computing)）”。\n\n1. 网络是稳定的。\n2. 网络传输的延迟是零。\n3. 网络的带宽是无穷大。\n4. 网络是安全的。\n5. 网络的拓扑不会改变。\n6. 只有一个系统管理员。\n7. 传输数据的成本为零。\n8. 整个网络是同构的。\n\n阿尔农·罗特姆 - 盖尔 - 奥兹（Arnon Rotem-Gal-Oz）写了一篇长文 [Fallacies of Distributed Computing Explained](http://www.rgoarchitects.com/Files/fallacies.pdf) 来解释为什么这些观点是错误的。另外，[加勒思·威尔逊（Gareth Wilson）的文章](https://www.computing.dcu.ie/~ray/teaching/CA485/notes/fallacies.pdf) 则用日常生活中的例子，对这些点做了通俗的解释。为什么我们深刻地认识到这 8 个错误？是因为，这要我们清楚地认识到——在分布式系统中错误是不可能避免的，我们在分布式系统中，能做的不是避免错误，而是要把错误的处理当成功能写在代码中。\n\n下面分享几篇一致性方面的论文。\n\n- 当然，关于经典的 CAP 理论，也存在一些误导的地方，这个问题在 2012 年有一篇论文 [CAP Twelve Years Later: How the Rules Have Changed](https://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed) （[中译版](http://www.infoq.com/cn/articles/cap-twelve-years-later-how-the-rules-have-changed)）中做了一些讨论，主要是说，在 CAP 中最大的问题就是分区，也就是 P，在 P 发生的情况下，非常难以保证 C 和 A。然而，这是强一致性的情况。\n\n  其实，在很多时候，我们并不需要强一致性的系统，所以后来，人们争论关于数据一致性和可用性时，主要是集中在强一致性的 ACID 或最终一致性的 BASE。当时，BASE 还不怎么为世人所接受，主要是大家都觉得 ACID 是最完美的模型，大家很难接受不完美的 BASE。在 CAP 理论中，大家总是觉得需要“三选二”，也就是说，P 是必选项，那“三选二”的选择题不就变成数据一致性 (consistency)、服务可用性 (availability) 间的“二选一”？\n\n  然而，现实却是，P 很少遇到，而 C 和 A 这两个事，工程实践中一致性有不同程度，可用性也有不同等级，在保证分区容错性的前提下，放宽约束后可以兼顾一致性和可用性，两者不是非此即彼。其实，在一个时间可能允许的范围内是可以取舍并交替选择的。\n\n- [Harvest, Yield, and Scalable Tolerant Systems](https://pdfs.semanticscholar.org/5015/8bc1a8a67295ab7bce0550886a9859000dc2.pdf) ，这篇论文是基于上面那篇“CAP 12 年后”的论文写的，它主要提出了 Harvest 和 Yield 概念，并把上面那篇论文中所讨论的东西讲得更为仔细了一些。\n\n- [Base: An Acid Alternative](https://queue.acm.org/detail.cfm?id=1394128) （[中译版](http://www.cnblogs.com/savorboard/p/base-an-acid-alternative.html)），本文是 eBay 的架构师在 2008 年发表给 ACM 的文章，是一篇解释 BASE 原则，或者说最终一致性的经典文章。文中讨论了 BASE 与 ACID 原则的基本差异, 以及如何设计大型网站以满足不断增长的可伸缩性需求，其中有如何对业务做调整和折中，以及一些具体的折中技术的介绍。一个比较经典的话是——“在对数据库进行分区后, 为了可用性（Availability）牺牲部分一致性（Consistency）可以显著地提升系统的可伸缩性 (Scalability)”。\n\n- [Eventually Consistent](https://www.allthingsdistributed.com/2008/12/eventually_consistent.html) ，这篇文章是 AWS 的 CTO 维尔纳·沃格尔（Werner Vogels）在 2008 年发布在 ACM Queue 上的一篇数据库方面的重要文章，阐述了 NoSQL 数据库的理论基石——最终一致性，对传统的关系型数据库（ACID，Transaction）做了较好的补充。\n\n# 小结\n\n好了，总结一下今天分享的内容。文章的开头，我给出了学习分布式架构需要注意的几个关键点，然后列出了入门学习的资源，基本涵盖了所有与系统架构相关的技术。随后讲述了拜占庭容错系统研究中有三个重要理论：CAP、FLP 和 DLS，以及 8 条荒谬的分布式假设，从理论和认知等角度让你更为清楚地理解分布式系统。最后分享了几篇一致性相关的论文，很实用很经典，推荐阅读。\n\n下篇文章中，我将推荐一些分布式架构的经典图书和论文，并给出了导读文字，几乎涵盖了分布式系统架构方面的所有关键的理论知识。敬请期待。\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/10603\" > </iframe>","categories":["左耳听风"]},{"title":"082丨程序员练级攻略：分布式架构经典图书和论文","url":"/posts/3997887101.html","content":"\n\n\n# 经典图书\n\n首先，我推荐几本分布式架构方面的经典图书。\n\n- **[Distributed Systems for fun and profit](http://book.mixu.net/distsys/single-page.html)**，这是一本免费的电子书。作者撰写此书的目的是希望以一种更易于理解的方式，讲述以亚马逊的 Dynamo、谷歌的 Bigtable 和 MapReduce 等为代表的分布式系统背后的核心思想。\n\n- **[Designing Data Intensive Applications](https://book.douban.com/subject/27154352/)**，这本书是一本非常好的书，我们知道，在分布式的世界里，数据结点的扩展是一件非常麻烦的事。这本书深入浅出地用很多的工程案例讲解了如何让数据结点做扩展。作者马丁·科勒普曼（Martin Kleppmann）在分布式数据系统领域有着很深的功底，并在这本书中完整地梳理各类纷繁复杂设计背后的技术逻辑，不同架构之间的妥协与超越，很值得开发人员与架构设计者阅读。\n\n  这本书深入到 B-Tree、SSTables、LSM 这类数据存储结构中，并且从外部的视角来审视这些数据结构对 NoSQL 和关系型数据库的影响。这本书可以让你很清楚地了解到真正世界的大数据架构中的数据分区、数据复制的一些坑，并提供了很好的解决方案。最赞的是，作者将各种各样技术的本质非常好地关联在一起，令你触类旁通。\n\n  而且，这本书完全就是抽丝剥茧，循循善诱，从“提出问题”到“解决问题”、“解决方案”、“优化方案”和“对比不同的方案”，一点一点地把非常晦涩的技术和知识展开。本书的引用相当多，每章后面都有几百个 Reference，通过这些 Reference 你可以看到更为广阔、更为精彩的世界。\n\n- [Distributed Systems: Principles and Paradigms](http://barbie.uta.edu/~jli/Resources/MapReduce&Hadoop/Distributed Systems Principles and Paradigms.pdf) ，本书是由计算机科学家安德鲁·斯图尔特·塔能鲍姆（Andrew S. Tanenbaum）和其同事马丁·范·斯蒂恩（Martin van Steen）合力撰写的，是分布式系统方面的经典教材。\n\n  语言简洁，内容通俗易懂，介绍了分布式系统的七大核心原理，并给出了大量的例子；系统讲述了分布式系统的概念和技术，包括通信、进程、命名、同步化、一致性和复制、容错以及安全等；讨论了分布式应用的开发方法（即范型）。但本书不是一本指导“如何做”的手册，仅适合系统性地学习基础知识，了解编写分布式系统的基本原则和逻辑。中文翻译版为[《分布式系统原理与范型》（第二版）](https://item.jd.com/10079452.html)。\n\n- [Scalable Web Architecture and Distributed Systems](http://www.aosabook.org/en/distsys.html)，\n  这是一本免费的在线小册子，其中文翻译版 [可扩展的 Web 架构和分布式系统](http://nettee.github.io/posts/2016/Scalable-Web-Architecture-and-Distributed-Systems/)。本书主要针对面向互联网（公网）的分布式系统，但其中的原理或许也可以应用于其他分布式系统的设计中。作者的观点是，通过了解大型网站的分布式架构原理，小型网站的构建也能从中受益。本书从大型互联网系统的常见特性，如高可用、高性能、高可靠、易管理等出发，引出了一个类似于 Flickr 的典型的大型图片网站的例子。\n\n- [Principles of Distributed Systems](http://dcg.ethz.ch/lectures/podc_allstars/lecture/podc.pdf) ，本书是苏黎世联邦理工学院的教材。它讲述了多种分布式系统中会用到的算法。虽然分布式系统的不同场景会用到不同算法，但并不表示这些算法都会被用到。不过，作为学生来说，掌握了算法设计的精髓也就能举一反三地设计出解决其他问题的算法，从而得到分布式系统架构设计中所需的算法。\n\n# 经典论文\n\n## 分布式事务\n\n想了解分布式模型中最难的“分布式事务”，你需要看看 Google App Engine 联合创始人瑞恩·巴雷特（Ryan Barrett）在 2009 年的 Google I/O 大会上的演讲《[Transaction Across DataCenter](http://snarfed.org/transactions_across_datacenters_io.html)》（[YouTube 视频](http://www.youtube.com/watch?v=srOgpXECblk)）。\n\n在这个演讲中，巴雷特讲述了各种经典的解决方案如何在一致性、事务、性能和错误上做平衡。而最后得到为什么分布式系统的事务只有 Paxos 算法是最好的。\n\n下面这个图是这个算法中的结论。\n\n![image-20230928091230650](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928091230650.png)\n\n\n\n\n\n你也可以移步看一下我在 Coolshell 上写的这篇文章《[分布式系统的事务处理](https://coolshell.cn/articles/10910.html)》。\n\n## Paxos 一致性算法\n\nPaxos 算法，是莱斯利·兰伯特（Lesile Lamport）于 1990 年提出来的一种基于消息传递且具有高度容错特性的一致性算法。但是这个算法太过于晦涩，所以一直以来都属于理论上的论文性质的东西。其真正进入工程圈，主要是来源于 Google 的 Chubby lock——一个分布式的锁服务，用在了 Bigtable 中。直到 Google 发布了下面这两篇论文，Paxos 才进入到工程界的视野中来。\n\n- [Bigtable: A Distributed Storage System for Structured Data](https://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf)\n- [The Chubby lock service for loosely-coupled distributed systems](https://static.googleusercontent.com/media/research.google.com/en//archive/chubby-osdi06.pdf)\n\nGoogle 与 Bigtable 相齐名的还有另外两篇论文。\n\n- [The Google File System](https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf)\n- [MapReduce: Simplified Data Processing on Large Clusters](https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf)\n\n不过，这几篇文章中并没有讲太多的 Paxos 算法上的细节，反而是在[Paxos Made Live - An Engineering Perspective](https://static.googleusercontent.com/media/research.google.com/en//archive/paxos_made_live.pdf) 这篇论文中提到了很多工程实现的细节。这篇论文详细解释了 Google 实现 Paxos 时遇到的各种问题和解决方案，讲述了从理论到实际应用二者之间巨大的鸿沟。\n\nPaxos 算法的原版论文比较晦涩，也不易懂。这里推荐一篇比较容易读的—— [Neat Algorithms - Paxos](http://harry.me/blog/2014/12/27/neat-algorithms-paxos/) 。这篇文章中还有一些小动画帮助你读懂。还有一篇可以帮你理解的文章是 [Paxos by Examples](https://angus.nyc/2012/paxos-by-example/)。\n\n## Raft 一致性算法\n\n因为 Paxos 算法太过于晦涩，而且在实际的实现上有太多的坑，并不太容易写对。所以，有人搞出了另外一个一致性的算法，叫 Raft。其原始论文是 [In search of an Understandable Consensus Algorithm (Extended Version) ](https://raft.github.io/raft.pdf)，寻找一种易于理解的 Raft 算法。这篇论文的译文在 InfoQ 上，题为《[Raft 一致性算法论文译文]([https://infoq.cn/article/raft-paper](https://infoq.cn/article/raft-paper))》，推荐你读一读。\n\n这里推荐几个不错的 Raft 算法的动画演示。\n\n- [\n  Raft - The Secret Lives of Data](http://thesecretlivesofdata.com/raft/)\n- [Raft Consensus Algorithm](https://raft.github.io/)\n- [Raft Distributed Consensus Algorithm Visualization](http://kanaka.github.io/raft.js/)\n\n## Gossip 一致性算法\n\n后面，业内又搞出来一些工程上的东西，比如 Amazon 的 DynamoDB，其论文[Dynamo: Amazon’s Highly Available Key Value Store](http://bnrg.eecs.berkeley.edu/~randy/Courses/CS294.F07/Dynamo.pdf) 的影响力非常大。这篇论文中讲述了 Amazon 的 DynamoDB 是如何满足系统的高可用、高扩展和高可靠的。其中展示了系统架构是如何做到数据分布以及数据一致性的。GFS 采用的是查表式的数据分布，而 DynamoDB 采用的是计算式的，也是一个改进版的通过虚拟结点减少增加结点带来数据迁移的一致性哈希。\n\n这篇文章中有几个关键的概念，一个是 Vector Clock，另一个是 Gossip 协议。\n\n- [Time, Clocks and the Ordering of Events in a Distributed System](https://www.microsoft.com/en-us/research/publication/time-clocks-ordering-events-distributed-system/) ，这篇文章是莱斯利·兰伯特（Leslie Lamport）于 1978 年发表的，并在 2007 年被选入 SOSP 的名人堂，被誉为第一篇真正的“分布式系统”论文，该论文曾一度成为计算机科学史上被引用最多的文章。分布式系统中的时钟同步是一个非常难的问题，因为分布式系统中是使用消息进行通信的，若使用物理时钟来进行同步，一方面是不同的 process 的时钟有差异，另一方面是时间的计算也有一定的误差，这样若有两个时间相同的事件，则无法区分它们谁前谁后了。这篇文章主要解决分布式系统中的时钟同步问题。\n- [马萨诸塞大学课程 Distributed Operating System](http://lass.cs.umass.edu/~shenoy/courses/spring05/lectures.html) 中第 10 节 [Clock Synchronization](http://lass.cs.umass.edu/~shenoy/courses/spring05/lectures/Lec10.pdf)，这篇讲义讲述了时钟同步的问题。\n- 关于 Vector Clock，你可以看一下[ Why Vector Clocks are Easy](http://basho.com/posts/technical/why-vector-clocks-are-easy/) 和 [Why Vector Clocks are Hard](http://basho.com/posts/technical/why-vector-clocks-are-hard/) 这两篇文章。\n\n用来做数据同步的 Gossip 协议的原始论文是 [Efficient Reconciliation and Flow Control for Anti-Entropy Protocols](https://www.cs.cornell.edu/home/rvr/papers/flowgossip.pdf)。Gossip 算法也是 Cassandra 使用的数据复制协议。这个协议就像八卦和谣言传播一样，可以“一传十、十传百”传播开来。但是这个协议看似简单，细节上却非常麻烦。\n\nGossip 协议也是 NoSQL 数据库 Cassandra 中使用到的数据协议，你可以上 YouTube 上看一下这个视频介绍： [Understanding Gossip (Cassandra Internals)](https://www.youtube.com/watch?v=FuP1Fvrv6ZQ)。\n\n关于 Gossip 的一些图示化的东西，你可以看一下动画 [Gossip Visualization](https://rrmoelker.github.io/gossip-visualization/)。\n\n## 分布式存储和数据库\n\n除了前面的 Google 的 BigTable 和 Google File System 那两篇论文，还有 Amazon 的 DynamoDB 的论文，下面也有几篇也是要读一下的。\n\n- 一篇是 AWS Aurora 的论文 [Amazon Aurora: Design Considerations for High Throughput Cloud -Native Relation Databases](http://www.allthingsdistributed.com/files/p1041-verbitski.pdf)。\n- 另一篇是比较有代表的论文是 Google 的 [Spanner: Google’s Globally-Distributed Database](http://static.googleusercontent.com/media/research.google.com/zh-CN//archive/spanner-osdi2012.pdf)。 其 2017 年的新版论文：[Spanner, TrueTime & The CAP Theorem](https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45855.pdf)。\n- [F1 - The Fault-Tolerant Distributed RDBMS Supporting Google’s Ad Business](http://research.google.com/pubs/archive/38125.pdf) 。\n- [Cassandra: A Decentralized Structured Storage System](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.161.6751&rep=rep1&type=pdf) 。\n- [CRUSH: Controlled, Scalable, Decentralized Placement of Replicated Data](http://www.ssrc.ucsc.edu/Papers/weil-sc06.pdf), 这里提到的算法被应用在了 Ceph 分布式文件系统中，其架构可以读一下 [RADOS - A Scalable, Reliable Storage Service for Petabyte-scale\n  Storage Clusters](https://ceph.com/wp-content/uploads/2016/08/weil-rados-pdsw07.pdf) 以及 [Ceph 的架构文档](http://docs.ceph.com/docs/jewel/architecture/)。\n\n## 分布式消息系统\n\n- 分布式消息系统，你一定要读一下 Kafka 的这篇论文 [Kafka: a Distributed Messaging System for Log Processing](http://research.microsoft.com/en-us/UM/people/srikanth/netdb11/netdb11papers/netdb11-final12.pdf)。\n- [Wormhole: Reliable Pub-Sub to Support Geo-replicated Internet Services](https://www.usenix.org/system/files/conference/nsdi15/nsdi15-paper-sharma.pdf) ，Wormhole 是 Facebook 内部使用的一个 Pub-Sub 系统，目前还没有开源。它和 Kafka 之类的消息中间件很类似。但是它又不像其它的 Pub-Sub 系统，Wormhole 没有自己的存储来保存消息，它也不需要数据源在原有的更新路径上去插入一个操作来发送消息，是非侵入式的。其直接部署在数据源的机器上并直接扫描数据源的 transaction logs，这样还带来一个好处，Wormhole 本身不需要做任何地域复制（geo-replication）策略，只需要依赖于数据源的 geo-replication 策略即可。\n- [All Aboard the Databus! LinkedIn’s Scalable Consistent Change Data Capture Platform](https://engineering.linkedin.com/research/2012/all-aboard-the-databus-linkedlns-scalable-consistent-change-data-capture-platform) ， 在 LinkedIn 投稿 SOCC 2012 的这篇论文中，指出支持对不同数据源的抽取，允许不同数据源抽取器的开发和接入，只需该抽取器遵循设计规范即可。该规范的一个重要方面就是每个数据变化都必须被一个单调递增的数字标注（SCN），用于同步。这其中的一些方法完全可以用做异地双活的系统架构中。（和这篇论文相关的几个链接如下：[PDF 论文](https://915bbc94-a-62cb3a1a-s-sites.googlegroups.com/site/acm2012socc/s18-das.pdf?attachauth=ANoY7cpF7igQlU-DGe3gMeW4PZr0cnRDm6cFsuJnv8n5LtJqYrEE9TMMzctK8P9OUTzPD-M2efmpes3zsc10VXN0g6RmdqTpSv3YwgUIW08RBmUvv3XMpUhEAiHkLdrzqC5thiAu5kyskHhkflK3wPYPvA6PeH4uM_XD3u4Quo0MR87BXnE_TcmnRnPzUzNAAYLng2K5t5elUuTj9NaU4o8QSfFX8edgwA%3D%3D&attredirects=0) 、 [PPT 分享](https://www.slideshare.net/amywtang/databus-socc-v3)。）\n\n## 日志和数据\n\n- [The Log: What every software engineer should know about real-time data’s unifying abstraction](https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying) ，这篇文章好长，不过这是一篇非常好非常好的文章，这是每个工程师都应用知道的事，必看啊。你可以看中译版《[日志：每个软件工程师都应该知道的有关实时数据的统一概念](https://github.com/oldratlee/translations/blob/master/log-what-every-software-engineer-should-know-about-real-time-datas-unifying/README.md)》。\n\n- [The Log-Structured Merge-Tree (LSM-Tree)](https://www.cs.umb.edu/~poneil/lsmtree.pdf) ，N 多年前，谷歌发表了 Bigtable 的论文，论文中很多很酷的方面，其一就是它所使用的文件组织方式，这个方法更一般的名字叫 Log Structured-Merge Tree。LSM 是当前被用在许多产品的文件结构策略：HBase、Cassandra、LevelDB、SQLite，甚至在 MongoDB 3.0 中也带了一个可选的 LSM 引擎（Wired Tiger 实现的）。LSM 有趣的地方是它抛弃了大多数数据库所使用的传统文件组织方法。实际上，当你第一次看它时是违反直觉的。这篇论文可以让你明白这个技术。（如果读起来有些费解的话，你可以看看中文社区里的这几篇文章：[文章一](http://www.cnblogs.com/siegfang/archive/2013/01/12/lsm-tree.html)、[文章二](https://kernelmaker.github.io/lsm-tree)。）\n\n- [Immutability Changes Everything](http://cidrdb.org/cidr2015/Papers/CIDR15_Paper16.pdf) ，这篇论文是现任 Salesforce 软件架构师帕特·赫兰德（Pat Helland）在 CIDR 2015 大会上发表的（[相关视频演讲](https://vimeo.com/52831373)）。\n\n- [Tango: Distributed Data Structures over a Shared Log](https://www.microsoft.com/en-us/research/wp-content/uploads/2013/11/Tango.pdf)）。这个论文非常经典，其中说明了不可变性（immutability）架构设计的优点。随着为海量数据集存储和计算而设计的以数据为中心的新型抽象技术的出现，分布式系统比以往任何时候都更容易构建。但是，对于元数据的存储和访问不存在类似的抽象。\n\n  为了填补这一空白，Tango 为开发人员提供了一个由共享日志支持的内存复制数据结构（例如地图或树）的抽象。Tango 对象易于构建和使用，通过共享日志上简单的追加和读取操作来复制状态，而不是复杂的分布式协议。在这个过程中，它们从共享日志中获得诸如线性化、持久性和高可用性等属性。Tango 还利用共享日志支持跨不同对象的快速事务处理，允许应用程序跨机器进行状态划分，并在不牺牲一致性的情况下扩展到底层日志的上限。\n\n## 分布式监控和跟踪\n\n- Google 的分布式跟踪监控论文 - [Dapper, a Large-Scale Distributed Systems Tracing Infrastructure](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36356.pdf)， 其开源实现有三个 [Zipkin](http://zipkin.io/)、[Pinpoint](https://github.com/naver/pinpoint) 和 [HTrace](http://htrace.incubator.apache.org/)。我个人更喜欢 Zipkin。\n\n## 数据分析\n\n- [The Unified Logging Infrastructure for Data Analytics at Twitter](http://vldb.org/pvldb/vol5/p1771_georgelee_vldb2012.pdf) ，Twitter 公司的一篇关于日志架构和数据分析的论文。\n- [Scaling Big Data Mining Infrastructure: The Twitter Experience](http://www.datascienceassn.org/sites/default/files/Scaling Big Data Mining Infrastructure - The Twitter Experience.pdf) ，讲 Twitter 公司的数据分析平台在数据量越来越大，架构越来越复杂，业务需求越来越多的情况下，数据分析从头到底是怎么做的。\n- [Dremel: Interactive Analysis of Web-Scale Datasets](http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/pubs/archive/36632.pdf)，Google 公司的 Dremel，是一个针对临时查询提供服务的系统，它处理的是只读的多层数据。本篇文章介绍了它的架构与实现，以及它与 MapReduce 是如何互补的。\n- [Resident Distributed Datasets: a Fault-Tolerant Abstraction for In-Memory Cluster Computing](https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf)，这篇论文提出了弹性分布式数据集（Resilient Distributed Dataset，RDD）的概念，它是一个分布式存储抽象，使得程序员可以在大型集群上以容错的方式执行内存计算；解释了其出现原因：解决之前计算框架在迭代算法和交互式数据挖掘工具两种应用场景下处理效率低下的问题，并指出将数据保存在内存中，可以将性能提高一个数量级；同时阐述了其实现原理及应用场景等多方面内容。很有趣儿，推荐阅读。\n\n## 与编程相关的论文\n\n- [Distributed Programming Model](http://web.cs.ucdavis.edu/~pandey/Research/Papers/icdcs01.pdf)\n- [PSync: a partially synchronous language for fault-tolerant distributed algorithms](http://www.di.ens.fr/~cezarad/popl16.pdf)\n- [Programming Models for Distributed Computing](http://heather.miller.am/teaching/cs7680/)\n- [Logic and Lattices for Distributed Programming](http://db.cs.berkeley.edu/papers/UCB-lattice-tr.pdf)\n\n## 其它的分布式论文阅读列表\n\n除了上面上的那些我觉得不错的论文，下面还有三个我觉得不错的分布式系统论文的阅读列表，你可以浏览一下。\n\n- [Services Engineering Reading List](https://github.com/mmcgrana/services-engineering)\n- [Readings in Distributed Systems](http://christophermeiklejohn.com/distributed/systems/2013/07/12/readings-in-distributed-systems.html)\n- [Google Research - Distributed Systems and Parallel Computing](https://ai.google/research/pubs/?area=DistributedSystemsandParallelComputing)\n\n# 小结\n\n今天分享的内容是分布式架构方面的经典图书和论文，并给出了导读文字，几乎涵盖了分布式系统架构方面的所有关键的理论知识。这些内容非常重要，是学好分布式架构的基石，请一定要认真学习。\n\n下篇文章中，我们将讲述分布式架构工程设计方面的内容，包括设计原则、设计模式以及工程实践等方面的内容。敬请期待。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/10604\" > </iframe>\n\n\n\n","categories":["左耳听风"]},{"title":"083丨程序员练级攻略：分布式架构工程设计","url":"/posts/4000825612.html","content":"\n\n\n要学好分布式架构，你首先需要学习一些架构指导性的文章和方法论，即分布式架构设计原则。下面是几篇很不错的文章，值得一读。\n\n- [Designs, Lessons and Advice from Building Large Distributed Systems](https://www.cs.cornell.edu/projects/ladis2009/talks/dean-keynote-ladis2009.pdf)，Google 杰夫·迪恩（Jeff Dean）2009 年一次演讲的 PPT。2010 年，斯坦福大学请杰夫·迪恩到大学里给他们讲了一节课，你可以在 YouTube 上看一下，[Building Software Systems At Google and Lessons Learned](https://www.youtube.com/watch?v=modXC5IWTJI) ，其回顾了 Google 发展的历史。\n- [The Twelve-Factor App](https://12factor.net/) ，如今，软件通常会作为一种服务来交付，它们被称为网络应用程序，或软件即服务（SaaS）。12-Factor 为构建 SaaS 应用提供了方法论，是架构师必读的文章。（[中译版](https://12factor.net/zh_cn/)）这篇文章在业内的影响力很大，必读！\n- [Notes on Distributed Systems for Young Bloods](http://www.somethingsimilar.com/2013/01/14/notes-on-distributed-systems-for-young-bloods/) ，给准备进入分布式系统领域的人的一些忠告。\n- [On Designing and Deploying Internet-Scale Services](https://www.usenix.org/legacy/event/lisa07/tech/full_papers/hamilton/hamilton_html/index.html)（[中译版](http://darktea.github.io/notes/2014/07/23/On-Designing-and-Deploying-Internet-Scale-Services.html)），微软 Windows Live 服务平台的一些经验性的总结文章，很值得一读。\n- [4 Things to Keep in Mind When Building a Platform for the Enterprise](https://blog.box.com/blog/4-things-to-keep-in-mind-when-building-a-platform-for-the-enterprise/) ，Box 平台 VP 海蒂·威廉姆斯（Heidi Williams）撰写的一篇文章，阐述了为企业构建平台时需要牢记的四件关于软件设计方面的事：1. Design Broadly, Build Narrowly； 2. Platforms Are Powerful and Flexible. Choose wisely what to expose when!；3. Build Incrementally, Get Feedback, and Iterate；4. Create a Platform-first Mentality。文章中有详细的解读，推荐看看。\n- [Principles of Chaos Engineering](https://www.usenix.org/conference/srecon17americas/program/presentation/rosenthal) ，我们知道，Netflix 公司有一个叫 Chaos Monkey 的东西，这个东西会到分布式系统里“瞎搞”，以此来测试系统的健壮和稳定性。这个视频中，Netflix 分享了一些软件架构的经验和原则，值得一看。\n- [Building Fast & Resilient Web Applications](https://www.igvita.com/2016/05/20/building-fast-and-resilient-web-applications/) ，伊利亚·格里高利克（Ilya Grigorik）在 Google I/O 2016 上的一次关于如何通过弹力设计来实现快速和可容错的网站架构的演讲，其中有好些经验分享。\n- [Design for Resiliency](http://highscalability.com/blog/2012/12/31/designing-for-resiliency-will-be-so-2013.html) ，这篇文章带我们全面认识“弹力（Resiliency）”，以及弹力对于系统的重要性，并详细阐述了如何设计和实现系统的弹力。\n- 微软的 Azure 网站上有一系列的 [Design Principle](https://docs.microsoft.com/en-us/azure/architecture/guide/design-principles/) 的文章，你可以看看这几篇： [Design for Self-healing](https://docs.microsoft.com/en-us/azure/architecture/guide/design-principles/self-healing) 、[Design for Scaling Out](https://docs.microsoft.com/en-us/azure/architecture/guide/design-principles/scale-out) 和 [Design for Evolution](https://docs.microsoft.com/en-us/azure/architecture/guide/design-principles/design-for-evolution) 。\n- [Eventually Consistent](https://www.allthingsdistributed.com/2008/12/eventually_consistent.html) ，AWS CTO 维尔纳·沃格尔斯（Werner Vogels）发布在自己 Blog 上的一篇关于最终一致性的好文。\n- [Writing Code that Scales](https://blog.rackspace.com/writing-code-that-scales) ，Rackspace 的一篇很不错的博文，告诉我们一些很不错的写出高扩展和高性能代码的工程原则。\n- [Automate and Abstract: Lessons from Facebook on Engineering for Scale](https://architecht.io/lessons-from-facebook-on-engineering-for-scale-f5716f0afc7a) ，软件自动化和软件抽象，这是软件工程中最重要的两件事了。通过这篇文章，我们可以看到 Facebook 的关于这方面的一些经验教训。\n\n# 设计模式\n\n有了方法论后，你还需要学习一些比较细节的落地的技术。最好的方式就是学习被前人总结出来的设计模式，虽然设计模式也要分场景，但是设计模式可以让你知道一些套路，这些套路对于我们设计的分布式系统有非常大的帮助，不但可以让我们少走一些弯路，而且还能让我们更为系统和健壮地设计我们的架构。\n\n下面是一些分布式架构设计模式的网站。\n\n首先，需要重点推荐的是微软云平台 Azure 上的设计模式。 [Cloud Design Patterns](https://docs.microsoft.com/en-us/azure/architecture/patterns/) ，这个网站上罗列了分布式设计的各种设计模式，可以说是非常全面和完整。对于每一个模式都有详细的说明，并有对其优缺点的讨论，以及适用场景和不适用场景的说明，实在是一个非常不错的学习分布式设计模式的地方。其中有如下分类。\n\n- [设计模式：可用性](https://docs.microsoft.com/en-us/azure/architecture/patterns/category/availability)；\n- [设计模式：数据管理](https://docs.microsoft.com/en-us/azure/architecture/patterns/category/data-management)；\n- [设计模式：设计和实现](https://docs.microsoft.com/en-us/azure/architecture/patterns/category/design-implementation)；\n- [设计模式：消息](https://docs.microsoft.com/en-us/azure/architecture/patterns/category/messaging)；\n- [设计模式：管理和监控](https://docs.microsoft.com/en-us/azure/architecture/patterns/category/management-monitoring)；\n- [设计模式：性能和扩展](https://docs.microsoft.com/en-us/azure/architecture/patterns/category/performance-scalability)；\n- [设计模式：系统弹力](https://docs.microsoft.com/en-us/azure/architecture/patterns/category/resiliency)；\n- [设计模式：安全](https://docs.microsoft.com/en-us/azure/architecture/patterns/category/security)。\n\n除此之外，还有其它的一些关于分布式系统设计模式的网站和相关资料。\n\n- [AWS Cloud Pattern](http://en.clouddesignpattern.org/index.php/Main_Page) ，这里收集了 AWS 云平台的一些设计模式。\n- [Design patterns for container-based distributed systems](https://research.google.com/pubs/archive/45406.pdf) ，这是 Google 给的一篇论文，其中描述了容器化下的分布式架构的设计模式。\n- [Patterns for distributed systems](https://www.slideshare.net/pagsousa/patterns-fro-distributed-systems) ，这是一个 PPT，其中讲了一些分布式系统的架构模式，你可以顺着到 Google 里去搜索。\n\n我个人觉得微服务也好，SOA 也好，都是分布式系统的一部分，这里有两个网站罗列了各种各样的服务架构模式。\n\n- [A Pattern Language for Micro-Services](http://microservices.io/patterns/index.html) ；\n- [SOA Patterns](http://soapatterns.org/)。\n\n当然，还有我在极客时间上写的那些分布式的设计模式的总结。\n\n- **弹力设计篇**，内容包括：认识故障和弹力设计、隔离设计、异步通讯设计、幂等性设计、服务的状态、补偿事务、重试设计、熔断设计、限流设计、降级设计、弹力设计总结。\n- **管理设计篇**，内容包括：分布式锁、配置中心、边车模式、服务网格、网关模式、部署升级策略等。\n- **性能设计篇**，内容包括：缓存、异步处理、数据库扩展、秒杀、边缘计算等。\n\n# 设计与工程实践\n\n## 分布式系统的故障测试\n\n- [FIT: Failure Injection Testing](https://medium.com/netflix-techblog/fit-failure-injection-testing-35d8e2a9bb2) ，Netflix 公司的一篇关于做故障注入测试的文章。\n- [Automated Failure Testing](https://medium.com/netflix-techblog/automated-failure-testing-86c1b8bc841f) ，同样来自 Netflix 公司的自动化故障测试的一篇博文。\n- [Automating Failure Testing Research at Internet Scale](https://people.ucsc.edu/~palvaro/socc16.pdf) ，Netflix 公司伙同圣克鲁斯加利福尼亚大学和 Gremlin 游戏公司一同撰写的一篇论文。\n\n## 弹性伸缩\n\n- [4 Architecture Issues When Scaling Web Applications: Bottlenecks, Database, CPU, IO](http://highscalability.com/blog/2014/5/12/4-architecture-issues-when-scaling-web-applications-bottlene.html) ，本文讲解了后端程序的主要性能指标，即响应时间和可伸缩性这两者如何能提高的解决方案，讨论了包括纵向和横向扩展，可伸缩架构、负载均衡、数据库的伸缩、CPU 密集型和 I/O 密集型程序的考量等。\n- [Scaling Stateful Objects](http://ithare.com/scaling-stateful-objects/) ，这是一本叫《Development&Deployment of Multiplayer Online Games》书中一章内容的节选，讨论了有状态和无状态的节点如何伸缩的问题。虽然还没有写完，但是可以给你一些很不错的基本概念和想法。\n- [Scale Up vs Scale Out: Hidden Costs](https://blog.codinghorror.com/scaling-up-vs-scaling-out-hidden-costs/) ，Coding Horror 上的一篇有趣的文章，详细分析了可伸缩性架构的不同扩展方案（横向扩展或纵向扩展）所带来的成本差异，帮助你更好地选择合理的扩展方案，可以看看。\n- [Best Practices for Scaling Out](https://blog.openshift.com/best-practices-for-horizontal-application-scaling/) ，OpenShift 的一篇讨论 Scale out 最佳实践的文章。\n- [Scalability Worst Practices](https://www.infoq.com/articles/scalability-worst-practices) ，这篇文章讨论了一些最差实践，你需要小心避免。\n- [Reddit: Lessons Learned From Mistakes Made Scaling To 1 Billion Pageviews A Month](http://highscalability.com/blog/2013/8/26/reddit-lessons-learned-from-mistakes-made-scaling-to-1-billi.html) ，Reddit 分享的一些关于系统扩展的经验教训。\n- 下面是几篇关于自动化弹性伸缩的文章。\n  - [Autoscaling Pinterest](https://medium.com/@Pinterest_Engineering/auto-scaling-pinterest-df1d2beb4d64)；\n  - [Square: Autoscaling Based on Request Queuing](https://medium.com/square-corner-blog/autoscaling-based-on-request-queuing-c4c0f57f860f)；\n  - [PayPal: Autoscaling Applications](https://www.paypal-engineering.com/2017/08/16/autoscaling-applications-paypal/)；\n  - [Trivago: Your Definite Guide For Autoscaling Jenkins](http://tech.trivago.com/2017/02/17/your-definite-guide-for-autoscaling-jenkins/)；\n  - [Scryer: Netflix’s Predictive Auto Scaling Engine](https://medium.com/netflix-techblog/scryer-netflixs-predictive-auto-scaling-engine-a3f8fc922270)。\n\n## 一致性哈希\n\n- [Consistent Hashing](http://www.tom-e-white.com/2007/11/consistent-hashing.html) ，这是一个一致性哈希的简单教程，其中还有代码示例。\n- [Consistent Hashing: Algorithmic Tradeoffs](https://medium.com/@dgryski/consistent-hashing-algorithmic-tradeoffs-ef6b8e2fcae8) ，这篇文章讲述了一致性哈希的一些缺陷和坑，以及各种哈希算法的性能比较，最后还给了一组代码仓库，其中有各种哈希算法的实现。\n- [Distributing Content to Open Connect](https://medium.com/netflix-techblog/distributing-content-to-open-connect-3e3e391d4dc9) ，Netflix 的一个对一致性哈希的实践，提出了 Uniform Consistent Hashing，是挺有意思的一篇文章。\n- [Consistent Hashing in Cassandra](https://blog.imaginea.com/consistent-hashing-in-cassandra/) ，这是 Cassandra 中使用到的一致性哈希的相关设计。\n\n## 数据库分布式\n\n- [Life Beyond Distributed Transactions](https://queue.acm.org/detail.cfm?id=3025012) ，该文是 Salesforce 的软件架构师帕特·赫兰德（Pat Helland）于 2016 年 12 月发表的针对其在 2007 年 CIDR（创新数据库研究会议）上首次发表的同名文章的更新和缩写版本。业界谈到分布式事务通常指两段提交 2PC 事务（Spring/JEE 中 JTA 等) 或者 Paxos 与 Raft，这些事务都有明显缺点和局限性。\n\n  而赫兰德在本文讨论的是另外一种基于本地事务情况下的事务机制，它是基于实体和活动（Activity）的概念，其实类似 DDD 聚合根和领域事件的概念，这种工作流类型事务虽然需要程序员介入，依靠消息系统实现，但可以实现接近无限扩展的大型系统。赫兰德文中提出了重要的观点：“如果你不能使用分布式事务，那么你就只能使用工作流。”\n\n- [How Sharding Works](https://medium.com/@jeeyoungk/how-sharding-works-b4dec46b3f6) ，这是一篇很不错的探讨数据 Sharding 的文章。基本上来说，数据 Sharding 可能的问题都在这篇文章里谈到了。\n\n- [Why you don’t want to shard](https://www.percona.com/blog/2009/08/06/why-you-dont-want-to-shard/) ，这是 Percona 的一篇文章，其中表达了，不到万不得已不要做数据库分片。是的，最好还是先按业务来拆分，先把做成微服务的架构，然后把数据集变简单，然后再做 Sharding 会更好。\n\n- [How to Scale Big Data Applications](https://www.percona.com/sites/default/files/presentations/How to Scale Big Data Applications.pdf) ，这也是 Percona 给出的一篇关于怎样给大数据应用做架构扩展的文章。值得一读。\n\n- [MySQL Sharding with ProxySQL](https://www.percona.com/blog/2016/08/30/mysql-sharding-with-proxysql/) ，用 ProxySQL 来支撑 MySQL 数据分片的一篇实践文章。\n\n## 缓存\n\n- [缓存更新的套路](https://coolshell.cn/articles/17416.html)，这是我在 CoolShell 上写的缓存更新的几个设计模式，包括 Cache Aside、Read/Write Through、Write Behind Caching。\n- [Design Of A Modern Cache](http://highscalability.com/blog/2016/1/25/design-of-a-modern-cache.html) ，设计一个现代化的缓存系统需要注意到的东西。\n- [Netflix: Caching for a Global Netflix](https://medium.com/netflix-techblog/caching-for-a-global-netflix-7bcc457012f1) ，Netflix 公司的全局缓存架构实践。\n- [Facebook: An analysis of Facebook photo caching](https://code.facebook.com/posts/220956754772273/an-analysis-of-facebook-photo-caching/) ，Facebook 公司的图片缓存使用分析，这篇文章挺有意思的，用数据来调优不同的缓存大小和算法。\n- [How trivago Reduced Memcached Memory Usage by 50%](https://tech.trivago.com/2017/12/19/how-trivago-reduced-memcached-memory-usage-by-50/) ，Trivago 公司一篇分享自己是如何把 Memcached 的内存使用率降了一半的实践性文章。很有意思，可以让你学到很多东西。\n- [Caching Internal Service Calls at Yelp](https://engineeringblog.yelp.com/2018/03/caching-internal-service-calls-at-yelp.html) ，Yelp 公司的缓存系统架构。\n\n## 消息队列\n\n- [Understanding When to use RabbitMQ or Apache Kafka](https://content.pivotal.io/blog/understanding-when-to-use-rabbitmq-or-apache-kafka) ，什么时候使用 RabbitMQ，什么时候使用 Kafka，通过这篇文章可以让你明白如何做技术决策。\n- [Trello: Why We Chose Kafka For The Trello Socket Architecture](https://tech.trello.com/why-we-chose-kafka/) ，Trello 的 Kafka 架构分享。\n- [LinkedIn: Running Kafka At Scale](https://engineering.linkedin.com/kafka/running-kafka-scale) ，LinkedIn 公司的 Kafka 架构扩展实践。\n- [Should You Put Several Event Types in the Same Kafka Topic?](https://www.confluent.io/blog/put-several-event-types-kafka-topic/) ，这个问题可能经常困扰你，这篇文章可以为你找到答案。\n- [Billions of Messages a Day - Yelp’s Real-time Data Pipeline](https://engineeringblog.yelp.com/2016/07/billions-of-messages-a-day-yelps-real-time-data-pipeline.html) ，Yelp 公司每天十亿级实时消息的架构。\n- [Uber: Building Reliable Reprocessing and Dead Letter Queues with Kafka](https://eng.uber.com/reliable-reprocessing/) ，Uber 公司的 Kafka 应用。\n- [Uber: Introducing Chaperone: How Uber Engineering Audits Kafka End-to-End](https://eng.uber.com/chaperone/) ，Uber 公司对 Kafka 消息的端到端审计。\n- [Publishing with Apache Kafka at The New York Times](https://open.nytimes.com/publishing-with-apache-kafka-at-the-new-york-times-7f0e3b7d2077) ，纽约时报的 Kafka 工程实践。\n- [Kafka Streams on Heroku](https://blog.heroku.com/kafka-streams-on-heroku) ，Heroku 公司的 Kafka Streams 实践。\n- [Salesforce: How Apache Kafka Inspired Our Platform Events Architecture](https://engineering.salesforce.com/how-apache-kafka-inspired-our-platform-events-architecture-2f351fe4cf63) ，Salesforce 的 Kafka 工程实践。\n- [Exactly-once Semantics are Possible: Here’s How Kafka Does it](https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/) ，怎样用 Kafka 让只发送一次的语义变为可能。这是业界中一个很难的工程问题。\n- [Delivering billions of messages exactly once](https://segment.com/blog/exactly-once-delivery/) 同上，这也是一篇挑战消息只发送一次这个技术难题的文章。\n- [Benchmarking Streaming Computation Engines at Yahoo!](https://yahooeng.tumblr.com/post/135321837876/benchmarking-streaming-computation-engines-at)。Yahoo! 的 Storm 团队在为他们的流式计算做技术选型时，发现市面上缺乏针对不同计算平台的性能基准测试。于是，他们研究并设计了一种方案来做基准测试，测试了 Apache Flink、Apache Storm 和 Apache Spark 这三种平台。文中给出了结论和具体的测试方案。（如果原文链接不可用，请尝试搜索引擎对该网页的快照。）\n\n## 关于日志方面\n\n- [Using Logs to Build a Solid Data Infrastructure - Martin Kleppmann](https://www.confluent.io/blog/using-logs-to-build-a-solid-data-infrastructure-or-why-dual-writes-are-a-bad-idea/) ，设计基于 log 结构应用架构的一篇不错的文章。\n- [Building DistributedLog: High-performance replicated log service](https://blog.twitter.com/engineering/en_us/topics/infrastructure/2015/building-distributedlog-twitter-s-high-performance-replicated-log-servic.html) ，Distributed 是 Twitter 2016 年 5 月份开源的一个分布式日志系统。在 Twitter 内部已经使用 2 年多。其主页在 [distributedlog.io](http://distributedlog.io/)。这篇文章讲述了这个高性能日志系统的一些技术细节。另外，其技术负责人是个中国人，其在微信公众号中也分享过这个系统 [Twitter 高性能分布式日志系统架构解析](https://mp.weixin.qq.com/s?__biz=MzAwMDU1MTE1OQ==&mid=403051208&idx=1&sn=1694ac05acbcb5ca53c88bfac8a68856&scene=2&srcid=1224xZuQ9QQ4sRmiPVdHTppL)。\n- [LogDevice: a distributed data store for logs](https://code.facebook.com/posts/357056558062811/logdevice-a-distributed-data-store-for-logs/) ，Facebook 分布式日志系统方面的一些工程分享。\n\n## 关于性能方面\n\n- [Understand Latency](http://highscalability.com/latency-everywhere-and-it-costs-you-sales-how-crush-it) ，这篇文章收集并整理了一些和系统响应时间相关的文章，可以让你全面了解和 Latency 有关的系统架构和设计经验方面的知识。\n- [Common Bottlenecks](http://highscalability.com/blog/2012/5/16/big-list-of-20-common-bottlenecks.html) ，文中讲述了 20 个常见的系统瓶颈。\n- [Performance is a Feature](https://blog.codinghorror.com/performance-is-a-feature/) ，Coding Horror 上的一篇让你关注性能的文章。\n- [Make Performance Part of Your Workflow](https://codeascraft.com/2014/12/11/make-performance-part-of-your-workflow/) ，这篇文章是图书《[Designing for Performance](http://shop.oreilly.com/product/0636920033578.do)》中的节选（国内没有卖的），其中给出来了一些和性能有关的设计上的平衡和美学。\n- [CloudFlare: How we built rate limiting capable of scaling to millions of domains](https://blog.cloudflare.com/counting-things-a-lot-of-different-things/)，讲述了 CloudFlare 公司是怎样实现他们的限流功能的。从最简单的每客户 IP 限流开始分析，进一步讲到 anycast，在这种情况下 PoP 的分布式限流是怎样实现的，并详细解释了具体的算法。\n\n## 关于搜索方面\n\n- [Instagram: Search Architecture](https://instagram-engineering.com/search-architecture-eeb34a936d3a)\n- [eBay: The Architecture of eBay Search](http://www.cs.otago.ac.nz/homepages/andrew/papers/2017-8.pdf)\n- [eBay: Improving Search Engine Efficiency by over 25%](https://www.ebayinc.com/stories/blogs/tech/making-e-commerce-search-faster/)\n- [LinkedIn: Introducing LinkedIn’s new search architecture](https://engineering.linkedin.com/search/did-you-mean-galene)\n- [LinkedIn: Search Federation Architecture at LinkedIn](https://engineering.linkedin.com/blog/2018/03/search-federation-architecture-at-linkedin)\n- [Slack: Search at Slack](https://slack.engineering/search-at-slack-431f8c80619e)\n- [DoorDash: Search and Recommendations at DoorDash](https://blog.doordash.com/powering-search-recommendations-at-doordash-8310c5cfd88c)\n- [Twitter: Search Service at Twitter (2014)](https://blog.twitter.com/engineering/en_us/a/2014/building-a-complete-tweet-index.html)\n- [Pinterest: Manas: High Performing Customized Search System](https://medium.com/@Pinterest_Engineering/manas-a-high-performing-customized-search-system-cf189f6ca40f)\n- [Sherlock: Near Real Time Search Indexing at Flipkart](https://tech.flipkart.com/sherlock-near-real-time-search-indexing-95519783859d)\n- [Airbnb: Nebula: Storage Platform to Build Search Backends](https://medium.com/airbnb-engineering/nebula-as-a-storage-platform-to-build-airbnbs-search-backends-ecc577b05f06)\n\n## 各公司的架构实践\n\n[High Scalability](http://highscalability.com/) ，这个网站会定期分享一些大规模系统架构是怎样构建的，下面是迄今为止各个公司的架构说明。\n\n- [YouTube Architecture](http://highscalability.com/youtube-architecture)\n- [Scaling Pinterest](http://highscalability.com/blog/2013/4/15/scaling-pinterest-from-0-to-10s-of-billions-of-page-views-a.html)\n- [Google Architecture](http://highscalability.com/google-architecture)\n- [Scaling Twitter](http://highscalability.com/scaling-twitter-making-twitter-10000-percent-faster)\n- [The WhatsApp Architecture](http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html)\n- [Flickr Architecture](http://highscalability.com/flickr-architecture)\n- [Amazon Architecture](http://highscalability.com/amazon-architecture)\n- [Stack Overflow Architecture](http://highscalability.com/blog/2009/8/5/stack-overflow-architecture.html)\n- [Pinterest Architecture](http://highscalability.com/blog/2012/5/21/pinterest-architecture-update-18-million-visitors-10x-growth.html)\n- [Tumblr Architecture](http://highscalability.com/blog/2012/2/13/tumblr-architecture-15-billion-page-views-a-month-and-harder.html)\n- [Instagram Architecture](http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html)\n- [TripAdvisor Architecture](http://highscalability.com/blog/2011/6/27/tripadvisor-architecture-40m-visitors-200m-dynamic-page-view.html)\n- [Scaling Mailbox](http://highscalability.com/blog/2013/6/18/scaling-mailbox-from-0-to-one-million-users-in-6-weeks-and-1.html)\n- [Salesforce Architecture](http://highscalability.com/blog/2013/9/23/salesforce-architecture-how-they-handle-13-billion-transacti.html)\n- [ESPN Architecture](http://highscalability.com/blog/2013/11/4/espns-architecture-at-scale-operating-at-100000-duh-nuh-nuhs.html)\n- [Uber Architecture](http://highscalability.com/blog/2015/9/14/how-uber-scales-their-real-time-market-platform.html)\n- [DropBox Design](https://www.youtube.com/watch?v=PE4gwstWhmc)\n- [Splunk Architecture](http://www.splunk.com/view/SP-CAAABF9)\n\n# 小结\n\n今天我们分享的内容是高手成长篇分布式架构部分的最后一篇——分布式架构工程设计，讲述了设计原则、设计模式等方面的内容，尤其整理和推荐了国内外知名企业的设计思路和工程实践，十分具有借鉴意义。\n\n下篇文章中，我们将分享微服务架构方面的内容。敬请期待。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/11232\" > </iframe>","categories":["左耳听风"]},{"title":"084丨程序员练级攻略：微服务","url":"/posts/4176675349.html","content":"\n\n\n微服务是分布式系统中最近比较流行的架构模型，也是 SOA 架构的一个进化。微服务架构并不是银弹，所以，也不要寄希望于微服务架构能够解决所有的问题。微服务架构主要解决的是如何快速地开发和部署我们的服务，这对于一个能够适应快速开发和成长的公司是非常必要的。同时我也觉得，微服务中有很多很不错的想法和理念，所以学习微服务是每一个技术人员迈向卓越的架构师的必经之路。\n\n首先，你需要看一下，Martin Fowler 的这篇关于微服务架构的文档 - [Microservice Architecture](http://martinfowler.com/articles/microservices.html) （[中译版](https://blog.csdn.net/wurenhai/article/details/37659335)），这篇文章说明了微服务的架构与传统架构的不同之处在于，微服务的每个服务与其数据库都是独立的，可以无依赖地进行部署。你也可以看看 Martin Fowler 老人家现身说法的[视频](https://www.youtube.com/watch?v=wgdBVIX9ifA)。\n\n另外，你还可以简单地浏览一下，各家对微服务的理解。\n\n- [AWS 的理解 - What are Microservices?](https://aws.amazon.com/microservices/)。\n- [Microsoft 的理解 - Microservices architecture style](https://docs.microsoft.com/en-us/azure/architecture/guide/architecture-styles/microservices)。\n- [Pivotal 的理解 - Microservices](https://pivotal.io/microservices)。\n\n# 微服务架构\n\n接下来，你可以看一下 [IBM 红皮书：Microservices Best Practices for Java](https://www.redbooks.ibm.com/redbooks/pdfs/sg248357.pdf) ，这本书非常好，不但有通过把 Spring Boot 和 Dropwizard 来架建 Java 的微服务，而且还谈到了一些标准的架构模型，如服务注册、服务发现、API 网关、服务通讯、数据处理、应用安全、测试、部署、运维等，是相当不错的一本书。\n\n当然，有一本书你也可以读一下—— [微服务设计](https://book.douban.com/subject/26772677/)。这本书全面介绍了微服务的建模、集成、测试、部署和监控，通过一个虚构的公司讲解了如何建立微服务架构。主要内容包括认识微服务在保证系统设计与组织目标统一上的重要性，学会把服务集成到已有系统中，采用递增手段拆分单块大型应用，通过持续集成部署微服务，等等。\n\n与此相似的，也有其它的一系列文章，值得一读。\n\n下面是 Nginx 上的一组微服务架构的系列文章。\n\n- [Introduction to Microservices](https://www.nginx.com/blog/introduction-to-microservices/)\n- [Building Microservices: Using an API Gateway](https://www.nginx.com/blog/building-microservices-using-an-api-gateway/)\n- [Building Microservices: Inter-Process Communication in a Microservices Architecture](https://www.nginx.com/blog/building-microservices-inter-process-communication/)\n- [Service Discovery in a Microservices Architecture](https://www.nginx.com/blog/service-discovery-in-a-microservices-architecture/)\n- [Event-Driven Data Management for Microservices](https://www.nginx.com/blog/event-driven-data-management-microservices/)\n- [Choosing a Microservices Deployment Strategy](https://www.nginx.com/blog/deploying-microservices/)\n- [Refactoring a Monolith into Microservices](https://www.nginx.com/blog/refactoring-a-monolith-into-microservices/)\n\n下面这是 [Auto0 Blog](https://auth0.com/blog/) 上一系列的微服务的介绍，有代码演示。\n\n- [An Introduction to Microservices, Part 1](https://auth0.com/blog/an-introduction-to-microservices-part-1/)\n- [API Gateway. An Introduction to Microservices, Part 2](https://auth0.com/blog/an-introduction-to-microservices-part-2-API-gateway/)\n- [An Introduction to Microservices, Part 3: The Service Registry](https://auth0.com/blog/an-introduction-to-microservices-part-3-the-service-registry/)\n- [Intro to Microservices, Part 4: Dependencies and Data Sharing](https://auth0.com/blog/introduction-to-microservices-part-4-dependencies/)\n- [API Gateway: the Microservices Superglue](https://auth0.com/blog/apigateway-microservices-superglue/)\n\n还有 Dzone 的这个 Spring Boot 的教程。\n\n- [Microservices With Spring Boot - Part 1 - Getting Started](https://dzone.com/articles/microservices-with-spring-boot-part-1-getting-star)\n- [Microservices With Spring Boot - Part 2 - Creating a Forex Microservice](https://dzone.com/articles/microservices-with-spring-boot-part-2-creating-a-f)\n- [Microservices With Spring Boot - Part 3 - Creating Currency Conversion Microservice](https://dzone.com/articles/microservices-with-spring-boot-part-3-creating-cur)\n- [Microservices With Spring Boot - Part 4 - Using Ribbon for Load Balancing](https://dzone.com/articles/microservices-with-spring-boot-part-4-using-ribbon)\n- [Microservices With Spring Boot - Part 5 - Using Eureka Naming Server](https://dzone.com/articles/microservices-with-spring-boot-part-5-using-eureka)\n\n当然，如果你要玩得时髦一些的话，我推荐你使用下面的这套架构。\n\n- **前端**：[React.js](https://reactjs.org/) 或 [Vue.js](https://vuejs.org/)。\n- **后端**：[Go 语言](https://golang.org/) + 微服务工具集 [Go kit](https://gokit.io/) ，因为是微服务了，所以，每个服务的代码就简单了。既然简单了，也就可以用任何语言了，所以，我推荐 Go 语言。\n- **通讯**：[gRPC](https://grpc.io/)，这是 Google 远程调用的一个框架，它比 Restful 的调用要快 20 倍到 50 倍的样子。\n- **API**：[Swagger](https://swagger.io/) ，Swagger 是一种 Restful API 的简单但强大的表示方式，标准的，语言无关，这种表示方式不但人可读，而且机器可读。可以作为 Restful API 的交互式文档，也可以作为 Restful API 形式化的接口描述，生成客户端和服务端的代码。今天，所有的 API 应该都通过 Swagger 来完成。\n- **网关**：[Envoy](https://envoyproxy.github.io/) 其包含了服务发现、负载均衡和熔断等这些特性，也是一个很有潜力的网关。当然，Kubernetes 也是很好的，而且它也是高扩展的，所以，完全可以把 Envoy 通过 Ingress 集成进 Kubernetes。这里有一个开源项目就是干这个事的 - [contour](https://github.com/heptio/contour)。\n- **日志监控**：[fluentd](https://www.fluentd.org/) + [ELK](https://www.elastic.co/webinars/introduction-elk-stack) 。\n- **指标监控**：[Prometheus](https://prometheus.io/) 。\n- **调用跟踪**：[Jaeger](http://jaeger.readthedocs.io/en/latest/) 或是 [Zipkin](http://zipkin.io/)，当然，后者比较传统一些，前者比较时髦，最重要的是，其可以和 Prometheus 和 Envory 集成。\n- **自动化运维**：[Docker](https://docker.io/) + [Kubernetes](https://kubernetes.io/) 。\n\n# 微服务和 SOA\n\n在对微服务有了一定的认识以后，一定有很多同学分不清楚微服务和 SOA 架构，对此，你可以看一下这本电子书 - 《[Microservices vs. Service-Oriented Architecture](https://www.nginx.com/resources/library/microservices-vs-soa/)》。通过这本书，你可以学到，服务化架构的一些事实，还有基础的 SOA 和微服务的架构知识，以及两种架构的不同。这本书的作者马克·理查兹（Mark Richards）同学拥有十年以上的 SOA 和微服务架构的设计和实现的经验。\n\n另外，还有几篇其它对比 SOA 和微服务的文章你也可以看看。\n\n- [DZone: Microservices vs. SOA](https://dzone.com/articles/microservices-vs-soa-2)\n- [DZone: Microservices vs. SOA - Is There Any Difference at All?](https://dzone.com/articles/microservices-vs-soa-is-there-any-difference-at-al)\n- [Microservices, SOA, and APIs: Friends or enemies?](https://www.ibm.com/developerworks/websphere/library/techarticles/1601_clark-trs/1601_clark.html)\n\n除此之外，我们还需要知道微服务和其它架构的一些不同和比较，这样我们就可以了解微服务架构的优缺点。下面几篇文章将帮助获得这些知识。\n\n- [PaaS vs. IaaS for Microservices Architectures: Top 6 Differences](http://blog.altoros.com/microservices-architectures-paas-vs-iaas-top-6-differences.html)\n- [Microservices vs. Monolithic Architectures: Pros, Cons, and How Cloud Foundry (PaaS) Can Help](https://www.slideshare.net/altoros/microservices-vs-monolithic-architectures-pros-and-cons)\n- [Microservices - Not A Free Lunch!](http://highscalability.com/blog/2014/4/8/microservices-not-a-free-lunch.html)\n- [The Hidden Costs Of Microservices](https://www.stackbuilders.com/news/the-hidden-costs-of-microservices)\n\n# 设计模式和最佳实践\n\n然后，你可以看一下微服务的一些设计模式。\n\n- [Microservice Patterns](http://microservices.io/)，微服务架构的设计模式和最佳实践。\n- [Microservice Antipatterns and Pitfalls](https://www.oreilly.com/ideas/microservices-antipatterns-and-pitfalls)，微服务架构的一些已知的反模式和陷阱。\n- [Microservice Architecture: All The Best Practices You Need To Know](https://codingsans.com/blog/microservice-architecture-best-practices)，这是一篇长文，里面讲述了什么是微服务、微服务架构的优缺点、微服务最大的挑战和解决方案是什么、如何避免出错，以及构建微服务架构的最佳实践等多方面的内容。推荐阅读。\n- [Best Practices for Building a Microservice Architecture](https://www.vinaysahni.com/best-practices-for-building-a-microservice-architecture) ，这篇文章分享了构建微服务架构的最佳实践。\n- [Simplicity by Distributing Complexity](https://jobs.zalando.com/tech/blog/simplicity-by-distributing-complexity/)，这是一篇讲如何使用事件驱动构建微服务架构的文章，其中有很多不错的设计上的基本原则。\n\n# 相关资源\n\n- [Microservices Resource Guide](http://martinfowler.com/microservices/) ，这个网页上是 Martin Fowler 为我们挑选的和微服务相关的文章、视频、书或是 podcast。\n- [Awesome Microservices](https://github.com/mfornos/awesome-microservices/) ，一个各种微服务资源和相关项目的集中地。\n\n# 小结\n\n好了，总结一下今天的内容。我认为，微服务中有很多很不错的想法和理念，所以学习微服务是每一个技术人员迈向卓越的架构师的必经之路。在这篇文章中，我先给出了 AWS、Microsoft 和 Pivotal 对微服务的理解；然后给出了好几个系列的教程，帮你全面学习和理解微服务架构；然后通过一系列文章帮你来区分何为微服务，何为 SOA；最后给出了微服务架构的设计模式和最佳实践，以及相关资源。相信通过这一系列内容的学习，你一定会对微服务有全面、透彻的理解。\n\n下篇文章，我们将讲述的容器化和自动化运维方面的内容。敬请期待。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/11116\" > </iframe>","categories":["左耳听风"]},{"title":"086丨程序员练级攻略：机器学习和人工智能","url":"/posts/2064791055.html","content":"\n\n\n我之前写过一篇机器学习的入门文章，因为我也是在入门和在学习的人，所以，那篇文章和这篇机器学习和人工智能方向的文章可能都会有点太肤浅。如果你有更好的学习方式或资料，欢迎补充。\n\n# 基本原理简介\n\n我们先来介绍一下机器学习的基本原理。\n\n机器学习主要有两种方式，一种是监督式学习（Supervised Learning），另一种是非监督式学习（Unsupervised Learning）。下面简单地说一下这两者的不同。\n\n- **监督式学习（Supervised Learning）**。所谓监督式学习，也就是说，我们需要提供一组学习样本，包括相关的特征数据和相应的标签。我们的程序可以通过这组样本来学习相关的规律或是模式，然后通过得到的规律或模式来判断没有被打过标签的数据是什么样的数据。\n\n  举个例子，假设需要识别一些手写的数字，我们要找到尽可能多的手写体数字的图像样本，然后人工或是通过某种算法来明确地标注上什么是这些手写体的图片，谁是 1，谁是 2，谁是 3…… 这组数据叫样本数据，又叫训练数据（training data）。然后通过机器学习的算法，找到每个数字在不同手写体下的特征，找到规律和模式。通过得到的规律或模式来识别那些没有被打过标签的手写数据，以此完成识别手写体数字的目的。\n\n- **非监督式学习（Unsupervised Learning）**。对于非监督式学习，也就是说，数据是没有被标注过的，所以相关的机器学习算法需要找到这些数据中的共性。因为大量的数据是没被被标识过的，所以这种学习方式可以让大量的未标识的数据能够更有价值。而且，非监督式学习，可以为我们找到人类很难发现的数据里的规律或模型，所以也有人称这种学习为“特征点学习”，其可以让我们自动地为数据进行分类，并找到分类的模型。\n\n  一般来说，非监督式学习会应用在一些交易型的数据中。比如，你有一堆堆的用户购买数据，但是对于人类来说，我们很难找到用户属性和购买商品类型之间的关系。所以，非监督式学习算法可以帮助我们找到它们之间的关系。比如，一个在某年龄段的女性购买了某种肥皂，有可能说明这个女性在怀孕期，或是某人购买儿童用品，有可能说明这个人的关系链中有孩子，等等。于是，这些信息会被用作一些所谓的精准市场营销活动，从而可以增加商品销量。\n\n我们这么来说吧，监督式学习是在被告诉过了正确的答案后的学习，而非监督式学习是在没有被告诉正确答案时的学习。所以，非监督式学习是在大量的非常乱的数据中找寻一些潜在的关系，这个成本也比较高。非监督式学习经常被用来检测一些不正常的事情发生，比如信用卡的诈骗或是盗刷。也被用在推荐系统，比如买了这个商品的人又买了别的什么商品，或是如果某个人喜欢某篇文章、某个音乐、某个餐馆，那么他可能会喜欢某个车、某个明星或某个地方。\n\n在监督式学习算法下，我们可以用一组“狗”的照片来确定某个照片中的物体是不是狗。而在非监督式学习算法下，我们可以通过一个照片来找到其中有与其相似的事物的照片。这两种学习方式都有些有用的场景。\n\n关于机器学习，你可以读一读 [Machine Learning is Fun!](https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471) ，这篇文章（[中文翻译版](https://zhuanlan.zhihu.com/p/24339995)）恐怕是全世界最简单的入门资料了。\n\n- [Data Science Simplified Part 1: Principles and Process](https://becominghuman.ai/data-science-simplified-principles-and-process-b06304d63308)\n- [Data Science Simplified Part 2: Key Concepts of Statistical Learning](https://towardsdatascience.com/data-science-simplified-key-concepts-of-statistical-learning-45648049709e)\n- [Data Science Simplified Part 3: Hypothesis Testing](https://towardsdatascience.com/data-science-simplified-hypothesis-testing-56e180ef2f71)\n- [Data Science Simplified Part 4: Simple Linear Regression Models](https://towardsdatascience.com/data-science-simplified-simple-linear-regression-models-3a97811a6a3d)\n- [Data Science Simplified Part 5: Multivariate Regression Models](https://towardsdatascience.com/data-science-simplified-part-5-multivariate-regression-models-7684b0489015)\n- [Data Science Simplified Part 6: Model Selection Methods](https://towardsdatascience.com/data-science-simplified-part-6-model-selection-methods-2511cbdf7cb0)\n- [Data Science Simplified Part 7: Log-Log Regression Models](https://towardsdatascience.com/data-science-simplified-part-7-log-log-regression-models-499ecd1495f0)\n- [Data Science Simplified Part 8: Qualitative Variables in Regression Models](https://towardsdatascience.com/data-science-simplified-part-8-qualitative-variables-in-regression-models-d1817d56245c)\n- [Data Science Simplified Part 9: Interactions and Limitations of Regression Models](https://towardsdatascience.com/data-science-simplified-part-9-interactions-and-limitations-of-regression-models-4702dff03820)\n- [Data Science Simplified Part 10: An Introduction to Classification Models](https://towardsdatascience.com/data-science-simplified-part-10-an-introduction-to-classification-models-82490f6c171f)\n- [Data Science Simplified Part 11: Logistic Regression](https://towardsdatascience.com/data-science-simplified-part-11-logistic-regression-5ae8d994bf0e)\n\n# 相关课程\n\n接下来，我们需要比较专业地学习一下机器学习了。\n\n在学习机器学习之前，我们需要学习数据分析，所以，我们得先学一些大数据相关的东西，也就是 Data Science 相关的内容。下面是两个不错的和数据科学相关的教程以及一个资源列表。\n\n- [UC Berkeley’s Data 8: The Foundations of Data Science](http://data8.org/) 和电子书 [Computational and Inferential Thinking](https://www.inferentialthinking.com/) 会讲述数据科学方面非常关键的概念，会教你在数据中找到数据的关联、预测和相关的推断。\n- [Learn Data Science](https://github.com/nborwankar/LearnDataScience) ，这是 GitHub 上的一本电子书，主要是一些数据挖掘的算法，比如线性回归、逻辑回归、随机森林、K-Means 聚类的数据分析。然后，[donnemartin/data-science-ipython-notebooks](https://github.com/donnemartin/data-science-ipython-notebooks#scikit-learn) 这个代码仓库中用 TensorFlow、scikit-learn、Pandas、NumPy、Spark 等把这些经典的例子实现了个遍。\n- [Data Science Resources List](https://www.datascienceweekly.org/data-science-resources/the-big-list-of-data-science-resources) ，这个网站上有一个非常长的和数据科学相关的资源列表，你可以从中得到很多你想要的东西。\n\n之后，有下面几门不错的在线机器学习的课程供你入门，也是非常不错。\n\n- 吴恩达教授（Andrew Ng）在 [Coursera 上的免费机器学习课程](https://www.coursera.org/learn/machine-learning) 非常棒。我强烈建议从此入手。对于任何拥有计算机或科学学位的人，或是还能记住一点点数学知识的人来说，都应该非常容易入门。这个斯坦福大学的课程请尽量拿满分。可以在 [网易公开课](http://open.163.com/special/opencourse/machinelearning.html) 中找到这一课程。除此之外，吴恩达教授还有一组新的和深度学习相关的课程，现在可以在网易公开课上免费学习——[Deep Learning Specialization](https://mooc.study.163.com/smartSpec/detail/1001319001.htm)。\n- [Deep Learning by Google](https://www.udacity.com/course/deep-learning--ud730) ，Google 的一个关于深度学习的在线免费课程，其支持中英文。这门课会教授你如何训练和优化基本神经网络、卷积神经网络和长短期记忆网络。你将通过项目和任务接触完整的机器学习系统 TensorFlow。\n- 卡内基梅隆大学汤姆·米切尔（Tom Mitchell）的机器学习 [英文原版视频与课件 PDF](http://www.cs.cmu.edu/~tom/10701_sp11/lectures.shtml) 。\n- 2013 年加利福尼亚理工学院亚瑟·阿布 - 穆斯塔法（Yaser Abu-Mostafa）的 Learning from Data [课程视频及课件 PDF](http://work.caltech.edu/lectures.html)，内容更适合进阶。\n- 关于神经网络方面，YouTube 上有一个非常火的课程视频，由宾夕法尼亚大学的雨果·拉罗歇尔（Hugo Larochelle）出品的教学课程 - [Neural networks class - Université de Sherbrooke ](https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH)。\n\n除此之外，还有很多的在线大学课程可以供你学习。比如：\n\n- 斯坦福大学的《[统计学学习](https://lagunita.stanford.edu/courses/HumanitiesandScience/StatLearning/Winter2015/about)》、《[机器学习](http://cs229.stanford.edu/)》、《[卷积神经网络](http://cs231n.stanford.edu/)》、《[深度学习之自然语言处理](http://cs224d.stanford.edu/)》等。\n- 麻省理工大学的《[神经网络介绍](http://ocw.mit.edu/courses/brain-and-cognitive-sciences/9-641j-introduction-to-neural-networks-spring-2005/index.htm) 》、《[机器学习](http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-867-machine-learning-fall-2006/)》、《[预测](http://ocw.mit.edu/courses/sloan-school-of-management/15-097-prediction-machine-learning-and-statistics-spring-2012/index.htm)》等。\n\n更多的列表，请参看——[Awesome Machine Learning Courses](https://github.com/RatulGhosh/awesome-machine-learning)。\n\n# 相关图书\n\n- 《[Pattern Recognition and Machine Learning](https://book.douban.com/subject/2061116/)》，这本书是机器学习领域的圣经之作。该书也是众多高校机器学习研究生课程的教科书，Google 上有[PDF 版的下载](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop - Pattern Recognition And Machine Learning - Springer  2006.pdf)。这本书很经典，但并不适合入门来看。GitHub 上有这本中的 [Matlab 实现](https://github.com/PRML/PRMLT)。\n\n- 下面这两本电子书也是比较经典的，其中讲了很多机器学习的知识，可以当做手册或字典。\n\n  - 《[Understanding Machine Learning: From Theory to Algorithms](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf)》。\n  - 《[The Elements of Statistical Learning - Second Edition](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)》。\n\n- 《[Deep Learning: Adaptive Computation and Machine Learning series](https://book.douban.com/subject/27087503/)》 中文翻译为《深度学习》。这本书由全球知名的三位专家伊恩·古德费洛（Ian Goodfellow）、友华·本吉奥（Yoshua Bengio）和亚伦·考维尔（Aaron Courville）撰写，是深度学习领域奠基性的经典教材。\n\n  全书内容包括 3 部分：第 1 部分介绍基本的数学工具和机器学习的概念，它们是深度学习的预备知识；第 2 部分系统深入地讲解现今已成熟的深度学习方法和技术；第 3 部分讨论某些具有前瞻性的方向和想法，它们被公认为是深度学习未来的研究重点。这本书的官网为 “[deeplearningbook.org](http://www.deeplearningbook.org/)”，在 GitHub 上也有中文翻译 - 《[Deep Learning 中文翻译](https://github.com/exacity/deeplearningbook-chinese)》。\n\n- 《[Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/)》（[中文翻译版](https://tigerneil.gitbooks.io/neural-networks-and-deep-learning-zh/content/)），这是一本非常不错的神经网络的入门书，在[豆瓣上评分 9.5 分](https://book.douban.com/subject/26727997/)，从理论讲到了代码。虽然有很多数学公式，但是有代码相助，就不难理解了。其中讲了很多如激活函数、代价函数、随机梯度下降、反向传播、过度拟合和规范化、权重初始化、超参数优化、卷积网络的局部感受野、混合层、特征映射的东西。\n\n- 《[Introduction to Machine Learning with Python](https://book.douban.com/subject/26279609/)》，算是本不错的入门书，也是本比较易读的英文书。其是以 Scikit-Learn 框架来讲述的。如果你用过 Scikit 这个框架，那么你学这本书还是很不错的。\n\n- 《[Hands-On Machine Learning with Scikit-Learn and TensorFlow](https://book.douban.com/subject/26840215/) 》，这是一门以 TensorFlow 为工具的入门书，其用丰富的例子从实站的角度来让你学习。这本书对于无基础的人也是适合的，对于小白来说虽然略难但是受益匪浅。\n\n# 相关文章\n\n除了上述的那些课程和图书外，下面这些文章也很不错。\n\n- YouTube 上的 Google Developers 的 [Machine Learning Recipes with Josh Gordon](https://www.youtube.com/playlist?list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal) ，这 9 集视频，每集不到 10 分钟，从 Hello World 讲到如何使用 TensorFlow，非常值得一看。\n- 还有 [Practical Machine Learning Tutorial with Python Introduction](https://pythonprogramming.net/machine-learning-tutorial-python-introduction/) 上面一系列的用 Python 带着你玩 Machine Learning 的教程。\n- Medium 上的 [Machine Learning - 101](https://medium.com/machine-learning-101) ，讲述了好些我们上面提到过的经典算法。\n- Medium 上的 [Marchine Learning for Humans](https://medium.com/machine-learning-for-humans)。\n- [Dr. Jason Brownlee 的博客](https://machinelearningmastery.com/blog/) ，也非常值得一读，其中好多的 “How-To”，会让你有很多的收获。\n- [Rules of Machine Learning: Best Practices for ML Engineering](http://martin.zinkevich.org/rules_of_ml/rules_of_ml.pdf) ，一些机器学习相关的最佳实践。\n- [i am trask](http://iamtrask.github.io) ，也是一个很不错的博客。\n- 关于 Deep Learning 中的神经网络，YouTube 上有介绍视频 [Neural Networks](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)。\n- 麻省理工学院的电子书 [Deep Learning](http://www.deeplearningbook.org)。\n- 用 Python 做自然语言处理[Natural Language Processing with Python](http://www.nltk.org/book/)。\n- 最后一个是 Machine Learning 和 Deep Learning 的相关教程列表，[Machine Learning & Deep Learning Tutorials](https://github.com/ujjwalkarn/Machine-Learning-Tutorials)。\n\n下面是一些和神经网络相关的不错的文章。\n\n- [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) ，这是一篇必读的文章 ，告诉你为什么要学 RNN，以及展示了最简单的 NLP 形式。\n- [Neural Networks, Manifolds, and Topology](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/) ，这篇文章可以帮助你理解神经网络的一些概念。\n- [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) ，解释了什么是 LSTM 的内在工作原理。\n- [Attention and Augmented Recurrent Neural Networks](http://distill.pub/2016/augmented-rnns/) ，用了好多图来说明了 RNN 的 attention 机制。\n- [Recommending music on Spotify with deep learning](http://benanne.github.io/2014/08/05/spotify-cnns.html) ，一个在 Spotify 的实习生分享的音乐聚类的文章。\n\n# 相关算法\n\n下面是 10 个非常经典的机器学习的算法。\n\n- 对于监督式学习，有如下经典算法。\n  1. [决策树（Decision Tree）](https://en.wikipedia.org/wiki/Decision_tree)，比如自动化放贷、风控。\n  2. [朴素贝叶斯分类器（Naive Bayesian classifier)](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)，可以用于判断垃圾邮件、对新闻的类别进行分类，比如科技、政治、运动、判断文本表达的感情是积极的还是消极的、人脸识别等。\n  3. [最小二乘法（Ordinary Least Squares Regression）](https://en.wikipedia.org/wiki/Ordinary_least_squares)，是一种线性回归。\n  4. [逻辑回归（Logisitic Regression）](https://en.wikipedia.org/wiki/Logistic_regression)，一种强大的统计学方法，可以用一个或多个变量来表示一个二项式结果。可以用于信用评分，计算营销活动的成功率，预测某个产品的收入。\n  5. [支持向量机（Support Vector Machine，SVM）](https://en.wikipedia.org/wiki/Support_vector_machine)，可以用于基于图像的性别检测、图像分类等。\n  6. [集成方法（Ensemble methods）](https://en.wikipedia.org/wiki/Ensemble_learning)，通过构建一组分类器，然后通过它们的预测结果进行加权投票来对新的数据点进行分类。原始的集成方法是贝叶斯平均，但最近的算法包括纠错输出编码、Bagging 和 Boosting。\n- 对于无监督式的学习，有如下经典算法。\n  1. [聚类算法（Clustering Algorithms）](https://en.wikipedia.org/wiki/Cluster_analysis)。聚类算法有很多，目标是给数据分类。有 5 个比较著名的聚类算法你必需要知道：[K-Means](https://en.wikipedia.org/wiki/K-means_clustering)、[Mean-Shift](https://en.wikipedia.org/wiki/Mean_shift)、[DBSCAN](https://en.wikipedia.org/wiki/DBSCAN)、[EM/GMM](https://en.wikipedia.org/wiki/Expectation–maximization_algorithm)、和 [Agglomerative Hierarchical](https://en.wikipedia.org/wiki/Hierarchical_clustering)。\n  2. [主成分分析（Principal Component Analysis，PCA）](https://en.wikipedia.org/wiki/Principal_component_analysis)。PCA 的一些应用包括压缩、简化数据便于学习、可视化等。\n  3. [奇异值分解（Singular Value Decomposition，SVD）](https://en.wikipedia.org/wiki/Singular-value_decomposition)。实际上，PCA 是 SVD 的一个简单应用。在计算机视觉中，第一个人脸识别算法使用 PCA 和 SVD 来将面部表示为\"特征面\"的线性组合，进行降维，然后通过简单的方法将面部匹配到身份。虽然现代方法更复杂，但很多方面仍然依赖于类似的技术。\n  4. [独立成分分析（Independent Component Analysis，ICA）](https://en.wikipedia.org/wiki/Independent_component_analysis)。ICA 是一种统计技术，主要用于揭示随机变量、测量值或信号集中的隐藏因素。\n\n如果你想了解更全的机器学习的算法列表，你可以看一下 Wikipedia 上的 [List of Machine Learning Algorithms](https://en.wikipedia.org/wiki/Outline_of_machine_learning#Machine_learning_algorithms)。\n\n在 [A Tour of Machine Learning Algorithms](https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/) ，这篇文章带你概览了一些机器学习算法，其中还有一个\"脑图\"可以下载，并还有一些 How-To 的文章供你参考。\n\n对于这些算法，[SciKit-Learn](http://scikit-learn.org/stable/)有一些文档供你学习。\n\n- [1. Supervised learning](http://scikit-learn.org/stable/supervised_learning.html#supervised-learning)\n- [2.3 Clustering](http://scikit-learn.org/stable/modules/clustering.html#clustering)\n- [2.5. Decomposing signals in components (matrix factorization problems)](http://scikit-learn.org/stable/modules/decomposition.html#decompositions)\n- [3. Model selection and evaluation](http://scikit-learn.org/stable/model_selection.html#model-selection)\n- [4.3. Preprocessing data](http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing)\n\n# 相关资源\n\n- 对于初学者来说，动手是非常非常重要的，不然，你会在理论的知识里迷失掉自己，这里有篇文章\"[8 Fun Machine Learning Projects for Beginners](https://elitedatascience.com/machine-learning-projects-for-beginners)\"，其中为初学者准备了 8 个很有趣的项目，你可以跟着练练。\n- 学习机器学习或是人工智能你需要数据，这里有一个非常足的列表给你足够多的公共数据 – 《[Awesome Public Datasets](https://github.com/awesomedata/awesome-public-datasets)》，其中包括农业、生物、天气、计算机网络、地球科学、经济、教育、金融、能源、政府、健康、自然语言、体育等。\n- GitHub 上的一些 Awesome 资源列表。\n  - [Awesome Deep Learning](https://github.com/ChristosChristofidis/awesome-deep-learning)\n  - [Awesome - Most Cited Deep Learning Papers](https://github.com/terryum/awesome-deep-learning-papers)\n  - [Awesome Deep learning papers and other resources](https://github.com/endymecy/awesome-deeplearning-resources)\n\n# 小结\n\n总结一下今天的内容。我首先介绍了机器学习的基本原理：监督式学习和非监督式学习，然后给出了全世界最简单的入门资料 [Machine Learning is Fun!](https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471)。随后给出了与机器学习密切相关的数据分析方面的内容和资料，然后推荐了深入学习机器学习知识的在线课程、图书和文章等，尤其列举了神经网络方面的学习资料。最后描述了机器学习的十大经典算法及相关的学习资料。\n\n在机器学习和人工智能领域，我也在学习，也处于入门阶段，所以本文中推荐的内容，可能在你看来会有些浅。如果你有更好的信息和资料，欢迎补充。目前文章中给出来的是，我在学习过程中认为很不错的内容，我从中受益良多，所以希望它们也能为你的学习提供帮助。\n\n从下篇文章开始，我们将进入前端知识的学习，包括基础和底层原理、性能优化、前端框架、UI/UX 设计等内容。敬请期待。\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/11669\" > </iframe>","categories":["左耳听风"]},{"title":"085丨程序员练级攻略：容器化和自动化运维","url":"/posts/666788709.html","content":"\n\n\n这篇文章我们来重点学习 Docker 和 Kubernetes，它们已经是分布式架构和自动化运维的必备工具了。对于这两个东西，你千万不要害怕，因为技术方面都不算复杂，只是它们的玩法和传统运维不一样，所以你不用担心，只要你花上一点时间，一定可以学好的。\n\n# Docker\n\n- 你可以先看一下 Docker 的官方介绍 [Docker Overview](https://docs.docker.com/engine/docker-overview/) 。\n- 然后再去一个 Web 在线的 Playground 上体验一下， [Katacoda Docker Playground](https://www.katacoda.com/courses/docker/playground) 或者是 [Play With Docker](https://training.play-with-docker.com/) 。\n- 接下来，跟着 [Learn Docker](https://github.com/dwyl/learn-docker) 这个文档中的教程自己安装一个 Docker 的环境，实操一把。\n- 然后跟着 [Docker Curriculum](https://docker-curriculum.com/) 这个超详细的教程玩一下 Docker。\n\n有了上述的一些感性体会之后，你就可以阅读 Docker 官方文档 [Docker Documentation](https://docs.docker.com/) 了，这是学习 Docker 最好的方式。\n\n如果你想了解一下 Docker 的底层技术细节，你可以参看我的文章。\n\n- [Docker 基础技术：Linux Namespace（上）](https://coolshell.cn/articles/17010.html)\n- [Docker 基础技术：Linux Namespace（下）](https://coolshell.cn/articles/17029.html)\n- [Docker 基础技术：Cgroup](https://coolshell.cn/articles/17049.html)\n- [Docker 基础技术：AUFS](https://coolshell.cn/articles/17061.html)\n- [Docker 基础技术：DeviceMapper](https://coolshell.cn/articles/17200.html)\n\n还有一些不错的与 Docker 网络有关的文章你需要阅读及实践一下。\n\n- [A container networking overview](https://jvns.ca/blog/2016/12/22/container-networking/)\n- [Docker networking 101 - User defined networks](http://www.dasblinkenlichten.com/docker-networking-101-user-defined-networks/)\n- [Understanding CNI (Container Networking Interface)](http://www.dasblinkenlichten.com/understanding-cni-container-networking-interface/)\n- [Using CNI with Docker](http://www.dasblinkenlichten.com/using-cni-docker/)\n\nDocker 有下面几种网络解决方案：[Calico](https://www.projectcalico.org/getting-started/docker/) 、[Flannel](https://github.com/coreos/flannel/) 和 [Weave](https://github.com/weaveworks/weave) ，你需要学习一下。另外，还需要学习一下 [netshoot](https://github.com/nicolaka/netshoot) ，这是一个很不错的用来诊断 Docker 网络问题的工具集。\n\n关于这几个容器网络解决方案的性能对比，你可以看一下下面这几篇文章或报告。\n\n- [Battlefield: Calico, Flannel, Weave and Docker Overlay Network](http://chunqi.li/2015/11/15/Battlefield-Calico-Flannel-Weave-and-Docker-Overlay-Network/)\n- [Comparison of Networking Solutions for Kubernetes](http://machinezone.github.io/research/networking-solutions-for-kubernetes/)\n- [Docker Overlay Networks: Performance analysis in high-latency enviroments](http://www.delaat.net/rp/2015-2016/p50/report.pdf)\n\n如果你对 Docker 的性能有什么问题的话，你可以看一下下面这些文章。\n\n- [IBM Research Report: An Updated Performance Comparison of Virtual Machines and Linux Containers](https://domino.research.ibm.com/library/cyberdig.nsf/papers/0929052195DD819C85257D2300681E7B/MY_ZUES_CHARFile/rc25482.pdf)\n- [An Introduction to Docker and Analysis of its Performance](http://paper.ijcsns.org/07_book/201703/20170327.pdf)\n\n下面是一些和存储相关的文章。\n\n- [Storage Concepts in Docker: Network and Cloud Storage](http://cloud-mechanic.blogspot.de/2014/10/storage-concepts-in-docker-network-and.html)\n- [Storage Concepts in Docker: Persistent Storage](http://cloud-mechanic.blogspot.de/2014/10/storage-concepts-in-docker-persistent.html)\n- [Storage Concepts in Docker: Shared Storage and the VOLUME directive](http://cloud-mechanic.blogspot.de/2014/10/storage-concepts-in-docker.html)\n\n然后是跟运维相关的文章。\n\n- [Docker Monitoring with the ELK Stack: A Step-by-Step Guide](https://logz.io/learn/docker-monitoring-elk-stack/)\n\n最后，推荐看看 [Valuable Docker Links](http://www.nkode.io/2014/08/24/valuable-docker-links.html) ，其中收集并罗列了一系列非常不错的 Docker 文章。\n\n**最佳实践**\n\n下面分享一些与 Docker 相关的最佳实践。\n\n- [Best Practices for Dockerfile](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/) ，Docker 官方文档里的 Dockerfile 的最佳实践。\n- [Docker Best Practices](https://github.com/FuriKuri/docker-best-practices) ，这里收集汇总了存在于各个地方的使用 Docker 的建议和实践。\n- [Container Best Practices](http://docs.projectatomic.io/container-best-practices/) ，来自 Atomic 项目，是一个介绍容器化应用程序的架构、创建和管理的协作型文档项目。\n- [Eight Docker Development Patterns](http://hokstad.com/docker/patterns) ，八个 Docker 的开发模式：共享基础容器、共享同一个卷的多个开发容器、开发工具专用容器、测试环境容器、编译构建容器、防手误的安装容器、默认服务容器、胶黏容器。\n\n# Kubernetes\n\nKubernetes 是 Google 开源的容器集群管理系统，是 Google 多年大规模容器管理技术 Borg 的开源版本，也是 CNCF 最重要的项目之一，主要功能包括：\n\n- 基于容器的应用部署、维护和滚动升级；\n- 负载均衡和服务发现；\n- 跨机器和跨地区的集群调度；\n- 自动伸缩；\n- 无状态服务和有状态服务；\n- 广泛的 Volume 支持；\n- 插件机制保证扩展性。\n\nKubernetes 发展非常迅速，已经成为容器编排领域的领导者。\n\n首先，我推荐你阅读 Kubernetes 前世今生的一篇论文。\n\n- [Borg, Omega, and Kubernetes](https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/44843.pdf) ，看看 Google 这十几年来从这三个容器管理系统中得到的经验教训。\n\n学习 Kubernetes，有两个免费的开源电子书。\n\n- 《[Kubernetes Handbook](https://jimmysong.io/kubernetes-handbook/)》，这本书记录了作者从零开始学习和使用 Kubernetes 的心路历程，着重于经验分享和总结，同时也会有相关的概念解析。希望能够帮助你少踩坑，少走弯路，还会指引你关注 kubernetes 生态周边，如微服务构建、DevOps、大数据应用、Service Mesh、Cloud Native 等领域。\n- 《[Kubernetes 指南](https://kubernetes.feisky.xyz/zh/)》，这本书旨在整理平时在开发和使用 Kubernetes 时的参考指南和实践总结，形成一个系统化的参考指南以方便查阅。\n\n这两本电子书都不错，前者更像是一本学习教程，而且面明显广一些，还包括 Cloud Natvie、Service Mesh 以及微服务相关的东西。而后者聚焦于 Kubernetes 本身，更像一本参考书。\n\n**另外，我这两天也读完了《Kubernetes in Action》一书，感觉写的非常好，一本很完美的教科书，抽丝剥茧，图文并茂。如果你只想读一本有关 Kubernetes 的书来学习 Kubernetes，那么我推荐你就选这本。**\n\n但是也别忘了 Kubernetes 的官方网站：[Kubernetes.io](https://kubernetes.io/)，上面不但有[全面的文档](https://kubernetes.io/docs/home/) ，也包括一个很不错的 [官方教程](https://kubernetes.io/docs/tutorials/kubernetes-basics/) 。\n\n此外，还有一些交互式教程，帮助你理解掌握，以及一些很不错的文章推荐你阅读。\n\n**一些交互式教程**\n\n- [Katacoda](https://www.katacoda.com/courses/kubernetes)\n- [Kubernetes Bootcamp](https://kubernetesbootcamp.github.io/kubernetes-bootcamp/)\n\n**一些文章**\n\n这里还有一些不错的文档，你应该去读一下。\n\n- [Kubernetes tips & tricks](https://opsnotice.xyz/kubernetes-tips-tricks/)\n- [Achieving CI/CD with Kubernetes](http://theremotelab.com/blog/achieving-ci-cd-with-k8s/)\n- [How to Set Up Scalable Jenkins on Top of a Kubernetes Cluster](https://dzone.com/articles/how-to-setup-scalable-jenkins-on-top-of-a-kubernet)\n- 10 Most Common Reasons Kubernetes Deployments Fail [Part I](https://kukulinski.com/10-most-common-reasons-kubernetes-deployments-fail-part-1/) 和 [Part II](https://kukulinski.com/10-most-common-reasons-kubernetes-deployments-fail-part-2/)\n- [How to Monitor Kubernetes](http://sysdig.com/blog/monitoring-kubernetes-with-sysdig-cloud/) ，一共有 4 个篇章\n- [Logging in Kubernetes with Fluentd and Elasticsearch](http://www.dasblinkenlichten.com/logging-in-kubernetes-with-fluentd-and-elasticsearch/)\n- [Kubernetes Monitoring: Best Practices, Methods, and Existing Solutions](https://dzone.com/articles/kubernetes-monitoring-best-practices-methods-and-e)\n\n**网络相关的文章**\n\n要学习 Kubernetes，你只需要读一下，下面这个 Kubernetes 101 系列的文章。\n\n- [Kubernetes 101 - Networking](http://www.dasblinkenlichten.com/kubernetes-101-networking/)\n- [Kubernetes networking 101 - Pods](http://www.dasblinkenlichten.com/kubernetes-networking-101-pods/)\n- [Kubernetes networking 101 - Services](http://www.dasblinkenlichten.com/kubernetes-networking-101-services/)\n- [Kubernetes networking 101 - (Basic) External access into the cluster](http://www.dasblinkenlichten.com/kubernetes-networking-101-basic-external-access-into-the-cluster/)\n- [Kubernetes Networking 101 - Ingress resources](http://www.dasblinkenlichten.com/kubernetes-networking-101-ingress-resources/)\n- [Getting started with Calico on Kubernetes](http://www.dasblinkenlichten.com/getting-started-with-calico-on-kubernetes/)\n\n**CI/CD 相关的文章**\n\n- [Automated Image Builds with Jenkins, Packer, and Kubernetes](https://cloud.google.com/solutions/automated-build-images-with-jenkins-kubernetes#kubernetes_architecture)\n- [Jenkins setups for Kubernetes and Docker Workflow](http://iocanel.blogspot.in/2015/09/jenkins-setups-for-kubernetes-and.html)\n- [Lab: Build a Continuous Deployment Pipeline with Jenkins and Kubernetes](https://github.com/GoogleCloudPlatform/continuous-deployment-on-kubernetes)\n\n**最佳实践**\n\n- [Kubernetes Best Practices](https://medium.com/@sachin.arote1/kubernetes-best-practices-9b1435a4cb53) by [Sachin Arote](https://medium.com/@sachin.arote1?source=post_header_lockup) ，AWS 工程师总结的最佳实践。\n- [Kubernetes Best Practices](https://speakerdeck.com/thesandlord/kubernetes-best-practices) by [Sandeep Dinesh](https://github.com/thesandlord) ，Google 云平台工程师总结的最佳实践。\n\n**Docker 和 Kubernetes 资源汇总**\n\n下面是 GitHub 上和 Docker & Kubernetes 相关的 Awesome 系列。\n\n- [Awesome Docker](https://github.com/veggiemonk/awesome-docker)。\n- [Awesome Kubernetes](https://github.com/ramitsurana/awesome-kubernetes)。\n\n虽然上面的这些系列非常全的罗列了很多资源，但是我觉得很不系统。对于系统的说明 Docker 和 Kubernetes 生态圈，我非常推荐大家看一下 The New Stack 为 Kubernetes 出的一系列的电子书或报告。\n\n- [The New Stack eBook Series](http://thenewstack.io/ebookseries/) ，非常完整和详实的 Docker 和 Kubernetes 生态圈的所有东西。\n  - Book 01: [The Docker Container Ecosystem](https://thenewstack.io/ebooks/docker-and-containers/the-docker-container-ecosystem/)\n  - Book 02: [Applications & Microservices with Docker & Containers](https://thenewstack.io/ebooks/docker-and-containers/applications-microservices-docker-containers/)\n  - Book 03: [Automation & Orchestration with Docker & Containers](https://thenewstack.io/ebooks/docker-and-containers/automation-orchestration-docker-containers/)\n  - Book 04: [Network, Security & Storage with Docker & Containers](https://thenewstack.io/ebooks/docker-and-containers/networking-security-storage-docker-containers/)\n  - Book 05: [Monitoring & Management with Docker & Containers](https://thenewstack.io/ebooks/docker-and-containers/monitoring-management-docker-containers/)\n  - Book 06: [Use Cases for Kubernetes](https://thenewstack.io/ebooks/use-cases/use-cases-for-kubernetes/)\n  - Book 07: [State of the Kubernetes Ecosystem](https://thenewstack.io/ebooks/kubernetes/state-of-kubernetes-ecosystem/)\n  - Book 08: [Kubernetes Deployment & Security Patterns](https://thenewstack.io/ebooks/kubernetes/kubernetes-deployment-and-security-patterns/)\n  - Book 09: [CI/CD with Kubernetes](https://thenewstack.io/ebooks/kubernetes/ci-cd-with-kubernetes/)\n  - Book 10: [Kubernetes solutions Directory](https://thenewstack.io/ebooks/kubernetes/kubernetes-solutions-directory/)\n  - Book 11: [Guid to Cloud-Native Microservices](https://thenewstack.io/ebooks/microservices/cloud-native-microservices-2018/)\n\n# 小结\n\n总结一下今天的内容。Docker 和 Kubernetes 已经成为分布式架构和自动化运维方面的不可或缺的两大基本构成，是你必需要学习的。虽然它们的玩法跟传统运维不一样，但技术方面并不算复杂，只要你花上一点时间，一定会学好的。\n\n在这篇文章中，我推荐了 Docker 和 Kubernetes 基础技术方面的学习资料，并给出了存储、运维、网络、CI/CD 等多方面的资料，同时列出了与之相关的最佳实践。相信认真学习和消化这些知识，你一定可以掌握 Docker 和 Kubernetes 两大利器。\n\n下篇文章，我们将学习机器学习和人工智能方面的内容。敬请期待。\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/11665\" > </iframe>","categories":["左耳听风"]},{"title":"087丨程序员练级攻略：前端基础和底层原理","url":"/posts/3352672426.html","content":"\n\n\n对于前端的学习和提高，我的基本思路是这样的。首先，前端的三个最基本的东西 HTML 5、CSS 3 和 JavaScript（ES6）是必须要学好的。这其中有很多很多的技术，比如，CSS 3 引申出来的 Canvas（位图）、SVG（矢量图） 和 WebGL（3D 图），以及 CSS 的各种图形变换可以让你做出非常丰富的渲染效果和动画效果。\n\nES6 简直就是把 JavaScript 带到了一个新的台阶，JavaScript 语言的强大，大大释放了前端开发人员的生产力，让前端得以开发更为复杂的代码和程序，于是像 React 和 Vue 这样的框架开始成为前端编程的不二之选。\n\n我一直认为学习任何知识都要从基础出发，所以这篇文章我会着重介绍基础知识和基本原理，尤其是如下的这些知识，都是前端程序员需要花力气啃下来的硬骨头。\n\n- **JavaScript 的核心原理**。这里我会给出好些网上很不错的讲 JavaScript 的原理的文章或图书，你一定要学好语言的特性，并且详细了解其中的各种坑。\n- **浏览器的工作原理**。这也是一块硬骨头，我觉得这是前端程序员需要了解和明白的关键知识点，不然，你将无法深入下去。\n- **网络协议 HTTP**。也是要着重了解的，尤其是 HTTP/2，还有 HTTP 的几种请求方式：短连接、长连接、Stream 连接、WebSocket 连接。\n- **前端性能调优**。有了以上的这些基础后，你就可以进入前端性能调优的主题了，我相信你可以很容易上手各种性能调优技术的。\n- **框架学习**。我只给了 React 和 Vue 两个框架。就这两个框架来说，Virtual DOM 技术是其底层技术，组件化是其思想，管理组件的状态是其重点。而对于 React 来说，函数式编程又是其编程思想，所以，这些基础技术都是你需要好好研究和学习的。\n- **UI 设计**。设计也是前端需要做的一个事，比如像 Google 的 Material UI，或是比较流行的 Atomic Design 等应该是前端工程师需要学习的。\n\n而对于工具类的东西，这里我基本没怎么涉及，因为本文主要还是从原理和基础入手。那些工具我觉得都很简单，就像学习 Java 我没有让你去学习 Maven 一样，因为只要你去动手了，这种知识你自然就会获得，我们还是把精力重点放在更重要的地方。\n\n下面我们从前端基础和底层原理开始讲起。先来讲讲 HTML5 相关的内容。\n\n# HTML 5\n\nHTML 5 主要有以下几本书推荐。\n\n- [HTML 5 权威指南](https://book.douban.com/subject/25786074/) ，本书面向初学者和中等水平 Web 开发人员，是牢固掌握 HTML 5、CSS 3 和 JavaScript 的必读之作。书看起来比较厚，是因为里面的代码很多。\n- [HTML 5 Canvas 核心技术](https://book.douban.com/subject/24533314/) ，如果你要做 HTML 5 游戏的话，这本书必读。\n\n对于 SVG、Canvas 和 WebGL 这三个对应于矢量图、位图和 3D 图的渲染来说，给前端开发带来了重武器，很多 HTML5 小游戏也因此蓬勃发展。所以，你可以学习一下。\n\n学习这三个技术，我个人觉得最好的地方是 MDN。\n\n- [SVG: Scalable Vector Graphics](https://developer.mozilla.org/en-US/docs/Web/SVG)\n- [Canvas API](https://developer.mozilla.org/kab/docs/Web/API/Canvas_API)\n- [The WebGL API: 2D and 3D graphics for the web](https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API)\n\n最后是几个资源列表。\n\n- [Awesome HTML5](https://github.com/diegocard/awesome-html5) 。GitHub 上的 Awesome HTML5，其中有大量的资源和技术文章。\n- [Awesome SVG](https://github.com/willianjusten/awesome-svg)\n- [Awesome Canvas](https://github.com/raphamorim/awesome-canvas)\n- [Awesome WebGL](https://github.com/sjfricke/awesome-webgl)\n\n# CSS\n\n在《程序员练级攻略》系列文章最开始，我们就推荐过 CSS 的在线学习文档，这里再推荐一下 [MDN Web Doc - CSS](https://developer.mozilla.org/zh-CN/docs/Web/CSS) 。我个人觉得只要你仔细读一下文档，CSS 并不难学。绝大多数觉得难的，一方面是文档没读透，另一方面是浏览器支持的标准不一致。所以，学好 CSS 最关键的还是要仔细地读文档。\n\n之后，在写 CSS 的时候，你会发现，你的 CSS 中有很多看起来相似的东西。你的 DRY - Don’t Repeat Yourself 洁癖告诉你，这是不对的。所以，你需要学会使用 [LESS](http://lesscss.org/) 和 [SaSS](http://sass-lang.com) 这两个 CSS 预处理工具，其可以帮你提高很多效率。\n\n然后，你需要学习一下 CSS 的书写规范，前面的《程序员修养》一文中提到过一些，这里再补充几个。\n\n- [Principles of writing consistent, idiomatic CSS](https://github.com/necolas/idiomatic-css)\n- [Opinionated CSS styleguide for scalable applications](https://github.com/grvcoelho/css-styleguide)\n- [Google HTML/CSS Style Guide](https://google.github.io/styleguide/htmlcssguide.html)\n\n如果你需要更有效率，那么你还需要使用一些 CSS Framework，其中最著名的就是 Twitter 公司的 [Bootstrap](http://getbootstrap.com/)，其有很多不错的 UI 组件，页面布局方案，可以让你非常方便也非常快速地开发页面。除此之外，还有，主打清新 UI 的 [Semantic UI](https://semantic-ui.com/) 、主打响应式界面的 [Foundation](http://foundation.zurb.com/) 和基于 Flexbox 的 [Bulma](http://bulma.io/)。\n\n当然，在使用 CSS 之前，你需要把你浏览器中的一些 HTML 标签给标准化掉。所以，推荐几个 Reset 或标准化的 CSS 库：[Normalize](https://github.com/necolas/normalize.css)、[MiniRest.css](https://github.com/jgthms/minireset.css)、[sanitize.css](https://github.com/jonathantneal/sanitize.css/) 和 [unstyle.css](https://github.com/Martin-Pitt/css-unstyle)。\n\n关于更多的 CSS 框架，你可以参看[Awesome CSS Frameworks](https://github.com/troxler/awesome-css-frameworks) 上的列表。\n\n接下来，是几个公司的 CSS 相关实践，供你参考。\n\n- [CodePen’s CSS](https://codepen.io/chriscoyier/post/codepens-css)\n- [Github 的 CSS](http://markdotto.com/2014/07/23/githubs-css/)\n- [Medium’s CSS is actually pretty f***ing good](https://medium.com/@fat/mediums-css-is-actually-pretty-fucking-good-b8e2a6c78b06)\n- [CSS at BBC Sport](https://medium.com/bbc-design-engineering/css-at-bbc-sport-part-1-bab546184e66)\n- [Refining The Way We Structure Our CSS At Trello](https://blog.trello.com/refining-the-way-we-structure-our-css-at-trello)\n\n最后是一个可以写出可扩展的 CSS 的阅读列表 [A Scalable CSS Reading List](https://github.com/davidtheclark/scalable-css-reading-list) 。\n\n# JavaScript\n\n下面是学习 JavaScript 的一些图书和文章。\n\n- [JavaScript: The Good Parts](https://book.douban.com/subject/11874748/) ，中文翻译版为《JavaScript 语言精粹》。这是一本介绍 JavaScript 语言本质的权威图书，值得任何正在或准备从事 JavaScript 开发的人阅读，并且需要反复阅读。学习、理解、实践大师的思想，我们才可能站在巨人的肩上，才有机会超越大师，这本书就是开始。\n- [Secrets of the JavaScript Ninja](https://book.douban.com/subject/26638316/) ，中文翻译版为《JavaScript 忍者秘籍》，本书是 jQuery 库创始人编写的一本深入剖析 JavaScript 语言的书。适合具备一定 JavaScript 基础知识的读者阅读，也适合从事程序设计工作并想要深入探索 JavaScript 语言的读者阅读。这本书有很多晦涩难懂的地方，需要仔细阅读，反复琢磨。\n- [Effective JavaScript](https://book.douban.com/subject/25786138/) ，Ecma 的 JavaScript 标准化委员会著名专家撰写，作者凭借多年标准化委员会工作和实践经验，深刻辨析 JavaScript 的内部运作机制、特性、陷阱和编程最佳实践，将它们高度浓缩为极具实践指导意义的 68 条精华建议。\n- 接下来是 ES6 的学习，这里给三个学习手册源。\n  - [ES6 in Depth](https://hacks.mozilla.org/category/es6-in-depth/)，InfoQ 上有相关的中文版 - [ES6 深入浅出](http://www.infoq.com/cn/es6-in-depth/)。还可以看看 [A simple interactive ES6 Feature list](https://codetower.github.io/es6-features?utm_source=mybridge&utm_medium=email&utm_campaign=read_more) ，或是看一下 [阮一峰翻译的 ES6 的教程](http://es6.ruanyifeng.com) 。\n  - [ECMAScript 6 Tools](https://github.com/addyosmani/es6-tools) ，这是一堆 ES6 工具的列表，可以帮助你提高开发效率。\n  - [Modern JS Cheatsheet](https://mbeaudru.github.io/modern-js-cheatsheet/) ，这个 Cheatsheet 在 GitHub 上有 1 万 6 千颗星，你就可见其影响力了。\n- 然后，还有一组很不错的《[You Don’t Know JS 系列](https://github.com/getify/You-Dont-Know-JS)》 的书。\n  - [You Don’t Know JS: “Up & Going”](https://github.com/getify/You-Dont-Know-JS/blob/master/up & going/README.md#you-dont-know-js-up--going)\n  - [You Don’t Know JS: “Scope & Closures”](https://github.com/getify/You-Dont-Know-JS/blob/master/scope & closures/README.md#you-dont-know-js-scope--closures)\n  - [You Don’t Know JS: “this & Object Prototypes”](https://github.com/getify/You-Dont-Know-JS/blob/master/this & object prototypes/README.md#you-dont-know-js-this--object-prototypes)\n  - [You Don’t Know JS: “Types & Grammar”](https://github.com/getify/You-Dont-Know-JS/blob/master/types & grammar/README.md#you-dont-know-js-types--grammar)\n  - [You Don’t Know JS: “Async & Performance”](https://github.com/getify/You-Dont-Know-JS/blob/master/async & performance/README.md#you-dont-know-js-async--performance)\n  - [You Don’t Know JS: “ES6 & Beyond”](https://github.com/getify/You-Dont-Know-JS/blob/master/es6 & beyond/README.md#you-dont-know-js-es6--beyond)\n- 接下来是一些和编程范式相关的文章。\n  - [Glossary of Modern JavaScript Concepts: Part 1](https://auth0.com/blog/glossary-of-modern-javascript-concepts/) ，首先推荐这篇文章，其中收集了一些编程范式方面的内容，比如纯函数、状态、可变性和不可变性、指令型语言和声明式语言、函数式编程、响应式编程、函数式响应编程。\n  - [Glossary of Modern JavaScript Concepts: Part 2](https://auth0.com/blog/glossary-of-modern-javascript-concepts-part-2/) ，在第二部分中主要讨论了作用域和闭包，数据流，变更检测，组件化……\n- 下面三篇文章是德米特里·索什尼科夫（Dmitry Soshnikov）个人网站上三篇讲 JavaScript 内在的文章。\n  - [JavaScript. The Core: 2nd Edition](http://dmitrysoshnikov.com/ecmascript/javascript-the-core-2nd-edition/)\n  - [JavaScript. The Core (older ES3 version)](http://dmitrysoshnikov.com/ecmascript/javascript-the-core/)\n  - [JS scope: static, dynamic, and runtime-augmented](https://medium.com/@DmitrySoshnikov/js-scope-static-dynamic-and-runtime-augmented-5abfee6223fe)\n- “**How JavaScript Works**” 是一组非常不错的文章（可能还没有写完），强烈推荐。这一系列的文章是 SessionStake 的 CEO 写的，现在有 13 篇，我感觉可能还没有写完。这个叫 [亚历山大·兹拉特科夫（Alexander Zlatkov）](https://blog.sessionstack.com/@zlatkov) 的 CEO 太猛了。\n  - [An overview of the engine, the runtime, and the call stack](https://blog.sessionstack.com/how-does-javascript-actually-work-part-1-b0bacc073cf)\n  - [Inside the V8 engine + 5 tips on how to write optimized code](https://blog.sessionstack.com/how-javascript-works-inside-the-v8-engine-5-tips-on-how-to-write-optimized-code-ac089e62b12e) ，了解 V8 引擎。这里，也推荐 [Understanding V8’s Bytecode](https://medium.com/dailyjs/understanding-v8s-bytecode-317d46c94775) 这篇文章可以让你了解 V8 引擎的底层字节码。\n  - [Memory management + how to handle 4 common memory leaks](https://blog.sessionstack.com/how-javascript-works-memory-management-how-to-handle-4-common-memory-leaks-3f28b94cfbec) ，内存管理和 4 种常见的内存泄露问题。\n  - [Event loop and the rise of Async programming + 5 ways to better coding with async/await](https://blog.sessionstack.com/how-javascript-works-event-loop-and-the-rise-of-async-programming-5-ways-to-better-coding-with-2f077c4438b5) ，Event Loop 和异步编程。\n  - [Deep dive into WebSockets and HTTP/2 with SSE + how to pick the right path](https://blog.sessionstack.com/how-javascript-works-deep-dive-into-websockets-and-http-2-with-sse-how-to-pick-the-right-path-584e6b8e3bf7) ，WebSocket 和 HTTP/2。\n  - [A comparison with WebAssembly + why in certain cases it’s better to use it over JavaScript](https://blog.sessionstack.com/how-javascript-works-a-comparison-with-webassembly-why-in-certain-cases-its-better-to-use-it-d80945172d79) ，JavaScript 内在原理。\n  - [The building blocks of Web Workers + 5 cases when you should use them](https://blog.sessionstack.com/how-javascript-works-the-building-blocks-of-web-workers-5-cases-when-you-should-use-them-a547c0757f6a) ，Web Workers 技术。\n  - [Service Workers, their lifecycle and use cases](https://blog.sessionstack.com/how-javascript-works-service-workers-their-life-cycle-and-use-cases-52b19ad98b58) ，Service Worker 技术。\n  - [The mechanics of Web Push Notifications](https://blog.sessionstack.com/how-javascript-works-the-mechanics-of-web-push-notifications-290176c5c55d) ，Web 端 Push 通知技术。\n  - [Tracking changes in the DOM using MutationObserver](https://blog.sessionstack.com/how-javascript-works-tracking-changes-in-the-dom-using-mutationobserver-86adc7446401) ，Mutation Observer 技术。\n  - [The rendering engine and tips to optimize its performance](https://blog.sessionstack.com/how-javascript-works-the-rendering-engine-and-tips-to-optimize-its-performance-7b95553baeda) ，渲染引擎和性能优化。\n  - [Inside the Networking Layer + How to Optimize Its Performance and Security](https://blog.sessionstack.com/how-javascript-works-inside-the-networking-layer-how-to-optimize-its-performance-and-security-f71b7414d34c) ，网络性能和安全相关。\n  - [Under the hood of CSS and JS animations + how to optimize their performance](https://blog.sessionstack.com/how-javascript-works-under-the-hood-of-css-and-js-animations-how-to-optimize-their-performance-db0e79586216) ，CSS 和 JavaScript 动画性能优化。\n- 接下来是 Google Chrome 工程经理 [阿迪·奥斯马尼（Addy Osmani）](https://medium.com/@addyosmani) 的几篇 JavaScript 性能相关的文章，也是非常好的。\n  - [The Cost Of JavaScript](https://medium.com/dev-channel/the-cost-of-javascript-84009f51e99e)\n  - [JavaScript Start-up Performance](https://medium.com/reloading/javascript-start-up-performance-69200f43b201)\n- 其它与 JavaScript 相关的资源。\n  - [JavScript has Unicode Problem](https://mathiasbynens.be/notes/javascript-unicode) ，这是一篇很有价值的 JavaScript 处理 Unicode 的文章。\n  - [JavaScript Algorithms](https://mgechev.github.io/javascript-algorithms/index.html) ，用 JavaScript 实现的各种基础算法库。\n  - [JavaScript 30 秒代码](https://github.com/Chalarangelo/30-seconds-of-code) ，一堆你可以在 30 秒内看懂各种有用的 JavaScript 的代码，在 GitHub 上有 2 万颗星了。\n  - [What the f*ck JavaScript](https://github.com/denysdovhan/wtfjs) ，一堆 JavaScript 搞笑和比较 tricky 的样例。\n  - [Airbnb JavaScript Style Guide](https://github.com/airbnb/javascript) ，Airbnb 的 JavaScript 的代码规范，GitHub 上有 7 万多颗星。\n  - [JavaScript Patterns for 2017](https://www.youtube.com/watch?v=hO7mzO83N1Q) ，YouTube 上的一个 JavaScript 模式分享，值得一看。\n\n# 浏览器原理\n\n你需要了解一下浏览器是怎么工作的，所以，你必需要看《[How browsers work](http://taligarsiel.com/Projects/howbrowserswork1.htm)》。这篇文章受众之大，后来被人重新整理并发布为《[How Browsers Work: Behind the scenes of modern web browsers](https://www.html5rocks.com/en/tutorials/internals/howbrowserswork/)》，其中还包括中文版。这篇文章非常非常长，所以，你要有耐心看完。如果你想看个精简版的，可以看我在 Coolshell 上发的《[浏览器的渲染原理简介](https://coolshell.cn/articles/9666.html)》或是看一下[这个幻灯片](http://arvindr21.github.io/howBrowserWorks)。\n\n然后，是对 Virtual DOM 的学习。Virtual DOM 是 React 的一个非常核心的技术细节，它也是前端渲染和性能的关键技术。所以，你有必要要好好学习一下这个技术的实现原理和算法。当然，前提条件是你需要学习过前面我所推荐过的浏览器的工作原理。下面是一些不错的文章可以帮你学习这一技术。\n\n- [How to write your own Virtual DOM](https://medium.com/@deathmood/how-to-write-your-own-virtual-dom-ee74acc13060)\n- [Write your Virtual DOM 2: Props & Events](https://medium.com/@deathmood/write-your-virtual-dom-2-props-events-a957608f5c76)\n- [How Virtual-DOM and diffing works in React](https://medium.com/@gethylgeorge/how-virtual-dom-and-diffing-works-in-react-6fc805f9f84e)\n- [The Inner Workings Of Virtual DOM](https://medium.com/@rajaraodv/the-inner-workings-of-virtual-dom-666ee7ad47cf)\n- [深度剖析：如何实现一个 Virtual DOM 算法](https://github.com/livoras/blog/issues/13)\n- 以及两个 Vitual-DOM 实现供你参考：\n  - [Matt-Esch/Virtual-DOM](https://github.com/Matt-Esch/virtual-dom)\n  - [Maquette](https://maquettejs.org/)\n\n# 网络协议\n\n- [High Performance Browser Networking](https://book.douban.com/subject/25856314/) ，本书是谷歌公司高性能团队核心成员的权威之作，堪称实战经验与规范解读完美结合的产物。本书目标是涵盖 Web 开发者技术体系中应该掌握的所有网络及性能优化知识。\n\n  全书以性能优化为主线，从 TCP、UDP 和 TLS 协议讲起，解释了如何针对这几种协议和基础设施来优化应用。然后深入探讨了无线和移动网络的工作机制。最后，揭示了 HTTP 协议的底层细节，同时详细介绍了 HTTP 2.0、 XHR、SSE、WebSocket、WebRTC 和 DataChannel 等现代浏览器新增的能力。\n\n- 另外，[HTTP/2](https://en.wikipedia.org/wiki/HTTP/2)也是 HTTP 的一个新的协议，于 2015 年被批准通过，现在基本上所有的主流浏览器都默认启用这个协议。所以，你有必要学习一下这个协议。下面相关的学习资源。\n\n  - [Gitbook - HTTP/2 详解](https://legacy.gitbook.com/book/ye11ow/http2-explained/details)\n  - [http2 explained](http://daniel.haxx.se/http2/)（[中译版](https://www.gitbook.com/book/ye11ow/http2-explained/details)）\n  - [HTTP/2 for a Faster Web](https://cascadingmedia.com/insites/2015/03/http-2.html)\n  - [Nginx HTTP/2 白皮书](https://www.nginx.com/wp-content/uploads/2015/09/NGINX_HTTP2_White_Paper_v4.pdf)\n  - HTTP/2 的两个 RFC：\n    - [RFC 7540 - Hypertext Transfer Protocol Version 2 (HTTP/2)](https://httpwg.org/specs/rfc7540.html) ，HTTP/2 的协议本身。\n    - [RFC 7541 - HPACK: Header Compression for HTTP/2](https://httpwg.org/specs/rfc7541.html) ，HTTP/2 的压缩算法。\n\n- 新的 HTML5 支持 [WebSocket](https://en.wikipedia.org/wiki/WebSocket)，所以，这也是你要学的一个重要协议。\n\n  - [HTML5 WebSocket: A Quantum Leap in Scalability for the Web](http://www.websocket.org/quantum.html) ，这篇文章比较了 HTTP 的几种链接方式，Polling、Long Polling 和 Streaming，并引入了终级解决方案 WebSocket。你知道的，了解一个技术的缘由是非常重要的。\n  - [StackOverflow: My Understanding of HTTP Polling, Long Polling, HTTP Streaming and WebSockets](https://stackoverflow.com/questions/12555043/my-understanding-of-http-polling-long-polling-http-streaming-and-websockets) ，这是 StackOverflow 上的一个 HTTP 各种链接方式的比较，也可以让你有所认识。\n  - [An introduction to Websockets](http://blog.teamtreehouse.com/an-introduction-to-websockets) ，一个 WebSocket 的简单教程。\n  - [Awesome Websockets](https://github.com/facundofarias/awesome-websockets) ，GitHub 的 Awesome 资源列表。\n  - 一些和 WebSocket 相关的想法，可以开阔你的思路：\n    - [Introducing WebSockets: Bringing Sockets to the Web](https://www.html5rocks.com/en/tutorials/websockets/basics/)\n    - [Websockets 101](http://lucumr.pocoo.org/2012/9/24/websockets-101/)\n    - [Real-Time Web by Paul Banks](https://banksco.de/p/state-of-realtime-web-2016.html)\n    - [Are WebSockets the future?](https://samsaffron.com/archive/2015/12/29/websockets-caution-required)\n\n# 小结\n\n总结一下今天的内容。我一直认为学习任何知识都要从基础出发，所以今天我主要讲述了 HTML 5、CSS 3 和 JavaScript（ES6）这三大基础核心，给出了大量的图书、文章以及其他一些相关的学习资源。之后，我建议你学习浏览器的工作原理和网络协议相关的内容。我认为，掌握这些原理也是学好前端知识的前提和基础。值得花时间，好好学习消化。\n\n下篇文章中，我们将讲讲如何做前端性能优化，并推荐一些好用的前端框架。敬请期待。\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/12271\" > </iframe>","categories":["左耳听风"]},{"title":"088丨程序员练级攻略：前端性能优化和框架","url":"/posts/1127708437.html","content":"\n\n\n# 前端性能优化\n\n首先是推荐几本前端性能优化方面的图书。\n\n- [Web Performance in Action](http://www.allitebooks.in/web-performance-action/) ，这本书目前国内没有卖的。你可以看电子版本，我觉得是一本很不错的书，其中有 CSS、图片、字体、JavaScript 性能调优等。\n\n- [Designing for Performance](http://designingforperformance.com/) ，这本在线的电子书很不错，其中讲了很多网页优化的技术和相关的工具，可以让你对整体网页性能优化有所了解。\n\n- [High Performance JavaScript](https://book.douban.com/subject/5362856/) ，这本书在国内可以买到，能让你了解如何提升各方面的性能，包括代码的加载、运行、DOM 交互、页面生存周期等。雅虎的前端工程师尼古拉斯·扎卡斯（Nicholas C. Zakas）和其他五位 JavaScript 专家介绍了页面代码加载的最佳方法和编程技巧，来帮助你编写更为高效和快速的代码。你还会了解到构建和部署文件到生产环境的最佳实践，以及有助于定位线上问题的工具。\n\n- [High Performance Web Sites: Essential Knowledge for Front-End Engineers](https://book.douban.com/subject/26411563/) ，这本书国内也有卖，翻译版为《高性能网站建设指南：前端工程师技能精髓》。作者给出了 14 条具体的优化原则，每一条原则都配以范例佐证，并提供了在线支持。\n\n  全书内容丰富，主要包括减少 HTTP 请求、Edge Computing 技术、Expires Header 技术、gzip 组件、CSS 和 JavaScript 最佳实践、主页内联、Domain 最小化、JavaScript 优化、避免重定向的技巧、删除重复 JavaScript 的技巧、关闭 ETags 的技巧、Ajax 缓存技术和最小化技术等。\n\n- 除了上面这几本书之外，Google 的 [Web Fundamentals](https://developers.google.com/web/fundamentals/) 里的 [Performance](https://developers.google.com/web/fundamentals/performance/why-performance-matters/) 这一章节也有很多非常不错的知识和经验。\n\n接下来是一些最佳实践性的文档。\n\n- [Browser Diet](http://browserdiet.com/zh/) ，前端权威性能指南（中文版）。这是一群为大型站点工作的专家们建立的一份前端性能的工作指南。\n- [PageSpeed Insights Rules](https://developers.google.com/speed/docs/insights/rules) ，谷歌给的一份性能指南和最佳实践。\n- [Best Practices for Speeding Up Your Web Site](https://developer.yahoo.com/performance/rules.html) ，雅虎公司给的一份 7 个分类共 35 个最佳实践的文档。\n\n接下来，重点推荐一个性能优化的案例学习网站 [WPO Stats](https://wpostats.com/) 。WPO 是 Web Performance Optimization 的缩写，这个网站上有很多很不错的性能优化的案例分享，一定可以帮助你很多。\n\n然后是一些文章和案例。\n\n- [A Simple Performance Comparison of HTTPS, SPDY and HTTP/2](http://blog.httpwatch.com/2015/01/16/a-simple-performance-comparison-of-https-spdy-and-http2/) ，这是一篇比较浏览器的 HTTPS、SPDY 和 HTTP/2 性能的文章，除了比较之外，还可以让你了解一些技术细节。\n- [7 Tips for Faster HTTP/2 Performance](https://www.nginx.com/blog/7-tips-for-faster-http2-performance/) ，对于 HTTP/2 来说，Nginx 公司给出的 7 个增加其性能的小提示。\n- [Reducing Slack’s memory footprint](https://slack.engineering/reducing-slacks-memory-footprint-4480fec7e8eb) ，Slack 团队减少内存使用量的实践。\n- [Pinterest: Driving user growth with performance improvements](https://medium.com/@Pinterest_Engineering/driving-user-growth-with-performance-improvements-cfc50dafadd7) ，Pinterest 关于性能调优的一些分享，其中包括了前后端的一些性能调优实践。其实也是一些比较通用的玩法，这篇文章主要是想让前端的同学了解一下如何做整体的性能调优。\n- [10 JavaScript Performance Boosting Tips](http://jonraasch.com/blog/10-javascript-performance-boosting-tips-from-nicholas-zakas) ，10 个提高 JavaScript 运行效率的小提示，挺有用的。\n- [17 Statistics to Sell Web Performance Optimization](http://www.guypo.com/17-statistics-to-sell-web-performance-optimization/) ，这个网页上收集了好些公司的 Web 性能优化的工程分享，都是非常有价值的。\n- [Getting started with the Picture Element](http://deanhume.com/Home/BlogPost/getting-started-with-the-picture-element/8109) ，这篇文章讲述了 Responsive 布局所带来的一些负面的问题。主要是图像适配的问题，其中引出了一篇文章\"[Native Responsive Images](https://dev.opera.com/articles/native-responsive-images/)\" ，值得一读。\n- [Improve Page Load Times With DNS Prefetching](http://www.deanhume.com/Home/BlogPost/improve-page-load-times-with-dns-prefetching/80) ，这篇文章教了你一个如何降低 DNS 解析时间的小技术——DNS prefetching。\n- [Jank Busting for Better Rendering Performance](http://www.html5rocks.com/en/tutorials/speed/rendering/) ，这是一篇 Google I/O 上的分享，关于前端动画渲染性能提升。\n- [JavaScript Memory Profiling](https://developer.chrome.com/devtools/docs/javascript-memory-profiling) ，这是一篇谷歌官方教你如何使用 Chrome 的开发工具来分析 JavaScript 内存问题的文章。\n\n接下来是一些性能工具。在线性能测试分析工具太多，这里只推荐比较权威的。\n\n- [PageSpeed](https://developers.google.com/speed/pagespeed/) ，谷歌有一组 PageSpeed 工具来帮助你分析和优化网站的性能。Google 出品的，质量相当有保证。\n- [YSlow](https://github.com/marcelduran/yslow) ，雅虎的一个网页分析工具。\n- [GTmetrix](https://gtmetrix.com/) ，是一个将 PageSpeed 和 YSlow 合并起来的一个网页分析工具，并且加上一些 Page load 或是其它的一些分析。也是一个很不错的分析工具。\n- [Awesome WPO](https://github.com/davidsonfellipe/awesome-wpo) ，在 GitHub 上的这个 Awesome 中，你可以找到更多的性能优化工具和资源。\n\n另外，中国的网络有各种问题（你懂的），所以，你不能使用 Google 共享的 JavaScript 链接来提速，你得用中国自己的。你可以到这里看看中国的共享库资源，[Forget Google and Use These Hosted JavaScript Libraries in China](http://chineseseoshifu.com/blog/china-hosted-javascript-libraries-jquery-dojo-boostrap.html) 。\n\n# 前端框架\n\n接下来，要学习的是 Web 前端的几大框架。目前而言，前端社区有三大框架 Angular.js、React.js 和 Vue.js。我认为，React 和 Vue 更为强劲一些，所以，我这里只写和 React 和 Vue 相关的攻略。关于两者的比较，网上有好多文章。我这里推荐几篇我觉得还不错的，供你参考。\n\n- [Angular vs. React vs. Vue: A 2017 comparison](https://medium.com/unicorn-supplies/angular-vs-react-vs-vue-a-2017-comparison-c5c52d620176)\n- [React or Vue: Which JavaScript UI Library Should You Be Using?](https://medium.com/js-dojo/react-or-vue-which-javascript-ui-library-should-you-be-using-543a383608d)\n- [ReactJS vs Angular5 vs Vue.js - What to choose in 2018?](https://medium.com/@TechMagic/reactjs-vs-angular5-vs-vue-js-what-to-choose-in-2018-b91e028fa91d)\n\n其实，比较这些框架的优缺点还有利弊并不是要比出个输赢，而是让你了解一下不同框架的优缺点。我觉得，这些框架都是可以学习的。而在我们生活工作中具体要用哪个框架，最好还是要有一些出发点，比如，你是为了找份好的工作，为了快速地搭一个网站，为了改造一个大规模的前端系统，还是纯粹地为了学习……\n\n不同的目的会导致不同的决定。我并不希望上述的这些比较会让你进入“二选一”或是“三选一”的境地。我只是想通过这些文章让你知道这些框架的设计思路和实现原理，这些才是让你受益一辈子的事。\n\n## React.js 框架\n\n下面先来学习一下 React.js 框架。\n\n**入门**\n\nReact 学起来并不复杂，就看 [React 官方教程](https://reactjs.org/tutorial/tutorial.html) 和其文档就好了（ [React 的中文教程](https://doc.react-china.org/) ）。\n\n然后，下面的文章会带你了解一下 React.js 的基本原理。\n\n- [All the fundamental React.js concepts](https://medium.freecodecamp.org/all-the-fundamental-react-js-concepts-jammed-into-this-single-medium-article-c83f9b53eac2) ，这篇文章讲了所有的 React.js 的基本原理。\n- [Learn React Fundamentals and Advanced Patterns](https://blog.kentcdodds.com/learn-react-fundamentals-and-advanced-patterns-eac90341c9db) ，这篇文章中有几个短视频，每个视频不超过 5 分钟，是学习 React 的一个很不错的地方。\n- [Thinking in React](https://reactjs.org/docs/thinking-in-react.html)，这篇文章将引导你完成使用 React 构建可搜索产品数据表的思考过程。\n\n**提高**\n\n学习一个技术最重要的是要学到其中的思想和方法。下面是一些我觉得学习 React 中最重要的东西。\n\n- **状态**，对于富客户端来说是非常麻烦也是坑最多的地方，这里有几篇文章你可以一读。\n\n  - [Common React.js mistakes: Unneeded state](http://reactkungfu.com/2015/09/common-react-dot-js-mistakes-unneeded-state/) ，React.js 编程的常见错误——不必要的状态。\n  - [State is an Anti-Pattern](https://www.reddit.com/r/reactjs/comments/3bjdoe/state_is_an_antipattern/) ，关于如何做一个不错的组件的思考，很有帮助。\n  - [Why Local Component State is a Trap](https://www.safaribooksonline.com/blog/2015/10/29/react-local-component-state/) ，一些关于 “Single state tree” 的想法。\n  - [Thinking Statefully](https://daveceddia.com/thinking-statefully/) ，几个很不错的例子让你对声明式有状态的技术有更好的理解。\n  - 传统上，解决 React 的状态问题一般用 Redux。在这里推荐 [Tips to learn React + Redux in 2018](https://www.robinwieruch.de/tips-to-learn-react-redux/) 。Redux 是一个状态粘合组件，一般来说，我们会用 Redux 来做一些数据状态和其上层 Component 上的同步。这篇教程很不错。\n  - 最后是 \"State Architecture Patterns in React \" 系列文章，非常值得一读。\n    - [Part 1: A Review](https://medium.com/@skylernelson_64801/state-architecture-patterns-in-react-a-review-df02c1e193c6)\n    - [Part 2: The Top-Heavy Architecture, Flux and Performance](https://medium.com/@skylernelson_64801/state-architecture-patterns-in-react-part-2-the-top-heavy-architecture-flux-and-performance-a388b928ce89)\n    - [Part 3: Articulation Points, zine and An Overall Strategy](https://medium.com/@skylernelson_64801/state-architecture-patterns-in-react-part-3-articulation-points-zine-and-an-overall-strategy-cf076f906391)\n    - [Part 4: Purity, Flux-duality and Dataflow](https://medium.com/@skylernelson_64801/state-architecture-patterns-in-react-part-4-purity-flux-duality-and-dataflow-d06016b3379a)\n\n- **函数式编程**。从 jQuery 过来的同学一定非常不习惯 React，而从 Java 等后端过来的程序员就会很习惯了。所以，我觉得 React 就是后端人员开发的，或者说是做函数式编程的人开发的。对此，你需要学习一下 JavaScript 函数式编程的东西。\n\n  这里推荐一本免费的电子书 《[Professor Frisby’s Mostly Adequate Guide to Functional Programming](https://github.com/MostlyAdequate/mostly-adequate-guide)》，其中译版为《[JS 函数式编程指南中文版](https://jigsawye.gitbooks.io/mostly-adequate-guide/content/)》。\n\n  下面有几篇文章非常不错。前两篇和函数式编程有关的文章非常值得一读。后三篇是一些比较实用的函数式编程和 React 结合的文章。\n\n  - [Master the JavaScript Interview: What is Functional Programming?](https://medium.com/javascript-scene/master-the-javascript-interview-what-is-functional-programming-7f218c68b3a0?utm_source=mybridge&utm_medium=email&utm_campaign=read_more)\n  - [The Rise and Fall and Rise of Functional Programming (Composing Software)](https://medium.com/javascript-scene/the-rise-and-fall-and-rise-of-functional-programming-composable-software-c2d91b424c8c)\n  - [Functional UI and Components as Higher Order Functions](https://blog.risingstack.com/functional-ui-and-components-as-higher-order-functions/)\n  - [Functional JavaScript: Reverse-Engineering the Hype](http://banderson.github.io/functional-js-reverse-engineering-the-hype/)\n  - [Some Thoughts on Function Components in React](https://medium.com/javascript-inside/some-thoughts-on-function-components-in-react-cb2938686bc7)\n\n- **设计相关**。接下来是学习一些 React 的设计模式。[React Pattern](https://reactpatterns.com/) 是一个不错的学习 React 模式的地方。除此之外，还有如下的一些不错的文章也会对你很有帮助的。\n\n  - [React Higher Order Components in depth](https://medium.com/@franleplant/react-higher-order-components-in-depth-cf9032ee6c3e)\n  - [Presentational and Container Components](https://medium.com/@dan_abramov/smart-and-dumb-components-7ca2f9a7c7d0)\n  - [Controlled and uncontrolled form inputs in React don’t have to be complicated](https://goshakkk.name/controlled-vs-uncontrolled-inputs-react/)\n  - [Function as Child Components](https://medium.com/merrickchristensen/function-as-child-components-5f3920a9ace9)\n  - [Writing Scalable React Apps with the Component Folder Pattern](https://medium.com/styled-components/component-folder-pattern-ee42df37ec68)\n  - [Reusable Web Application Strategies](https://medium.freecodecamp.org/reusable-web-application-strategies-d51517ea68c8)\n  - [Characteristics of an Ideal React Architecture](https://medium.com/@robftw/characteristics-of-an-ideal-react-architecture-883b9b92be0b)\n\n- **实践和经验**\n\n还有一些不错的实践和经验。\n\n- [9 things every React.js beginner should know](https://camjackson.net/post/9-things-every-reactjs-beginner-should-know)\n- [Best practices for building large React applications](https://engineering.siftscience.com/best-practices-for-building-large-react-applications/)\n- [Clean Code vs. Dirty Code: React Best Practices](https://americanexpress.io/clean-code-dirty-code/)\n- [How to become a more productive React Developer](https://dev.to/jakoblind/how-to-become-a-more-productive-react-developer)\n- [8 Key React Component Decisions](https://medium.freecodecamp.org/8-key-react-component-decisions-cc965db11594)\n\n**资源列表**\n\n最后就是 React 的资源列表。\n\n- [Awesome React](https://github.com/enaqx/awesome-react) ，这是一些 React 相关资源的列表，很大很全。\n- [React/Redux Links](https://github.com/markerikson/react-redux-links) ，这也是 React 相关的资源列表，与上面不一样的是，这个列表主要收集了大量的文章，其中讲述了很多 React 知识和技术，比上面的列表好很多。\n- [React Rocks](https://react.rocks/) ，这个网站主要收集各种 React 的组件示例，可以让你大开眼界。\n\n## Vue.js 框架\n\nVue 可能是一个更符合前端工程师习惯的框架。不像 React.js 那样使用函数式编程方式，是后端程序员的思路。\n\n- 通过文章 “[Why 43% of Front-End Developers want to learn Vue.js](https://medium.com/vue-mastery/why-43-of-front-end-developers-want-to-learn-vue-js-7f23348bc5be)” ，你可以看出其编程方式和 React 是大相径庭的，符合传统的前端开发的思维方式。\n- 通过文章 [Replacing jQuery With Vue.js: No Build Step Necessary](https://www.smashingmagazine.com/2018/02/jquery-vue-javascript/) ，我们可以看到，从 jQuery 是可以平滑过渡到 Vue 的。\n- 另外，我们可以通过 “[10 things I love about Vue](https://medium.com/@dalaidunc/10-things-i-love-about-vue-505886ddaff2)” ，了解 Vue 的一些比较优秀的特性。\n\n最令人高兴的是，Vue 的作者是我的好朋友尤雨溪（Evan You），最近一次对他的采访 “[Vue on 2018 - Interview with Evan You](https://blog.hackages.io/https-blog-hackages-io-evanyoubhack2017-cc5559806157)” 当中有很多故事以及对 Vue 的展望。（**注意：Vue 是完全由其支持者和用户资助的，这意味着它更接近社区而不受大公司的控制。**）\n\n要学习 Vue 并不难，我认为上官网看文档（ [Vue 官方文档](http://vuejs.org/guide/)（[中文版](https://cn.vuejs.org/v2/guide/)）），照着搞一搞就可以很快上手了。[Vue.js screencasts](https://laracasts.com/series/learn-vue-2-step-by-step) 是一个很不错的英文视频教程。\n\n另外，推荐 [新手向：Vue 2.0 的建议学习顺序](https://zhuanlan.zhihu.com/p/23134551) ，这是 Vue 作者写的，所以有特殊意义。\n\nVue 的确比较简单，有 Web 开发经验的人上手也比较快，所以这里也不会像 React 那样给出很多的资料。下面是一些我觉得还不错的内容，推荐给你。\n\n- [How not to Vue](https://itnext.io/how-not-to-vue-18f16fe620b5) ，任何技术都有坑，了解 Vue 的短板，你就能扬长避短，就能用得更好。\n- [Vue.js Component Communication Patterns](https://alligator.io/vuejs/component-communication/)\n- [4 AJAX Patterns For Vue.js Apps](https://medium.com/js-dojo/4-ajax-patterns-for-vue-js-apps-add915fc9168)\n- [How To (Safely) Use A jQuery Plugin With Vue.js](https://vuejsdevelopers.com/2017/05/20/vue-js-safely-jquery-plugin/)\n- [7 Ways To Define A Component Template in Vue.js](https://vuejsdevelopers.com/2017/03/24/vue-js-component-templates/)\n- [Use Any Javascript Library With Vue.js](https://vuejsdevelopers.com/2017/04/22/vue-js-libraries-plugins/)\n- [Dynamic and async components made easy with Vue.js](https://lobotuerto.com/blog/dynamic-and-async-components-made-easy-with-vuejs/)\n\n当然，最后一定还有 [Awesome Vue](https://github.com/vuejs/awesome-vue) ，Vue.js 里最为巨大最为优秀的资源列表。\n\n# 小结\n\n总结一下今天的内容。我先介绍的是前端性能优化方面的内容，推荐了图书、最佳实践性的文档、案例，以及一些在线性能测试分析工具。随后重点讲述了 React 和 Vue 两大前端框架，给出了大量的文章、教程和相关资源列表。我认为，React.js 使用函数式编程方式，更加符合后端程序员的思路，而 Vue 是更符合前端工程师习惯的框架。因此，两者比较起来，Vue 会更容易上手一些。\n\n下篇文章，我们将讲述前端工程师的一个基本功——UI/UX 设计。敬请期待。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/12389\" > </iframe>","categories":["左耳听风"]},{"title":"089丨程序员练级攻略：UI-UX设计","url":"/posts/1522567895.html","content":"\n\n\n上面的技术都讲完了，前端还有一个很重要的事就是设计。作为前端人员，我们有必要了解现在的一些知名且流行的设计语言或是一些设计规范或是设计方法，学习它们的设计思想和方法，有助于我们拓宽眼界、与时俱进。我并不觉得这些内容是设计师要学习的，如果你要成为一个前端程序员，那么学习这些设计上的东西可以让你有更好的成长空间。\n\n对于学习设计的新手来说，推荐看看 [7 steps to become a UI/UX designer](https://blog.nicolesaidy.com/7-steps-to-become-a-ui-ux-designer-8beed7639a95) ，这是一篇很不错的让新手入门的文章，非常具有指导性。首先，你得开始学习设计的一些原则和套路，如配色、平衡、排版、一致性等。还有用户体验的 4D 步骤——Discover、Define、Develop 和 Delivery。然后，开始到一些网站上找灵感。接下来，是到不同的网站上读各种文章和资源，开始学习使用设计工具，最后是找人拜师。此外，其中还链接了其它一些不错的文章、网站、博客和工具。我认为，这篇文章是一篇很不错的设计师从入门到精通的练级攻略。\n\n虽然有这么一个速成的教程，但我觉得还是应该系统地学习一下，所以有了下面这些推荐。\n\n# 图书和文章推荐\n\n先推荐几本书。\n\n- [Don’t Make Me Think](https://book.douban.com/subject/1827702/) ，这是我看的第一本和设计相关的书。这本书对我的影响也比较深远。这本书践行了自己的理论，整本书短小精悍，语言轻松诙谐，书中穿插大量色彩丰富的屏幕截图、趣味丛生的卡通插图以及包含大量信息的图表，使枯燥的设计原理变得平易近人。\n- [Simple and Usable Web,Mobile,and Interaction Design](https://book.douban.com/subject/5394309/) ，中文版译名为《简约至上》。本书作者贾尔斯（Giles）有 20 多年交互式设计的探索与实践。提出了合理删除、分层组织、适时隐藏和巧妙转移这四个达成简约至上的终极策略，讲述了为什么应该站在主流用户一边，以及如何从他们的真实需求和期望出发，简化设计，提升易用性。\n- [Designing with the Mind in Mind: Simple Guide to Understanding User Interface Design Rules](https://book.douban.com/subject/6792322/) ，中文版译名为《认知与设计：理解 UI 设计准则》。这本书语言清晰明了，将设计准则与其核心的认知学和感知科学高度统一起来，使得设计准则更容易在具体环境中得到应用。涵盖了交互计算机系统设计的方方面面，为交互系统设计提供了支持工程方法。不仅如此，这也是一本人类行为原理的入门书。\n- [Designing Interfaces: Patterns for Effective Interaction Design](https://book.douban.com/subject/25716088/) ，中文版译名为《界面设计模式》。这本书开篇即总结了“与人有关”的各类问题，为读者提供了界面设计总体思路上的指引，帮助读者举一反三。然后，收集并分析了很多常用的界面设计模式，帮助读者理解在实现级别的各种常用解决方案，将它们灵活地运用到自己的设计中。\n\n除了上面的这几本书，还有下面的这几篇文章也是很不错的，推荐一读。\n\n- [The Psychology Principles Every UI/UX Designer Needs to Know](https://uxplanet.org/the-psychology-principles-every-ui-ux-designer-needs-to-know-24116fd65778) ，这篇文章讲述了 6 大用户界面用户体验设计的心理学原则。\n- [18 designers predict UI/UX trends for 2018](https://blog.figma.com/18-designers-predict-ui-ux-trends-for-2018-2d04d41361c6)， 我倒不觉得这篇文章中所说的 UI/UX 是在 2018 年的趋势，我反而觉得，这 18 条原则是指导性的思想。\n- [The Evolution of UI/UX Designers Into Product Designers](https://medium.com/thinking-design/the-evolution-of-ui-ux-designers-into-product-designers-623e4e7eaab3) ，这篇文章是 Adobe 公司的一篇博客，其在回顾整个产品设计的演化过程中有一些不错的思考和想法，并提供了一些方法论。\n\n# 原子设计（Atomic Design）\n\n在 2013 年网页设计师布拉德·弗罗斯特（Brad Frost）从化学中受到启发：原子（Atoms）结合在一起，形成分子（Molecules），进一步结合形成生物体（Organisms）。布拉德将这个概念应用在界面设计中，我们的界面就是由一些基本的元素组成的。\n\n乔希·杜克（Josh Duck）的“HTML 元素周期表”完美阐述了我们所有的网站、App、企业内部网、hoobadyboops 等是如何由相同的 HTML 元素组成的。通过在大层面（页）和小层面（原子）同时思考界面，布拉德认为，可以利用原子设计建立一个适应组件的动态系统。\n\n为什么要玩原子设计，我认为，这对程序员来说是非常好理解的，因为这就是代码模块化重用化的体现。于是，你就是要像搭积木一样开发和设计网页，当你把其模块化组件化了，也更容易规范整体的风格，而且容易维护……这些都意味着你可以更容易地维护你的代码。所以，这个方法论导致了 Web 组件化的玩法。这是设计中非常重要的方法论。\n\n关于这个设计方法论，你可以阅读一下下面这几篇文章。\n\n- [Atomic Design 原子设计┃构建科学规范的设计系统](https://www.jianshu.com/p/13e87bf4f857)\n- [网页设计：Atomic Design 简介及工作实例](https://medium.com/uxeastmeetswest/網頁設計-atomic-design簡介及工作實例-42e666358d52)\n\n但是，真正权威的地方还是布拉德·弗罗斯特的电子书、博客和实验室，可以从中获取更多的信息。\n\n- [电子书：Atomic Design by Brad Frost](http://atomicdesign.bradfrost.com) 是布拉德·弗罗斯特写的一本书。\n- [博　客：Atomic Design](http://bradfrost.com/blog/post/atomic-web-design/) 是布拉德·弗罗斯特的博客。\n- [实验室：Pattern lab](http://patternlab.io) 是布拉德·弗罗斯特依照这个设计系统所建立的一套工具，可以前往 Pattern Lab 的 [GitHub](https://github.com/bradfrost/patternlab) 来试试 Atomic design。\n\n接下来是关于这个设计方法和 React.js 框架的几篇文章。\n\n- [Atomic Design with React](https://codeburst.io/atomic-design-with-react-e7aea8152957)\n- [Atomic Components: Managing Dynamic React Components using Atomic Design](https://medium.com/@yejodido/atomic-components-managing-dynamic-react-components-using-atomic-design-part-1-5f07451f261f)\n\n# 设计语言和设计系统\n\n下面来介绍一下设计语言和设计系统。\n\n## Fluent Design System\n\n[**Fluent Design System**](https://fluent.microsoft.com) 中文翻译为流畅设计体系，是微软于 2017 年开发的设计语言。流畅设计是 Microsoft Design Language 2 的改版，其中包含为所有面向 Windows 10 设备和平台设计的软件中的设计和交互的指导原则。\n\n该体系基于五个关键元素：光感、深度、动效、材质和缩放。新的设计语言包括更多对动效、深度及半透明效果的使用。过渡到流畅设计体系是一个长期项目，没有具体的完成目标，但是从创作者更新以来，新设计语言的元素已被融入到个别应用程序中。它将在未来的 Windows 10 秋季创作者更新中更广泛地使用，但微软也表示，该设计体系不会在秋季创作者更新内完成。\n\n微软于 2017 年 5 月 11 日的 Microsoft Build 2017 开发者大会上公开了该设计体系。\n\n- [What’s new and coming for Windows UI: XAML and composition](https://channel9.msdn.com/Events/Build/2017/B8100) ，从概念上讲了一下 Fluent Design System 的各个部分。\n- [Introducing Fluent Design](https://channel9.msdn.com/Events/Build/2017/B8066) ，介绍了 Fluent Design System 的各个部分。\n\n还有 Build 2018 上的一些微软的 YouTube 分享。\n\n- [Fluent Design: Evolving our Design System : Build 2018](https://www.youtube.com/watch?v=AnqwdPgVXAI)\n- [Microsoft Build 2018 - Fluent Design System Demo](https://www.youtube.com/watch?v=dMq8CMIE1xU)\n- [Microsoft Build 2018 - Fluent Design System Evolution](https://www.youtube.com/watch?v=pUuHSuCnDGE)\n- [Fluent Design System inside of Microsoft: Office : Build 2018](https://www.youtube.com/watch?v=DKvkRfQD8Yg)\n\n## Material Design\n\n[**Material Design**](https://material.io) 中文翻译为质感设计，或是材质设计、材料设计。这是由 Google 开发的设计语言。扩展于 [Google Now](https://en.wikipedia.org/wiki/Google_Now) 的“卡片”设计，Material Design 基于网格的布局、响应动画与过渡、填充、深度效果（如光线和阴影）。设计师马蒂亚斯·杜阿尔特（Matías Duarte）解释说：“与真正的纸张不同，我们的数字材质可以智能地扩大和变形。材质具有实体的表面和边缘。接缝和阴影表明组件的含义。”Google 指出他们的新设计语言基于纸张和油墨。\n\nMaterial Design 于 2014 年的 Google I/O 大会上发布（参看 [Google I/O 2014 - Material witness: How Android material applications work](https://www.youtube.com/watch?v=97SWYiRtF0Y&feature=youtu.be)）。其可借助 v7 appcompat 库用于 Android 2.1 及以上版本，几乎支持所有 2009 年以后制造的 Android 设备。随后，Material Design 扩展到 Google 的网络和移动产品阵列，提供一致的跨平台和应用程序体验。Google 还为第三方开发人员发布了 API，开发人员可将质感设计应用到他们的应用程序中。\n\n除了到 [官网](https://material.io) 学习 Material Design，你还可以访问 [Material Design 中文版](http://design.1sters.com/) 来学习。\n\n另外，Wikipedia 上有一张 [Material Design 实现的比较表](https://en.wikipedia.org/wiki/Comparison_of_Material_Design_implementations)，供你参考。\n\n下面是几个可供你使用的 Material UI 的工程实现。\n\n- [Material Design Lite](https://www.getmdl.io/) ，这是 Google 官方的框架，简单易用。\n- [Materialize](https://materializecss.com/) ，一组类似于 Bootstrap 的前端 UI 框架。\n- [Material-UI](https://material-ui.com/) 是基于 Google Material Design 的 React 组件实现。\n- [MUI](https://www.muicss.com/) 是一个轻量级的 CSS 框架，遵循 Google 的 Material Design 设计方针。\n\n## 其它公司\n\n接下来再来推荐其它几家公司的设计语言。\n\n- [苹果公司的设计指南](https://developer.apple.com/design/)，在这个网站有苹果的各种设备的设计规范和指导，一方面可以让你的 App 能和苹果的 UI 融合在一起，另一方面，你也可以从中看到苹果的审美和思维方式。\n- [IBM 公司的设计语言](https://www.ibm.com/design/language/) ，我们总觉得 IBM 公司是一家比较传统的没有新意的公司，但是并不是这样的。IBM 公司的这个设计语言的确比较出众。所以，在这里推荐一下。\n- [Salesforce 公司的 Lightning Design System](https://www.lightningdesignsystem.com/) ，是在 Salesforce 生态系统中用于创建统一 UI 的设计模式、组件和指南的集合，是一个企业级的产品。\n- [Facebook Design - What’s on our mind?](http://facebook.design/) ，Facebook 的设计师们收集的一系列的文章、视频和资源。很不错哦。\n\n## 动画效果设计\n\n我认为，要了解 Web 动画效果设计的第一步，最好的地方是 [CodePen](https://codepen.io/)。这个网站不只是让人分享 HTML、CSS 和 JavaScript 代码的网站。其中也有很多分享样例都和动画效果有关。这个网站可以让你对动画效果有一些感性认识，当然还有代码供你参考。\n\n接下来，我们要了解动画效果设计的一些方法。基本上来说，动画设计都会受 “[动画的 12 项基本法则](https://en.wikipedia.org/wiki/12_basic_principles_of_animation) ”的影响，这个方法论源自于迪士尼动画师奥利·约翰斯顿（Ollie Johnston）和弗兰克·托马斯（Frank Thomas）在 1981 年所出的《The Illusion of Life: Disney Animation》一书。这些法则已被普遍采用，至今仍与制作 3D 动画法则有关联。这里还有一篇文章 “[Understand the 12 principles of animation](https://www.creativebloq.com/advice/understand-the-12-principles-of-animation)” 是对这个法则的解读和理解。\n\n除此之外，还有几个动画设计指南和相关文章供你参考和学习。\n\n- [6 Animation Guidelines for UX Design](https://blog.prototypr.io/6-animation-guidelines-for-ux-design-74c90eb5e47a)。这是 Prototypr 公司的一个指南，其中主要指出，动画效果不是为了炫配，而是能让你的 UI/UX 能活起来，自然，不消耗时间，并且是生动故事型的动画效果。其中还推荐了如下几篇很不错的文章。\n  - [Transitional Interfaces](https://medium.com/@pasql/transitional-interfaces-926eb80d64e3)\n  - [UI Animation and UX: A Not-So-Secret Friendship](https://alistapart.com/article/ui-animation-and-ux-a-not-so-secret-friendship)\n  - [Invisible animation](https://medium.com/@stevenfabre/invisible-animation-ffa27d0b77e5)\n  - [Creating Usability with Motion: The UX in Motion Manifesto](https://medium.com/ux-in-motion/creating-usability-with-motion-the-ux-in-motion-manifesto-a87a4584ddc)\n- [Designing Interface Animation](http://alistapart.com/article/designing-interface-animation) ，这篇文章同样说明，任何一个小动画都是要讲一个微故事的，而且这些微故事会和你的品牌和产品理念相融合。动画会给人更深的印象，让人们更容易记住你。这篇文章主要是讲品牌动画。\n- [Animation principles in motion design](https://www.freepik.com/blog/animation-principles-in-motion-design/) ，这篇文章有点像设计模式，给了一些动画效果的套路和演示。\n- [Creating Usability with Motion: The UX in Motion Manifesto](https://medium.com/ux-in-motion/creating-usability-with-motion-the-ux-in-motion-manifesto-a87a4584ddc)\n- [Integrating Animation into a Design System](http://alistapart.com/article/integrating-animation-into-a-design-system)\n- Great UI/UX Animations 是设计师丹尼尔（Daniel）收集的一些很不错的动画，可以给你一些灵感。\n  - [Great UI/UX Animations 第一组](https://fromupnorth.com/mixed-ui-ux-animations-4d7a22f9ab7)\n  - [Great UI/UX Animations 第二组](https://fromupnorth.com/great-ui-ux-animations-3e9a0baa336f)\n\n# 相关资源\n\n下面分享一下 UI/UX 设计的相关资源。文章资源主要有以下这些。\n\n## 文章资源\n\n- [Web Designer News](http://webdesignernews.com) ，一个文章聚合的网站。除此之外，还有两个文章聚合网站，你也可以订阅。一个是[Designer News](https://www.designernews.co/) ，另一个是 [Reddit Web Design](https://www.reddit.com/r/web_design/)。\n- [Marvel Blog](http://blog.marvelapp.com) ，Marvel 团队的博客。\n- [The Next Web](http://thenextweb.com/section/creative/) ，内容主要涵盖国际技术新闻、商业和文化等多个方面。\n- [Medium - Design](https://medium.com/design) ，Medium 现在已经成为一个好文章的集散地了，这个地方必去。\n- [Smashing Magazine](http://smashingmagazine.com) ，这个地方是给专业的 Web 设计师和程序员的。不但有设计还有 HTML、CSS 和 JavaScript 等各种资源。\n- [Sitepoint](https://www.sitepoint.com/design-ux/) ，这个网站上也有很多不错的给 Web 前端程序员和设计师看的文章（当然，给程序员看的有点简单了，我觉得更像是让设计师来学写程序的网站）。\n\n## 设计收集\n\n接下来推荐一些优秀设计的聚集地。\n\n- [Awwwards](http://awwwards.com) ，这个网站给一些设计得不错网站的评分，在这里你可以看到很多设计不错的网站。\n- [One Page Love](http://onepagelove.com) ，就是一个单页的网页设计的收集。\n- [Inspired UI](http://inspired-ui.com/) ，移动 App 的设计模式。\n- [Behance](http://behance.net)，这个地言有很不错的很有创意的作品。\n- [Dribbble](http://dribbble.com) ，这应该是设计师都知道也都爱去的网站。除了你可以看到一些很不错的作品外，你还可以在这里看到很多不错的设计师。\n- [UI Movement](https://uimovement.com) ，也是个设计的收集网站，上面有很多很不错的 UI 设计，大量的动画。虽说会像抖音一样，让你不知不觉就看了好几小时，但是它比抖音让你的收获大多了。\n\n# 小结\n\n总结一下今天的内容。我并不认为 UI/UX 设计这些内容只是设计师要学习的，如果你要成为一个前端程序员，那么学习这些设计上的东西可以让你有更好的成长空间。首先，我推荐了一些图书和文章，让你更好地了解经典的设计原则和指导思想。\n\n然后介绍了原子设计，以及深入学习和理解这一设计方法论的图书、文章和其他相关资源。最后分享了当下主流和知名公司中在用的设计语言和设计系统，并给出了大量的学习资源，推荐了一些优秀设计的聚集地。相信通过学习这些内容，你在 UI/UX 设计方面不仅能收获方法，还能获得非常多的灵感。\n\n下篇文章是程序员练级攻略高手成长篇的最后一篇，我将推荐大量有价值的技术资源，这些内容将会为你后续的学习和成长提供很大的助力。敬请期待。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/12486\" > </iframe>","categories":["左耳听风"]},{"title":"090丨程序员练级攻略：技术资源集散地","url":"/posts/471859320.html","content":"\n\n\n# 个人技术博客\n\n首先，我先推荐一些不错的个人技术博客。\n\n- [Coding Horror](https://blog.codinghorror.com/) ，这是杰夫·阿特伍德（Jeff Atwood）于 2004 年创办的博客，记录其在软件开发经历中的所思所想、点点滴滴。时至今日，该博客每天都有近 10 万人次的访问量，读者纷纷参与评论，各种观点与智慧在这里不断地激情碰撞。其博文选集在中国被翻译成《[高效能程序员的修练](https://book.douban.com/subject/24868904/)》，在豆瓣上有 8.3 的高分。2008 年，他和 Joel Spolsky 联合创办了 [StackOverflow](https://stackoverflow.com) 问答网站，为程序员在开发软件时节省了非常多的时间，并开启了“StackOverflow Copy + Paste 式编程”。\n- [Joel on Software](https://joelonsoftware.com/) ，Joel Spolsky 的这个博客在全世界都有很多的读者和粉丝，其博文选集在中国被翻译成《[软件随想录](https://book.douban.com/subject/4163938/)》在豆瓣上有 8.7 的高分。这是一本关于软件技术、人才、创业和企业管理的随想文集，作者以诙谐幽默的笔触将自己在软件行业的亲身感悟娓娓道来，观点新颖独特，简洁实用。\n- [Clean Coder Blog](http://blog.cleancoder.com/) ，这是编程大师“Bob 大叔”的博客，其真名叫 Robert C. Martin，世界级软件开发大师，设计模式和敏捷开发先驱，敏捷联盟首任主席，C++ Report 前主编，被后辈程序员尊称为“Bob 大叔”。其博文选集在中国被翻译成《[程序员的职业素养](https://book.douban.com/subject/11614538/)》，在豆瓣上有 8.8 的高分。\n- [Martin Fowler](https://martinfowler.com/) ，这是另外一个程序员大师，Martin 主要专注于面向对象分析与设计、统一建模语言、领域建模，以及敏捷软件开发方法，包括极限编程。他的《[重构](https://book.douban.com/subject/1229923/)》、《[分析模式](https://book.douban.com/subject/4832380/)》、《[企业应用架构模式](https://book.douban.com/subject/1230559/)》、《[领域特定语言](https://book.douban.com/subject/21964984/)》和《[NoSQL 精粹](https://book.douban.com/subject/25662138/)》都是非常不错的书。在他的博客上有很多很多的编程和架构模式方法可以学习。\n- [Paul Graham Essays](http://www.paulgraham.com/articles.html) ，美国著名程序员、风险投资家、博客和技术作家。《[黑客与画家](https://book.douban.com/subject/6021440/)》是他的著作之一。2005 年他与人共同创建了科技创业孵化器 Y Combinator，孵化了 Airbnb、Dropbox、Stripe 等知名互联网公司。他有几篇创业方面的文章都很经典，如果你想创业，可以读一读这几篇：《[How to Get Startup Ideas](http://paulgraham.com/startupideas.html)》、《[Do Things that Don’t Scale](http://paulgraham.com/ds.html)》、《[Startup = Growth](http://www.paulgraham.com/growth.html)》。Paul Graham 的文章以清新自然，思想深刻见长。不仅可以跟 Paul Graham 学创业，学思考，学技术，更可以学习写作。\n- [Steve Yegge](https://medium.com/@steve.yegge) ，Steve Yegge 这个人算是一个知名的程序员了，在 Amazon 呆过，现在在 Google，他的文章都是长篇大论，最知名的文章就是[对 Amazon 和 Google 平台的吐槽](https://coolshell.cn/articles/5701.html)，这篇文章引发了大家的讨论和议论。\n- [Bruce Eckel’s Programming Blog](http://bruceeckel.github.io/) ，《Thinking in Java》作者的博客，他之前的博客在 artima - [Computing Thoughts](https://www.artima.com/weblogs/index.jsp?blogger=beckel) 。\n- [Herb Sutter](https://herbsutter.com/) ，C++ 大拿，C++ 标准委员会专家，微软软件架构师。《Exceptional C++ 》、《More Exceptional C++》、《Exceptional C++ Style》作者。\n- [Eli Bendersky’s website](https://eli.thegreenplace.net/) ，这位老哥从 2003 年就一直写博客到今天，其中的文章都非常不错，原理型的，主要是 C、C++ 和 Python 相关的。里面有很多干货。\n- [Peter Krumins’ blog ](http://www.catonmat.net/)，这位老哥从 2007 年开始写博客，他博客里好玩的东西太多了。\n- [Brendan D. Gregg](http://www.brendangregg.com/index.html) ，Brendan 是 Netflix 的工程师，他的博客里有大量的非常不错的文章，基本上都是和 Linux 性能分析相关的，这是一个如果你要玩底层性能分析一定不能错过的博客。\n- [Evan Klitzke](https://eklitzke.org/) ，主要讨论 Linux 和 C++ 相关的内容。\n- [Julia Evans](https://jvns.ca/) ，主要讨论 Linux debug 工具和网络相关的内容。\n- [null program](http://nullprogram.com/) ，和 C/C++ 相关的一个博客。其中关于 Linux 系统调用、GPU、无锁编程、JIT 编译的一些文章非常不错。\n- [Fluent {C++}](http://www.fluentcpp.com/) ，博主是 Murex 的首席工程师，主要玩 C++，在这个博客里有很多很不错的 C++ 相关的文章。\n- [Preshing on Programming](http://preshing.com/) ，这也是一个和 C/C++ 相关的博客，其中有很多的干货。\n- [Programming is Terrible](https://programmingisterrible.com/) ，这个博客有很多强观点的文章，主要是软件开发中的一些教训。\n- [Accidentally Quadratic](https://accidentallyquadratic.tumblr.com/) ，姑且翻译成事故二次方，这里有好些非常有趣的文章。\n- [Hacker Noon](https://hackernoon.com/) ，这是一个一堆人在写的博客，里面有很多质量很高的文章。\n\n其实还有很多不错的博客，不过，现在国外不错的博客都在一个叫 [Medium](https://medium.com/) 的网站，我也发现我 Google 很多东西时都会到这个网站上。这个网站上的内容不只有技术的，还有很多很多其他方面的内容，比如文化、艺术、科学等等。这个网站就是一个博客发布系统，其是由 Twitter 联合创始人埃文·克拉克·威廉姆斯（Evan Clark Williams）和克里斯多福·艾萨克·比兹·斯通（Christopher Isaac Biz Stone）创办的，这两个人觉得 Twitter 上全是垃圾没有营养的信息。所以，创办了 Medium，这个平台上有专业和非专业的贡献者，亦有受雇的编者。\n\n我已经感觉到，未来高质量的文章都会在 Medium 这个平台上出现，因为有一些公司的技术博客也在这个平台上发布了，比如 Netflix 的。所以，你有必要上到这个平台上 follow 一些作者、专栏和主题。\n\n# YouTube 技术频道\n\n下面是我订阅的一些我认为还不错的和编程相关的频道，推荐给你。\n\n- [Devoxx](https://www.youtube.com/channel/UCCBVCTuk6uJrN3iFV_3vurg) ，Devoxx 的频道，其中有各种很不错的技术分享。\n- [Coding Tech](https://www.youtube.com/channel/UCtxCXg-UvSnTKPOzLH4wJaQ) ，也是个非常不错的编程频道，涵盖各种技术。\n- [Amazon Web Services](https://www.youtube.com/channel/UCd6MoB9NC6uYN2grvUNT-Zg)\n- [Facebook Developers](https://www.youtube.com/user/FacebookDevelopers/)\n- [Google Developer](https://www.youtube.com/user/GoogleDevelopers) ，Google 公司的官方频道，其中包括 Google I/O 大会、教程、新闻、最佳实践、技巧分享……\n- [Spring Developer](https://www.youtube.com/user/SpringSourceDev) ，Spring 的官方频道。\n- [Microsoft Research](https://www.youtube.com/user/MicrosoftResearch)\n- [MIT 公开课](https://www.youtube.com/user/MIT)\n- [Stanford Online](https://www.youtube.com/user/stanfordonline)\n- [Prof. Dr. Jens Dittrich](https://www.youtube.com/user/jensdit) ，一个德国教授开的一个关于数据库相关的频道，里面有很不错的数据库内在原理的内容。\n- [Red Hat Summit](https://www.youtube.com/user/redhatsummit) ，RedHat 峰会频道，其中有很多和 Linux 相关的技术新闻和分享。\n- [Open Networking Summit](https://www.youtube.com/user/OpenNetSummit) ，这是一个网络相关的频道。\n- [Dan Van Boxel](https://www.youtube.com/user/dvbuntu/) ，这是一个机器学习工程师折腾各种事的视频，挺有意思的。\n- [The New Boston](https://www.youtube.com/user/thenewboston/) ，这个频道应该是前端开发工程师必去的地方，可能也是我所知道的最好的关于前端技术的 YouTube 频道。\n- [Derek Banas](https://www.youtube.com/user/derekbanas) 是一个教程型的频道，其中包括编程语言、游戏开发、Web 开发……我个人觉得是一个可以用来练英文听力的频道。\n- [Java](https://www.youtube.com/user/java/) ，Java 相关的各种分享。\n- [CppCon](https://www.youtube.com/user/CppCon) ，C++ 大会的一些视频，可以让你了解很多 C++ 最新功能和相关的动态。\n- [Computerphile](https://www.youtube.com/user/Computerphile) ，这个频道是布雷迪·哈伦（Brady Haran）运作的几个频道中的一个，在这个频道里你可以看到很多很有趣的技术方面的科普教程、资讯、见闻等，说得都非常地简单易懂，所以有大量的订阅用户。布雷迪是个对任何技术都很有热情的人，这个频道是关于计算机技术的。除此之外，他还运作 [Numberphile](https://www.youtube.com/user/Numberphile)（数学）、[Periodic Videos](https://www.youtube.com/user/periodicvideos)（化学）、[Sixty Symbols](https://www.youtube.com/user/sixtysymbols)（物理）、[Deep Sky Videos](https://www.youtube.com/user/DeepSkyVideos)（天文）等有众多阅人数的频道。如果你喜欢，你都可以一一订阅，感觉就是一个个人版的 Discovery。\n- 关于安全，有如下四个频道你可以订阅一下：\n  - [DEFCONConference](https://www.youtube.com/user/DEFCONConference) ，defcon.org 的官方频道。\n  - [CCCen](https://www.youtube.com/user/mediacccde/) ，Chaos Computer Club。\n  - [RSA Conference](https://www.youtube.com/user/RSAConference) ，RSA Conference。\n  - [Black Hat](https://www.youtube.com/user/BlackHatOfficialYT) - Black Hat Conference。\n\n# 各大公司技术博客\n\n细心的你一定会发现这份攻略中的很多推荐文章都来自于各个公司的技术团队的博客。是的，跟随这些公司的博客，你不但可以看到这些公司的工程技术，还能掌握到一些技术方向和趋势。\n\n下面是 Airbnb、AWS、Cloudera、Dropbox、Facebook、Google 等各个公司的技术博客列表。\n\n- [Airbnb Engineering](http://nerds.airbnb.com/)\n- AWS 相关\n  - [All Things Distributed](https://www.allthingsdistributed.com/)\n  - [AWS Architecture Blog](https://aws.amazon.com/cn/blogs/architecture/)\n  - [On Efficiency, Reliability, Scaling - James Hamilton, VP at AWS](http://mvdirona.com/jrh/work/)\n- [Bandcamp Tech](http://bandcamptech.wordpress.com/)\n- [BankSimple Simple Blog](https://www.simple.com/engineering/)\n- [Bitly Engineering Blog](http://word.bitly.com/)\n- [Cloudera Developer Blog](http://blog.cloudera.com/blog/)\n- [Dropbox Tech Blog](https://tech.dropbox.com/)\n- [Etsy Code as Craft](http://codeascraft.com/)\n- [Facebook Engineering](https://www.facebook.com/Engineering)\n- [Flickr Code](http://code.flickr.net/)\n- [Foursquare Engineering Blog](http://engineering.foursquare.com/)\n- [Google Research Blog](http://googleresearch.blogspot.com/)\n- [Groupn Engineering Blog](https://engineering.groupon.com/)\n- [High Scalability](http://highscalability.com/)\n- [Instagram Engineering](http://instagram-engineering.tumblr.com/)\n- [LinkedIn Engineering](http://engineering.linkedin.com/blog)\n- [Oyster Tech Blog](http://tech.oyster.com/)\n- [Pinterest Engineering Blog](http://engineering.pinterest.com/)\n- [Quora Engineering](http://engineering.quora.com/)\n- [Songkick Technology Blog](http://devblog.songkick.com/)\n- [SoundCloud Backstage Blog](https://developers.soundcloud.com/blog/)\n- [Square The Corner](http://corner.squareup.com/)\n- [The Reddit Blog](http://www.redditblog.com/)\n- [The GitHub Blog](https://github.com/blog/category/engineering)\n- [The Netflix Tech Blog](http://techblog.netflix.com/)\n- [Twilio Engineering Blog](http://www.twilio.com/engineering)\n- [Twitter Engineering](https://engineering.twitter.com/)\n- [WebEngage Engineering Blog](http://engineering.webengage.com/)\n- [Yammer Engineering](http://eng.yammer.com/blog/)\n- [Yelp Engineering Blog](http://engineeringblog.yelp.com/)\n- [Smarkets Blog](https://smarketshq.com/)\n\n# 论文\n\n要想将技术研究得精深，论文是必不可少的。那要如何读论文呢？\n\n## 如何读论文\n\n下面有几篇文章，教你一些读论文的方法，非常不错。\n\n- [How to read an academic article](http://organizationsandmarkets.com/2010/08/31/how-to-read-an-academic-article/)\n- [Advice on reading academic papers](https://www.cc.gatech.edu/~akmassey/posts/2012-02-15-advice-on-reading-academic-papers.html)\n- [How to read and understand a scientific paper](http://violentmetaphors.com/2013/08/25/how-to-read-and-understand-a-scientific-paper-2/)\n- [Should I Read Papers?](http://michaelrbernste.in/2014/10/21/should-i-read-papers.html)\n- [The Refreshingly Rewarding Realm of Research Papers](https://www.youtube.com/watch?v=8eRx5Wo3xYA)\n\n## 论文集散地\n\n要成长为一个高手，论文是你一定要读的。下面是一些非常不错的计算机方面的论文集散地。\n\n- [2 Minute Papers](https://www.youtube.com/user/keeroyz) ，这是一个 YouTube 的频道，其会给出一些非常不错的和计算机相关的论文介绍，让你了解目前最有意思的一些科学突破，每次两分钟左右。\n\n- [Best Paper Awards in Computer Science](http://jeffhuang.com/best_paper_awards.html) ，从 1996 年以来，获奖的计算机科学方面的论文收集。\n\n- [Google Scholar](http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=eng) ，Google 学术搜索（英语：Google Scholar）是一个可以免费搜索学术文章的网络搜索引擎，由计算机专家阿努拉格·阿查里雅（Anurag Acharya）开发。2004 年 11 月，Google 第一次发布了 Google 学术搜索的试用版。该项索引包括了世界上绝大部分出版的学术期刊。\n\n- [Facebook](https://research.fb.com/publications/) ，Facebook 公司的论文。\n\n- [Research at Google](https://research.google.com/pubs/papers.html) ，Google 发布一些论文。\n\n- [Microsoft Research](http://research.microsoft.com/apps/catalog/default.aspx?t=publications) ，微软发布的论文。\n\n- [MIT’s Artificial Intelligence Lab Publications](http://dspace.mit.edu/handle/1721.1/39813) ，MIT 和人工智能相关的论文。\n\n- [MIT’s Distributed System’s Reading Group](http://dsrg.pdos.csail.mit.edu/) ，MIT 和分布式系统相关的论文。\n\n- [arXiv Paper Repository](http://arxiv.org/) ，arXiv 是一个收集物理学、数学、计算机科学与生物学的论文预印本的网站，始于 1991 年 8 月 14 日。截至 2008 年 10 月，arXiv.org 已收集超过 50 万篇预印本。至 2014 年底，藏量达到 1 百万篇。\n\n  在 2014 年时，约以每月 8000 篇的速度增加。arXiv 的存在是造就科学出版业中所谓开放获取运动的因素之一。现今的一些数学家及科学家习惯先将其论文上传至 arXiv.org，再提交予专业的学术期刊。这个趋势对传统学术期刊的经营模式造成了可观的冲击。\n\n- [SciRate](https://scirate.com/) ，arXiv 上的论文太多，所以，SciRate 索引了 arXiv 上的一些好评的论文，并供大家评论和打分。（[开源代码](https://github.com/scirate/scirate)。）\n\n- [cat-v.org](http://doc.cat-v.org/) ，这个网站，不只有论文，还有技术手册或是一些有意思的文章，包括一些历史资料什么的。\n\n- [Usenix: Best Papers](https://www.usenix.org/conferences/best-papers) ，Usenix 上推荐的最佳论文。\n\n- [The Morning Paper](https://blog.acolyer.org/) ，该博客会每天推送一篇论文，特别棒。\n\n- [Lobste.rs tagged as PDF](https://lobste.rs/t/pdf) ，Lobsters 是一个聚焦于技术的社区，主要是链接聚合和对话题进行讨论。其中的 PDF 分类可以认为也是一个论文的集散地。\n\n- [Papers We Love](https://github.com/papers-we-love/papers-we-love) ，GitHub 上的一个近 3 万颗星的计算机科学方面的论文社区。\n\n# 小结\n\n总结一下今天的内容。这篇文章我主要跟你分享了一些好的学习资源，帮你开拓眼界，为后续学习夯实基础。\n\n首先，我推荐了 Coding Horror、Joel on Software、Clean Coder Blog、Martin Fowler、Paul Graham Essays 等多个知名的个人技术博客。然后分享了一些我认为还不错的和编程相关的 YouTube 频道，比如 Coding Tech、Amazon Web Services、Facebook Developers、Google Developer 等。\n\n随后是 Airbnb、AWS、Cloudera、Dropbox、Facebook、Google 等各个公司的技术博客，跟随这些公司的博客，你不但可以看到这些公司的工程技术，还能掌握到一些技术方向和趋势。最后，想成长为一个高手，论文是一定要读的。所以，我给出了一个非常不错的计算机方面的论文集散地，并推荐了一些学习资源来教你如何读这些论文。\n\n我一直认为，学习需要自我驱动，要学会自己“找食物”，而不是“等着喂”。程序员练级攻略 2018 版到今天就全部更新完成了，但我认为，这其实只是技术练级的起点，还有很多知识和技术，需要我们不断地去探索和发现。加油，我能做到的，你一定也可以做到。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/12561\" > </iframe>","categories":["左耳听风"]},{"title":"091丨程序员面试攻略：面试前的准备","url":"/posts/3034919374.html","content":"\n\n\n学习了《程序员练级攻略》以后，我觉得你应该来学习一下“如何面试”了。在我的职业生涯中，我应聘过很多公司，小公司、中型公司、大公司、国内的公司、国外的公司都有。我有成功获得 offer 的经历，也有过不少失败的经历。\n\n我从 2007 年做管理以来，面试过至少 1000 多人次的工程师。这十多年来，我发现有一些事情没什么变化，我们一代又一代的年轻人在应聘时的表现和我 20 年前没什么两样，连简历都没什么改进，更不要说程序员在表达能力方面的长进了。如果只看面试表现的话，感觉世界停止了 20 年似的。\n\n我一直在想，为什么应聘、与人沟通、赚钱等这些重要的软技能，学校里不教呢？这么重要的技能居然要你自己去学，不得不说是教育上的一种失败。另外，关于如何应聘的事，估计你也看过一些文章了，我这里只分享一些我的实实在在的经验和相关的技巧。一定你和看过的不太一样。相信一定能帮得到你！\n\n应聘是需要准备的，下面这些点你需要好好地准备一下。如果你没有准备的话，那么被 pass 掉的概率会非常大。\n\n# 怎样写简历\n\n首先你要准备的是简历。简历很重要，这是别人了解你的第一个地方，所以简历要好好写。当然，**我们知道真正的好简历是要用自己的经历去写的**，比如，有人的简历就是一句话：我发明了 Unix。\n\n当然，并不是所有的人都有这样的经历，但这依然告诉我们，自己的经历才是简历最大的亮点。所以，你要去那些能让你的简历有更多含金量的公司工作，要做那些能让你的简历更闪亮的工作。这是写简历的最佳实践——用自己的经历聊，而不是用文字写。\n\n但从另一方面来说，简历这个文本也是要好好写的，况且，我们不是每个人都会有很耀眼的经历，所以，还是要好好写简历。基本上来说，简历上的信息不要写太多，信息太多相当于没有信息，不要单纯地罗列，要突出自己的长处和技能。一般来说，简历需要包括以下几项内容。\n\n- **自我简介**。这个自我简介是用最简单的话来说明自己的情况，不超过 200 字。比如：10+ 年的软件开发经验（说明你的主业），4+ 年的团队 leader 经验（说明你的领导力），擅长高可用高性能的分布式架构（说明你的专业和专攻），多年互联网和金融行业背景（说明你的行业背景），任职于 XXX 公司的 XX 职位（说明你的职业），负责 XXX 平台或系统（说明你的业务场景）……\n- **个人信息**。这里有几点需要注意。\n  - **基本信息**。电子邮箱建议用 Gmail，千万不要用 QQ 邮箱，要让人感觉职业化一些。\n  - **个人网站**。如果你有个人主页、博客、GitHub 或是 Stack Overflow，请一定附上，这是加分项。如果个人主页或博客有独立域名，那更好，这会给人一种你爱动手做事的感觉。页面也要干净有美感，这样会让人感觉你有品味。\n  - **网站内容**。一般来说这些项都会被面试官点看浏览，所以，里面的内容你需要小心组织和呈现，千万不要造假。另外，除了技术上的一些知识总结（不要太初级，要有深度的、原理型的、刨根问底型的文章），你也可以秀一秀自己的技术价值观（比如，对代码整洁的追求，对一些技术热点事件的看法），这会让你更容易获得面试官的好感。面试官的好感很重要。\n  - **作品展**。如果你有一些作品展现，会更好。当然，对于前端程序员来说，这是比较容易的。而对于后端程序员来说，这会比较难一些，只能展示一下自己的 GitHub 了。如果你有一些比较不错的证书或奖项（如微软的认证、Oracle 的认证），也可以展示一下。\n- **个人技能**。个人信息下面你应该罗列几条个人的技能。这些内容要能很明显地让对方了解你掌握的技术和熟悉的领域。\n  - **技术技能栈**。其中包括你擅长和会用的编程语言（如 Java、Go、Python 等），编程框架或一些重要的库（如 Spring Boot、Netty、React.js、gRPC 等），熟悉的一些技术软件（如 Redis、Kafka、Docker 等），设计或架构（如面向对象设计、分布式系统架构、异步编程、高性能调优等）。\n  - **技术领域**。前端、算法、机器学习、分布式、底层、数据库等。\n  - **业务领域**。一方面是行业领域，如金融、电商、电信等，另一方面是业务领域，如 CRM、支付、物流、商品等。\n  - **经验和软技能**。带过多少人的团队、有多少年的项目管理经验、学习能力如何、执行力怎么样、设计过什么样的系统。（不要太多，几句话就好）\n\n其实和用人单位发布的招聘信息中的职位技能需求很相似。有时候我都在想，明明用人单位的职位需求里写成那样，为什么应聘人还不依葫芦画瓢呢？所以，**对应于你的简历，如果能和职位需求看齐有相类似的描述，这样可以快速地让人觉得你和要应聘的职位很匹配**。\n\n- **工作经历和教育经历**\n  - 列一下你的工作经历。每份工作完成的主要项目（不要列一大堆项目，挑重要的），主要突出项目的难度、规模、挑战、职责，以及获得的认可和荣誉。\n  - 工作经历和教育经历，主要是对上述的个人技能的印证。不要东拉西扯，要紧紧地围绕着你的技能、特长和亮点来展开。\n\n一般来说，你简历中的内容最好控制在两页 A4 纸以内，最好有中英文版，简历不要是 Word 版的，最好是 PDF 版，然后**简历的格式和风格请参考 LinkedIn 上的**（在 [微软的 Office 模板网站](https://templates.office.com/en-us/Resumes-and-Cover-Letters) 上也能找到一些不错的简历模板）。简历的内容不要太多，内容太多，重点就不明显了。写简历的目的是呈现自己的特长、亮点和特点。只要你能呈现出 2-3 个亮点和特长，就可以吸引到人了。\n\n简历只是一块敲门砖。一些热门的公司和项目能够吸引到很多很多人的简历，所以，你要在众多的简历中脱颖而出。除了自己的经历和能力有亮点外，你还需要有吸引用人单位的方法。\n\n有很多公司都是 HR 先来筛一遍简历，HR 其实并不懂技术，她们只会看你的过往经历、能力是否和职位描述上的匹配。如果简历上的经历和技术亮点不足的话，那么你可以在简历的版式和形式的制作上花些心思，以及在简历的自我描述中加上一些“虚”的东西。\n\n比如“工作态度积极，不分份内和份外的事，只要对公司和个人有利，都会努力做好；勤奋踏实，热爱学习，喜欢做一个全栈工程师；善于发现问题，并解决问题……”表示我虽然现在的经历和技能不足以打动你，但是我的态度端正，潜力巨大，你不能错过……\n\n# 技术知识准备\n\n一般来说，你的简历上写什么，面试官就会问什么，所以，不要打自己的脸，精通就是精通，熟悉就是熟悉，了解就是了解。然后对于你列出来的这些技术，你一定要把其最基本的技术细节给掌握了。面试官一般也会逐步加大问题的难度和深度，看看你到底在哪个层次上。所以，你还是需要系统地看看书，才能应对面试官的问题。比如：\n\n- 你写上了 Java，那么 Java 的基本语法都要了解，并发编程、NIO、JVM 等，你多少要有点儿了解，Spring、Netty 这些框架也要了解。\n- 你写上了 Go，那么至少得把官网上的 Effective Go 给看了。\n- 你写上了 Redis，那么除了 Redis 的数据结构，Redis 的性能优化、高可用配置、分布式锁什么的，你多少也要把官网上的那几篇文章读一读。\n- 你写上了面向对象，那么怎么着也得把《设计模式》中的 23 个模式了解一下。\n- 你写上了分布式架构，那么 CAP 理论、微服务架构、弹力设计、Spring Cloud、Cloud Native 这些架构就要做到心里有数。\n- 你写上网络编程，那么 TCP/IP 的三次握手，四次挥手，两端的状态变化你得知道吧，Socket 编程的那几个系统调用，还有 select、poll、epoll 这些异步 IO 多路复用的东西，你得知道。\n\n总之，无论你在简历里写什么技术，这些技术的基础知识你都得学一下。本质上来说，这跟考试一样啊。你想想你是怎样准备期末考试的，是不是得把教科书上所有章节中的关键知识点都过一下？你不见得要记住所有的知识点，但是 80% 以上的关键知识点，你多少得知道吧。\n\n# 算法题准备\n\n国外的公司一般还会面算法题，他们用算法题来过滤掉那些非计算机专业出身的人。国内的一些公司也一样，尤其是一些校招面试，也有很多算法题。所以，算法是很重要的，是你需要努力学习和准备的。\n\nLeetCode 是一个不错的地方。如果你能完成其中 50% 的题，那么你基本上可以想面哪里就面哪里了。这里，你要知道，一些面试官也是新手，他们也是从网上找一些算法题来考你。所以，你不用太害怕算法题，都是有套路的。比如：\n\n1. 如果是数据排序方面的题，那基本上是和二分查找有关系的。\n2. 如果是在一个无序数组上的搜索或者统计，基本上来说需要动用 O(1) 时间复杂度的 hash 数据结构。\n3. 在一堆无序的数据中找 top n 的算法，基本上来说，就是使用最大堆或是最小堆的数据结构。\n4. 如果是穷举答案相关的题（如八皇后、二叉树等），基本上来说，需要使用深度优先、广度优先或是回溯等递归的思路。\n5. 动态规划要重点准备一下，这样的题很多，如最大和子数组、买卖股票、背包问题、爬楼梯、改字符……这里有一个 [Top 20 的动态规划题的列表](https://www.geeksforgeeks.org/top-20-dynamic-programming-interview-questions/) 。\n6. 一些经典的数据结构算法也要看一下，比如，二叉树、链表和数组上的经典算法，LRU 算法，Trie 树，字符串子串匹配，回文等，这些常见的题都是经常会被考到的。\n\n基本上来说，算法题主要是考察应聘者是否是计算机专业出身的，对于基本的数据结构和算法有没有相应的认识。你做得多了，就是能感觉得到其中的套路和方法的。所以，本质来说，还是要多练多做。\n\n# 工作项目准备\n\n无论什么公司的面试，都会让你说一个你做过的项目，或是你过去解决过的一个难题。但我很好奇怪，这种必问的题，为什么很多应聘者都没有好好准备一下。\n\n一般来说，会有下面这样的几个经典的面试问题。\n\n1. 说一个你做过的最自豪的项目，或是最近做过的一个项目。\n2. 说一个你解决过的最难的技术问题，或是最有技术含量的问题。\n3. 说一个你最痛苦的项目，或最艰难的项目。\n4. 说一个犯过的最大的技术错误，或是引发的技术故障。\n\n对于上面这四个问题：第一个问题，主要是想看看你过去工作中做过的最高级的事是什么，还有你的兴趣点和兴奋点是什么；第二和第三个问题，主要是想看看你解决难题的能力，以及面对压力和困难时的心态；第四个问题，主要是想了解一下你面对错误时的态度，还要了解你是否会对错误有所总结和改进。\n\n这些问题都会伴随着对各种细节的不停追问，因为这样的问题太容易造假了。所以，面试官会不停地追问细节，就像审问一样。因为一个谎言需要用更多的谎言来掩盖，如果没有经过高强度和专业的训练的话，最好不要撒谎。因此对于业余的不是做特工或是间谍的人来说，谎言是经不起追问的。\n\n怎样准备这样的题，我这里有几个提示。\n\n- **要有框架**。讲故事要学会使用 STAR 。Situation - 在什么样的环境和背景下，Task - 你要干什么样的事，Action - 你采取了什么样的行动和努力，Result - 最终得到了什么样的效果。这是整个语言组织的框架，不要冗长啰嗦。\n- **要有细节**。没有细节的故事听起来就很假，所以，其中要有很多细节。因为是技术方面的，所以，一定要有很多技术细节。\n- **要有感情**。讲这些故事一定要带感情。要让面试官感受到你的热情、骄傲、坚韧和顽强。一定要是真实的，只有真实的事才会有真实的感情。\n- **要有思考**。只有细节和故事还不够，还要有自己的思考和得失总结，以及后续的改进。\n\n要做到上述，是不容易的。一般来说，你也是需要训练的。首先，你要形成及时总结的习惯，对自己的日常工作和经历做总结，否则难免会有“书到用时方恨少”的感觉。另外，你还需要训练自己的语言组织能力。最后，你还要有对这些事件的思考，这需要和其他人进行讨论和总结。\n\n对此，如果你想有一个比较好的面试回答效果，**这不是你能临时准备出来的，工夫都是花在平时的。而训练这方面能力的最好方式就是在工作中写文档 ，在工作之余写博客**。只有写得多了，写得好了，你这样的能力才能训练出来。\n\n# 小结\n\n总结一下今天的内容。面试前的准备该怎样做，对面试成功与否至关重要。在这篇文章中，我分享了自己总结一些经验和相关技巧。首先是怎样写简历，我认为，简历上的信息不要写太多，信息太多相当于没有信息，不要单纯地罗列，要突出自己的长处和技能。\n\n然后是技术知识的准备，我强调，无论你在简历里写什么技术，这些技术的基础知识你都得学一下。即便不能记住所有的知识点，但是 80% 以上的关键知识点，你多少得知道吧。随后是算法题的准备，我推荐了 LeetCode，并给出了好几种经典算法题的解题套路。\n\n最后是工作项目的准备，给出了几种经典的面试问题及应答思路，并分享了该如何做准备。我认为，想有一个比较好的面试回答效果，是临时准备不出来的，要将工夫花在平时。\n\n下篇文章中，介绍的是面试中的技巧，比如，答不出来时该怎么办、如何回答尖锐问题、如何抓住最后提问的机会等，很有实践指导意义。敬请期待。\n\n\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/13067\" > </iframe>","categories":["左耳听风"]},{"title":"093丨程序员面试攻略：面试风格","url":"/posts/1493512634.html","content":"\n\n\n国内公司和国外公司在面试风格上完全不一样，所以，这里我们也需要了解一下不同风格的面试方法，这样有利于你准备。\n\n说句实话，国内的公司是比较好面的，国外的公司是比较难面的。从职位招聘信息上你就可以看出来，国内的公司包括知名公司更多的是面试在表面上。因为国内公司招的基本上都是马上能来干活的，所以，问的更多的是一些技术知识上的东西。\n\n准备这些知识性的东西，本质上来说跟准备考试没什么两样，恶补一下相关知识就好了。然后讲一个项目，项目中他们也不怎么追问细节，面试的过程中，也不需要写代码，也不需要解决一个难题，所以，容易蒙混过关。\n\n国外的知名公司就没有那么容易了，真是全方位的考察，你的表达能力、沟通能力、思维方式、解题思路、代码风格、算法和数据结构、设计和架构能力、解决难题的能力……这是很难靠恶补就可以过关的，没有踏踏实实的沉淀、钻研和思考，你是很难过关的。\n\n# 国内公司\n\n对于在基层干活的程序员来说，国内的公司，小公司不说了，诸如 BAT 这样的公司，基本上来说，都是比较好面的。一般来说，都会问你一些技术知识，比如：Java 语言的一些特性啊，会不会用 Spring 和 Netty 啊，JVM 怎么配置怎么调试啊，并发编程是怎么玩的……\n\n这些问题基本上来说都是知识性的问题，都是可以 Google 的，通过查手册查文档就可以知道的。所以，这些问题是很容易准备的，只要你老老实实地看几本我在《程序员练级攻略》里推荐的书就好了。当然，还是有很多人连这些基本的问题都回答不上来，这只能怪自己了。\n\n回答完这些知识性的问题，就是项目经历描述了。你可以随便讲你做过的项目，把这个项目用到的一些技术架构都说清楚就好了，还有怎么上线的，怎么运维的，怎么加班的，怎么苦逼的，怎么带人的，怎么管理项目的。面试官也很少追问技术细节，因为可能面试官自己都不懂（哈哈）。\n\n只要你按照我前面说的那个讲项目的方式来，面试官一看你用到的技术栈和我这边的很类似，他就开始想要你了。当然，国内的公司更多的是缺劳动力，所以，只要你能让他们感到你很能吃苦耐劳、任劳任怨，而且能很快上手干活就好了。\n\n然后就是 HR 和老板的面试了，HR 和老板不懂技术，也不会问你技术问题，他们主要是看看你的性格和态度等。只要你表现能吃苦耐劳，踏实肯干，如果还有一点“灵性”（脑子转得快，与人好沟通，一来一回有问有答，性格外向点儿），在国内的面试你是很容易通过的。\n\n基本上来说，国内公司喜欢快进快出，也就是说，不在面试上花太多的精力，进来就干活，不行就开掉，基本上是找工人找劳动力的玩法，也不关心员工的成长。所以，面试过程基本上来说，都是围绕你干什么，我这边这些事你会不会干，你会不会加班、能不能吃苦耐劳，听不听话等这样的内容进行的。\n\n当然，对于架构师或是高级别的技术人员，又是另一种面试方式，这在国内的大公司中得分两种。\n\n- 一种是业务型部门的高级技术人员，基本上来说，不会再问你一些技术的细节，只会问你一些架构方面、项目管理方面，以及技术方面的事，或者一些业务架构上的事情。相对来说，业务或应用方面的架构师和高级工程师需要对业务和行业比较了解，有丰富的业务项目经验就好了，技术上倒不需要有多深的知识。我觉得，在一个行业呆久了，只要你对业务有思考，再加上有技术把持，基本上来说，只要平时多读一些不错的业务上的想法，还是比较好过的（因为不会问及细节问题）。\n- 另一种是偏技术部门的架构师和高级工程师，比如核心基础技术，或是云计算之类的。那就会问你很多技术细节上的东西了，而且问得还很深，需要你有相应的项目经验，或是开源社区里的工作经验。你需要有过相当的经历才有可能面过。但是，回过头来说，就算是这样的岗位，本质上还是会回到面知识型问题的方法，所以，无非就是你能钻研的知识深一点儿罢了。知识是死的，只要你努力，你总有一天能学会的。\n\n总体来说，与国外公司相比，国内的公司不管是哪个层级上的面试都是比较好通过的。\n\n# 国外公司\n\n国外的公司我面过的不多，只面过，Amazon、Google、Microsoft、Facebook 这几个大公司，还有一些小公司就不在这里说了。这几个大公司中，Facebook 是相对比较好面的，Google 是相对最难面的。这些公司的面试最近都有改观，不再以算法为主要面试手段了，但还是会多多少少面你算法方面的题目。而且，无论初级还是高级的技术人员的面试都还是有点难的，因为这些公司的招聘标准是要招超过现有团队同等级别 50% 以上的人。这就要求团队成员只能越来越好，最终导致标准越来越高。\n\n一般来说，会有两轮电话面试，一轮是工程师面写代码，主要是算法相关的代码，然后可能还是工程师再面一轮技术，或是经理电话面一轮，主要想了解一下你目前的工作职责还有你的一些长处和喜好，包括你的一些想法什么的。如果没有什么问题，你就会进入到 in-house 面试。\n\nin-house 面试一般要面一天，最少 5 轮，3 轮和技术相关（包括代码、算法、设计、架构、Problem solving），1 轮是经理 (包括做过的项目、解决问题的能力、学习能力、思考方式……)，1 轮是 HR（包括性格、喜好、薪水……）。老实说，这种车轮战的面试，如果你之前没玩过，是第一次上，那么会非常不习惯。一天面下来，你会累死。当然，习惯了你就会觉得没什么问题，所以还是要多练习。\n\n国外的公司面试时一定会让你写代码，无论你面多高级的职位，只要是技术岗，基本上都会让你写代码。你千万不要把代码写得跟面条一样，至少要分模块函数，把函数接口定义得清楚点儿，代码逻辑也要简洁清楚（有大量的 if-else 嵌套的一定不是好代码），变量命名也要好一点儿。写代码的过程中如果有觉得不好的要打上 `//TODO:refactor me` 之类的注释，这样会是一个好的编码习惯。一般写完代码后，面试官会问如下几个问题。\n\n- 讲解一下你的代码。这主要是跟你一起 Review 代码，一般会考你的表达能力。最好用一到两个 case 来讲解一下代码会更好。\n- 分析一下代码的时间和空间复杂度。\n- 优化代码，包括代码中的 Bug 以及更高性能的算法。\n\n在这个过程中，面试官除了要答案以外，也会了解你的思维方式或是做事方式。\n\n注意，有些很有经验的面试官会从一个很简单的编码题开始，然后不断地加需求，或是改需求。一旦你发现这个事的时候，我给你的建议是不要马上实现新的需求，而是停下来，和面试官讨论需求，感觉一下未来可能的需求变化，然后开始重构代码，抽象该抽象的代码，将接口和实现分离，把程序逻辑和业务功能分离。\n\n这里，你需要使用很多编码技巧甚至一些设计模式。如果你让面试官看到你是在 Case-by-Case 地写代码，那你就完蛋了。基本上来说，如果你平时写代码不是这样的习惯，在这个过程中你是无法装的，你会被搞得原形毕露的。\n\n在设计和架构中，一般会涉及面向对象方面、数据库设计方面和系统架构方面的内容。系统架构方面的内容问得也很多，基本上都在问一些和高并发、高可用、高性能和大规模分布式相关的架构。但是，在你解题前，你一定要问清楚需求，不要急着说结论。先调研需求，最好再问一下，为什么要做这个需求？做这个需求的意义是什么？\n\n当你了解完需求后，你还可以挑战一下，如果是这个需求的话，为什么不用另外一种方式或架构？这些问题，都是加分项。搞清楚需求后，你要开始设计系统了。设计系统时，你不要只是拍脑袋，还需要做一点容量计算。如果数据不完整，你直接跟面试官说清楚就好了，有数据上的支持会让你更好地设计你的架构，而且，这会是非常大的加分项。\n\n另外，在设计系统时，还要考虑到系统未来的扩展性，也就是未来如果又加入一些别的东西进来，或是量变得很大了，你的系统是否可以容易地进行功能扩展或性能扩展。这个架构问题，如果你没有足够丰富的经验，或是严谨的思考，并不容易做得出来。\n\nProblem Solving 是一些国外公司尤其是 Amazon 最喜欢面的一个环节了。国外的这些大公司都认为他们要解决的问题是没有人解决过的，所以他们需要的人才也是能解决自己从来没有见过的问题的人。一般来说，面试官会给你一个你从来没有见过的问题，而且是很难的问题，很明显是一个只有工程师才能解的问题。\n\n比如，用最简单的方式统计一条公路上向两个方向开出的汽车（比如在公路路面上放两个压力传感器什么的），或是让你设计一个自动化的学校排座系统，能够让性格接近的人坐在自己身边等。一般来说，他也不指望你能在一个小时的面试中找到问题的最优解，主要看你的解题思路。另一方面，面试官也会和你一起来解（有可能面试官自己也不知道答案），这样他想感觉一下，和你一起工作，一起解难题是个什么样的体验。\n\n总之，面试国外的公司不是你在短期就能准备的，尤其是面一些高级别的技术职位，还是比较难的。基本上来说，你脑子要转得快，智商也要比较高，还要在日常受过比较好的软件开发或是工程架构上的训练，平时还要很系统、很工程地做事，用正确且严谨的方式做事。不然，你一定是面不过的。\n\n# 小结\n\n总结一下今天的内容。我认为，国内外公司的面试风格有很大不同。国内的公司是比较好面的，国外的公司相对难面一些。国内公司包括知名公司要招的基本上都是马上能来干活的，所以，面试中问的更多的是一些技术知识上的东西。比较好准备，恶补一下相关知识就好了。不怎么追问细节，也不需要写代码，也不需要解决一个难题，容易蒙混过关。\n\n国外知名公司则对面试者进行全方位的考察，你的表达能力、沟通能力、思维方式、解题思路、代码风格、算法和数据结构、设计和架构能力、解决难题的能力……这些是很难靠恶补就能过关的。因此，我针对这两种不同的面试风格，给出了相应的面试流程，以及应对技巧。\n\n下篇文章中，我们将介绍是程序员面试攻略：实力才是王中王的相关内容。\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/13191\" > </iframe>","categories":["左耳听风"]},{"title":"094丨程序员面试攻略：实力才是王中王","url":"/posts/4097184250.html","content":"\n\n\n之前的《程序员练级攻略》系列文章，对于面试成功与否是非常重要的，但是因为内容太多，所以，你可能会迷失。这里，我再补充一下相关的知识。\n\n对于后端程序员来说，C、C++ 和 Java 是一定要学好的，TCP 网络和 Linux 系统编程也是需要学好的。《练级攻略》中那些资料如果你能全部吃透和掌握的话（也就是“编程语言”和“系统知识”这两个章节），那么，中国的所有公司你都可以进，包括 BAT，职位可以面到一级的高级工程师。年薪至少 30 万左右。\n\n如果你要更为底层的话，那么需要掌握高手篇中的“Linux 系统、内存和网络”、“异步 I/O”、“Lock-Free”，以及“Java 的底层知识”，把里面的那些资料都看懂学透，那么，你可以面过年薪 50 万的职位。这是没有问题的。\n\n如果你要往架构师方面发展，一方面你需要有足够多的经验，以及相关的项目实施经验，这需要在相当的大公司里做过相应的项目和架构。再辅助以高手篇中的分布式架构的三篇：入门、经典图书和论文、工程设计，以及微服务和容器化这些内容，我保证你至少可以拿到年薪 60 万以上的工作。\n\n前端的东西如果要学习好的话，并不难。攻略中也有三篇和前端相关的文章，那三篇文章学习个 3-5 年，你也是一个非常厉害的前端工程师了，能找到 30 万 - 50 万的工作应该没什么问题。只不过，如果你还想更好的话，你需要走两个方向，一个是设计（不是软件设计，而是 UI/UX 设计），另一个是后端架构技术。\n\n你一定要明白，真正解决用户的问题的不是前端技术，而且是后端的业务逻辑和数据计算。**前端并不是计算机的本质，计算机提升社会运作效率并不是靠前端完成的，而是靠自动化来完成的，前端只是辅助。**\n\n另外，如果你今天还在做支持性的工作，那么你要赶快转到有产出性的工作上去，不然的话，你未来也危险了。比如像测试、运维、项目管理等，这些都是支持性的工作。我个人建议你转到开发工作上，比如开发测试工具，开发运维系统和工具，开发项目管理软件……只有到了开发上，你才会有更好的发展空间。\n\n多唠叨一句，学习不要图快，要学会找到掌握知识的方法，而不是死记硬背。学习要细嚼慢咽，一天吃不成个胖子。\n\n# 面试的训练\n\n对面试来说，比较好的训练就是要经常出去面试，所以还是应该隔三岔五就出去面试一下的。一方面可以攒攒经验值，可以训练一下自己的语言表达能力和应对各种问题的回答。另一方面更重要，可以了解一下目前市场的需求（技术、技能和业务），同时了解一下自己的身价。\n\n我记得以前我在一家公司埋头干了 4 年不问外界的事。有一天，被朋友推荐到某公司，去面了一把。那家公司问我要多少钱，我说，8 千一个月。对方说，你要少了，你这样的能力，市场价至少一万五了（我在当时所在的公司才拿 6 千）。所以，我开始更新简历，面了好些公司，发现我的薪资、岗位以及我的能力，果然与市场价严重不匹配……\n\n你之所以会紧张，会不知所措，会感到不适，会觉得难，大多数情况下是因为你不熟悉这个环境，你对这个环境还很陌生。只要你面得多了，你就会熟悉这个环境，你也就能驾轻就熟了。“老司机”之所以能成为“老司机”，还不是因为经常跟女孩子聊天交谈，时间长了，就成老司机了。\n\n另外，对于语言组织的训练，除了多多与人交流，还有就是你平时需要多看多写，喜欢看书和写作的人通常在语言表达能力方面也不会差，而反之则通常会比较差。所以，写 blog，表达自己的想法是很重要的。\n\n# 跳槽和升职\n\n有人说，跳槽是升职加薪最好的手段，这么说也有一定道理，因为只有用人单位在竞争你，你的职位和薪资才能提得上去。如果你想靠公司的良心，这是比较难的，除非你非常非常出色。很多人都是会以跳槽来作为升职或加薪的手段的。\n\n我认为，对于一个人来说，适当的跳槽还是很有必要的。有些时候，在一个地方做得再好，也要出去看看外面的世界是什么样的。一方面，有了对比后，你才会更明白自己要什么，另一方面，想把握趋势和行业动态，也需要你跳槽。只是跳槽不宜太频繁，最好不要低于两年换一次，而且最好承前启后，不要有太多的过渡。\n\n如果你想在一家公司内从普通员工升职到公司高管这个可能还是有点难的，所以，通过跳槽的方式来达到这一目标还是可能的。但是，这需要一定的策略。比如，你需要先去世界顶尖公司，在里面做到高级技术人员的级别，甚至可能你先要去读书深造。总之，你需要先进入国外一流公司（比如微软），然后，在里面升 1 或 2 级，然后可以跳到另一家相当的公司（比如谷歌或亚马逊）。\n\n此时，你的简历会非常亮眼了，只要你的级别是高级程序员（对应于亚马逊的 SDE3），你会成为国内各大公司追捧的人才，你回国到 BAT 这样的公司里做个高级管理人员是没有任何问题的。然而，如果你一开始不是去这些顶尖公司，而是直接到 BAT 里做个程序员，我觉得未来能上到中高层的机会不会多。\n\n总之，如果你决定在职场大展宏图的话，那么在年轻的时候，让自己的简历变得越漂亮越好。最好是先去国外，然后在需要职业成长的时候，被国内公司重金请回来，会比直接在国内的公司里发展要好一些。这是我个人觉得比较好的方式。\n\n# 最重要的事\n\n程序员面试中，最重要的事还是自己技术方面的能力，国内会注重你的项目经验，国外会注重你的基础知识、项目经验、解题思路，以及软件设计能力。所以，要努力提高自己的这些技术技能和见解。\n\n在《程序员练级攻略》这一系列文章中，除了一个大型的地图，以及很多技术的学习资料和资源外，我也给出了很多公司的最佳实践和解题思路。就算你没有实际工作经验，通过思考和研究这些前人的经验，站在巨人的肩膀上，会为你开启更大的舞台。当你去到这些大公司后，就可以把你学习到的这些知识立马用上。\n\n当然，计算机软件开发是一件动手能力很强的事，所以，你需要不断地动手。好在这个世界有开源项目，加入开源项目会比加入一个公司的门槛要低得多。你完全可以到开源项目中攒经验，这可能会比在工作中攒到的经验更多。\n\n总之，我想说的是，要应付并通过面试并不难，但是，千万不要应付你的人生，你学技术不是用来面试的，它至少来说是你谋生的技能，要尊重自己的谋生技能，说不定，哪天你还要用这些技能造福社会、改变世界的。\n\n# 小结\n\n总结一下今天的内容。《程序员练级攻略》系列文章，对于面试成功与否是非常重要的，但内容太多，所以在本文一开始，我总结概述了其中的重点内容，方便你能提纲挈领地掌握关键知识点。\n\n随后，我强调要想取得良好的面试效果，也是需要多加练习的，隔三岔五就出去面试一下，积累面试经验的同时，也了解一下市场行情。然后探讨一个有些敏感的话题“跳槽和加薪”，我认为，先去国外，然后在需要职业成长的时候，被国内公司重金请回来，会比直接在国内的公司里发展要好一些。\n\n最后分享的是程序员面试过程中最重要的事：技术能力，国内会注重你的项目经验，国外会注重你的基础知识、项目经验、解题思路，以及软件设计能力。所以，要努力提高自己的技术技能和见解。但是你要记住，学技术不是用来面试的，它只是你谋生的技能，要尊重自己的谋生技能。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/13192\" > </iframe>","categories":["左耳听风"]},{"title":"092丨程序员面试攻略：面试中的技巧","url":"/posts/139316865.html","content":"\n\n\n前面一篇文章讲的是面试前的准备，我从简历、技术知识、算法题和工作项目四个方面一一分享了该如何做准备，以及其中的经验和技巧。今天我们就来聊聊面试中的技巧。\n\n# 形象和谈吐\n\n面试过程很短，对一个人的认识和了解也是很有限的。如果你的技能一般的话，那么就需要加强你的形象和谈吐了。总之，你不能内在和外在都不要吧，最好是内在和外在都很好。\n\n形象方面，最好还是穿工作便装，休闲的也没事，但是要让人感到干净、整洁。不要有异味，不要邋遢——头不梳、胡子不刮、衣服也皱巴巴的，还是要修修边幅的。因为有 HR 的人会来面你的，HR 一般都是女孩子，所以不要吓到她们。\n\n另外，保持微笑，表现得热情、开朗和幽默是非常重要的。每个人都喜欢和开朗风趣积极向上的人相处。经常微笑，表现出自己的热情，适当开开玩笑，自嘲一下，会让人觉得你很容易亲近。交谈时千万不要像挤牙膏一样，别人问你一句，你答一句，要把完整的前因后果讲完。别人问你个事，你就多分享一些这个事中的酸甜苦辣，把故事讲得生动有趣点儿，能逗笑 HR 妹子最好（但不要撩）。\n\n说话的时候，要看着对方，一方面这是对对方的尊重和礼貌，另一方面，这也是一种自信。就算没有面好，也不要低着头，又不是做错了什么事。有什么事说不清楚的，不要犹豫，该画图画图。对于比较复杂的面试官听不懂的问题，要变换不同的方式来描述。\n\n面试官问的问题，你要给出充足的细节，千万不要让面试官不断地追问，那样就被动了。你问我解决过的最难的问题是什么，我就把这个问题的来龙去脉和其中的各种细节给你滔滔不绝地讲个遍。当然，也要讲得清楚干净有条理，不要东拉西扯的，也不要云山雾罩的。这些表达和谈吐还是要多练！\n\n最好的训练就写作，你写得多了，能把复杂的问题描述清楚了，自然也会体现在语言组织能力上了。\n\n# 答不出来\n\n面试中有一些问题很难，但是不要放弃，要不断尝试。很多时候，面试官并不期待你能在很短的时候内解出一道难题，他只是想看一下你遇到难题时的态度和思维方式。如果你能证明给面试官看，你解决问题的方向和方法是正确的，就算是没有找到答案，也是很不错的。因为只要方向走对了，剩下的就是时间问题了。\n\n如果实在解不出来，或是被问了不懂的知识性问题，那么就直接说不懂就好了。记下来，回去多看多练，下次记住了就好。\n\n另外，对于没有答上来的问题，有的人会在面试后请教一下面试官。但是我觉得更好的方式是，问面试官要个他的邮箱或微信，回去后，努力搞懂，举一反三，然后写个东西再发回去。这样做是有可能让你起死回生的。多少可以暗示对方：“你看，我有不懂的，但是我能下工夫很快就搞懂了，你看我的学习能力还不错哦。你就不再考虑一下了吗？”\n\n# 尖锐问题\n\n应聘的时候，你有可能会被问到几个尖锐的问题，这时你要小心做答。一般来说，你会遇到这几个常见的比较尖锐的问题。\n\n- **你为什么要离开现在的公司**？这种问题一般都是来问你的离职动机的，招聘方有理由相信，你是怎样离开前东家的，就会怎样离开我。另外，从这个问题上，招聘方想了解你真实的动机，对工作的想法和个人的喜好。一般来说，永远不要说之前公司的坏话，最标准的外交词令是：“我离开现有公司的原因是我太喜欢你们公司了”。\n\n  这样的回答，对于招聘方来说毫无破绽可言，而如果你开始抱怨你现在的公司了，很可能会引出很多问题把你问到最后都抬不起头来。当然，你也可以说前公司的问题，比如：自己心爱的项目被公司废弃了、公司转型了、公司业绩下滑了、在现有的公司没有成长空间了…… 这些都还是可以说的。\n\n- **说一下你的缺点**？并给出几个例子。这个问题也是很难很难回答的。但是，我想说，人无完人，是个人总是会有缺点的，但是有的缺点也有点不好意思说。所以，这个问题是比较难的。这个问题不能说套话，说套话会显得特别假。这个问题还是要说实话，也不能说一些不痛不痒的小毛病，这样会让他觉得你避重就轻。\n\n  只要你认识到任何性格的人都有问题，那么这个问题你就好回答了。比如，对我来说，我个是比较着急的人，急性子，而且是个做事的人。所以，我最大的问题就是在推进一些事的时候，会忽略别人的感受。当压力变大的时候，我甚至会说出一些别人难以接受的话（俗话说的情商为零）。这个没什么不好意思承认的，我这么多年来也在改进自己。\n\n  总之，我想说的是，我们每个人都应审视一下自己，思考一下自己光明面的后面。而回答这个问题的最佳方法，就是想想附着在正面事件上的阴暗面，那就是你的答案。比如，我对事情的要求太高了，跟我在一起工作人的压力太大。我太内向了，所以别人和我沟通起来有点费劲。我太过关心团队了，所以，有时候会忽略了项目成本和时间进度……\n\n  **最后还要补一句，我知道我的缺点，我也在努力改正，我正在通过什么样的方式改正。这非常关键，因为这基本上是面试官最喜欢看到的答案了，就是你不仅能正视自己的缺点，而且还能不断地改正**。\n\n  另外，与这个问题相对应的是，说一下你的优点。这个问题是比较坑的，你的优点是需要用证据来说明的。比如，我通常的回答是，我的优点就是学习能力强，因为我掌握的技术面很广，而且，我什么样的技术都学，比如最新的 Cloud Native 技术。作为后端人员我还学前端方面的技术如 React.js 和 Vue.js，这一切都来源于我扎实的基础知识……\n\n  回答这个问题的时候，一般都会反衬出你的价值观，HR 就是想了解你的价值观。比如，我比较踏实，我想把技术一直做到老。再比如，我有韧性，我受过哪些挫折、失败、不公、无奈和无助，我没有当逃兵……\n\n- **你为什么换工作换得这么勤**？很多公司的 HR 都会对应聘者频繁换工作持比较负面的评价。频繁换工作在职业生涯中真不是一件好事，因为用人方会觉得要么是你太不踏实了，要么是你太不行了。所以，工作不要换得太频繁。但是如果换得太频繁了，我给你一个建议，在简历里面写上离职原因。\n\n  另外，在面试时被问到这个问题时，你需要给出合理的解释，以消除用人方的疑惑。怎么给出合理的解释呢？一方面，你还是需要诚恳一点儿，另一方面，你在解释时需要承认频繁换工作也不是自己想的，自己何尝不想在一份工作上干得时间长一点儿。\n\n  无奈，要么是公司有变化，要么就是自己没选好。一方面表达自己也厌倦了频繁换工作这种事，另一方面，你要把这个话题引到另外一个方向上——什么样的工作自己可以干很久？自己所期望的工作内容和工作环境是什么样的？这样就转而去谈你所向往的工作内容和环境了，并再表达一下在这样的工作环境下，是可以很长时间做下去的，并愿意和公司一起发展。\n\n  但是，先不要说得太理想了，不然，用人方也会觉得自己是做不到的。正确的说法是，自己并不担心公司有各种各样的问题，只要有一起扛事的队友一起拼搏，这才是最关键的。\n\n- **你在一家公司呆了接近 10 年为什么没有做到管理层？你又是怎么保持竞争力的**？一般来说，不想做管理的程序员也挺多的，在技术的方向上勤勤恳恳深耕细作，会是一个非常难得的优秀工程师。专注于技术，不分心，不断地在技术上的深度和广度上钻研，这就是保持竞争力最好的方式。所以，其实这个问题挺好回答的。\n\n  但另一个更难的问题是：你工作满 5 年了，为什么还不是一个高级程序员？对于国外的顶尖公司来说，如果你有 5 年的工作经验，但还不能胜任高级程序员（Amazon 的 SDE2）的职位，那么你这个人就基本会被 pass 掉了，包括在职的员工也是一样的。于是，对于工作年限超过 5 年的程序员，如果你还不能证明你可以独当一面，你的能力能够驾驭复杂难题，那么国外的顶尖公司都不会问你这个问题的。\n\n  国内的公司可能会问你这个问题，对此，我个人认为比较好的回答是要分几方面来谈。一方面，过去因为什么原因耽误了些时间（环境因素、客观条件因素），另一方面，要表示同样也有主观因素，不然显得有点找借口的感觉，不诚恳。\n\n  接下来，要表明自己心里面也比较慌（表明自己不用别人提醒可以自己意识到自己的问题），所以，近一年来一直在学习，罗列一下学过哪些东西，最好还有学习目标和学习计划（表明自己除了有意识外，还有行动）。当然，厉害的面试官会不断地追问你一些细节，以此来确定你没有说假话，对此，你要有充足的准备。\n\n- **你为什么换了一个方向？你觉得你有什么优势**？ 这个问题其实并不难回答，实话实说就好了。但是不要让招聘方感受到你浮燥的内心，或是朝三暮四的性格，更不要让人感觉到你像“小猫钓鱼”那样一边不行又来搞另一边。\n\n  我觉得回答这个问题有两种方式：一种是非常自信的回答——“我从来没有改变我的方向，因为种种原因，我没能得到我想要的方向，虽然现在很残酷，但是我一直都没有放弃我的方向，我一直都在努力学习……”如果你要这么回答了，你就要真的是这样的，在新的方向有所研究和建树，不然会被识破的。\n\n  另一种回答则常规一点，首先说明一下，自己的兴趣爱好，为什么这个方向要比之前的那个方向更适合自己。可以用几个例子来说明，但其中要有一些细节，比如，自己试过这个新方向 ，发现干得比原来那边更好，更容易出成绩，自己的兴奋点更大，所以觉得新方向更适合自己。然后，承认换一个方向短期内并没有优势。但是，因为自己的某某特质，比如，学习能力强、勤奋、聪明等特质，未来一定是可以胜任的。\n\n  但是，你要用证据证明你的学习能力强，你比一般人勤奋，比一般人聪明。不然如果对方追问下去，会让你破绽百出的。总之，回答这样的问题，需要一定的证据作为补充，而且还要伴随着以降职降薪为代价。所以，一般来说，选定方向最好不要再变了，如果一定要变的话，你也要有必胜的信心和先下后上的心态，而且这些信心和心态要让招聘方看到。\n\n- **对于技术的热情或初心体现在你生活和工作中的哪里**？这个问题其实是想了解一下你的性格，以及对生活和工作的态度。这个问题会伴随着很多细节上的追问。所以，你要小心回答，而且是要带感情的，但一定要是真实的。\n\n  一般来说，热情和初心不是停留在嘴上的，而是要表现在行动上的，你需要给出几个曾经发生过的示例。这些示例可以是：你死磕某个事解决某个难题不认输的精神；你坚持做某件事，无论风吹雨打，无论有没有激励；你在某个逆境中依然没有放弃依然努力的态度；在面对压力时，你勇于承担责任的精神；你严谨细心、精益求精的做事风格；面对诱惑能沉得住气，不浮躁……\n\n  **总结一下，对技术的热情或初心，需要表现在这么几个特质上：执着、坚持、坚韧、不服输、担当、不妥协、不浮燥……我说一句，我相信每个人或多或少都会有这些特质，这是你的亮点，要小心呵护。不然，你跟一条咸鱼就没什么两样了。**\n\n- **你觉得你比男性程序员有什么优势**？这种问题一看就带有性别歧视。我的建议是，首先从更高的维度教育一下对方，放出观点，性别不能算优势，人与人的不同和差距是体现在工作技能和态度上的。然后，把回答转向到自己的工作技能和工作态度上来，随后从诸如想象力、品味、沟通能力、严谨细心、承受压力等方面说明自己的长处。\n\n  当然，能问得出这样问题的公司一定不是好公司，千万不要去了。所以，可以放心地怼回去。需要注意的是，职场中的怼人是要用数据和事实打脸的。\n\n  比如：世界上第一个程序员就是女的叫 Ada，她不仅预言了通用计算机的可能，还发明了世界上第一个计算机程序。世界上第一台通用计算机 ENIAC 的编译和部署工作是由 6 位女程序员组成的团队完成的。把阿波罗送到月球的程序员也是女的，叫 Margaret Hamilton。微软 Halo 游戏引擎的主程也是女的，还是中国香港人，叫余国荔……另外，在中国的运动比赛上，女性运动员比男性运动员的成绩要好……\n\n  在各个公司，我看到更多的男性除了在使蛮力和搬砖上比女性要强，也没什么其他长项。如果认为写程序是劳动密集型的工种，当然是男性比女性好用。对了，你们这里是劳动密集型的公司吗？最后，我认为，就对女性尊重方面还是国外公司做得好。所以，建议女程序员还是要去国外公司工作。\n\n最后，我想说一下，回答尖锐问题你会有两种方法，一般是比较官方的，像外交或是政治词令，另一种是比较诚恳的、真实的。虽然两者都可以，但是我觉得后者更好一些。因为那是能打动人的。对于一些不礼貌的问题，我觉得你要站在更高的维度教育他们，这样才会显得他们的 low。\n\n# 结尾问题\n\n一般来说，面试结束的时候，都会问你有没有什么问题。不要放弃这个机会。\n\n- **如果你面得比较好**，这个时候可以问几个尖锐的问题，这样有利于后面谈 offer 和岗位（抓住机会反转被动为主动）。比如，我就问过国外某一线公司的面试官下面两组问题：\n\n  - 你们公司有多少一线开发经理还在写代码？你们的一线经理都没有时间来写代码了，不知道细节怎么做好管理？另外是不是说明你们公司有大量的内耗？\n  - 任何公司都有好的有不好的，你能不能分享一下你最喜欢这个公司的地方和最不喜欢的地方？\n\n  基本上来说，面试官都会被我问住，然后开始语塞。能让说英语母语的老外在我这个英文一般的人面前说不清话，我还是很满足的。哈哈哈。当然，也不一定是非要像我这么尖锐地问问题，你也可以设计几个柔和一点儿的问题。总之，问这样问题的目的是，暗示一下对方，我来不来还不一定呢，也别想压低我的 offer，你们公司也不是什么都好，要想让我来，得再加点……（嘿嘿嘿）\n\n- **如果你面得一般**，这个时候你也可以问些加分的问题。比如：目前贵公司或是贵团队最需要解决什么样的问题？我能帮贵公司做些什么？能不能给我一些资料我先了解一下，这样我后面如果能进来，就能上手更快一些了。因为你面得一般的话，面试官会比较犹豫和纠结，此时你需要让面试官不要犹豫，所以，你可以表现得更加热情和主动一点。你看，竟然一副通过面试明天就要上班的“无耻嘴脸”也会为你加点分的……（哈哈哈）\n\n- **如果你面得很不行，基本挂掉了**。这个时候，也要问问题。但最好问一下面试官对你的评价，并且让他指出你的不足和需要改进的地方。面试本来就是一次经历和一次学习，你也可以把其当作是一种受教育的过程。所以，不要放过自己可以成长的机会。通过面试官给你的评价，你日后就知道自己需要努力的地方和方向了。这是多好的一件事儿啊。\n\n# 小结\n\n总结一下今天的内容。我认为，形象和谈吐对于面试成功与否非常重要。着装方面一定要大方得体，干净整洁；谈吐方面一定要自信从容，能够清楚准确地表达自己的观点和想法。随后是如何面对一些答不上来的问题，如何回答尖锐问题，以及在面试结束之后，如何提问，为自己争取福利或者机会。\n\n下一篇文章，我们将谈谈国内外公司的面试风格，知己知彼，更好地做面试准备。敬请期待。\n\n\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/13069\" > </iframe>","categories":["左耳听风"]},{"title":"096丨高效学习：源头、原理和知识地图","url":"/posts/443817677.html","content":"\n\n\n有了上一篇文章中分享的那些观点，我们来看看应该怎么做。下面是我觉得比较不错的一些学习的方法，或者说对我来说最有效的学习方法。我相信，只要你和我一样，做到的话，你的学习效率一定能够提升很快。\n\n# 挑选知识和信息源\n\n还是我在《程序员练级攻略》中说的那样，英文对于我们来说至关重要，尤其是对于计算机知识来说。如果你觉得用百度搜中文关键词就可以找到自己想要的知识，那么你一定远远落后于这个时代了。如果你用 Google 英文关键词可以找到自己想要的知识，那么你算是能跟得上这个时代。如果你能在社区里跟社区里的大牛交流得到答案，那么你算是领先于这个时代了。\n\n所以，我认为你的信息源要有下面几个特质。\n\n- 应该是第一手资料，不是被别人理解过、消化过的二手资料。尤其对于知识性的东西来说，更是这样。应该是原汁原味的，不应该是被添油加醋的。\n- 应该是有佐证、有数据、有引用的，或是有权威人士或大公司生产系统背书的资料。应该是被时间和实践检验过的，或是小心求证过的，不是拍脑袋野路子或是道听途说出来的资料。\n- 应该是加入了一些自己的经验和思考，可以引发人深思的，是所谓信息的密集很大的文章。\n\n顺便说一句，我发现 Medium 上的文章质量比较高，很多文章都 Google 到了 Medium 上。\n\n我在《程序员练级攻略 》后期的文章中罗列了很多文章资源，有的读者很不能理解，他们觉得我多少应该导读一下或是写上一些自己的想法，而不是只是简单地罗列出来。这里请允许我辩解一下，我之所以这样做，并不是因为偷懒，我完全可以把这些信息资料全部隐藏起来，翻译也好，搬运也好，导读也好，自己消化完后再写出来。那么，我可以写出多少个专栏来？\n\n我觉得，只要我有时间，极客时间上的所有专栏都不用写了，我一个人就 OK 了。我可以写得又快又好，而且超出所有的人。那我可以挣到很多钱。但我不想这样，我想把我读过的好的文章推荐给大家，就像推荐书一样。那些是信息源头，已经写得非常不错了，我不用再多废话。而且那些文章底部都有很多的引用，你可以一路点过去。\n\n但**我想通过这些简单链接的方式，为我的读者打开一个全新的世界，他们可以在这个世界中自己找食吃，而不需要依赖我，这才是我想给大家带来的东西**。我不知道，我的那些推荐文章，有没有让你看到了一个很广阔的世界，在那里，每天都在产生很多最新、最酷、最有营养的一手信息，而不是被我或他人消化过的二手信息。\n\n这里，我只想说，对于一个学习者来说，找到优质的信息源可以让你事半功倍。一方面，就像找到一本很好的武林秘籍一样，而不是被他人翻译过或消化过的，也不会有信息损失甚至有错误信息会让你走火入魔。另一方面，你需要的不只有知识和答案，更重要的是掌握学习的方法和技能。你要的是“渔”，而不是“鱼”。\n\n# 注重基础和原理\n\n我在很多的场合都提到过，基础知识和原理性的东西是无比重要的。这些基础知识就好像地基一样，只要足够扎实，就要可以盖出很高很高的楼。正所谓“勿在浮沙筑高台”。我说过，很多人并不是学得不够快，而他们的基础真的不行。基础不行，会影响你对事物的理解，甚至会让你不能理解为什么是这样。当你对事物的出现有不理解的东西时，通常来说，是因为你的基础知识没有跟上。\n\n在《程序员练级攻略 》一文中，我用了很大的篇幅给出了学习基础技术的路径。只要你努力学习那些基础知识，了解了其中的原理，就会发现这世界上的很多东西是大同的。\n\n举个例子，如果你学习过底层的 Socket 编程，了解多路复用和各种 I/O 模型的话（select, poll, epoll, aio, windows completion port, libevent 等），那么，对于 Node.js、Java NIO、Nginx、C++ 的 ACE 框架等这些中间件或是编程框架，你就会发现，无论表现形式是什么样的，其底层原理都是一个样的。\n\n无论是 JVM 还是 Node，或者是 Python 解释器里干了什么，它都无法逾越底层操作系统 API 对“物理世界”的限制。而当你了解了这个底层物理世界以后，无论那些技术玩成什么花样，它们都无法超出你的掌控（这种感觉是很爽的）。\n\n再举一个例子，当学了足够多的语言，并有了丰富的实践后，你开始对编程语言的各种编程范式或是控制流有了原理上的了解，这时再学一门新语言的话，你会发现自己学得飞快。\n\n就像我 2010 年学习 Go 语言一样，除了那些每个语言都有的 if-else、 for/while-loop、function 等东西以外，我重点在看的就是，出错处理是怎么玩的？内存管理是怎么玩的？数据封装和扩展怎么玩的？多态和泛型怎么搞的？运行时识别和反射机制是怎么玩的？并发编程怎样玩？……\n\n这些都是现代编程语言必需的东西，如果没有，那么这个语言的表达能力就很落后了。所以，当知道编程语言的本质和原理后，你学习一门新的语言是非常非常快的，而且可以直达其高级特性。\n\n**最最关键的是，这些基础知识和原理性的东西和技术，都是经历过长时间的考验的，所以，这些基础技术也有很多人类历史上的智慧结晶，会给你很多启示和帮助**。比如：TCP 协议的状态机，可以让你明白，如果你要设计一个异步通信协议，状态机是一件多么重要的事，还有 TCP 拥塞控制中的方式，让你知道，设计一个以响应时间来限流的中件间是什么样的。\n\n当学习算法和数据结构到一定程度的时候，你就会知道，算法不仅对于优化程序很重要，而且，会让你知道，该如何设计数据结构和算法来让程序变得更为健壮和优雅。\n\n有时候，学习就像拉弓蓄力一样，学习基础知识感觉很枯燥很不实用，工作上用不到，然而学习这些知识是为了未来可以学得更快。基础打牢，学什么都快，而学得快就会学得多，学得多，就会思考得多，对比得多，结果是学得更快……这种感觉，对于想速成的人来说，很难体会。\n\n这里我想再次强调一下，请一定要注重基础知识和原理上的学习！\n\n# 使用知识图\n\n先讲一个故事，2000 年我从昆明到上海，开始沪飘的岁月。刚到上海，找不到好工作，只能大量地学习和看书，C/C++/Java，TCP/IP，Windows 编程，Unix 编程，等等。结果呢，书太多了，根本看不过来。我想要更多地掌握知识，结果我发现以死记硬背的方式根本就是在使蛮力学习，我很难在很短的时间内学习很多的知识。\n\n于是我自己发明了一种叫“联想记忆法”的方法，比如，在学习 C++ 的时候，面对《C++ Primer》这种厚得不行的书，我就使用联想记忆法。\n\n我把 C++ 分成三部分。\n\n- 第一部分是 C++ 是用来解决 C 语言的问题的，那么 C 语言有什么问题呢？指针、宏、错误处理、数据拷贝…… C++ 用什么技术来解决这些问题呢？\n- 第二部分是 C++ 的面向对象特性：封装、继承、多态。封装，让我想到了构造函数、析构函数等。构造函数让我想到了初始化列表，想到了默认构造函数，想到了拷贝构造函数，想到了 new……多态，让我想到了虚函数，想到了 RTTI，RTTI 让我想到了 dynamic_cast 和 typeid 等。\n- 第三部分是 C++ 的泛型编程。我想到了 template，想到了操作符重载，想到了函数对象，想到 STL，想到数据容器，想到了 iterator，想到了通用算法，等等。\n\n于是，我通过“顺藤摸瓜”的方式，从知识树的主干开始做广度或是深度遍历，于是我就得到了一整棵的知识树。这种“顺藤摸瓜”的记忆方式让我记住了很多知识。**最重要的是，当出现一些我不知道的知识点时，我就会往这棵知识树上挂，而这样一来，也使得我的学习更为系统和全面**。\n\n这种画知识图的方式可以让你从一个技术最重要最主干的地方出发开始遍历所有的技术细节，也就是画地图的方式。如果你不想在知识的海洋中迷路，你需要有一份地图，所以，**学习并不是为了要记忆那些知识点，而是为了要找到一个知识的地图，你在这个地图上能通过关键路径找到你想要的答案**。\n\n# 小结\n\n总结一下今天的内容。首先，我强调了，挑选知识和信息源的重要性，因为优质的信息源可以让你事半功倍。其次，我认为，一定要注重基础和原理，基础打牢，学什么都快，而学得快就会学得多，学得多，就会思考得多，对比得多，结果是学得更快。\n\n最后，我指出，学习时一定要使用知识图，学习并不是为了要记忆那些知识点，而是为了要找到一个知识的地图，你在这个地图上能通过关键路径找到你想要的答案。我相信，只要掌握了好的方法，你能做到的话，你的学习效率一定提升很快。\n\n下篇文章中，我将接着介绍几个不错的学习方法。希望对你有帮助。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/14321\" > </iframe>","categories":["左耳听风"]},{"title":"095丨高效学习：端正学习态度","url":"/posts/876275901.html","content":"\n\n\n在开始这一系列文章之前，我想说，如果你想从我这里得到一些速成的方法，那么你就不用往下看了，学习是不可能速成的。这里只有一些方法和技巧，是我这么多年来行之有效的，分享出来也许对你有帮助。一方面，可能会让你学得更多和更累，另一方面，可能会让你学得更系统、更全面。总之，学习是一件“逆人性”的事，就像锻炼身体一样，**需要人持续付出，会让人感到痛苦，并随时想找理由放弃**。\n\n大部分人都认为自己爱学习，但是：\n\n- 他们都是只有意识没有行动，他们是动力不足的人。\n- 他们都不知道自己该学什么，他们缺乏方向和目标。\n- 他们都不具备自主学习的能力，没有正确的方法和技能。\n- 更要命的是，他们缺乏实践和坚持。\n\n如果你去研究一下古今中外的成功人士，就会发现，他们基本上都是非常自律的，也都是非常热爱学习的。他们可以沉得下心来不断地学习，在学习中不断地思考、探索和实践。\n\n所以，如果你不能克服自己 DNA 中的弱点，不能端正自己的态度，不能自律，不能坚持，不能举一反三，不能不断追问等，那么，无论有多好的方法，你都不可能学好。所以，有正确的态度很重要。\n\n然后，我会在后面给你一些方法和相关的技能，让你可以真正实际操作起来。\n\n# 主动学习和被动学习\n\n1946 年，美国学者埃德加·戴尔（Edgar Dale）提出了「学习金字塔」（Cone of Learning）的理论。之后，美国缅因州国家训练实验室也做了相同的实验，并发布了「学习金字塔」报告。\n\n![image-20230922212657119](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230922212657119.png)\n\n人的学习分为「被动学习」和「主动学习」两个层次。\n\n- **被动学习**：如听讲、阅读、视听、演示，学习内容的平均留存率为 5%、10%、20% 和 30%。\n- **主动学习**：如通过讨论、实践、教授给他人，会将原来被动学习的内容留存率从 5% 提升到 50%、75% 和 90%。\n\n这个模型很好地展示了不同学习深度和层次之间的对比。\n\n我们可以看到，你听别人讲，或是自己看书，或是让别人演示给你，这些都不能让你真正获得学习能力，因为你是在被别人灌输，在听别人说。\n\n只有你开始自己思考，开始自己总结和归纳，开始找人交流讨论，开始践行，并开始对外输出，你才会掌握到真正的学习能力。\n\n举个大家都懂的例子，那就是学习英文，我们从小就是在开始学习英文了，很多人英文成绩可以考得很好，语法也可以不错。然而，哪天真正要和外国人交流的时候，却发现自己的英文能力渣得不要不要的，只会回答：Fine. Thank you, and you? 这就是浅度学习的结果。\n\n我的英文能力也是一样的，直到有一天进到外企，外企请了个外教每周来公司三次和我们练英文，我的英文能力才有一点点进步，然而，还是不够。后来有一天，公司的客户抱怨我们的一线客服处理问题太慢，问我们在后台做开发的人有谁去一线支持客户，我举手了。于是我接了半年来自日本、新加坡、德国、法国、英国等多个国家的客户电话和邮件。\n\n在这期间，我的英文能力直线上升，速度快得不得了。一方面是我要把自己知道的讲给客户听，另一方面要跟客户有交流，所以我学得更努力，也更有效果。主要是日本人和德国人给了我足够的信心，这两个国家的人可能是这世界上最严谨的人，他们非常喜欢打破沙锅问到底，而且他们的英文也不怎么好，但是他们都用很慢的语速来和我交流，一方面是怕他们自己说不好，另一方面是也希望我用慢速的话和他们说。于是，大家都在一种慢速的环境下说英文，把每个单词的音都发准了，这使我提高了英文能力。\n\n后面再跟一些口音很奇葩的老外（比如印度人和法国人）说英文的时候，我就会让他们说慢点，以便我适应他们的口音。几年后，我到了另外一家外国公司工作，需要跟一些口音非常重的印度人和非洲人说英文，我都能听懂，着实把我身边的同事们都震住了。这就是深度学习的最好的例子，要践行！\n\n**所以，学习不是努力读更多的书，盲目追求阅读的速度和数量，这会让人产生低层次的勤奋和成长的感觉，这只是在使蛮力。要思辨，要践行，要总结和归纳，否则，你只是在机械地重复某件事，而不会有质的成长的。**\n\n# 浅度学习和深度学习\n\n老实说，对于当前这个社会：\n\n- 大多数人的信息渠道都被微信朋友圈、微博、知乎、今日头条、抖音占据着。这些信息渠道中有营养的信息少之又少。\n- 大多数公司都是实行类似于 996 这样的加班文化，在透支和消耗着下一代年轻人，让他们成长不起来。\n- 因为国内互联网访问不通畅，加上英文水平受限，所以，大多数人根本没法获取到国外的第一手信息。\n- 快餐文化盛行，绝大多数人都急于速成，心态比较浮燥，对事物不求甚解。\n\n所以，你看，在这种环境下，你根本不需要努力的。你只需要踏实一点，像以前那样看书，看英文资料，你只需要正常学习，根本不用努力，就可以超过你身边的绝大多数人。\n\n我们整个世界进入了前所未有的信息爆炸时代，人们担忧的不再是无知识可学，而是有学不完的知识。而且时代的节奏变得越来越快，你可能再也不像 20 年前，可以沉着优雅平和地泡上一杯茶，坐在一个远离喧嚣的环境下，认认真真地看本书。这个时代，你再也不会有大块大块的时间，你的时间都被打成碎片了，不知不觉你也成为了快餐文化的拥趸……\n\n在这样一个时代下，种种迹象表明，快速、简单、轻松的方式给人带来的快感更强烈，而高层次的思考、思辨和逻辑则被这些频度高的快餐信息感所弱化。于是，商家们看到了其中的商机，看到了如何在这样的时代里怎么治愈这些人在学习上的焦虑，他们在想方设法地用一些手段推出各种代读、领读和听读类产品，让人们可以在短时间内体会到轻松获取知识的快感，并产生勤奋好学和成长的幻觉（老实说，像我这种付费专栏或是得到等知识付费产品基本上就是类似的产物）。\n\n这些所谓的“快餐文化”可以让你有短暂的满足感，但是无法让你有更深层次的思考和把知识转换成自己的技能的有效路径，因为那些都是需要大量时间和精力的付出，不符合现代人的生活节奏。人们开始在朋友圈、公众号、得到等这样的地方进行学习，导致他们越学越焦虑，越学越浮燥，越学越不会思考。于是，他们成了“什么都懂，但依然过不好这一生”的状态。\n\n只要你注意观察，就会发现，少数的精英人士，他们在训练自己获取知识的能力，他们到源头查看第一手的资料，然后，深度钻研，并通过自己的思考后，生产更好的内容。而绝大部分受众享受轻度学习，消费内容。\n\n你有没有发现，在知识的领域也有阶层之分，那些长期在底层知识阶层的人，需要等着高层的人来喂养，他们长期陷于各种谣言和不准确的信息环境中，于是就导致错误或幼稚的认知，并习惯于那些不费劲儿的轻度学习方式，从而一点点地丧失了深度学习的独立思考能力，从而再也没有能力打破知识阶层的限制，被困在认知底层翻不了身。\n\n可见深度学习十分重要，但应该怎样进行深度学习呢？下面几点是关键。\n\n- **高质量的信息源和第一手的知识**。\n- **把知识连成地图，将自己的理解反述出来**。\n- **不断地反思和思辨，与不同年龄段的人讨论**。\n- **举一反三，并践行之，把知识转换成技能**。\n\n换言之，学习有三个步骤。\n\n- **知识采集**。信息源是非常重要的，**获取信息源头、破解表面信息的内在本质、多方数据印证**，是这个步骤的关键。\n- **知识缝合**。所谓缝合就是把信息组织起来，成为结构体的知识。这里，**连接记忆，逻辑推理，知识梳理**是很重要的三部分。\n- **技能转换**。通过**举一反三、实践和练习**，以及**传授教导**，把知识转化成自己的技能。这种技能可以让你进入更高的阶层。\n\n我觉得这是任何人都是可以做到的，就是看你想不想做了。\n\n此外，在正式开始讲如何学习之前，让我先说一些关于学习的观点，这是在为后面的那些学习方法和技巧做提纲挈领的铺垫。\n\n# 学习是为了找到方法\n\n**学习不仅仅是为了找到答案，而更是为了找到方法**。很多时候，尤其是中国的学生，他们在整个学生时代都喜欢死记硬背，因为他们只有一个 KPI，那就是在考试中取得好成绩，所以，死记硬背或题海战术成了他们的学习习惯。然而，在知识的海洋中，答案太多了，你是记不住那么多答案的。\n\n只有掌握解题的思路和方法，你才算得上拥有解决问题的能力。所有的练习，所有的答案，其实都是在引导你去寻找一种“以不变应万变”的方法或能力。在这种能力下，你不需要知道答案，因为你可以用这种方法很快找到答案，找到解，甚至可以通过这样的方式找到最优解或最优雅的答案。\n\n这就好像，你要去登一座山，一种方法是通过别人修好的路爬上去，一种是通过自己的技能找到路（或是自己修一条路）爬上去。也就是说，需要有路才爬得上山的人，和没有路能造路的人相比，后者的能力就会比前者大得多得多。所以，**学习是为了找到通往答案的路径和方法，是为了拥有无师自通的能力**。\n\n# 学习是为了找到原理\n\n**学习不仅仅是为了知道，而更是为了思考和理解**。在学习的过程中，我们不是为了知道某个事的表面是什么，而是要通过表象去探索其内在的本质和原理。真正的学习，从来都不是很轻松的，而是那种你知道得越多，你的问题就会越多，你的问题越多，你就会思考得越多，你思考得越多，你就会越觉得自己知道得少，于是你就会想要了解更多。如此循环，是这么一种螺旋上升上下求索的状态。\n\n但是，这种循环，会在你理解了某个关键知识点后一下子把所有的知识全部融会贯通，让你赫然开朗，此时的那种感觉是非常美妙而难以言语的。在学习的过程中，我们要不断地问自己，这个技术出现的初衷是什么？是要解决什么样的问题？为什么那个问题要用这种方法解？为什么不能用别的方法解？为什么不能简单一些？……\n\n这些问题都会驱使你像一个侦探一样去探索背后的事实和真相，并在不断的思考中一点一点地理解整个事情的内在本质、逻辑和原理。**一旦理解和掌握了这些本质的东西，你就会发现，整个复杂多变的世界在变得越来越简单。你就好像找到了所有问题的最终答案似的，一通百通了**。\n\n# 学习是为了了解自己\n\n**学习不仅仅是为了开拓眼界，而更是为了找到自己的未知，为了了解自己**。英文中有句话叫：You do not know what you do not know，可以翻译为：你不知道你不知道的东西。也就是说，你永远不会去学习你不知道其存在的东西。就好像你永远 Google 不出来你不知道的事，因为对于你不知道的事，你不知道用什么样的关键词，你不知道关键词，你就找不到你想要的知识。\n\n这个世界上有很多东西是你不知道的，所以，学习可以让你知道自己不知道的东西。只有当我们知道有自己不知道的东西，我们才会知道我们要学什么。所以，我们要多走出去，与不同的人交流，与比自己聪明的人共事，你才会知道自己的短板和缺失，才会反过来审视和分析自己，从而明白如何提升自己。\n\n山外有山，楼外有楼，人活着最怕的就是坐井观天，自以为是。因为这样一来，你的大脑会封闭起来，你会开始不接受新的东西，你的发展也就到了天花板。**开拓眼界的目的就是发现自己的不足和上升空间，从而才能让自己成长**。\n\n# 学习是为了改变自己\n\n**学习不仅仅是为了成长，而更是为了改变自己**。很多时候，我们觉得学习是为了自己的成长，但是其实，学习是为了改变自己，然后才能获得成长。为什么这么说呢？我们知道，人都是有直觉的，但如果人的直觉真的靠谱，那么我们就不需要学习了。而学习就是为了告诉我们，我们的很多直觉或是思维方式是不对的，不好的，不科学的。\n\n只有做出了改变后，我们才能够获得更好的成长。你可以回顾一下自己的成长经历，哪一次你有质的成长时，不是因为你突然间开窍了，开始用一种更有效率、更科学、更系统的方式做事，然后让你达到了更高的地方。不是吗？当你学习了乘法以后，在很多场景下，就不需要用加法来统计了，你可以使用乘法来数数，效率提升百倍。\n\n当你有一天知道了逻辑中的充要条件或是因果关系后，你会发现使用这样的方式来思考问题时，你比以往更接近问题的真相。**学习是为了改变自己的思考方式，改变自己的思维方式，改变自己与生俱来的那些垃圾和低效的算法。总之，学习让我们改变自己，行动和践行，反思和改善，从而获得成长**。\n\n# 小结\n\n总结一下今天的内容。首先，学习是一件“逆人性”的事，就像锻炼身体一样，需要人持续付出，但会让人痛苦，并随时可能找理由放弃。如果你不能克服自己 DNA 中的弱点，不能端正自己的态度，不能自律，不能坚持，不能举一反三，不能不断追问等，那么，无论有多好的方法，你都不可能学好。因此，有正确的态度很重要。\n\n此外，还要拥有正确的学习观念：学习不仅仅是为了找到答案，而更是为了找到方法；学习不仅仅是为了知道，而更是为了思考和理解；学习不仅仅是为了开拓眼界，而更是为了找到自己的未知，为了了解自己；学习不仅仅是为了成长，而更是为了改变自己，改变自己的思考方式，改变自己的思维方式，改变自己与生俱来的那些垃圾和低效的算法。\n\n端正的学习态度和正确的学习观念，是高效学习的第一步，拥有这两者一定可以让你事半功倍。然后就是要总结和掌握高效学习的方法，这是我们下篇文章中将要分享的内容。敬请期待。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/14271\" > </iframe>\n\n","categories":["左耳听风"]},{"title":"098丨高效学习：如何学习和阅读代码","url":"/posts/3493959216.html","content":"\n\n\n# 读文档还是读代码\n\n杰夫·阿特伍德（Jeff Atwood）说过这么一句话：“[Code Tells You How, Comments Tell You Why](https://blog.codinghorror.com/code-tells-you-how-comments-tell-you-why/)”。我把其扩展一下：\n\n- **代 码 => What, How & Details**\n- **文档 / 书 => What, How & Why**\n\n可见，**代码并不会告诉你 Why**，看代码只能靠猜测或推导来估计 Why，是揣测，不准确，所以会有很多误解。**而且，我们每个人都知道，Why 是能让人一通百通的东西，也是能让人醍醐灌顶的东西**。\n\n但是，**代码会告诉你细节**，这是书和文档不能给你的。**细节是魔鬼，细节决定成败**。这样的话我们不但听过很多，我们做技术的也应该体会过很多。当然，我们也要承认，这些代码细节给人带来的快感毕竟不如知道 Why 后的快感大（至少对我是这样的）。\n\n**书和文档是人对人说的话，代码是人对机器说的话**（注：代码中有一部份逻辑是控制流程的逻辑，不是业务逻辑）。所以：\n\n1. **如果你想知道人为什么要这么搞，那么应该去看书**（像 Effective C++、Code Complete、Design Pattern、Thinking in Java 等），**看文档**。\n2. **如果你要知道让机器干了什么？那你应该看代码！**（就像 Linus 去看 zlib 的代码来找性能问题。）\n\n因此，我认为都比较重要，关键看你的目的是什么了。\n\n- **如果你想了解一种思想，一种方法，一种原理，一种思路，一种经验，恐怕，读书和读文档会更有效率一些**，因为其中会有作者的思路描述。像 Effective C++ 之类的书，里面有很多对不同用法和设计的推敲，TCP/IP 详解里面也会有对 TCP 算法好坏的比较……这些思维方式能让你对技术的把握力更强，而光看代码很难达到这种级别。（现在你知道什么样的书是好书了吧 ;-)）\n- **如果你想了解的就是具体细节，比如某协程的实现，某个模块的性能，某个算法的实现，那么你还是要去读代码的**，因为代码中会有更具体的处理细节（尤其是对于一些 edge case 或是代码技巧方面的内容）。\n\n另外，看看下面的几个现象，你可以自己比较一下。\n\n- 很多时候，我们去读代码，那是因为没有文档，或是文档写得太差。\n- 很多时候，**在 Google、Stack Overflow、GitHub 过后，你会发现，你掌握的知识就是一块一块的碎片，既不系统，也不结构化，更别说融会贯通了。你会觉得自己需要好好地读一本书，系统地掌握知识。你的这种感觉一定很强烈吧**。\n- 很多时候，在读别人代码的时候，你会因为基础知识或是原理不懂，或是你在不知道为什么的情况下，要么完全读不懂代码，要么会误解代码。比如，如果你没有 C 语言和 TCP 原理方面的基础知识，就根本读不懂 Linux 下 TCP 的相关代码。我们因为误解代码用意而去修改代码造成的故障还少吗？\n- 很多时候，看到一个算法或是一个设计时，比如 Paxos，你是不是会想去看一下这个算法的实现代码是什么样的？思考一下如何才能实现得好？（但是如果你没看过 Paxos 的算法思想，我不认为你光看代码实现，就能收获 Paxos 的思想。）\n- 很多时候，**当你写代码的时候，你能感觉得到自己写的代码有点别扭，怎么写都别扭，这个时候，你也会有想去看别人的代码是怎么实现的冲动**。\n\n类似的情况还有很多，但从代码中收获大，还是从书中收获大，在不同的场景、不同的目的下，会有不同的答案。这里，谈一谈人的学习过程吧。从学习的过程中，我们来分析一下看代码和看书这两个活动。人对新事物的学习过程基本都是从“感性认识”到“理性认识”的。\n\n- **如果你是个新手，那应该多读代码，多动手写代码**，因为你需要的是“感性认识”，这个时候“理性认识”你体会不到。一是因为，你没有切身的感受，即便告诉你 Why 你也体会不到。另一方面，这个阶段，你要的不是做漂亮，而是做出来。所以，在**新手阶段，你会喜欢 GitHub 这样的东西**。\n- **如果你是个老手，你有多年的“感性认识”了，那么你的成长需要更多的“理性认识”**。因为这个阶段，一方面，你会不满足于做出来，你会想去做更牛更漂亮的东西；另一方面，你知道的越多，你的问题也越多，你迫切地需要知道 Why！这时，你需要大量地找牛人交流（读牛人的书，是一种特殊的人与人的交流），所以，**这个阶段，你会喜欢读好的书和文章**。\n\n然而，对于计算机行业这个技术创新能力超强、技术种类繁多的行业来说，我们每个人都既是新手，也是老手。\n\n# 如何阅读源代码\n\n很多人问过我，如何读代码。因为我在外企里工作的时间较长，所以，我经常接手一些国外团队写的代码。我发现，虽然老外写的代码比国人好一点儿（有 Code Review），但依然有文档缺失、代码注释不清、代码风格混乱等一些问题，这些都是阅读代码的障碍。这里，我把我的一些阅读源代码的经验分享给你，希望对你有用。\n\n首先，在阅读代码之前，我建议你需要有下面的这些前提再去阅读代码，这样你读起代码来会很顺畅。\n\n1. **基础知识**。相关的语言和基础技术的知识。\n2. **软件功能**。你先要知道这个软件完成的是什么样的功能，有哪些特性，哪些配置项。你先要读一遍用户手册，然后让软件跑起来，自己先用一下感受一下。\n3. **相关文档**。读一下相关的内部文档，Readme 也好，Release Notes 也好，Design 也好，Wiki 也好，这些文档可以让你明白整个软件的方方面面。如果你的软件没有文档，那么，你只能指望这个软件的原作者还在，而且他还乐于交流。\n4. **代码的组织结构**。也就是代码目录中每个目录是什么样的功能，每个文档是干什么的。如果你要读的程序是在某种标准的框架下组织的，比如：Java 的 Spring 框架，那么恭喜你，这些代码不难读了。\n\n接下来，你要了解这个软件的代码是由哪些部分构成的，我在这里给你一个列表，供你参考。\n\n1. **接口抽象定义**。任何代码都会有很多接口或抽象定义，其描述了代码需要处理的数据结构或者业务实体，以及它们之间的关系，理清楚这些关系是非常重要的。\n2. **模块粘合层**。我们的代码有很多都是用来粘合代码的，比如中间件（middleware）、Promises 模式、回调（Callback）、代理委托、依赖注入等。这些代码模块间的粘合技术是非常重要的，因为它们会把本来平铺直述的代码给分裂开来，让你不容易看明白它们的关系。\n3. **业务流程**。这是代码运行的过程。一开始，我们不要进入细节，但需要在高层搞清楚整个业务的流程是什么样的，在这个流程中，数据是怎么被传递和处理的。一般来说，我们需要画程序流程图或者时序处理图。\n4. **具体实现**。了解上述的三个方面的内容，相信你对整个代码的框架和逻辑已经有了总体认识。这个时候，你就可以深入细节，开始阅读具体实现的代码了。对于代码的具体实现，一般来说，你需要知道下面一些事实，这样有助于你在阅读代码时找到重点。\n   - **代码逻辑**。代码有两种逻辑，一种是业务逻辑，这种逻辑是真正的业务处理逻辑；另一种是控制逻辑，这种逻辑只是用控制程序流转的，不是业务逻辑。比如：flag 之类的控制变量，多线程处理的代码，异步控制的代码，远程通讯的代码，对象序列化反序列化的代码等。这两种逻辑你要分开，很多代码之所以混乱就是把这两种逻辑混在一起了（详情参看《编程范式游记》）。\n   - **出错处理**。根据二八原则，20% 的代码是正常的逻辑，80% 的代码是在处理各种错误，所以，你在读代码的时候，完全可以把处理错误的代码全部删除掉，这样就会留下比较干净和简单的正常逻辑的代码。排除干扰因素，可以更高效地读代码。\n   - **数据处理**。只要你认真观察，就会发现，我们好多代码就是在那里倒腾数据。比如 DAO、DTO，比如 JSON、XML，这些代码冗长无聊，不是主要逻辑，可以不理。\n   - **重要的算法**。一般来说，我们的代码里会有很多重要的算法，我说的并不一定是什么排序或是搜索算法，可能会是一些其它的核心算法，比如一些索引表的算法，全局唯一 ID 的算法、信息推荐的算法、统计算法、通读算法（如 Gossip）等。这些比较核心的算法可能会非常难读，但它们往往是最有技术含量的部分。\n   - **底层交互**。有一些代码是和底层系统的交互，一般来说是和操作系统或是 JVM 的交互。因此，读这些代码通常需要一定的底层技术知识，不然，很难读懂。\n5. **运行时调试**。很多时候，代码只有运行起来了，才能知道具体发生了什么事，所以，我们让代码运行进来，然后用日志也好，debug 设置断点跟踪也好。实际看一下代码的运行过程，是了解代码的一种很好的方式。\n\n总结一下，阅读代码的方法如下：\n\n- 一般采用自顶向下，从总体到细节的“剥洋葱皮”的读法。\n- 画图是必要的，程序流程图，调用时序图，模块组织图……\n- 代码逻辑归一下类，排除杂音，主要逻辑才会更清楚。\n- debug 跟踪一下代码是了解代码在执行中发生了什么的最好方式。\n\n对了，阅读代码你需要一个很好的 IDE。我记得以前读 C 和 C++ 代码时，有一个叫 source insight 的工具就大大提高了我的代码阅读效率。说白了就是可以查看代码间相互的调用 reference 的工具，这方面 Visual Studio 做得是非常好的。\n\n# 小结\n\n总结一下今天的内容。我先跟你探讨了“是读文档，还是读代码”，分析对比了从文档和代码中各自能收获到哪些东西，然后给出建议，如果想了解思想、方法和原理，读书和读文档会更有效率；如果想知道具体细节，还是应该读代码。随后分享了一些我阅读代码和源代码时候的方法和技巧。希望对你有启发。\n\n下篇文章是《高效学习》系列的最后一篇，我将分享一下面对枯燥和量大的知识时，我们该怎样做。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/14380\" > </iframe>","categories":["左耳听风"]},{"title":"097丨高效学习：深度，归纳和坚持实践","url":"/posts/3850805091.html","content":"\n\n\n# 系统地学习\n\n在学习某个技术的时候，我除了会用到上篇文章中提到的知识图，还会问自己很多个为什么。于是，我形成了一个更高层的知识脑图。下面我把这这个方法分享出来。当然学习一门技术时，Go 语言也好，Docker 也好，我都有一个学习模板。只有把这个学习模板中的内容都填实了，我才罢休。这个模板如下。\n\n1. **这个技术出现的背景、初衷和要达到什么样的目标或是要解决什么样的问题**。这个问题非常关键，也就是说，你在学习一个技术的时候，需要知道这个技术的成因和目标，也就是这个技术的灵魂。如果不知道这些的话，那么你会看不懂这个技术的一些设计理念。\n2. **这个技术的优势和劣势分别是什么，或者说，这个技术的 trade-off 是什么**。任何技术都有其好坏，在解决一个问题的时候，也会带来新的问题。另外，一般来说，任何设计都有 trade-off（要什么和不要什么），所以，你要清楚这个技术的优势和劣势，以及带来的挑战。\n3. **这个技术适用的场景**。任何技术都有其适用的场景，离开了这个场景，这个技术可能会有很多槽点，所以学习技术不但要知道这个技术是什么，还要知道其适用的场景。没有任何一个技术是普适的。注意，所谓场景一般分别两个，一个是业务场景，一个是技术场景。\n4. **技术的组成部分和关键点**。这是技术的核心思想和核心组件了，也是这个技术的灵魂所在了。学习技术的核心部分是快速掌握的关键。\n5. **技术的底层原理和关键实现**。任何一个技术都有其底层的关键基础技术，这些关键技术很有可能也是其它技术的关键基础技术。所以，学习这些关键的基础底层技术，可以让你未来很快地掌握其它技术。可以参看我在 CoolShell 上写的 Docker 底层技术那一系列文章。\n6. **已有的实现和它之间的对比**。一般来说，任何一个技术都会有不同的实现，不同的实现都会有不同的侧重。学习不同的实现，可以让你得到不同的想法和思路，对于开阔思维，深入细节是非常重要的。\n\n基本上来说，如果你按照我上面所提的这 6 大点来学习一门技术，你一定会学习到技术的精髓，而且学习的高度在一开始就超过很多人了。如果你能这样坚持 2-3 年，我相信你一定会在某个领域成为炙手可热的佼佼者。\n\n# 举一反三\n\n举一反三的道理人人都知道，所以，在这里我并不想讨论为什么要举一反三，而是想讨论如何才能有举一反三的能力。我认为，人与人最大的差别就是举一反三的能力。那些聪明的或者是有经验的人举一反三起来真是太令人惊叹。\n\n我觉得一个人的举一反三能力，可以分解成如下三种基本能力。\n\n1. **联想能力**。这种能力的锻炼需要你平时就在不停地思考同一个事物的不同的用法，或是联想与之有关的其他事物。对于软件开发和技术学习也一样。\n2. **抽象能力**。抽象能力是举一反三的基本技能。平时你解决问题的时候，如果你能对这个问题进行抽象，你就可以获得更多的表现形式。抽象能力需要找到解决问题的通用模型，比如数学就是对现实世界的一种抽象。只要我们能把现实世界的各种问题建立成数据模型（如，建立各种维度的向量），我们就可以用数学来求解，这也是机器学习的本质。\n3. **自省能力**。所谓自省能力就是自己找自己的难看。当你得到一个解的时候，要站在自己的对立面来找这个解的漏洞。有点像左右手互博。这种自己和自己辩论的能力又叫思辨能力。将自己分裂成正反方，左右方，甚至多方，站在不同的立场上来和自己辩论，从而做到不漏过一个 case，从而获得完整全面的问题分析能力。\n\n在这方面，我对自己的训练如下。\n\n1. 对于一个场景，制造出各种不同的问题或难题。\n2. 对于一个问题，努力寻找尽可能多的解，并比较这些解的优劣。\n3. 对于一个解，努力寻找各种不同的测试案例，以图让其健壮。\n\n老实说，要获得这三种能力，除了你要很喜欢思考和找其它人来辩论或讨论以外，还要看你自己是否真的善于思考，是否有好奇心，是否喜欢打破沙锅问到底，是否喜欢关注细节，做事是否认真，是否严谨……\n\n这一系列的能力最终能构建出你强大的思考力，而这个思考力会直接转换成你的求知和学习能力。其实，我也是在不断地加强自己的这些能力。\n\n# 总结和归纳\n\n对自己的知识进行总结和归纳是提高学习能力的一个非常重要的手段。这是把一个复杂问题用简单的语言来描述的能力。就像我小时候上学时，老师让我们写文章的中心思想一样。这种总结和归纳能力会让你更好地掌握和使用知识。\n\n也就是说，我们把学到的东西用自己的语言和理解重新组织并表达出来，本质上是对信息进行消化和再加工的过程，这个过程可能会有信息损失，但也可能会有新信息加入，本质上是信息重构的过程。\n\n**我们积累的知识越多，在知识间进行联系和区辨的能力就越强，对知识进行总结和归纳也就越轻松**。而想要提高总结归纳的能力，首先要多阅读，多积累素材，扩大自己的知识面，多和别人讨论，多思辨，从而见多识广。\n\n不过，我们需要注意的是，如果只学了部分知识或者还没有学透，就开始对知识进行总结归纳，那么总结归纳出来的知识结构也只能是混乱和幼稚的。因此，**学习的开始阶段，可以不急于总结归纳，不急于下判断，做结论，而应该保留部分知识的不确定性，保持对知识的开放状态**。当对整个知识的理解更深入，自己站的位置更高以后，总结和归纳才会更有条理。总结归纳更多是在复习中对知识的回顾和重组，而不是一边学习一边就总结归纳。\n\n我们来总结一下做总结归纳的方法：**把你看到和学习到的信息，归整好，排列好，关联好，总之把信息碎片给结构化掉，然后在结构化的信息中，找到规律，找到相通之处，找到共同之处，进行简化、归纳和总结，最终形成一种套路，一种模式，一种通用方法**。\n\n要训练自己这方面的能力，你需要多看一些经典的方法论图书，看看别人是怎样总结和归纳知识的。你可以在一开始模仿并把自己的理解的知识给写出来，写博客会是一种很好的方式。另外一种更好的方式是讲一遍给别人听。总之，你需要把你总结归纳的知识公开出来，给别人看，接受别人的批评和反馈，这样你才能成长得更快。其实，我也在锻炼这样的能力。\n\n如果你在 Coolshell 上看过我写的《[TCP 的那些事儿](https://coolshell.cn/?s=TCP的那些事儿)》，你就能知道我对《TCP/IP 详解》这本这么厚的书以及一些日常工作经验的总结，我写成了两篇比较简单的博客。你需要像我一样扩大自己的知识面，然后学会写博客，就能慢慢地拥有这种能力了。这种将信息删减、精炼和归纳的方法，可以让你的学习能力得到快速的提升。当你这么做的时候，一方面是在锻炼你抓重点的能力，另一方面是在锻炼你化繁为简的能力。这两种能力都是让你高效学习的能力。\n\n最后，还想说一下，一般来说，拥有这样能力的人，都需要有在更高的维度上思考问题的能力。比如一些名人的金句，就是这种能力的体现。这种能力需要你非常深入的思考，需要你的阅历和经验，当然，和聪明人在一起也是提升这种能力的最有效的选择。\n\n# 实践出真知\n\n所谓实践出真知，也就是学以致用，不然只是纸上谈兵，误国误民。只有实践过，你才能对学到的东西有更深的体会。就像我看 《Effective C++》和《More Effective C++》这两本书一样，一开始看的时候，我被作者的那种翻来覆去不断找到答案又否定自己的求知精神所折服。但是，作者的这种思维方式只有在我有了很多的实践和经验（错误）后，才能够真正地体会为什么是这样的。\n\n这两书不厚，但是，我看了十多年，书中的很多章节我都可以背出来，但是我想得到的不是这些知识，而是这种思维方式，这需要我去做很多的编程工作才能真正明白，才会有斯科特·迈耶斯（Scott Meyers）那样的思维方式，这才是最宝贵的。\n\n另外，实践出真知也就是英文中的 Eat your own dog food。吃自己的狗粮，你才能够有最真实的体会。那些大公司里的开发人员，写完代码，自己不测试，自己也不运维，我实在不知道他们怎么可能明白什么是好的设计，好的软件？不吃自己的狗粮，不养自己的孩子，他们就不会有痛苦，没有痛苦，就不会想改进，没有改进的诉求也就不会有学习的动力，没有学习，就不会进步，没有进步就只会开发很烂的软件……不断地恶性循环下去。\n\n实践是很累很痛苦的事，但只有痛苦才会让人反思，而反思则是学习和改变自己的动力。Grow up through the pain， 是非常有道理的。\n\n# 坚持不懈\n\n坚持不懈是一句正确的废话。前段时间，我在我的读者群中发起了一个名为 ARTS 的活动。每人每周写一个 ARTS：Algorithm 是一道算法题，Review 是读一篇英文文章，Technique/Tips 是分享一个小技术，Share 是分享一个观点。我希望大家可以坚持一年，但是我也相信，能够坚持下来的人一定很少，绝大多数人都是虎头蛇尾的，但是我依然相信会有人坚持下来的。\n\n坚持是一件反人性的事，所以，它才难能可贵，也更有价值。我从 2003 年写 blog 到今天 15 年了，看书学习写代码，我都会一点一点的坚持。人不怕笨，怕的是懒，怕的是找到各种理由放弃。\n\n这里，我想鼓励一下你。现在很多国外的在线视频课都是 3-5 分钟一节课，一共 20 节课，总时长不到两个小时。然而，你会发现，能坚持看完的不到千分之一。当年 Leetcode 只有 151 道题的时候，一共有十几万人上来做题，但全部做完的只有十几个，万分之一。所以，只要你能坚持，就可以超过这个世界上绝大多数人。想一想，如果全中国有 100 万个程序员，只要你能坚持学习技术 2-3 年，你就可以超过至少 99 万人了（可能还更多）。\n\n当然，坚持也不是要苦苦地坚持，有循环有成就感的坚持才是真正可以持续的。所以，**一方面你要把你的坚持形成成果晒出来，让别人来给你点赞，另一方面，你还要把坚持变成一种习惯，就像吃饭喝水一样，你感觉不到太多的成本付出。只有做到这两点，你才能够真正坚持**。\n\n希望我的这些话可以让你有足够的动力坚持下去。\n\n# 小结\n\n总结一下今天的内容。我分享了系统学习、举一反三、总结归纳、实践出真知和坚持不懈等几个方面的内容。\n\n- 在系统学习中，我给出了我学习时用的学习模板，它不但有助于你学习到技术的精髓，更能帮你提升你的学习高度。坚持几年，你一定能在某个领域成为炙手可热的佼佼者。\n- 在举一反三中，我分享了如何获得这种能力的方法。\n- 在总结和归纳中，我指出，积累的知识越多，在知识间进行联系和区辨的能力越强，总结归纳的能力越强，进而逐渐形成在更高维度上思考问题的能力。\n- 在实践出真知中，我阐明了实践的重要性，并认为，只有实践过，才能对学到的东西有更深的体会。\n- 最后，我强调，虽然学习方法很重要，但坚持不懈更为重要，并给出了怎样做才能让自己对学习这件反人类的事儿坚持不懈。\n\n下篇文章中，我将分享一些学习技巧，也是我这么多年来行之有效的。希望对你有帮助。\n\n下面是《高效学习》系列文章的目录。\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/14360\" > </iframe>","categories":["左耳听风"]},{"title":"099丨高效学习：面对枯燥和量大的知识","url":"/posts/1340308087.html","content":"\n\n\n# 如何面对枯燥的知识\n\n首先，我们要知道，为什么会有枯燥的知识？一般来说，枯燥的东西通常是你不感兴趣的东西，而你不感兴趣的东西，可能是你并不知道有什么用的东西。这样的知识通常是比较底层或是抽象度比较高的知识，比如：线性代数，或者一些操作系统内部的原理……越理论的东西就越让人觉得枯燥。\n\n我还记得，当初上大学学习《计算机网络》时，直接学习那个七层协议，以及那些报文，让我感觉枯燥得不行。那个时候，完全不知道这些东西有什么用，因为我连网络是什么都没有见过。直到有一天，我在老师的公司里看到了网卡、网线和 Hub，然后了解了 Windows NT 的域和 IP 地址，然后用 Power Builder 连上了 SQL Server，用 SQL 写入并读取了数据，我才真正明白网络原来有这么好玩。\n\n我开始学习《TCP/IP 详解》，又感到一阵枯燥。然后，有一个同事给我递来了《Unix 网络编程》，我照着其中的例子，写了一个聊天服务器，前端用 Delphi 写了一个 QQ 的样子，那种兴奋劲就别提了。再后来，因为要处理网络问题，调优网络性能，我才发现，以前随便学了点的《TCP/IP 详解》对我在排查网络问题上有很大的帮助。这个时候，我才认真地看了这本书，也正是这个时候，才算是真正读进去了。\n\n后来，我让我团队的一个人学《TCP/IP 详解》这本书，他发现有点难啃就买了一本《图解 TCP/IP》。我找来一看，发现这种图文并茂的书真是增加了很不错的阅读体验，一下子就觉得不是很枯燥了。这让我回想起来那本《从一到无穷大》的相对论科普书，简单、一点也不枯燥。然而，能把这么复杂的问题用这么简单的语言讲清楚的一定是这个领域的大牛了。\n\n我列举我的这个学习过程，就是想说，如果你发现有些知识太过于枯燥，那么可以通过下面的方法解决。\n\n1. 这个知识对于你来说来太高级了，你可能不知道能用在什么地方。\n2. 人的认知是从感性认识向理性认识转化的，所以，你可能要先去找一下应用场景，学点更实用的，再回来学理论。\n3. 学习需要有反馈，有成就感，带着相关问题去学习会更好。\n4. 当然，找到牛人来给你讲解，也是一个很不错的手段。\n\n# 如何面对大量的知识\n\n看过《程序员练级攻略》的朋友们，一定会有这样的疑问，东西太多了，怎么学。我给你的建议是，一点一点学，一口一口吃。你可以使用我前面说过的那些方法，注重基础，画知识图，多问为什么，多动手，然后坚持住，哪怕你每周就学一个知识点，你一年也可以学到 50 个知识点。只要你在进步，总有一天可以把这些知识学到手的。\n\n当然，你的目的不是学完这些知识，因为学无止境，你永远也学不完，所以你在学习时，一定不要学在表面上，一定要学到本质，学到原理上，那些东西是不容易变的，也是经得住时间考验的。把学习当成投资，这是这个世界上回报最好的投资。\n\n带着问题去学习，带着要解决的东西去学习，带着挑战去学习，于是每当你解决了一个问题，做了一个功能，完成了一个挑战，你就会感到兴奋和有成就感。这样，你也就找到了源源不断的学习驱动力。\n\n把你学习的心得、过程、笔记、代码分享出来，找到和你一同学习的人，因为一个人长跑很辛苦，有人同行就会好很多，就算没有人同行，你的读者，你的观众也会为你鼓掌加油，这些也是让你持续前行的动力。\n\n人的一生是要永远学习的。加油！\n\n# 认真阅读文档\n\n我发现很多技术问题都是出在技术人员不认真读技术手册上，我自己也一样。在我的成长生涯中，我发现很多答案或其实都在文档中，而我却没有仔细地去读一下。可能是，我们都不想投入太多的时间吧。\n\n在这里，我想说，用户手册（User Manual）一定要好好地读一读，很多很多提示都在里面了，这是让你可以少掉很多坑的法宝。比如：Unix 和 Linux 的 man，Docker 和 Kubernetes 的官方文档，Git 的操作文档……你的很多很多问题的答案都在这些文档中。\n\n举个例子，很多年前，我掉了一个坑，我把这个问题记录在了文章《 [C/C++ 返回内部静态成员的陷阱](https://blog.csdn.net/haoel/article/details/1388498) 》中。 其中提到了一个函数 `char *inet_ntoa(struct in_addr in);`，我还批评了一下这个函数。然而，只要你 man 一下这个函数，就可以看到：“The string is returned in a statically allocated buffer, which subsequent calls will overwrite”。\n\n还有，很多中国的文档都会教人把 tcp_tw_recycle 和 tcp_tw_resue 这两个参数打开。然而，只要你 man 一下 [TCP(7)](http://man7.org/linux/man-pages/man7/tcp.7.html) ，就可以看到这样的描述：\n\n![image-20230927153721035](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927153721035.png)\n\n你就可以看到这两个参数都是不建议被打开的。\n\n认真阅读用户手册不但可以让你少掉很多坑，同时，还能让你学习到很多。\n\n# 其它几个实用的技巧\n\n1. **用不同的方式来学习同一个东西**。比如：通过看书，听课，创建脑图，写博客，讲课，解决实际问题，等等。\n2. **不要被打断**。被打断简直就是学习的天敌，所以，你在学习的时候，最好把手机设置成勿扰模式放在一边，然后把电脑上的所有通知也关掉，最好到一个别人找不到你的地方。\n3. **总结压缩信息**。当你获得太多的信息时，你需要有一个“压缩算法”。我常用的压缩算法是只关心关键点，所以，你需要使用表格、图示、笔记或者脑图来帮助你压缩信息。\n4. **把未知关联到已知**。把你新学的知识点关联到已知的事物上来。比如，你在学习 Go 语言，你就把一些知识关联到自己已经学过的语言上比如 C 和 Java。通过类比，你会学得更扎实，也会思考得更多。\n5. **用教的方式来学习**。你想想，如果你过几天要在公开场合对很多人讲一个技术，那么这个压力会让你学得更好。因为要教给别人，所以，这么高的标准需要你不但要把自己已掌握的东西学好，还要把周边的也一并学了，才可能做到百问不倒。你才敢去教别人，不是么？（试试教 6 岁的孩子编程，如果你掌握了这种技能，那么你一定是把知识吃得非常透彻了。）\n6. **学以致用**。把学到的东西用起来，没有什么比用起来能让你的知识更巩固的了。在实践中，你才会有更为真实的体会，你才会遇到非常细节和非常具体的问题，这些都会让你重新思考，或深化学习。\n7. **不要记忆**。聪明的人不会记忆知识的，他们会找方法，那些可以推导出知识或答案的方法。这也是为什么外国人特别喜欢方法论。\n8. **多犯错误**。犯错会让你学得到更多，通过错误总结教训，你会比没有犯过错的人体会得更深。但是千万不要犯低级错误，也不要同一个错误犯两次。\n\n如果你有更好的一些技巧，欢迎你分享出来。\n\n# 小结\n\n总结一下今天的内容。首先，我先分析了为什么会有枯燥的知识。我认为，枯燥的知识通常是你不感兴趣的知识，也有可能是你不知道有什么用的东西。然后，结合自己的经历给出了面对枯燥的知识时该怎样做。此外，我们身处在信息爆炸时代，如何面对如此量大的知识，也是我们面临的一个挑战。我建议，一定不要学在表面上，一定要学到本质上、原理上，一定要学那些不容易改变，能经得住时间考验的东西。\n\n随后，我分享了认真阅读文档的重要性，不仅可以让你少掉很多坑，还可以让你学习到很多知识。最后，我分享了好几条实用的学习技巧，这些也是我在工作中慢慢收集和总结起来的。希望对你有帮助。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/14389\" > </iframe>","categories":["左耳听风"]},{"title":"100丨高效沟通：Talk和Code同等重要","url":"/posts/2054641664.html","content":"\n\n\n**Talk is cheap，show me the code**，是我们技术人常说的一句话，也是技术社区中经常用的一句话。这句话的意思是，那些光说不练的人说一句是很简单的，而写代码的人则会为一句话付出很多很多的精力，其表明，一个看上去再简单的东西，用一行一行的代码实现起来，并能让其运转起来也是一件很复杂很辛苦的事。说得容易，做起来难！\n\n这句话是 Linus 说的，也是我引入到中文社区的，然而，逐渐地，大众对这句话的解读开始有点变味了，走向了另外一个极端——他们觉得代码才是最重要的，甚至其中有些人开始觉得真正的技术人员是只用代码说话的！\n\n似乎，这个世界上总是会有一些人，当他们看到一个观点的时候，在他们的脑袋里只有两个答案，一个是 true，如果不是 true，那就是 false。就好像只要一个人犯了个错误，这个人就是一个不折不扣的大坏蛋，如果一个人是个好人，那他要在所有的地方都是优秀完美的。\n\n对于技术人员来说，其实，Talk 和 Code 是同样重要的， Talk 是人对人说的话，而 Code 也不仅仅只是人对机器说的话，也更是另外一种人对人说的话（因为 Code 需要易读和易维护，就需要让人读懂）。可见，无论是 Code 还是 Talk 其实都是要和人交流的，Code 是间接交流，Talk 则是直接交流。在公司中工作，需要了解公司的意图，与团队一起做项目，调研客户的需求，设计出用户易操作的界面……你会慢慢地发现，其实，Talk 并不 cheap，而 Code 才是其中比较 cheap 的（注：这是站在了另外一个角度）。\n\n一个好的程序员，需要有好的学习能力，这样你才能成为技术专家，但是，你还要有好的沟通能力，不然，你的技术能力完全发挥不出来。就像一棵大树一样，学习能力能让你的根越扎越深，无论遇到什么狂风暴雨，你都可以屹立不倒，而沟通能力则是树杆和枝叶，它们能让你伸展到更高更远的天空。\n\n所以，与人沟通是一项非常重要的软技能，我们应该刻意训练和培养自己这方面的能力。今天我们就来聊聊“技术人如何高效沟通”这一话题。我会分享很多我的工作经验，以及我这么多年来积累和总结的一些沟通技巧。它们在我的工作和生活中都起到了至关重要的作用，希望同样能给你一些启发。\n\n我特别想对技术人员强调一下我的观点：**有效的沟通是事业成功的必要条件**。不管你的目标是成为一名卓越的管理者，还是成为某个领域的技术牛人，你都应该提高自己的沟通能力。\n\n# 沟通的原理和问题\n\n想要获得高效的沟通，我们首先需要知道，什么是沟通以及其背后的原理。简单来说，沟通是指运用语言、文字或一些特定的非语言行为（面部表情、肢体动作等），把自己的想法、要求、信息等内容传递给对方。而沟通的原理跟计算机之间的通信有些类似。我在大脑里面将要表达的内容根据通信协议（比如中文）进行编码，发送出来，你接收到中文信息，但它表达的是什么意思呢？这时就需要去解码。\n\n然而，我们日常生活中经常出现的一种情况是，我这句话是这个意思，但却被对方理解为其他意思，即“说者无心，听者有意”。究其原因，其实是因为我们每个人的编码器和解码器完全不匹配造成的，这也是沟通中经常出现的问题。\n\n\n\n![image-20230926175352687](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230926175352687.png)\n\n那我们该怎样解决这个问题呢？我们来想象一下，在计算机世界中，遇到这个问题都是怎样解决呢？也就是出现编码器和解码器不一样的情况，怎么办？我们通常可以通过一些**约定**来解决这个问题。对应到沟通这个场景下，“约定”仍然是个好办法。我在一些国外公司工作过，基本上入职之后的第一件事都是，被告知公司里面有很多术语，在描述对应的事物时要用统一的术语。就好像江湖中的黑话一样，这就是我们的通讯协议的标准化，这样可以简化很多沟通的成本。\n\n此外，**反馈**也是个很好的方式，你把你理解的东西说给我听。如果有偏差，我再给你解释一下，直到双方达成**共识**。这就好像 TCP 协议一样，为了保证对方收到了，就需要接收方发出确认包。因为发送方和接收方的解码器不一样，所以，接收方把其解码的信息再编码后传回来，发送方这边再解码看看是不是同样的数据，于是就可以保证编码器和解码器中的信息是一致的了。这又叫“双工通信”（你看，我开始用到术语了，文科生听不懂了，嘿嘿），不要小看“双工”这事儿，它是有效沟通的前提。反之，则会有鸡同鸭讲、对牛弹琴的意味了。\n\n当然，就算是我们统一术语并且有反馈机制，人与人的沟通依然还是有很多的问题。最大的一个问题就是，我们的成长背景不一样，经历不一样，知识储备不一样，所以对相同事物的理解难免会存在一定的偏差。\n\n日常沟通可能还好一点，但涉及到一些专业领域中术语的表达，沟通不畅的问题会变得更为严重。比如，我在讲一些计算机术语，而那些没有计算机方面知识储备的人，是完全听不懂的。即便他能听懂我说的每一个字，但还是理解不了我在说什么。所以，这个世界上有一些“教 6 岁孩子学习 XXX”的文章，这种方式其实就是想把一些高级的知识通过低级知识来表达出来，以便可以让小孩子都能听懂，也就是所谓的科普。相信我，如果你能做到这点，你一定是这个行业的专家级人物了。\n\n就像那本相当经典的图书《[从一到无穷大](https://book.douban.com/subject/27182584/)》，其实它在讲的是高阶物理知识，其中有非常难以理解的爱因斯坦相对论，然而这本书却被作者写成了中学生都可以读懂的科普书。能把深奥的物理知识写得这么通俗易懂，只有真正的专家才可以做到。这本书的作者是：乔治·伽莫夫（George Gamow）美籍俄裔物理学家、宇宙学家、科普作家，热大爆炸宇宙学模型的创立者，也是最早提出遗传密码模型的人。\n\n信息在传递中的损失也不容忽视。相信很多人都玩过一个类似“传话”的游戏：一个人将一句话偷偷说给站在队首的人听，然后他把自己听到的内容传给第二个人，依次传下去，直到队尾。最后由队尾的人大声说出听到的内容。很多时候这个最终的结果都会令人哭笑不得，因为在传递的过程中，最初的信息已经完全变了样子。\n\n因为，每一次信息的传递都是由不同的编码器和解码器完成的，而传递信息所使用的协议（人类的语言）是很难准确地携带所有的信息的，所以每一次编码和解码都会有信息的丢失和失真。还有一些人会在其中有意无意地“加油添醋”，甚至加入“谣言”，导致整个信息传递过程被黑！\n\n与之对应的，如果一个公司层级越深，那么执行力一定越差。为什么呢？因为老大的“旨意”一层一层往下传递，传到最下面其实信息早就变了样儿。基本的模式都是，我听我的领导讲了，自己理解了一下，然后对下面的人讲。经常会出现这样的情况，最高层老板讲，我要的是这个，但最终员工交付的却是另外一个东西。信息传递的渠道越多，损失也会越大。所以，会有下面这张经典的图。\n\n![image-20230926175418766](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230926175418766.png)\n\n\n\n另一方面，在职场里，出于各种各样的原因，有些领导不想直接把自己上级的话对自己下属去讲。一方面，要把其变成下属能理解的语言去讲，他们觉得这样会更有效率，下属不用管公司或是别人要什么，只管好自己要干什么就好。\n\n而另一方面也有政治上的原因，他们把一些信息阻断了，甚至修改了，以此来达到控制别人的目的。通常来说，只要有等级存在，职场中的管理层就会对上粉过饰非，对下盘剥利诱，这就是职场的生存法则，尤其是大公司更是这样。所以，公司大了后，如果管理跟不上，听之任之，上层和下层脱节基本上来说是必然的。\n\n对我而言，不管以前做公司管理层，还是现在经营自己的公司，我一直都秉承的原则是，将信息源头的信息原模原样分享出去，而不是我“嚼过的”。因为，我认为后者的信息损失会非常大，而且产生的不良后果也会很大。真正的团队管理，不应该屏蔽信息，信息应该是公开透明的，因为我相信团队成熟到可以面对各种信息，并且是可以一起找解一起找出路的。\n\n# 小结\n\n总结一下今天的内容。在文章伊始我先强调了我的观点，Talk 和 code 同样重要，有效的沟通是你事业成功的必要条件。随后介绍了何为沟通及其背后的原理。我认为，沟通原理跟计算机世界中的通信原理有些类似。由于编码器和解码器的不同，会造成理解的偏差。这个问题可以通过约定和反馈来解决，也就是要先达成共识，然后基于共识来进行沟通。最后我阐述了一些沟通问题，以及应对这些问题的方法。\n\n下篇文章中，我将分析一下形成各种沟通问题的主要阻碍。敬请期待。\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/28550\" > </iframe>\n\n","categories":["左耳听风"]},{"title":"101丨高效沟通：沟通阻碍和应对方法","url":"/posts/2577985227.html","content":"\n\n\n了解了沟通原理和相关问题之后，我们来系统地分析一下哪些因素会成为沟通中最主要的障碍，并给出应对方法。\n\n信息不准确\n对照我们在沟通原理中提到的沟通模型，可以看到，如果被编码的信息本身是错误的，或是你的编码器中有 bug，把信息编辑错了，那么，无论是你有多牛的沟通技巧，采用多有效率的沟通方式，都不可能表达清楚。用词不当，词不达意，添油加醋，断章取义，歪曲事实……都是这类沟通方式最糟糕的表现。\n\n针对这类情况，我给出的建议是，在沟通之前，首先要想清楚沟通的目的是什么，然后整理自己的措辞。如果是一些比较重要的沟通，最好可以把自己的想法写下来，然后放一会儿，再回过头来看，想象一下如果是别人对自己讲这些话，自己会怎么理解。\n\n在实时交谈的过程中时，面对一些容易让人产生误解，或是自己感觉没有表达好的信息，你需要停下来，思考一下，换个方式，重新再来一次。我也经常这样。我会停一下，告诉对方，让他等一下，给我一点时间来组织语言和逻辑，或者说，对不起，我没表达好，我换个思路重新说……\n\n而当别人没有表达清楚的时候，你要及时打断对方，跟对方说，你没有听懂，你不知道这是什么意思，是否可以重新澄清一下，等等。这都是我们日常沟通中惯用的手法。而如果你明明知道你不懂却不好意思问的话，这就是沟通中最大的阻碍了，沟通就是要来来回回的确认。\n\n这里的关键点是，在信息不准确时，节约时间已经没有意义了。沟通效率的关键不在于快，而是准确！要做到这些，你需要不断地练习，多有几次准确表达自己、成功沟通的经历，就会驱使你的沟通表现越来越好。在《程序员面试攻略》中，我还分享了另一个方法，就是多看多写，养成写博客的习惯。当你越来越能把复杂的事情写清楚的时候，你的表达能力就会越好。\n\n信息太多\n信息太多就等于没有信息。有些人在交流的时候，会先说一些无效信息或者与主题无关的干扰信息。比如：\n\n害怕别人可能不能理解，就进行大量的前期铺垫和背景描述；\n\n害怕得罪别人，先花大量的时间进行解释和免责；\n\n想把所有的东西都告诉对方，在做 PPT 的时候，放入了大量的文字而让人 get 不到重点；\n\n怕别人听不进去，唠唠叨叨，车轱辘话来回说；\n\n用各种各样的比喻来说明一个事，但就是不直接说明这个事，把大家搞得云里雾里的；\n\n枝节太多，跑题，东拉西扯，抓不住重点；\n\n……\n\n我以前团队有个下属来跟我来说，“我最近工作很累，压力很大……”当时，听他这么说，我虽然表面故作镇定，但心里面却是不安的，我的直觉告诉我他可能接下来就要和我说离职了。然后，我开始安慰他，再把话题偏到和他分享我以前遇到相似的情况时我是怎么怎么做的。结果换来的是更多的解释，他跟我表达更复杂的情况，于是我又在帮他想办法……\n\n这样你躲我闪的沟通持续了三十分钟之后，我才搞明白他其实是只是想休假。他想请一个星期以上的长假，害怕申请不下来，所以，先给我解释这么多，而我以为他要离开。于是，在我俩各自“心怀鬼胎”的环境下，沟通变得越来越复杂了……\n\n其实，如果他第一句话就说：“我想请一周的假，想休息休息”，我觉得有点长了，自然会问他原因的，如果我不觉得长，我就马上给答案了。但无论是哪种情况，都不会像我以为他要离职这么复杂。\n\n是的，不要绕弯子，有话直说，这是最高效的沟通方式。这既是对对方的一种信任，也是一种对自己的尊重。这样沟通，事情往往能得到更好的解决。\n\n没有交互\n没有交互的沟通是一种有些令人沮丧的交流方式，这相当打击积极沟通的一方。尤其是面对程序员，开会也好，分享也好，我经常一个问题出去（比如：想听听大家有什么意见，我这么做有问题吗？等等），没有任何的回应，一片寂静，本来注视着你的眼神一下子都低下了头，相当令我沮丧，甚至有些令我不知所措。\n\n于是，沟通成了单向灌输，沟通中的一方或者双方喋喋不休地说，而且是只说不听，各说各的。这样不仅会把双方都搞得很疲倦，而且问题一点儿也没有解决。这样的沟通可以说是完全失败的，只是在浪费时间。遇到这种情况，一定要学会止损。也就是，一旦意识到这样的情况发生，就委婉终止这样的谈话，想办法脱身。而且还要反思自己和对方到底出了什么问题，然后寻找有效沟通的方式和技巧。\n\n这里多说一句，有时候，领导太过于威严，或是太过于强势，不听别人的观点，就会导致别人不敢表达自己的想法，或是觉得表达出来也没什么用。时间一长，就造成了没有交互的沟通。\n\n不要觉得这样“发命令式”的沟通很好，效率很高。实际上，你把你的员工当成不会思考的机器的话，他们也就真的成为了不会思考的机器。有一天，你需要你的员工为你分担压力，帮你贡献一些想法的时候，你会发现你这堆员工简直就跟机器一样没有差别。\n\n找到对方的兴趣点，降低表达自己真实想法的门槛，培养让大家畅所欲言的自由环境，把自己的答案变成问题，让其它人有参与感，这样才可能有好的沟通，也能够有好的结果。\n\n表达方式\n沟通中有两个非常重要的因素，一是沟通的内容，二就是表达方式和态度了。同样的沟通内容，以不同的表达方式说出来，实现的效果也会大相径庭。很多场景下，人们以一种平等且互相尊重的态度进行交流的时候，沟通一般都能得到顺利进行。\n\n试想如果一方态度不好，或者带着某种情绪，用听起来轻蔑且粗鲁的方式跟你说话的话，会出现什么样的结果？这就解释了为什么人们有时会为一些琐碎小事儿而争论不休。我们要尤其意识到，很多时候沟通失败，不是沟通内容出了问题，是表达方式、谈话的态度出了问题。后面讲述沟通技巧的时候，我会详细讲述这个问题。\n\n老实说，我有时候也会有这样的问题（就是那种情商为零的情况），我也在努力克服，努力改善中。要做到这些可能只有读万卷书，行万里路了……\n\n二手信息\n由于信息在传递过程中会自然损失的特性，导致即便在没有人为主观去篡改的情况下，很多二手信息内容的准确度也是不够的。这跟上面提到的“信息不准确”有些类似。通常来说，二手信息都是变味的信息，这些变味的信息在很多时候是会是影响人的判断力的。像道听途说、以讹传讹之类的二手信息，可能会让你做出严重的错误判断。流言止于智者，流言之所以能止于智者，不是因为智者聪明，而是智者会到信息源头上去求证。\n\n在网上有很多关于我的传闻和一些八卦故事，而且这些八卦是非常有生命的，里面那些所谓的“当事人”把一些事描述得活灵活现的，却基本没有人来找我求证是否真的是那样的？我怎么想也想也不明白：是我死了无法对证了，还是现在的人喜欢看八卦喜欢到已经不关心事实了？\n\n到信息的源头，向当事人去求证，会让这个世界更加和谐，也会让你变得更有智慧。\n\n信道被黑\n我们做计算机的人都知道，如果在网络通信的时候，信息在传输过程中被有恶意的人修改会产生什么样的后果。这就是信息不对称，这个世界有太多的人喜欢玩信息不对称的游戏，因为信息不对称了，轻则可以牟利，重则可以控制人的思想和行为。挑拨离间、散布谣言、假传圣旨、捏造事实、欺上瞒下……就是这方面的示例。所以，你应该知道信息平等是有多重要的一件事了。\n\n虽然有时候信息是负面的，隐瞒可以让你获得短暂的宁静，但是纸包不住火，一个谎言需要用更多的谎言去弥补，一旦被识破，你得到的将是信用的破产和大众报复性的结果。所以，在面对负面信息的时候，最好的方式不是隐瞒，而是公开以及给出解决方案。\n\n要解决信息被黑这个事，只有一条路可以走，那就是让信息公开透明，将没有被“嚼过”的信息，完整一致地传递给别人，让大家用自己的想法去理解它。尤其是在公司宣布一些变化的时候，千万别嚼完了再告知下属。但有些管理者会觉得，信息公开透明之后就不好做管理了，因为开启民智了。这些人的想法是：我就喜欢愚民，员工傻一点我好管。我让你加班你就加班，我让你朝东你就朝东，不会问我为什么朝东，为什么不朝西。\n\n但是，我想说，信息不对称只有短期利益，没有长期利益。短期来看，团队成员听话，团队好管理。但长远来看，这么做无疑是在剥夺员工自我成长的机会，从而无法培养员工的自驱性和创造力。当一个团队没有创造力，不会思考的时候，你还能走多远呢？\n\n小结\n总结一下今天的内容。在这篇文章中，我介绍了最主要的六种沟通阻碍：信息不准确、信息太多、没有交互、表达方式、二手信息和信道被黑，给出了各种阻碍所带来的沟通问题，同时给出了相应的解决办法。希望能够启发你的思考，并给你提供帮助。\n\n下篇文章中，我将分享一些行之有效的沟通方式和技巧。敬请期待。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/32619\" > </iframe>","categories":["左耳听风"]},{"title":"102丨高效沟通：沟通方式及技巧","url":"/posts/670565089.html","content":"\n\n\n# 沟通方式\n\n好的沟通方式有很多种，我主要介绍最常用的三种：尊重、倾听和情绪控制。\n\n## 尊重\n\n尊重对方在高效沟通中非常重要，也是一个很关键的前提。这里你需要记住以下两个原则。\n\n- **我可以不同意你，但是会捍卫你说话的权利**。即便在你不认同对方观点的情况下，也要尊重对方的表达，认真聆听，这个时候有可能你会发现不一样的东西，从而改变自己最初不准确的认知。\n\n- **赢得对方的尊重需要先尊重对方**。在你对他人表现出足够的尊重之后，同时你也能够赢得对方的尊重，他会更乐于跟你交谈，而且交流的内容也会更为细致和深入，从而实现良好的沟通效果。此外，在这样的背景下，当你和对方出现观点不一致的情况时，对方也会更乐于聆听你，并顺着你的思路去思考。\n\n  所以可以说，尊重对方并赢得对方尊重的沟通方式，通常会进行得比较深入，沟通效果也会很不错。\n\n注意，尊重并不代表要低三下四、随声附和，做一个墙头草可以让别人很容易和你相处，但要赢得对方的尊重，这还远远不够，**你一定要和对方有观点上的交互，甚至是碰撞。沟通的目的不是为了附和对方，而是产生一种更完整更全面的认知**。只有当双方都愿意接受不同的观点时，此时的沟通才会迸发出更多的火花，而这一切都需要发生在相互尊重的基础之上。\n\n## 倾听\n\n《沟通的艺术》一书中将“倾听”定位为至少与“说”同等重要的沟通形式，足以见其重要性。作者认为，倾听与听或者听到有很大不同，它是解读别人所说信息的过程，包含听到、专注、理解、回应和记忆五大元素。\n\n上面的说法有点高大上，我们还是实在一点。我们之所以要倾听，就是因为倾听可以让我们获得更多信息，对对方有更多的了解。倾听能让对方感觉到自己被尊重，所以才会跟你分享更多的信息。这其实是沟通中的高级技巧，因为当你掌握了对方很多信息时，你就可以了解这个人，也就对你越有利。所以，面试的时候，一般来说会面试的面试官基本上都不多说话，都是在听你讲，你讲的越多，他就了解你越多。那些电视里访谈类节目中的主持人都是很厉害的倾听高手，因为他们要挖到被采访人更多的信息。\n\n你一定要学会倾听，掌握到更多的信息，因为掌握不了足够的信息就会信息不对称，信息不对称就会做出错误的假设。尤其是在谈判的时候，你觉得他的利益点是这个，而实际上他的利益点可能是另外一个。所以，倾听其实不仅仅只是听，还要思考，要思考更深层的原因，不要被表象所迷惑，才会有更高效率的沟通，这才有助于你做出正确的决定。\n\n## 情绪控制\n\n能否控制好自己的情绪对于沟通效果来说至关重要。如果动不动就生气或者心怀戒心，通常会令沟通很难进行，更不用说实现高效沟通。如果能控制好自己的情绪，时刻保持理性思考，这不仅会使所沟通问题得到顺利解决，而且能给对方留下好的印象，进而形成良好的人际关系。我们都会说某个人的 EQ 比较高，并不是说这个人很会说话，很会说话、有随机应变能力的人通常都是 IQ 高，EQ 高的人一般都是可以控制自己情绪的人。\n\n具体该怎样做呢？我建议遵循以下两个原则。\n\n- **不要过早或者过度打岔和反驳**。倾听对方，即便有不同意见，也要耐心地听对方说完，不要打岔或反驳。断章取义是件非常可怕的事儿，因为当你听对方完整讲述完之后，很多时候会改变自己在聆听过程中的某些想法或者看法。此外，打断别人说话，是很不礼貌的事儿，次数多了，会给对方留下坏印象。\n\n- **求同存异，冷静客观**。每个人的知识储备不同，生长环境不同，经历和性格等也不同，所以看待和理解问题时，自然会有很大差异。所以，要懂得尊重这些差异，客观公正地思考问题，并给出相应的建议和看法。\n\n  **切莫在冲动之下，说出很多一些过分或过激的话，因为言语的力量是巨大的，杀伤力有时难以预估**。举一个有些极端的例子。假如你和铁哥们儿吵架了，对方一气之下，打了你两拳，你很有可能过两天就忘记了。但是如果对方说了几句伤你心的话，这种伤心则有可能会持续很久很久，甚至你们可能会因此而绝交。\n\n人是有情感的动物，并不是所有的人都能够控制得住自己的情绪的，尤其是血气方刚的年轻人。**有时候，我会自己告诫自己，情绪是自己的，不是别人的，不应该被别人 hack 了**。所以，无论发生什么事，自己才是自己心情的主人，而不是别人。话虽这样说，但是要做到并不容易。有时候，我也不能很好控制我的情绪，到今天都还不行，这也是我要用一生去成长的事……\n\n# 沟通技巧\n\n掌握了上面的沟通方式，下面来看几个我经常用的沟通技巧。\n\n## 引起对方的兴趣\n\n第一是**引起对方的兴趣**。如果对方没有兴趣的话，那么他是不愿意跟你沟通的。但你要怎样引起对方的兴趣呢？我现在也在创业。我出去跟客户谈，我技术好，是没有用的。只有利益，才能引起对方的兴趣。\n\n举一个真实的例子，为了找一家银行谈合作，我找了一堆关系，给我介绍了某个银行的副行长。见面的时候我的着装有些随意，而周围的人都穿着衬衫和西裤，很正式。估计要不是别人介绍的，他一眼都不想看我，几句话就能把我打发了。\n\n他一开始就问我：你是谁？你们公司叫什么名字？没听说过。注册资本多少？哎呀几十万呀……我被这几个问题搞得非常地狼狈和不堪，完全不知道该怎么往下继续。在这样的情况下，如果你是我你会怎么办呢？该怎样吸引他的兴趣呢？\n\n真实情况是我只用了 20 分钟时间就搞定了这件事。我分享一下，我是怎么做到的。\n\n首先，我见他之前做了一些功课，收集了一些信息。银行和金融业，今年下半年整个形势都是很糟糕的，银行贷款都办不了。国家货币在紧缩，还有 P2P 这些乱七八糟的事儿。于是，我就跟他说，我这边有一个客户，这个客户的现金流比较大，一天的流水大概是 3-5 个亿……\n\n还没等我讲完，他就打断了我，立马说：哦？！请坐，那个谁，过来倒点儿水……当一个人对你有兴趣了以后，后面的事就比较好谈了。当然，我并不是在忽悠他，我做的技术项目本来就是为大规模并发的场景而生的，所以，能用得上这些技术的用户基本上来说都是有一定的业务量的，也是有相应的现金流的……\n\n## 直达主题，强化观点\n\n第二是**直达主题，强化观点**。要做到这点，你需要做的是过滤信息，简明扼要地表达。信息不要空泛笼统，而要可以准确执行。亚马逊要求员工都有一个技能叫做 deal with ambiguity。ambiguity 就是歧义的、模糊的，不知道怎么执行的。工程师的情结通常是我写出来的代码 1 就是 1，0 就是 0。\n\n但很多时候产品需求都是很模糊的。而且很多时候，整个世界都是模糊的、有歧义的。有的人这么说，有的人那么说。你都不知道自己该信谁。所以亚马逊要求员工有一个能力就是，你一定要有把模糊的理解变成准确理解的能力，因为如果不这样，你是写不出代码来的。\n\n这种过滤掉无用或者非关键信息的能力很重要。**确定自己的目标，学会抓重点，知道自己要什么和不要什么，这样你要的才会更鲜明。当一些事情变得简明和鲜明起来时，你才会表现出有力量的观点和话语。而这些被强化过的观点和话语，只需要一句，就会在对方脑子里形成一个小爆点，要么击中了对方的软处（扎心），要么会让对方产生深度思考。**只有这样，你的信息才算是真正地传达过去，并在对方的脑子里生根发芽，这就是所谓的影响力！\n\n要有这样的能力，你需要通过反复练习来获得。在表达之前，要想明白自己表达的目的是什么，先组织一下自己要表达的内容，然后结合自己的表达目的反思这些信息中，哪些是有用信息，哪些是无用信息。留下有用信息之后，思考是否有更加简单明了的表达方式，是不是可以一句话就行。当你开始把大量的信息提炼浓缩成“金句”的时候，你就真正开始成为沟通的高手了。\n\n这里有个小技巧是换位思考，假设你自己获取到这样的信息会怎样理解和执行，甚至可以尝试多维度来理解，自己跟自己“互搏”，逐渐修正，直到令自己满意。这个过程需要花不少心思，也需要长时间的坚持和锻炼。你要对自己有信心。\n\n## 基于数据和事实\n\n第三是**用数据和事实说话**。你跟别人沟通，要尽量少说“可能、也许、我觉得就这样”等字眼，你最好通过数据和证据，通过权威的引用和证词，通过相关的实例和亲身的事例来让你的观点有不可被辩驳不可被质疑的特性。当你的信息出现了这样的特性时，接收信息的人，基本上来说，就会无条件地相信。别人会无条件地相信你说的话，你想想这是一种多么牛的沟能方式！\n\n我记得我在亚马逊的时候，产品经理整天在数据仓库里做各种的统计和分析，然后拿着数据来说服老板和开发人员开一个新的项目。当那些数据和事实放在你面前时，你真的是只有认命的份儿了。\n\n所以，在很多时候，我们要在沟通之前注意收集相关的数据和事实，多做一些沟通相关的功课，你的沟通会更有效率。基本上来说，数据、事实、证据和权威是沟通中的大规模杀伤性武器！\n\n# 小结\n\n总结一下今天的内容。简单来说，在沟通过程中，你要牢记三大沟通方式：尊重对方、倾听对方和情绪控制，从今天开始，你就可以在和别人沟通的时候刻意练习这几大沟通方式了。然后我还和你分享了几个对我帮助很大的沟通技巧。\n\n- 一是沟通之前，你要想方设法引起对方的兴趣，这里面你要思考对方最关注什么，你可以帮到他什么。\n- 二是直达主题，强化观点，要做到这一点，你需要过滤信息，简明扼要地表达。也就是说你要明确自己的沟通目的，然后围绕目的不断迭代自己的表达内容。同时，你可以用换位思考法来进一步确保自己的表达能够准确无误传递给对方。\n- 三是用数据和实例说话。沟通的时候，你应该尽量少用“可能”、“也许”之类不确定的话术，转而使用数据和实例等确定性的语言来夯实你的观点，当然，这中间你要学会如何积累“实例”。 这三样东西不仅可以帮你解决绝大多数问题，而且可以把你的沟通变得简单粗暴、直接有效。\n\n采用这样的方式和技巧，我想你基本上可以解决 80%-90% 以上的沟通问题了。还是那句话，我能做到的，你一定也可以。加油！\n\n下篇文章，我将分享我常用的一些沟通技术。敬请期待。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/32796\" > </iframe>","categories":["左耳听风"]},{"title":"104丨高效沟通：好老板要善于提问","url":"/posts/2268697446.html","content":"\n\n\n前面的几篇文章中，我分享了一些通用的沟通方法，如尊重、倾听和情绪控制等。接下来的几篇文章中，我将从如何与员工沟通、如何与客户沟通，以及如何与老板沟通这几个角度，和你聊聊这些沟通方法具体应该如何应用。\n\n作为一名团队 Leader，你首先应该学会如何与团队成员进行有效沟通，因为它是实现管理效果的必要手段和有效途径。但如何拥有这个基本功呢？我来分享一下我的经验。\n\n# 引导\n\n我在汤森路透工作的时候，曾经参加过一个管理上的培训课程。这个培训课程的第一课就是教这些管理者如何在沟通中引导员工，而不是给员工灌输自己的想法。课程里强调，管理者要想尽一切办法让员工自己思考问题，想出答案；而不是灌输，什么事儿都是自己在想，自己讲给员工听。员工不想，你怎么说，他都很难把你的话理解到位，也就是说你一定要让他自己把事情想出来。\n\n这有点儿像电影《盗梦空间》说的，你应该在思想里埋下一个种子。我们要干的就是在员工的思想里埋一个种子，让它生根发芽。但这要怎样实现呢？\n\n答案就是管理者要学会问问题，问员工怎样做。假如员工给出了一个方案，但不巧，可能由于他考虑得不全面，或者由于他不知道某些情况，不是你想要的答案。这时，该怎么办呢？\n\n你可以说，如果这么做的话，会有一个什么问题，而这个问题很重要，如何解决？然后，他会给出解决这个问题的方法。但这么做又会带来另一个问题，直到把他逼到你想要的答案上去。\n\n如果每次遇到问题，都让他自己想答案，次数多了以后，他会觉得自己的参与感越来越多。最后，他会觉得是他用他的观点说服了你。尽管这就是你想要的答案，但你还是要假装被说服。这样他会很开心的，会有一种参与感。然后，在执行这件事儿的时候，也会更加卖力，更加有激情。他会觉得自己在实现自己的想法，而且自己的想法是对的。\n\n作为 Leader，你要记住，**永远不要给员工答案，要让员工给你答案，而且不要只给一个答案，一定要给多个答案**。然后让他们比较这些答案，促使他们深入地进行思考。这不是在让员工做问答题，其实是在给员工成长机会，促进他们的成长。\n\n永远不要跟员工说，我给你一个任务，这个任务两星期完成。要让他来说，这个任务需要多久能完成。并要求员工提供多种执行方案，不要只给一个时间。你快点做怎么做，慢点做怎么做，是否还有其他方案。一定要员工自己去做计划，去思考。反之，如果你什么都想了，只让员工去执行，那么他就不思考了，而且有时还会生出一些怨念。比如抱怨领导这样安排不合理，那个执行方案有问题等。带有情绪的执行，势必会产生不够好的执行结果。\n\n但根据我的观察，喜欢给答案的管理者还是挺多的，他们总是习惯性地给员工答案，而不善于挖掘员工的实力和潜力。我觉得这是世界上最 Low 的管理模式了，是家长式、保姆式的管理。实际上，你的员工都是专业人才，你应该充分信任他们，并且想方设法激发他们的主观能动性，促使他们发挥自己的能力，积极地为你贡献答案，从而保持团队的活力和创造力。\n\n# 倾听\n\n倾听意味着在听他人讲话的时候，不让自己的想法扭曲别人传递的信息。你要做到毫无偏见，才能全面理解对方的信息。倾听不只是听或者听见，需要你用心聆听别人讲话，而不是只听自己想听到的内容。如我在《沟通方式及技巧》一文中提到的，倾听可以让员工感觉到自己被尊重，所以他们会乐意分享更多的信息。\n\n学会倾听不仅可以帮你拉近和员工的距离，还可以让你更加了解员工。我在汤森路透工作的时候，团队里有两个刚毕业的小伙子。一个来自农村，一个来自城市。来自农村的小伙子是家里老大，家里条件不太好，不仅要挣钱还自己的助学贷款，还要帮家里还外债。而那个来自城市的小伙子是家里老五，上面是四个姐姐，家里条件也相对比较好。不用去想人物性格，从这个背景里，就能大致猜出这两个人的差距。果不其然，有四个姐姐的小伙子，抗压能力相当低，觉得什么活儿都有难度，什么都适应不了。\n\n而要还外债的小伙子抗压能力相当高，没事儿就来跟我说，你把什么任务都给我，我什么都能搞定。经过几年的努力，他终于把家里的外债还干净了，然后特别高兴，请我吃饭。我说，你不用感谢我，要感谢你自己，是你自己做得多。通过这个例子，我想说明，通过倾听更多地了解员工，了解他们的生长环境和背景，可以帮你对每个员工建立更加合理的预期，从而更好地进行任务分配和人员管理。\n\n所以，外企一般都会要求经理和员工有周期性的一对一交谈，就是为了及时了解员工的各种动态和想法。\n\n# 共情\n\n共情，又被称为同理心，或者换位思考，它指的是站在对方立场设身处地思考问题的一种方式。换句话说，在人际交往过程中，你需要能够体会他人的情绪和想法、理解他人的立场和感受，并站在他人的角度思考和处理问题。\n\n比如，有团队成员要辞职了，你要怎样跟他谈呢？你肯定要找他谈感情。我们一起共事这么久，你要走了，我们一起回忆回忆过去。然后说，没关系，你看你要离开了，有没有什么我可以帮你的？不要强行让对方留下来，要多谈感情，多回忆一下，多听听对方的诉说。当他回想起过去一起同甘共苦的日子，难免会心生留恋，也许会回心转意的。当然，如果你并不能把他留下来时，不如大度一些，帮他看看他要去的另外一家公司是否是正确的选择，而且你还可以给他介绍更好的地方。既然留不下来，就索性为他介绍更好的地方。这样做至少还能引发他一些思考，“我都要离开了，我老板对我还这么好，我以后能不能找到这么好的老板？”\n\n这里的关键是，当对方开始想离开你了，你千万不要指责和教育对方，而一定要站在对方的角度来思考问题，理解对方，真心对对方好。晓之以理，动之以情。\n\n# 高维\n\n员工来跟你聊的，通常都是细节问题。这时，你可以耐心地跟员工沟通，并共同来寻找解决问题的方案。但有的时候涉及到公司的一些问题时，你自己也解决不了，那么你该怎样跟员工聊呢？比如，公司因为战略方向调整，想要砍掉你负责的业务，你和你团队都需要转到新的业务线上。\n\n你肯定不能跟自己的“弟兄们”说，公司混蛋，把我们这么好的业务给砍掉了。作为管理者，你应该知道，没有完美的公司，任何公司都存在这样那样的问题。你需要有更高的维度来看待这个问题，来给员工做出解释，让他们既能理解公司的决定，又能保持动力转到新的方向上。\n\n对于这样的问题，你首先应该肯定员工过去的努力以及取得的成绩，明确说明虽然业务被砍，但是我们的技术积累还在，这是我们谋求未来发展的基石。同时，帮助员工看清公司新的战略方向会给全公司的人带来什么前景，新的业务方向如何更能发挥出大家积累的经验和能力。在成功安抚人心的同时，引发大家对新业务方向的兴趣，从而更有利于帮助团队后续过渡到新业务方向上。\n\n当然，在讲这个事情的时候，千万不要太过了，还是要跟员工共情一下，也要表达出自己的不满，这样让员工觉得你是跟他们站在一起的，而不是跟公司站在一起的，后者无疑会引发你和大家的对立。这里的沟通思路是这样的：“公司的这个决定，我也有点难理解，我们这么辛苦做了这么多，没想会这样……但是我们做的事是很牛的，我们这个团队是强大的，强大到对于这样的打击都是没有问题的。这个世界就是这样的不完美，但是我们还是要去奋斗，不然就更不完美了……接下来，无论发生什么，我们都要一起扛！” 也许，这么说也没什么用，但至少，在困难到来时，你可以让大家的心更近了。\n\n# 反馈\n\n反馈是一种非常重要的沟通形式，对于确保团队的正常运转十分关键。但有时候员工没有反馈的意识，或者不愿意反馈，你应该怎么办？这时，你应该建立一些反馈机制。比如，在我目前的团队里面就在用“1-2-3 反馈机制”。\n\n1. 不管你遇到什么问题，如果自己在那儿憋一个小时找不到解决方案，或者说没有任何思路，就要反馈到高级工程师这边来。\n2. 如果跟高级工程师在一起两个小时内，找不到任何解决方案或者没有思路，那么就要反馈到一线 leader。\n3. 如果一线 leader、高级工程师，花了三个小时，依然找不到方案，那么这个事就可能是个大事了，要向上级反馈了。\n\n这么做，就是为了确保一个大问题，在一天之内能够上升到管理层。然后管理层可能会寻求更牛的人或是从外界获取帮助，以使得问题尽快能够得到解决。\n\n这个反馈机制不仅能确保问题及时被反应出来，并及时得到解决，而且能够帮团队节约大量的时间和精力，对团队来说是种很好的正向鼓励，属于正反馈。\n\n之前我一直强调，正反馈的重要性。在这个场景下，无疑也是如此。试想一下，你和你的“兄弟们”逢山开路，遇水搭桥，一路凯歌的样子，是不是很酣畅？这便是反馈机制的威力了，它会潜移默化地在团队中形成一种“解决问题”的文化，让我们在发现问题的第一时间正视问题，拼尽全力来解决问题，并能从中享受到“搞定问题”的成就感，从而形成正向循环。\n\n除了对工作中问题的反馈，反馈还可以存在与很多其他方面，你完全可以结合团队的实际需求拟定出各种合适的反馈机制。对于任何反馈机制的建立，你只需要记住两点：一是及时反馈；二是能够形成正向循环。\n\n# 小结\n\n总结一下今天的内容。我分享了我与员工沟通时经常用到的几大法宝：引导、倾听、共情、高维和反馈。\n\n- 引导，用提问的方式，“倒逼”员工找到答案，从而提高员工的参与感和成就感。\n- 倾听，心态平和，毫无偏见，全面接收和理解对方的信息，而不是只听自己想听的信息。\n- 共情，换位思考，站在对方立场设身处地思考和处理问题，动之以情，晓之以理。\n- 高维，提升自己的格局观，能从全局利益、长远利益思考问题，解决问题。\n- 反馈，建立反馈机制，及时发现问题、解决问题，形成正向循环。\n\n下篇文章中，我将继续就如何与员工沟通这个话题进行讨论，主要探讨如何进行一对一会议、如何做绩效沟通、如何定位性格特殊的员工、如何挽留离职员工、如何辞退员工等问题。敬请期待。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/33112\" > </iframe>","categories":["左耳听风"]},{"title":"103丨高效沟通：沟通技术","url":"/posts/3746806334.html","content":"\n\n\n上篇文章中我分享了一些常用的沟通方式：尊重、倾听和情绪控制，并给出了几个我认为很不错的沟通技巧，比如：引起对方的兴趣；过滤信息，简明扼要地表达；用数据和实例说话。这篇文章中，我来分享几个关键的沟通技术，相信掌握了这几大沟通法宝，你的沟通水平会大幅提升。\n\n# 逻辑\n\n你的逻辑能力一定要强。因为中国人从小就不学逻辑学，所以讲话不注重逻辑，而我们理科生尤其是学过数学的程序员是懂逻辑的，所以，对于我们程序员来说，我们是可以用缜密逻辑疯狂地碾压别人的。\n\n逻辑是一门科学，也是一门数学。谁是谁的充分条件、必要条件或充要条件，以及有没有关联关系，有没有因果关系等，这些东西你要做到心中有数，当对方的表达中出现逻辑错误时，你可以随时指出来。比如，这两个事儿没有因果关系，我们不要把它们放在一起谈。\n\n有一次，我就跟一家公司的产品团队 PK 了一下。这家公司的产品有一个视频下载功能，但他们统计数据发现，有大约 40% 的用户下载到一半就取消下载操作了。于是他们就想提高用户的下载体验，解决办法是模仿微信的绿色进度条的做法：让进度条的 90% 嗖地过去，然后最后的 10% 则对应实际剩下的下载进度。\n\n我们通过逻辑分析，不难发现这样做是不能赢得用户的。他们的逻辑是：“用户看到已经下载 90% 了，然后会想那 10% 很快就能下载好，所以会愿意多等一会儿。而不是下载 10% 就让用户等了半天，那他就不想等了。”这里的前置条件是用进度条欺骗用户，后置条件是用户愿意等待下载。\n\n但是不是进度条这样设计了以后，用户就真的愿意等到下载完成呢？不是的。不需要试验，我们脑补一下，当我们的微信打不开网页，或者打开速度超过我们的心理忍受限度时，无论那个进度条是多少，我们都不会等的。有这么一个逻辑在这里卡着。\n\n基于这种逻辑，我跟他们说，这种进度条设计会导致更低的下载率。因为视频通常比较大，下载的总时间是很长的，绝大多数用户对这个速度是没有概念的。打开网页的时间是很短的，90% 的网页在 3、4 秒内就打开了，只有少数偶尔需要 5 秒到 10 秒才能打开（因为移动网络的问题）。\n\n这时，我可以通过这种“就快完”的手段把用户多留下来一会儿。但是，视频下载无论怎样优化，至少需要半分钟，才能下载下来。此时，如果进度条不能反映真实进度的话，用户对总的打开时间是没有合理预期的，90% 的进度提前到了，剩下的 10% 花那么久，很容易让人认为是下载卡死了，从而放弃，乃至在多次重试无果后对应用和平台都失去兴趣。\n\n所以，这样的进度条设计只是用户愿意等一小下（15 秒以内）的充分条件（还不一定是必要条件），并不是用户愿意等待直到视频下载完成的充分条件或必要条件。\n\n在这样的逻辑面前，产品经理立马取消了这个功能的排期，说还需要想一想。你看，你可以用你的一些逻辑推理去分析问题的前因后果和条件，然后用这个条件来说服他。\n\n在逻辑层面说服对方，是一种非常高级的手段，就像懂微积分的人来解数学题一样，那些不懂微积分的只有被碾压的份儿了。\n\n# 信息\n\n信息要全面、准确。这里重点提一下 X/Y 问题。X/Y 问题是一件非常讨厌的事情。有时候我们拿着 Y 问题去找别人，问到一半才知道，我们原来要问的是 X 问题。\n\nStack Overflow 上有个问题，问的是“怎么截取一个字符串的最后三位？”大家给了一堆答案。突然有个人问：“你为什么要截取字符串的后三位？”他说：“我要找文件的扩展名”。实际上，文件的扩展名不一定是 3 个字符，而且有专门的函数干这个事儿，不需要自己写。这里，取文件的扩展名，这叫 X，取文件名的最后 3 个字符，这叫 Y。他想知道 X，但不知道该怎么说，于是就说成了 Y，导致别人都去解决一个不存在的问题。这叫 X/Y Problem。\n\n我可以告诉你，这个世界上到处都是 X/Y 问题。有些公司找我说，我们要做分布式架构，我们要做大中台，我们要做线下线上融合……这些问题都是 Y 问题。我都要反问，你为什么要做分布式架构？为了大规模营销，为了稳定性，还是为了加快开发速度？做大中台，你是为了什么？ 是为了打通各个业务线，为了快速开发，还是为了技术输出？等等。要解的真实问题才是 X 问题，手段都是 Y 问题。只有你真正了解了 X 问题，你才能真正明白整个事。\n\n当你了解了 X 问题后，你就要到源头，来质疑或是改良他的 Y 问题，甚至提出 Z 方案，而对方会陷入被动，被你牵着鼻子转。\n\n# 维度\n\n我们想一下，人与人不同都是细节上的不同，比如：身高、体重、手机号等，人与人的相同点都是在宏观上相同，比如：国籍，性别……这告诉我们，如果你要找不同就要到细节上去，如果你要找共同，就要到大局上去。\n\n所以，在和人争论时，如果要反驳，那一定是低维度反驳，越细节越好。而在说服对方时，则要在高维度说服对方，越宏观越好，比如从公司的大目标出发。高维度讲究的是求同存异。你跟别人相同的东西一定是高维度的，这就是大同，而你跟别人不同的一定是非常细节的东西。大同的东西，更容易让人产生共鸣，从而容易达成默契和共识。\n\n因此，**能够站在更高的维度来沟通是我们需要努力的目标**。我们经常会听到类似的话：“哎呀，大家都没有恶意。我们虽然争论成这样，但是大家都是为公司好，只不过我们的路径不对。”或者“我们的目标是一样的，但是我们的方式不一样。”能感觉到吧？气氛一下子就缓和了好多。\n\n站在更高的维度上讨论问题，可以让你有大局观，对方就会显得很小气，导致对方也会不好意思，于是就会出现“六尺巷”的故事中所描述的那种场景。\n\n# 共同\n\n这里讲的是共情，共享，共利，共识以及换位思考。如果你能站在对方的角度思考问题，那么你所想的问题以及所想沟通的内容，一定会跟只想自己有很大不同。同时，你会神奇地发现，换位思考能帮助你更为全面地理解并解决问题。\n\n寻找“共同”的过程，其实也可以理解成为化“敌”为“友”的过程。我们不妨想象一下，沟通双方剑拔弩张，随时一触即发的情况，和沟通双方有共同的目标一起思考和解决问题的状态，哪种更能获得更好的结果。而共同该怎样找，跟我们在维度中提及的很相似，就是从高维度，寻找共同之处。\n\n首先是共情，跟对方相互分享各自的情感，这是一种拉近距离最有效的手段，然后是相互共享自己的观点，在观点中寻求双方共同的利益点，然后不断地循环，一点一点地达成共识。\n\n# 三本书\n\n此外，我还想强调一点，**无论干什么，你一定要有一个非常犀利的观点，也就是金句**。如何得到这些金句呢？一定要多看书。你到那些公众号或者知乎里面看一些抖机灵的内容是没有用的。抖机灵的金句没有用。一定要是有思想深度的金句，才有力量。推荐你看三本书《[清醒思考的艺术](https://book.douban.com/subject/26871359/)》、《[简单逻辑学](https://book.douban.com/subject/24754537/)》和《[重来](https://book.douban.com/subject/5320866/)》。\n\n我是先被《重来》洗脑了，这本书帮我开拓了眼界，打破了我既有的思维模式，让我反思过去习以为常的每一件事。同时书中给出了实用、可操作的建议，让我头一次从心底感受到，原来世界还可以如此不同。\n\n然后，我看了《清醒思考的艺术》，这本书作者以显微镜般的观察发现人们常犯的 52 个思维错误，并一一列出。帮人们认识到错误的思维是如何发生，从而避免掉入思维陷阱中。看这本书的过程中，我能明显感觉到自己的思维方式在被重新构造。\n\n随后是《简单逻辑学》。逻辑学是很枯燥的，但这本书的作者以其简练而又充满趣味的笔触，将逻辑学活化为一种艺术，从它的基本原理，到论证，到非逻辑思维的根源，再到 28 种就发生在人们身边的非逻辑思维形式，带领我们进入这个精彩无比的逻辑世界，体会妙趣横生的思维交锋，跨过无处不在的逻辑陷阱，让人沉醉其中，欲罢不能。\n\n这三本书对我影响很大，也建议你好好读读，能改善你的思维，炼就你的火眼金睛。你会发现自己跟和别人不在一个频道上，你能看到事物更多的侧面，在阐述观点时，会比别人更加深刻、犀利和有见地。一些金句也会在你跟人互动交流时，随机地冒出来。你自己都能明显感觉到自己的气场要比其他人足。\n\n# 小结\n\n总结一下今天的内容。我们讲了沟通的四大关键技术：逻辑、信息、维度和共同。\n\n有逻辑的表达，更容易说服对方。信息全面准确，更有利于让沟通的双方清楚定位问题，从而更高效地解决问题。\n\n维度是个很有趣的事儿，有的时候要站在高维度去碾压对方；有的时候要站在低维度去碾压对方。如何把握这个度很重要。如果站在客户的角度，最好用高维度。但如果站在技术细节的角度，这是低维度。高维度容易拉拢对方，而在低维度更容易说服对方。只不过低维度容易爆发冲突，要恰当地控制好度。\n\n最后一点是共同，其实寻找共同的过程就是化“敌”为“友”的过程，帮助大家在共赢的大思路和环境下，共同思考问题的解，从而实现高效沟通。此外，我强调了金句的重要性，以及如何获得这些金句。答案是没有捷径可走，唯有多读书，多思考，才能慢慢获得。\n\n下篇文章，我们将进入《高效沟通》系列文章的实践部分，分享一下该如何与员工沟通。敬请期待。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/32902\" > </iframe>","categories":["左耳听风"]},{"title":"105丨高效沟通：好好说话的艺术","url":"/posts/774356879.html","content":"\n\n\n# 跟员工沟通\n\n在跟员工沟通部分，我将主要讨论令管理者头痛的五大难题：怎样进行一对一会议；员工绩效不好时，如何沟通；怎样“搞定”特立独行的员工；怎样挽留离职员工；如何劝退员工等。首先，我们来看看一对一会议。\n\n## 一对一会议\n\n一对一会议（one-one meeting）是一种非常重要的管理手段，它能拉近管理者与员工的关系。但你要记住，好的一对一会议是以员工为中心的，而不是以管理者为中心的。**一对一会议时，管理者需要做的是倾听，而非“喋喋不休”地教育**。\n\n我待过的几个外企里，一对一会议基本都是标配，频率是每半个月一次。会议重点涉及以下四个方面的内容。\n\n- **工作状态**，主要想了解员工的工作状态，因为人的状态是变化的，不是稳定的，或多或少会有这样或那样的一些问题。这个环节主要了解影响员工状态的细节，为员工进行疏导、激励和优化，并和员工一起对过去几周的工作做出得失总结，一起进步。\n- **个人发展**，员工的个人发展是员工和公司的头等大事，所以，你需要了解员工的兴趣、爱好、擅长做的事儿，以及缺点和不足，并结合公司的目标和实际项目需求，为员工创造更有挑战的工作，让员工更好地成长。\n- **公司组织**，让员工聊聊对公司有什么看法，觉得公司哪儿做得好，哪儿做得不好，有哪些可以改进的建议。如果公司非常大的话，可以请员工来聊聊自己所在的部门或者团队的一些情况。目的是了解员工是否认可公司的目标和方向，这其中可能会有一些误解，或者意见上的不统一，需要跟员工说明白。\n- **Leader 自己**。也就是，请员工聊聊对自己的看法。放平心态，不管是好的还是坏的，都用平常心看待。如果被员工指出哪里有不足，可以请员工给自己一些建议，或者请他来谈谈他认为怎样做会比较好。这个环节很重要，对管理者来说是个很好的反思和学习的过程。\n\n一对一会议的时间通常为半个小时到一个小时，时间不要太长。一对一会议中，我的核心沟通原则是将心比心。这其中的诀窍是让员工畅所欲言，不要有任何的忌讳，能够讲出最真实的想法，哪怕想法是很偏激很不中听的，只要是真实的都应该获得尊重。（作为管理者，你一定要明白，那些“直言不讳”的员工是不错的，因为他们的心思不用让你“猜”。“真言”虽然不中听，但相比那些中听的“谎言”来说，其实是会降低你的管理难度的。）\n\n另外，一对一的沟通都是直接跟下属聊，你的直接下属跟他的直接下属聊。此外，你还可以跳过层级直接跟下属团队中的骨干成员聊。骨干的意思是，特别被重视的人，是那些团队不愿意失去的人。跟骨干聊是很有必要的，这样能够体现出你对他的重视，对员工来说是一种认可的方式。\n\n## 绩效沟通\n\n绩效沟通对于管理者来说可能是最难的一个事了，尤其是跟那些绩效不好的人沟通一年的绩效结果，可能是管理者们最不愿意去做的事。\n\n我曾经的团队里发生过一件事儿，令我至今记忆犹新。有一个从别的团队转岗过来的女孩，工作一段时间之后，我和她原来团队的负责人来一起来 review 她的绩效。她原来的负责人上来就说，“你原来是做流程工具开发的，但是我们觉得你程序写得不好……”话没说完，这个小女孩就直接跳起来了，反问道：“我程序写得不好，你当时为什么不跟我说。你跟我说哪里做得不好，我马上改。可是你接受了，就说明我的绩效至少达标了……”不难想象，这场绩效沟通会议就是一个“翻车现场”！\n\n那时候，我刚做管理两个月，这事儿对于当时的我来说很是震撼。所以从那个时候开始，不管员工出什么问题，我都会立马给出反馈，明确告诉团队成员他工作的不足之处，以及改进方案。比如，你这段代码太松散了，这里的代码写得不够好。你最近好像状态不是很好，老出 Bug。这样的低级错误为什么会发生？哪里有问题？等等。是的，**沟通一定要放在平时，不要搞成像秋后算账一样！因为你是管理者，不是地主监工**。\n\n如果员工实在能力欠缺，难以达标，其实“帮助”过程中，他自己也是知道的。基本上，等不到年底，这样的员工也会自己离职走人，因为这样玩下去对他自己不利。\n\n**但要注意的是，反馈的过程中，不是我在指责员工，而是我在帮助员工。一定要有帮扶的态度，这样员工会更容易接受**。此外，说话的维度要高一点儿，要共情，不要激起员工的情绪，引发不必要的矛盾。在反馈和帮扶的过程中，你能够让员工感受到你的关注和重视，对员工来说是种很好的正向鼓励，有利于员工，乃至团队的进步和成长。\n\n## 特立独行的员工\n\n做过多年管理者的你，一定遇到过一些“特立独行”的员工，他们很自我，不服管，喜欢按照自己的思路做事儿。该如何对这类员工进行管理和沟通，想必会令你头痛不已。尤其是当你感觉到某些“特立独行”的员工天赋异禀的时候，你更希望能够将其优势充分发挥出来，为团队创造更大的价值。这里，我就来谈谈我的想法和经验。\n\n这里， 我们只讨论有很强能力的人（因为能力不强还特立独行的人最好劝退），对于这类员工，我有两个方法。\n\n- 第一个方法是给他找到匹配的人，要么是比他牛的人，要么是跟他旗鼓相当可以在一起共事儿的人，跟他一起工作。有能力的人，一般都受不了一群猪队友的，因为他们会觉得老是被问一些好无聊的问题，被问得很烦，而且有很多很简单的事，要讲半天，对方却还听不懂。是的，聪明的人都是这样的，很多聪明人都是特立独行的人。\n- 第二个方法是给他一些独立的工作，把他隔离出去。让他做一些相对独立和有挑战的事情。在微软等很多公司里面，都有一个工种叫 IC – Individual Contributor。把他们隔离出来是一个不错的选择。\n\n但是话说回来，有些人还是很难办的，以上两种方式可能对他都不起作用。我也遇到过这样的员工，能力很好，但是特别挑剔工作。任何事情都非常矫情。这个时候你要多找他聊一下，你需要直截了当，明确没有二义地说明他需要做的工作，以及岗位对他的要求。注意，一定要非常地明确！如果不行，那就只有分手了。\n\n这里有个原则你要记住：**当你在一个人身上花的精力和时间成本，大于你到外面找一个更好的人或者能力相当的人来替代他的时候，你就要坚决地把他替换掉**。\n\n## 挽留离职员工\n\n如果一个员工离职，而你又希望他留下来，怎么办？首先，**你要知道他离职的原因**。我觉得，绝大多数员工离职都是跟老板或者公司有关系的。\n\n但是你和他做沟通的时候，他肯定也不好意思说出真实原因。所以，你要做的是让他敞开心扉地去谈离职的事情。你可以看看，心理访谈类节目中的主持人是怎样做的。通过看这些节目，以及结合我自己的经验，我认为，想要让员工跟你袒露心扉，你一定要明确表达你对他的认同，甚至可以说一些公司的坏话。\n\n这样，你可以让他的心理界限逐渐消失，就会开始诉说自己的真实原因（谁没有点苦闷的心事呢）。这时你一定要认真倾听，就算是他在吐槽，也一定要让他吐干净。为什么呢？我觉得吐槽公司并不是什么坏事儿，员工吐槽公司，说明对公司还有感情，爱之深，责之切。\n\n借此，你可以收集一些意见，这些意见也许可以让公司变得更好，因为他的离职原因也有可能是其它人的离职原因，这对于留住还在职的员工是很有用的。其次，你可以知道他离开的真实原因，思考一下是否能采取什么举措，进行挽留。\n\n另外，**生意不行，友情在**。每个人的离开都是有各自不同的理由，实在挽留不成的时候，也要注意经营好这份情意。\n\n在我认为挽留不成的时候，我通常会站在他的角度作为他的朋友为他着想，甚至帮他介绍工作，或是在他离开时再为他争取一些利益或是别的什么。这样做会让员工觉得这样的知心老板不好找啊，就算最终还是离开，但是未来也一定会有联系，也许未来还能在一起共事儿。这里的逻辑是，**既然不能在此时挽留下来，那就放眼未来，人生还很长，能在一起工作的机会还有很多**。\n\n其实挽留是一件挺为难人的事情，因为对方做完了这个决定以后，再回头也需要很大的勇气。所以，你要提前判断员工离职的前兆。一个人要离职是有前兆的，你平时肯定是能感觉到的。比如，他一定会变得不积极，甚至会有一些抱怨。这时候其实是你挽留他的重要时机，因为有抱怨说明还喜欢这个公司。\n\n而他最终跟你摊牌的时候，或是对公司漠不关心的时候，留下来的机会是很小的。员工离职之前一定会有很多前兆的，我建议你，细心体会一下，在最佳挽留时机进行挽留，不流失自己的“爱将”。\n\n最后提一句，一般来说，任何员工，任何事，干了两年就是一个大限，离职率极高。\n\n## 劝退员工\n\n在员工没有达到最低绩效的时候，该怎样劝退员工，也是令很多管理者头痛的问题。还是那句话，劝退一定不要秋后算账，要把沟通放在平时。\n\n劝退一个人，你一定要给出一段时间的试用期，也就是我们说的缓冲期。一方面，表达出“我是愿意帮助你的，我也给你机会”的意思。同时，你也要给对方制定一个目标，一个月之内，他要解决和改进他的一些工作问题。因为人都是有状态的，你需要给他一段时间。另一方面，也要让员工有所准备，可以在外面寻找一些相关的机会，而不至于失业。\n\n注意，这里我想表达的是，**任何人都应该有可以纠正错误的机会，公司应该给员工这样的机会，员工也应该给公司同样的机会**。\n\n当然，在分手那天到来的时候，你可以跟员工一起看一下，他的工作是什么，他的职责是什么，但是他的成绩又是什么？你要找的是无可辩驳的证据。然后跟他说明，因为这些原因，我希望我们能够和平地分手。\n\n最好的方式是，给员工一个面子，让他把你开掉，比如：找外面的猎头，把员工挖走。亚马逊经常这么做。亚马逊还有主动离职奖金，第二年离职给 4000 美金，第三年给 6000 美金……国内公司则简单粗暴一些。\n\n在劝退的时候，你可以请他吃一顿饭，或者送他一个纪念品。这个纪念品，可以是他在你这儿工作过程中，做得最好的一件事儿。比如，我会把这件事儿印成一件 T 恤，送给他。事儿是事儿，人是人。把工作和私交分开，表明这并不代表我个人不愿意接受你，只是我有我的职责，我是公司的一名管理者，职位在身，需要负责。但是，像情人分手一样，分开后，我们还是好朋友。\n\n# 跟客户沟通\n\n在跟客户沟通这部分，我主要分享三方面的内容：吸引客户的兴趣、帮客户发现问题和管理客户的期望。\n\n## 吸引客户的兴趣\n\n在前面的《沟通方式及技巧》一文中，我分享了一个跟客户沟通的小技巧——初次和客户见面时要懂得吸引对方的兴趣。想做到这点，其实并不难，但它的前提条件是在见客户之前必须要做足功课，确保你自己了解客户的关注点，以及当下的痛点。然后在交谈的过程中，可以有目的性地在这些方面展开话题，突出一下自己在相关领域的优势和资源。一般情况下，这么做都是能很快引起客户兴趣的。\n\n举个例子里，我当天见的是某个银行的副行长，周围的人都穿着衬衫和西裤，很正式，而我的着装却有些随意。估计要不是别人介绍的，他一眼都不想看我，几句话就能把我打发了。开始的几个问题，也着实让我有些狼狈。问我，你们公司规模多大？有多少人？有什么案例？……我如实回答后，只看见他满脸不屑的样子……但我后来却用了不到 20 分钟的时间就成功吸引了他的兴趣。\n\n见他之前我做足了功课，了解金融业下半年整体趋势都很糟糕，银行贷款都办不了，国家货币在紧缩，还有 P2P 这些乱七八糟的事儿。于是，我就跟他说了一下形势和相关的解决方案，然后就明显地感觉到他开始感兴趣了，因为我谈的都是一般人不知道的（原谅我在这里不写这些了，因为这是我现在创业的商业机密）。于是我再加油添醋，说我这边可以接触的资源日流水好几亿……还没等我说完，他就开始对我这个人以及我的谈话内容充满了兴趣。\n\n也就是说，做足功课，了解客户的痛点或是 KPI 是与客户沟通的第一步，也是最关键的一步，不仅可以引起对方的兴趣，还能决定见面时沟通的内容。兵法有云：知己知彼方能百战不殆，说的就是这个道理。\n\n## 帮客户发现问题\n\n有了“兴趣”这块开门砖以后，接下来谈什么、怎样谈就要容易多了。这个时候，我们可能就要进入到问题的实质，深入交流了。这里有以下几个关键点需要你把握。\n\n- **结合客户的痛点，了解客户做过的尝试**。在这里我们一定要明白，客户的痛点其实就是我们的发力点，也就是我们的价值点。所以，我们一定要弄清楚客户的痛点是什么，以及针对这个痛点，客户曾经做过哪些尝试。\n\n  这样不仅能够让我们更加深入和全面地了解客户痛点，而且有助于我们在思考解决方案的时候绕开很多用户曾经踩过的雷。或者，我们也可以从这些已经做过的尝试中获得一些启发和帮助，因为很多时候尝试失败，并不一定意味着方法是错的，很有可能是技巧、能力或者资源配置出了问题。\n\n- **深入细节，了解细节才会有更准确的信息**。前面文章中提到了倾听的重要性，在与客户进行沟通的时候，倾听也尤为重要。因为你只有深入了解细节，才能掌握更准确的信息，从而给出更能帮助客户解决问题的方案。但是在与客户沟通的过程中，你有时会发现客户自己描述不清楚细节，或者说不清楚自己到底想要什么。\n\n  这时，你可以考虑让客户举个例子，说给你听。从这个例子中，你可以获得更多的信息，因为它将很多模糊不清的东西具象、形象化了。你可以把你的理解说给客户听，跟他确认你的理解是否准确，然后逐渐磨合，最终达成共识。这个更为准确的信息是你后面解决问题的前提和基础。\n\n- **小心 X/Y 问题，找到 X 问题**。在《沟通技术》一文中，我提到过 X/Y 问题。很多时候客户跟你提的都是 Y 问题，比如，我们要做分布式架构，我们要做大中台，我们要做线下线上融合，等等。每次面对这些问题，我都要反问，你为什么要做分布式架构？为了大规模营销，为了稳定性，还是为了加快开发速度？做大中台，你是为了什么？ 是为了打通各个业务线，为了快速开发，还是为了技术输出？等等。\n\n  要解的真实问题才是 X 问题，手段都是 Y 问题。只有你真正了解了 X 问题，才能真正明白问题背后的出发点。而当你了解了 X 问题后，你就要到源头，来质疑或是改良他的 Y 问题，甚至提出 Z 方案。这时，你会发现你的客户开始跟着你的思路走了。这里有个要点是，**一定要分析客户问题背后的本质原因，从根本上帮助客户解决问题**。\n\n很多时候，客户的问题只是表面的问题，你要深入下去，才能找到最本质最根本的 root-cause，这和我们定位 Bug 的道理是一样的。只有找到根本原因，你才能对症下药，标本兼治。所以，我现在也有了所谓的“一针见血”的沟通能力。\n\n## 管理客户的期望\n\n在帮助客户发现问题之后，我们就要来解决问题了。这个时候，帮助客户设立合理的目标就显得尤其重要了。一般来说，很多公司的销售都会把客户的期望搞得很高很高（因为要成单），经常性地用最少的时间，最低的价格，做最多的事，基本上来说这相当于把开发团队卖掉了。不要以为只有销售会这样，我们的很多管理者也是一样的，为了保住自己的位置，拼命地透支自己的团队，等成绩拿到以后，跳槽到别的公司。\n\n其实，我们是可能做到既让客户满意，又不会作茧自缚的，有以下几个手段可以使用。\n\n1. 要至少给出三套方案来让客户选择。一个是低成本的玩法，一个是高成本的玩法，一个是性价比比较高的玩法，这其中的取舍是我们可以去引导客户的。\n2. 另外，我们需要找一些相关的案例和参照物来对比我们给的上述方案，这样可以让客户有一个更为清醒的判断和认识。以此来教育客户不同的方案代表着不同的期望和不同的结果。\n\n然后跟客户进行讨论，该怎样优化和完善方案中的目标，最终达成双方都认可和接受的目标。这里一定要注意，只有经过了取舍，明确了哪些做哪些不做，我们达成共识的目标才会是明确的，有针对性的，而且是具有很强的可操作性的。\n\n当然，有的时候，客户可能会执意要求实现一些不切实际的方案。比如，有时客户可能会将项目时间压得太紧，这样你无法保证按质完成所有任务。除了需求分析、设计和开发外，一个完整的软件工程也要保证质量，至少必须包含测试（至少要有手动的集成测试，考虑可维护性的话还要包括自动的单元测试）和 bug 修复的部分，而这两个部分加起来的时间通常比开发本身的时间还要多。\n\n如果项目时间压得太紧，只有两条路可以选。第一，保证质量，但减少一些功能或其他要求，如去掉一些对还未调研清楚的第三方库的依赖；第二，保证主要功能完成，但不完全保证质量。\n\n这时，我们可以和客户一起分析，哪种选择更为合理、可行，将选择权交给客户。这里记住，**永远不要跟客户说不，要有条件地说是，告诉客户不同的期望要有不同的付出和不同的成本。不要帮客户做决定，而是给客户提供尽可能多的选项，让客户来做决定**。\n\n有的时候，客户对交付时间和完成的功能会有过高的预期。这时我们要和客户商谈，降低这个预期，但同时尽量给予一些其他的补偿。比如，这个事臣妾做不到啊，要不你多给我一些时间，我少收你点费用？或是，你这个太复杂了，太重了，要做我先做个简单版的，这样可以以低成本来看看客户的反应，然后根据客户的反应再看下一步怎么做，等等。我们不要拒绝，要疏导。\n\n如果客户不愿意放弃他的高目标，那么我们就争取一些补偿或是交换。一般来说，只要是合理的，人总是通情达理的，一般来说都会满足你的。比如：我们可以跟业务部门讨论，我做完这一版后，你要给我 1 个月的时间，重构一下我的代码，请给我们这些时间。\n\n**讨价还价是这个世界能运转的原因之一，要学会使用**。\n\n总结下来，在与客户沟通预期时，我通常会坚持以下几个原则。\n\n- **一定要给客户选择权，永远不要说不，要有条件地说是**。\n- **降低期望的同时给予其他的补偿**。\n- **提高期望的同时附加更多的条件**。\n- **对于比较大的期望要分步骤达到客户的期望**。\n- **不要帮客户做决定，而是给客户提供尽可能多的选项，然后引导客户做决定**。\n\n# 跟老板沟通\n\n## 了解你的老板\n\n在跟客户沟通中，我强调了了解客户及其痛点的重要性，这是第一步，也是最为关键的一步。同样，想跟老板进行良好的沟通，了解你的老板也很重要。首先，你需要了解老板的做事风格。比如，有的老板是事无巨细的，有的老板是大刀阔斧的，有的老板是威风管理，而有的老板则是老好人，等等。\n\n其次，你还要了解老板的目标和 KPI 是什么。最后，要知道老板的老板是谁，他的风格是什么，他的目标和 KPI 是什么，因为你老板的目标和 KPI 是你老板的老板给的。所以你了解老板的老板才更能了解你的老板，从而做更正确的事儿。\n\n想了解你的老板，最简单的方法就是察其言观其行，因此 “倾听”就显得尤其重要了。老板总是喜欢教育下属，总是喜欢发表高谈阔论的，所以，倾听老板是件不难的事，但是，这也是一件很难的事！因为老板职位在身，所以，有很多事老板是不会对下属说的，尤其是很多负面或是有压力的事。他不能表现得很懦弱，否则就没人听他的了。老板从来都是孤独和孤单的，牙被打掉了往肚子里咽。**所以，倾听老板会有一些出乎你的意料的发现，你要能了解老板背后的苦衷，那些才是最重要的**。\n\n## 赢得老板的信任\n\n你要赢得老板的信任，就要知道老板也是要有成绩的，他们只会关心那些能为他带来成绩的员工。所以，你要成为工作当中的骨干人员，能把自己的事搞定，能把别人搞不定的事搞定。这样老板才会依赖你，你才可能有更好的“议价能力”。不然，就算你对老板的马屁拍好了，你也不会真正和老板有平等的话语权，你也只不过是老板的跟班罢了。\n\n当你有了能力后，老板才会给你机会，你有了能力又有机会，你就会有更多的机会。这些机会能让你有更多的经验来提升自己的能力，于是形成一个正循环，你的老板会越来越信任你，你才能获得真正和老板平等的权利。\n\n## 管理老板的期望\n\n就算你很牛，老板很信任你，你还是要学习管理老板的期望。在每次和老板交流的时候，你都要确认老板的期望是什么，如果跟你的想法有所偏差，一定要及时反馈和讨论。因为每个人的特长和优势不同，老板希望你做的，未必是你擅长或者乐于做的。有什么想法一定要诚实地说出来，以免被安排了不喜欢的工作，自己越干越不开心，越干越没热情。这就很麻烦了。\n\n这和管理客户的期很相似，不要帮老板做决定，给老板几种方案，并引导他做决定。不要说不，要有条件地说是，在拒绝的同时给予补偿。如果反抗不了了，就争取其它的利益……\n\n你要明白，老板如果没人了，他将一事无成，所以，他一般都会是通情达理的。只要你注意表达的方式和方法，摆事实讲道理，态度上没问题；只要你从事情的不同角度展开，权衡一下利弊，并使用共情和高维这样的沟通方式，让老板能站在你的立场将这些问题想清楚，你一定能够争取得到你想要的。\n\n## 非暴力“怼”老板\n\n沉默是金，是我今天给出的最后一个方法。它应该在什么时候用呢？我来介绍一下。在工作中跟老板有意见分歧是在所难免的。但有一些时候，你明明觉得自己给老板提供了一个你认为从各个维度来讲都很不错的方案，但老板还是说，这不行，两个月时间太长，最多给你一个半月时间。这个时候最好的方法不是怒气冲冠，也不是直接 Say No，而是保持沉默不说话，闷着。\n\n相信我，只要你沉默下来，你的老板就会沉不住气的，气氛的尴尬不是他想要的，他只是希望你能听他的。所以，一般来说，老板马上就会打破沉默，对你开始各种“忽悠”，如果你依然不说话，你的老板就会开始妥协，换各种思路来说服你，然后你就可以顺着老板的话，跟老板谈条件了。这是一个非常有用的谈判技巧。\n\n比如，老板感到不安后，他一定会安慰你，也会给你开条件：这样吧，你努力把它弄完，年底给你涨工资。你不要立马答应下来，要表现出极不情愿，告诉老板这违背了客观发展规律。老板会再次利诱你。\n\n这时，你再表态，带着弟兄们拼一拼，争取一半月内搞定，但就这一次，下不为例。你是可以原谅老板“混蛋”一次的，给他一次机会。但你要让他感觉到欠你和你的团队人情，欠人情是最恐怖的事儿了。这样，他下次再做类似事情的时候，自己都会不好意思。\n\n# 小结\n\n好了，总结一下今天的内容。今天的内容好丰富，包含跟员工沟通、跟客户沟通以及跟老板沟通三大部分，将前几篇文章中介绍的沟通方法和技巧用了个遍。相信你一定有挺多的体会和感悟。\n\n其实不管对方是员工、客户，还是老板，甚至是自己的家人朋友，与人沟通的关键，都是要好好说话，静心聆听，能够尊重对方的想法和情绪，更能站在对方的角度来思考。只要你心中时刻想着共情、共赢，你的沟通一定会顺畅和高效很多。《高效沟通》系列今天更新结束，希望这些内容能给你一些帮助和启发。\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/41008\" > </iframe>","categories":["左耳听风"]},{"title":"106 |  结束语丨业精于勤，行成于思","url":"/posts/1180627074.html","content":"\n\n\n不知不觉，一年就这样过去了。这个专栏也到了结束的时候。在结束的时候，我需要跟大家正式说声再见，同时也谢谢各位对本专栏的厚爱，并希望大家从我的专栏里有所收获。我也借最后这个结束语回顾一下整个过程。\n\n老实说，在本专栏刚开始的时候，我对于这个专栏要写点什么是完全没有什么清晰的想法。一方面，我从来没有干过这样的事，这么高频度发表文章的玩法，在一开始来说我其实是相当懵逼的。另一方面，我内心对于收费这个事是很有压力的，不知道要写什么样的内容才值得收费。\n\n平时写 CoolShell，完全是想写什么写什么，别人爱不爱看都无所谓，而对于收费的内容反而有点不知所措了。所以，在不知道要写什么专题的情况下，只能起个“左耳听风”这么烂的名字，哈哈。这也是为什么在一开始专栏的文章比较散乱，也没什么主线的原因。\n\n同时，极客时间的编辑也不希望我写很技术的文章，因为他们对标的是“得到”。所以，我早早就写好的《编程范式游记》压了两个多月，而在一开始发表一些非技术类的和个人成长有关的文章（因为大家都觉得这样的文章不但人气足，而且也是我的专长，呵呵）。直到库存的文章用得差不多的时候，才开始发《编程范式游记》。那时我才觉得我应该一个专题一个专题地写，这样才能够扛得住一整年的更新。\n\n于是才有了后面的《区块链》系列，《分布式系统的本质》系列，和《分布式架构设计模式》系列，再之后是大规模的《程序员练级攻略》，以及个人发展的三个核心主题《面试》、《学习》、《沟通》，加上之前的《时间管理》，《技术领导力》，《技术变现》，以及流程相关的《故障处理》、《Git 协同工作流》、《安全问题》，还有《程序错误处理》、《Go，Docker 新技术选择》等等零散的文章，最终构成了整个专栏。\n\n这其中的选题基本上都是我给其它公司做的咨询的内容，或是我到一些公司里分享中的一些内容，其中的很多内容都是对公司收费的，有的是我做企业培训的内容，有的是我为企业解决实际问题后的总结和归纳，有的则是我为企业做的整体架构的设计方案。\n\n除此之外，还有我个人的很多的我一些比较私房的，只会跟我关系比较近，或是我觉得值得帮的人，才会分享的经验。这些东西我基本上都写在这个专栏里了。而且你可以发现，我的专栏的大多数文章都是在超标中，超过了原有的 5 分钟的音频时长，很多文章都是 10 分钟以上的，甚至 15 分钟左右的文章也有好多，最新的一篇沟通的文章长达 27 分钟。\n\n如果按“得到”那样一篇 2000 字音频 5 分钟，我的确也可以做到每周 5 篇的更新速度（但是每篇文章就不完整了）。对此，我觉得我还是对得起这个收费专栏的，因为这些内容我问企业的收费都比这个专栏高得多得多。这也是这个专栏在运作到一半的时候开始涨价的缘故，还希望大家能理解。\n\n当然，在写这个专栏的过程也是令我非常痛苦的，我基本上搭上了我的周末和节假日，因为我平时还有我的主业。我的主业在创业，各种忙，所以只能使用晚上或是休息时间。尤其是在写《程序员练级攻略》的时候，我足足花了 4-5 个月的时间，基本上把整个互联网人肉地翻了一遍。我在这几个月的时间里阅读了至少上千篇文章，最后我对整个互联网我能找得到的知识进行梳理和筛选，去除了至少 2/3 到 3/4 的内容，产生了现在你看到的专栏文章，然而也是很庞大的。\n\n然而，这个过程，对我也是很有收获的。一方面，我挑战了自己，我发现居然可以这么高产，有这么多的东西可以写下来。有很多系列，完全是可以出书的，这个专栏我觉得要出上 4-5 本书是没有问题的（当然，我不会出的）。\n\n另一方面，也是最重要的一方面，我的创业过程中见的人接收到的信息是以前打工时代的一百倍以上，我每天都在不停地学习，思考和总结。所以，正好用这个机会把我的这些思考和想法给总结下来了，这对于我个人来说，比这个专栏的意义更大。从这两方面，我觉得我的成长和收获远远超过了这个收费专栏的收入，因为这种成长的感觉是多少钱都换不来的。\n\n好了，讲完这个专栏和我自己在这个专栏中的收获，我该谈谈对读者的期望和寄语了。我在我的专栏中不断地说过，学习是没有捷径的，是逆人性的，你需要长期地付出时间和精力。如果一个人订一个收费专栏就可以成为高手，那么这种“高手”早就被“北大青鸟”这样的培训公司“量产”了。\n\n不过，好在现在的人都被微博、微信、知乎、今日头条、抖音等这些 App 消费着（注意：我说的不是人在消费 App，而是人被 App 消费），然后英文还不行，科学上网也不行。所以，你真的不需要努力，只需要正常，你就可以超过绝大多数人。\n\n你真的千万不要以为你订几个专栏，买几本书，听高手讲几次课，你就可以变成高手了。这就好像你以为你买了一个高级的机械键盘，27 吋的 4K 屏、高性能的电脑，高级的人体工程学的桌椅，你就可以写出好的代码来一样。我们要成为一个好的羽毛球高手，不是买几副好的运动装备，到正规的体育场去打球，而是要付出常人不能付出的汗水甚至伤痛。任何行业都是这样的。\n\n这里，我还要把我《高效学习》中那个学习金字塔再帖出来。\n\n![image-20230926181652240](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230926181652240.png)\n\n再次强调一下，这个世界上的学习只有两种，一种是被动学习，一种是主动学习。听课，看书，看视频，看别人的演讲，这些统统都是被动学习，知识的留存度最多只有 30%，不信你问问自己，今天我的专栏中，你记住了多少？而与别人讨论，实践和传授给别人，是主动学习，其可以让你掌握知识的 50% 到 90% 以上。\n\n所以，我希望我的专栏没有给你带来那种速成的幻觉，而是让你有了可以付出汗水的理由和信心。我没有把我获取知识的手段和我的知识图给隐藏起来，然后，用我理解的东西再贩卖给大家。这样，我可以把我的《程序员练级攻略》一共拆成 20-30 个小专栏，然后一点一点地来收割大家，这样，我可以把大家困在知识的最底层。\n\n然而，我并没有这样做。我觉得大家应该要去自己读最源头的东西，源头的文章都有很多的链接，你也会有第一手的感受，这样你可以顺着找到更好的知识源，并组织出适合你自己的学习路径和地图。订阅我的专栏，如果你不能够按照我专栏里的那些东西去践行的话，那么也毫无意义。\n\n这也是为什么我在我的读者群中推荐出 ARTS 的任务，每个人每周一个 Algorithm，Review 一篇英文文章，总结一个工作中的技术 Tip，以及 Share 一个传递价值观的东西！我希望这个事可以给大家得到相应的算法、代码、技术和影响力的训练。如果你不去践行，那么我专栏上的这些东西你也就只是看看罢了。\n\n在实施的过程中，我们建立了一个近 500 人的读者微信群，进这个群的人必需要承诺做 ARTS。然而事实上呢，并没有，敢进这个微信群的人已经很少了，而进来的，过了三个月后，还在坚持做的，只有个位数的人了。这个就是现实。\n\n这个世界不存在知识不够的情况，真的还没有到知识被少数精英的攥在手里面不给大家的情况，这个世界上的知识就像阳光和空气一样，根本不需要你付费，你就可以获得的。问题是，大多数人都失去了获取知识的能力，你就算把知识放在他们面前，他们也不会去学习，他们需要你喂，甚至需要你帮他们嚼碎了，帮他们消化过了，他们才能吃得到，消化得了。这才是最大的问题。不好意思，我又说实话了，难听但是对你有用。\n\n我的专栏更多的是我的经验和心得的分享，不是捷径和知识的搬运。我已经花了 20 年的投入和付出，而我的成长中走了很多的弯路和磨难，我希望我的这些经验可以让你只需要付出我一半的时间就可以远远地超过我。\n\n另外，有很多知识我把其称作为“硬核知识”，这类的知识就像硬核桃一样，相当难啃。就像那些数学公式、计算机底层原理、复杂的网络协议和操作系统的调度等等，这些知识，你除了死磕之外，没有其它的办法。\n\n不要说，某某技术因为太复杂了所以是“反人类的”，那些“硬核技术”不是反人类的，是“反低能人类”的。所以，别把自己归到那个类别中。要学会不断地挑战自己，挑战自己就是不让自己舒舒服服地像个僵尸一样地活着，而是改变自己让自己像凤凰一样在浴火中涅槃重生！\n\n青山不改，绿水长流，祝各位成长快乐！\n\n再见！\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/41118\" > </iframe>","categories":["左耳听风"]},{"title":"107 | 加餐丨谈谈我的“三观”","url":"/posts/2844770991.html","content":"\n\n\n也许是人到了四十多了，才敢写这么大的命题。不过，我还是想把我的想法记录下来，算是对我思考的一个“快照”（snapshot），给未来的我看看。我想这篇文章要么被未来的我打脸，要么打未来我的脸。但不管怎么样，我觉得对自己来说都很有意义。\n\n我在标题中提到的“三观”指的是世界观、人生观和价值观：\n\n- **世界观代表你是怎么看这个世界的，**是左还是右，是激进还是保守，是理想还是现实，是乐观还是悲观……\n- **人生观代表你想成为什么样的人，**是成为有钱人，还是成为人生的体验者，是成为老师，还是成为行业专家，是成为有思想的人，还是成为有创造力的人……\n- **价值观则代表你觉得什么对你来说更重要，**是名是利，是过程还是结果，是付出还是索取，是国家还是自己，是家庭还是职业……\n\n人的三观其实是会变的，回顾一下我的过去，我感觉我的三观至少在这几个阶段有比较明显的变化：学生时代、刚走上社会的年轻时代、三十岁后、还有现在。估计其他人也都差不多吧。\n\n- 学生时代的三观更多是学校给的，用各种标准答案给的。\n- 刚走上社会后发现完全不是这么一回事，但学生时代的三观已经在思想中根深蒂固，以至于三观开始分裂，内心开始挣扎。\n- 三十岁后，不如意的事越来越多，对社会越来越了解，有些人屈从现实，有些人不服输继续奋斗，有些人展露才能开始影响社会。此时我们分裂的三观开始收敛，而我属于还在继续奋斗的人。\n- 四十岁时，经历过的事太多，发现留给自己的时间不多了，世界太复杂，还有好多事没做，发现自己变得与世无争，也变得更加自我了。\n\n## 面对世界\n\n年轻的时候，我对世界上的一些国家有很深的偏见，也对各个国家之间的不公平现象感到非常愤怒。但后来，因为有各种机会出国长时间生活和工作，到过加拿大、英国、美国、日本……随着自己经历的丰富与眼界的开阔，自己的三观也发生了很多变化。发现有些事并不是自己一开始所认识的那样。**我深深感觉到，要有一个好的世界观，你需要亲身去经历和体会这个世界，而不是光听别人怎么说。**\n\n所以，到现在，我也不是很理解为什么国与国之间硬要比个你高我低，硬要分个高下，争个输赢。世界都已经发展到全球化的阶段了，很多产品早就是你中有我，我中有你的情况了。举个例子，一部手机中的元件，可能来自全世界数十个国家，我们已经说不清楚一部手机究竟是哪个国家生产的了。既然整个世界都在以一种合作共赢的姿态运作，我们就认准自己的位置，拥抱世界，持续向先进国家学习，互惠互利，不好吗？\n\n**我对国与国之间关系的态度是，有礼有节，不卑不亢，对待外国人，有礼貌但也要有节气，既不卑躬屈膝，也不趾高气昂。**整体而言，我并不觉得我们比国外有多差，也不觉得我们比国外有多好。我们还在成长，还需要帮助与协作，俗话说“四海之内皆兄弟”，无论在哪个国家，在老百姓的世界里，哪有那么多矛盾。**有机会多出去走走，多结交几个其它民族的朋友，你会觉得，在友善和包容的环境下，你的心情和生活可以更好。**\n\n你可能会说，不是我们不想这样，是别的国家不容许我们发展。**老实说，大的层面我也感受不到，但就我所在的互联网计算机行业而言，我觉得世界的开放性越来越好，开源项目空前的繁荣，互联网文化也空前的开放。在计算机和互联网行业，我们享受了太多开源和开放的红利，别人不开放，我们可能在很多领域还落后数十年。**\n\n随着自己经历越来越多，也发现这个世界越来越复杂，自己越来越渺小，这个世界有它自己的运作规律和方法，还有很多事情超出了我能理解的范围，更超出了我能控制的范围。\n\n我现在更多关心的是和我生活相关的东西，比如：上网、教育、医疗、食品、治安、税务、旅游、收入、物价、个人权益、个人隐私……我们可以看到，过去的几十年，我们国家已经有了长足的进步，这点也让我让感到非常开心和自豪。\n\n因此，我还要继续努力，不断提高自己。只有这样，当我面对哪些我们无法改变、无法影响的事情都时候，才能有更多选择的可能性。\n\n## 面对社会\n\n在网上与别人争论观点或事情，我觉得越来越无聊，以前被怼了，一定要怼回去，可现在不会了，视而不见。不是怕了，是因为在我看来，网络上的争论大多数都没有章法且逻辑混乱。\n\n1. 很多讨论不是针对事，而是直接骂人，随意给人扣帽子。\n2. 非黑即白，你说这个不是黑的，他们就会把你划到白的那边。\n3. 漂移观点，复杂化问题，东拉西扯，牵强附会，还扯出其它不相关的事来混淆。\n4. 杠精很多，不关心你的整体观点，抓住一个小辫子就大作文章。\n\n很明显，**与其花时间教育这些人，不如花时间提升自己，让自己变得更优秀，这样就有更高的可能性去接触更聪明、更成功、更高层次的人。**因为，一方面，你改变不了他们，另一方面，改变他们对你自己也没什么意义，改变自己，提升自己，让自己成长才有意义。时间是宝贵的，而那些人根本不值得你浪费时间，你应该花时间去结交更聪明、更有素质的人，做更有价值的事。 美国总统富兰克林·罗斯福的妻子埃莉诺·罗斯福（Eleanor Roosevelt）说过：\n\n> Great minds discuss ideas（伟人谈论想法）\n> Average minds discuss events（普通人谈论事件）\n> Small minds discuss people（庸人谈论他人）\n\n把时间多放在一些想法上，对自己、对社会都是有意义的，而把时间用来八卦别人，说长道短，**你既不可能改善自己的生活，也不会让你有所成长，更不会提升你的影响力。记住，你的影响力不是你对别人说长道短的能力，而是体现在有多少人信赖你并希望得到你的帮助。**因此，多交一些有想法的朋友，多把自己的想法付诸实践，哪怕没有成功，你的人生也会比别人过得有意义。\n\n如果你看过我以前的博客，你会发现一些吐槽性质的文章，但后面就再也没有了，我也不再针对具体的某个人做出评价。因为人太复杂了，经历越多，你就会发现你很难评价人，与其花时间在评论人和事上，不如花时间做一些力所能及的事来改善自己或身边的环境。所以，**我建议大家少一些对人的指责和批评，多通过一件事来引发你的思考，想一想有什么可以改善的地方，有什么方法可以做得更好，有哪些是自己可以添砖加瓦的？你会发现，只要你坚持这么做，你个人的提升以及对社会的价值会越来越大，你的影响力也会越来越大。**\n\n## 面对人生\n\n现在的我，既不是左派也不是右派，我更多时候是一个自由派，哪边都不站，只站我自己。\n\n《教父》里有这样的人生观：**第一步要努力实现自我价值，第二步要全力照顾好家人，第三步要尽可能帮助善良的人，第四步为族群发声，第五步为国家争荣誉。事实上作为男人，前两步成功，人生已算得上圆满，做到第三步堪称伟大，而随意颠倒次序的那些人，一般不值得信任。**这也是古人的“修身齐家治国平天下”！所以，在你我准备开始“平天下”的时候，也得先想想，自己的生活有没有过好，家人照顾好了么，身边有哪些事是自己力所能及可以去改善的。\n\n穷则独善其身，达则兼济天下。提升自己，照顾好自己的家人，尽己所能帮助身边的人，这已经很不错了！\n\n什么样的人干什么样的事，什么样的阶段做什么样的选择。**有人说，选择比努力更重要，我深以为然，而且，我觉得选择和决定，比努力更难。**努力是认准了一件事后不停地发力，而决定要认准哪件事作为自己坚持和努力的方向，则是令人彷徨和焦虑的（半途而废的人也很多）。面对人生，你每天都在做一个又一个的决定，在做一个又一个的选择，有的决定大，有的决定小，你的人生轨迹就是沿着这一个一个的决定和选择走出来的。\n\n我在 24 岁放弃房子，离开银行到小公司上班的时候，就知道人生的选择是一个翘翘板，你选择这一头就不能坐上另一头，**选择是有代价的，而不选择的代价更大；选择是要冒险的，你不敢冒险时风险可能更大；选择是需要放弃的，鱼和熊掌不可兼得。想想等你老了回头看时，好多事情在年轻的时候不敢做，可你再也没有机会了，你就知道不敢选择、不敢冒险的代价有多大了。**选择就是一种权衡（ trade off），这世上根本不会有什么完美，只要你想做事，有雄心壮志，你的人生就是一个坑接着一个坑，你所能做的就是找到你喜欢的方向跳坑。\n\n因此，你要想清楚自己要什么，不要什么，而且还不能要得太多，这样你才好做选择。否则，影响决定的因子太多，决定就不好做，也做不好。\n\n正如本文开头说的那样，你是激进派还是保守派，你是喜欢领导还是喜欢跟从，你是注重长期还是注重短期，你是注重过程还是注重结果……你对这些东西的坚持和守护，成为了你的“三观”，而你的三观影响着你的选择，你的选择影响着你的人生。\n\n## 价值取向\n\n下面是一些大家经常在说，可能也是大多数人关心的问题，就这些问题，我也谈谈我的价值取向。\n\n**1. 挣钱。\\**挣钱是一件大家都想做的事，但你得解决一个很核心的问题，那就是为什么别人愿意给你钱？对于挣钱这件事的看法，我从大学毕业到现在都没怎么变过，那就是我更多关注怎么提高自己的能力，让自己值那个价钱，让别人愿意付钱。另外，我发现\\**越是有能力的人，就越不计较一些短期得失，越计较短期得失的人往往都是很平庸的人。**\n\n有能力的人不会关心自己的年终奖得拿多少，会不会晋升，他们更关心自己的实力有没有超过更多人，更关注自己长远的成长，而不是一时的利益。聪明的人从不关心眼前的得失，不关心表面上的东西，他们更关心的是长期利益，关心长期利益的人一定不是投机者，而是投资者，**投资者会把时间、精力、金钱投资在能让自己成长与提升的地方，能让自己施展本领与抱负的地方，他们培养自己的领导力和影响力。**而投机者则是在职场溜须拍马、讨好领导，在学习上追求速成，在投资上使用跟随策略，在创业上甚至会不择手段。当风险来临时，投机者是几乎没有任何抗风险能力的，他们所谓的能力只不过是因为形势好。\n\n**2. 技术。**对于计算机技术来说，要学的东西实在是太多，我并不害怕要学的东西很多，因为学习能力是一个好的工程师必需具备的能力，所以我不惧怕困难和挑战。我觉得争论语言和技术谁好谁坏是一种幼稚的表现， 没有完美的技术，工程（Engineering ）玩的是权衡（ trade off）。所以，我对没有完美的技术并不担心，我担心的是，当我们进入一家公司后，这家公司会有一些技术上的沉淀，也就是针对公司自己的专用技术，比如一些中间件，一些编程框架，lib 库什么的。\n\n老实说，我比较害怕公司的专用技术，因为一旦失业，我建立在这些专用技术上的技能也会随之瓦解，有时候，我甚至害怕把我的技术建立在某一个平台上，小众的不用说了，大众的我也比较担扰，比如 Windows 或 Unix/Linux，因为一旦这个平台不流行或是被取代，那我也会随之被淘汰（过去的这 20 年已经发生过太多这样的事了）。为了应对这样的焦虑，**我更愿意花时间在技术的原理和技术的本质上，这导致我需要了解各种各样的技术的设计方法以及内在原理。**所以，在国内绝大多数程序员们更多关注架构性能的今天，我则花更多的时间去了解编程范式，代码重构，软件设计，计算机系统原理，领域设计，工程方法……只有原理、本质和设计思想才可能让我不会被绑在某个专用技术或平台上，除非我们人类的这条计算机之路没走对。\n\n**3. 职业。**在过去 20 多年的职业生涯中，我从基层工程师做到管理，很多做技术的人都会转管理，但我还是扎根技术，就算是在今天，还是会抠很多技术细节，包括写代码。一方面，我觉得不写代码的人一定是做不好技术管理的，技术管理要做技术决定，而从不上手技术的人是做不好技术决定的，另一方面，我觉得管理是支持性工作，不是产出性工作，大多数管理者无非是因为组织大了，需要管人管事，所以要花大量的时间和精力处理各种问题，甚至办公室政治。然而，如果有一天失业了，大环境变得不好了，一个管理者和一个程序员要出去找工作，程序员会比管理者更能自食其力。因此，我并不觉得管理者这个职业有意思，我还是觉得程序员这个有创造性的职业更有趣。**通常来说，管理者的技能需要到公司和组织中才能展现，而有创造性技能的人则可以让自己更加独立。相比之下，我觉得程序员的技能可以让我更稳定更自由地活着。**所以，我更喜欢“[电影工作组](https://coolshell.cn/articles/4951.html)”那样的团队和组织形式。\n\n**4. 打工。**对于打工，也就是加入一家公司工作，无论是在小公司还是大公司工作，都会有利有弊，任何公司都有其不完美的地方，这个需要承认。首先我必须完成公司交给我的任务（但我也不会是傻傻地完成工作，对于一些有问题的任务我也会提出我的看法）。然后，我会尽我所能找到工作中可以提高效率的地方，并改善它。在推动公司 / 部门 / 团队在技术与工程方面进步并不是一件很容易的事，因为进步是需要成本的。有时候，这种成本并不一定是公司和团队愿意接受的。\n\n另外，从客观规律上来说，某件事的进步一定会和现状有一些摩擦。有的人害怕摩擦而选择忍耐，我则不是，我觉得与别人的摩擦并不可怕，因为大家的目标都是基本一致的，只是做事的标准和方式不一样，这是可以沟通和相互理解的。反而，如果没有去推动这件事，我觉得对于公司或对于我个人来说，都是一种对人生的浪费。敬业也好，激情也好，其就是体现在你是否愿意冒险去推动一件于公于私都有利的事，而不是成为一个“听话”、“随大流”、“懒政”的人，这样即耽误了公司也耽误了自己。所以，我更信仰的是[《做正确的事情，等着被开除》，](http://www.aqee.net/post/do-the-right-thing-wait-to-get-fired.html)这些东西，可参看[《我看绩效考核》，](https://coolshell.cn/articles/17972.html)以及我在[GitChat 上的一些问答。](https://mp.weixin.qq.com/s?__biz=MzUyOTA1NTkzNw==&mid=2247484417&idx=1&sn=316f9f6d6ac7cdca97123815a67a665a&chksm=fa67adafcd1024b948caed0e5528c4817a7ef2b1b1a3ab8da34e0ff4231b28c2659ee9951112#rd)\n\n**5. 创业。**前两天，有个小伙跟我说，他要离开 BAT 去创业公司了，他觉得在那里更自由一些，没有大公司的种种问题。我毫不犹豫地教育了他。我说，你选择这个创业公司的动机不对啊，你无非就是在逃避一些东西罢了，你把创业公司当做一个避风港，这是不对的，因为创业公司的问题可能会更多。去创业公司更好的心态是，这个创业公司在干的事业是不是你的事业？说白了，如果你是为了你的事业，为了解决个什么问题，为了改进个什么东西，那么，创业是适合你的，**也只有在做自己事业的时候，你才能不惧困难，勇敢地面对一切。那种想找一个安稳的避风港的心态不会让你平静，你要知道世界本来就是不平静的，找到自己的归宿和目标才可能让你真正平静。**\n\n正因如此，在我现在的创业团队，我不要求大家加班，我也不灌洗脑鸡汤，对于想要加入的人，我会跟他讲我现在遇到的各种问题以及各种机遇，并让他自己思考，我们在做的事情是不是他自己的事业诉求？还可不可以更好？**每个人都应该为自己的事业、为自己的理想去活一次，追逐自己的事业和理想并不容易，需要有很大付出，也只有你内心的那个理想才值得这么大的付出……**\n\n**6. 客户。**基于上述的价值观，我现在创业面对客户时，并不会完全迁就客户，我的一些银行客户和互联网客户应该体会到我的做事方式了。虽然用户要什么我就给什么，用户想听什么我就说什么，这样更圆滑，可以省很多精力，但这都不是我喜欢的。**我更愿意鲜明地表达我的观点，并拉着用户跟我一起成长，因为我并不觉得完成客户的项目有成就感，我的成就感来自于客户的成长。**所以，面对客户做得不对的、有问题有隐患的地方，我基本上都是直言不讳地说出来。因为我觉得把真实的想法说出来是对客户、对自己最基本的尊重，不管客户最终的选择是什么，我都要把利弊跟客户讲清楚。我并不是在这里装，因为，我也想做一些更高级、更有技术含量的事。所以，对于一些还未达到我预期的客户，如果我不把他们拉上来，我也对不起自己。\n\n最后，对于我“不惑之年”形成的这些价值观体系，也许未来还会变，也许还不成熟，总之，我不愿跟大多数人一样，因为大多数人都是随遇而安或随大流的，他们觉得这样做风险最小，而我想走一条属于自己的路，做真正的自己。就像我 24 岁从银行里出来时想的那样，**我选择了一个正确的专业（计算机科学），待在了一个正确的年代（信息化革命），这样的“狗屎运”几百年不遇，如果我还患得患失，那我岂不辜负了活在这样一个刺激的时代？！我只需要在这个时代中做有价值的事就好了！**\n\n这个时代真的是太好了！\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/84603\" > </iframe>","categories":["左耳听风"]},{"title":"19丨基于Raft的分布式KV系统开发实战（一）：如何设计架构？","url":"/posts/3137639375.html","content":"\n\n\n你好，我是韩健。\n\n学完前面 2 讲之后，相信你已经大致了解了 Raft 算法的代码实现（Hashcorp Raft），也掌握了常用 API 接口的用法，对 Raft 算法的理解也更深刻了。那么，是不是掌握这些，就能得心应手的处理实际场景的问题了呢？\n\n在我看来，掌握的还不够，因为 Raft 算法的实现只是工具。而掌握了工具的用法，和能使用工具得心应手地处理实际场景的问题，是两回事。也就是说，我们还需要掌握使用 Raft 算法开发分布式系统的实战能力，然后才能游刃有余的处理实际场景的问题。\n\n我从这个角度出发，在接下来的 2 节课中，我会分别从架构和代码实现的角度，以一个基本的分布式 KV 系统为例，具体说一说，如何基于 Raft 算法构建一个分布式 KV 系统。**那么我希望你能课下多动手，自己写一遍，不给自己留下盲区。**如果条件允许的话，你还可以按需开发实现需要的功能，并将这套系统作为自己的“配置中心”“名字路由”维护下去，不断在实战中加深自己对技术的理解。\n\n可能有同学会问：“老韩，为什么不以 Etcd 为例呢？它不是已经在生产环境中落地了吗？”\n\n我是这么考虑的，这个基本的分布式 KV 系统的代码比较少，相对纯粹聚焦在技术本身，涉及的 KV 业务层面的逻辑少，适合入门学习（比如你可以从零开始，动手编程实现），是一个很好的学习案例。\n\n另外，对一些有经验的开发者来说，这部分知识能够帮助你掌握 Raft 算法中，一些深层次的技术实现，比如如何实现多种读一致性模型，让你更加深刻地理解 Raft 算法。\n\n今天这节课，我会具体说一说如何设计一个基本的分布式 KV 系统，也就是需要实现哪些功能，以及在架构设计的时候，你需要考虑哪些点（比如跟随者是否要转发写请求给领导者？或者如何设计接入访问的 API？）\n\n好了，话不多说，一起进入今天的课程吧！\n\n在我看来，基于技术深度、开发工作量、学习复杂度等综合考虑，一个基本的分布式 KV 系统，至少需要具备这样几块功能，就像下图的样子。\n\n![image-20230927221845880](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927221845880.png)\n\n接入协议：供客户端访问系统的接入层 API，以及与客户端交互的通讯协议。\n\nKV 操作：我们需要支持的 KV 操作（比如赋值操作）。\n\n分布式集群：也就是说，我们要基于 Raft 算法实现一个分布式存储集群，用于存放 KV 数据。\n\n需要你注意的是，这 3 点就是分布式 KV 系统的核心功能，也就是我们需要编程实现的需求。\n\n在我看来，要实现一个基本的分布式 KV 系统，首先要做的第一件事，就是实现访问接入的通讯协议。因为如果用户想使用这套系统，对他而言的第一件事，就是如何访问这套系统。那么，如何实现访问接入的通讯协议呢？\n\n## 如何设计接入协议？\n\n我想说的是，在早些时候，硬件性能低，服务也不是很多，开发系统的时候，主要矛盾是性能瓶颈，所以，更多的是基于性能的考虑，采用 UDP 协议和实现私有的二进制协议，比如，早期的 QQ 后台组件，就是这么做的。\n\n现在呢，硬件性能有了很大幅度的提升，后台服务器的 CPU 核数都近百了，开发系统的时候，主要的矛盾已经不是性能瓶颈了，而是快速增长的海量服务和开发效率，所以这时，基于开发效率和可维护性的考虑，我们就需要优先考虑标准的协议了（比如 HTTP）。\n\n如果使用 HTTP 协议，那么就需要设计 HTTP RESTful API，作为访问接口。具体怎么设计呢？\n\n我想说的是，因为我们设计实现的是 KV 系统，肯定要涉及到 KV 操作，那么我们就一定需要设计个 API（比如\"/key\"）来支持 KV 操作。也就是说，通过访问这个 API，我们能执行相关的 KV 操作了，就像下面的样子（查询指定 key（就是 foo）对应的值）。\n\n```sh\ncurl -XGET http://raft-cluster-host01:8091/key/foo\n```\n\n另外，需要你注意的是，因为这是一个 Raft 集群系统，除了业务层面（KV 操作），我们还需要实现平台本身的一些操作的 API 接口，比如增加、移除集群节点等。我们现在只考虑增加节点操作的 API（比如\"/join\"），就像下面的样子。\n\n```sh\nhttp://raft-cluster-host01:8091/join\n```\n\n另外，在故障或缩容情况下，如何替换节点、移除节点，我建议你在线下对比着增加节点的操作，自主实现。\n\n除此之外，在我看来，实现 HTTP RESTful API，还有非常重要的一件事情要做，那就是在设计 API 时，考虑如何实现路由，为什么这么说呢？你这么想象一下，如果我们实现了多个 API，比如\"/key\"和\"/join\"，那么就需要将 API 对应的请求和它对应的处理函数一一映射起来。\n\n我想说的是，我们可以在 serveHTTP() 函数（Golang）中，通过检测 URL 路径，来设置请求对应处理函数，实现路由。大概的原理，就像下面的样子。\n\n```go\nfunc (s *Service) ServeHTTP(w http.ResponseWriter, r *http.Request) {    // 设置HTTP请求对应的路由信息\n        if strings.HasPrefix(r.URL.Path, \"/key\") {\n                s.handleKeyRequest(w, r)\n        } else if r.URL.Path == \"/join\" {\n                s.handleJoin(w, r)\n        } else {\n                w.WriteHeader(http.StatusNotFound)\n        }\n}\n```\n\n从上面代码中，我们可以看到，当检测到 URL 路径为“/key”时，会调用 handleKeyRequest() 函数，来处理 KV 操作请求；当检测到 URL 路径为\"/join\"时，会调用 handleJoin() 函数，将指定节点加入到集群中。\n\n你看，通过\"/key\"和\"/join\"2 个 API，我们就能满足这个基本的分布式 KV 系统的运行要求了，既能支持来自客户端的 KV 操作，也能新增节点并将集群运行起来。\n\n当客户端通过通讯协议访问到系统后，它最终的目标，还是执行 KV 操作。那么，我们该如何设计 KV 操作呢？\n\n## 如何设计 KV 操作？\n\n我想说的是，常见的 KV 操作是赋值、查询、删除，也就是说，我们实现这三个操作就可以了，其他的操作可以先不考虑。具体可以这么实现。\n\n**赋值操作：**我们可以通过 HTTP POST 请求，来对指定 key 进行赋值，就像下面的样子。\n\n```sh\ncurl -XPOST http://raft-cluster-host01:8091/key -d '{\"foo\": \"bar\"}'\n```\n\n\n\n**查询操作：**我们可以通过 HTTP GET 请求，来查询指定 key 的值，就像下面的样子。\n\n```sh\ncurl -XGET http://raft-cluster-host01:8091/key/foo\n```\n\n\n\n**删除操作：**我们可以通过 HTTP DELETE 请求，来删除指定 key 和 key 对应的值，就像下面的样子。\n\n```sh\ncurl -XDELETE http://raft-cluster-host01:8091/key/foo\n```\n\n\n\n在这里，尤其需要你注意的是，操作需要具有幂等性。幂等性这个词儿你估计不会陌生，你可以这样理解它：同一个操作，不管执行多少次，最终的结果都是一样的，也就是，这个操作是可以重复执行的，而是重复执行不会对系统产生预期外的影响。\n\n为什么操作要具有冥等性呢？\n\n因为共识算法能保证达成共识后的值（也就是指令）就不再改变了，但不能保证值只被提交一次，也就是说，共识算法是一个“at least once”的指令执行模型，是可能会出现同一个指令被重复提交的情况，为什么呢？我以 Raft 算法为例，具体说一说。\n\n比如，如果客户端接收到 Raft 的超时响应后，也就是这时日志项还没有提交成功，如果此时它重试，发送一个新的请求，那么这个时候 Raft 会创建一个新的日志项，并最终将新旧 2 个日志项都提交了，出现了指令重复执行的情况。\n\n在这里我想强调的是，你一定要注意到这样的情况，在使用 Raft 等共识算法时，要充分评估操作是否具有幂等性，避免对系统造成预期外的影响，比如，直接使用“Add”操作，就会因重复提交，导致最终的执行结果不准了，影响到业务。这就可能会出现，用户购买了 100Q 币，系统却给他充值了 500Q 币，肯定不行了。\n\n说完如何设计 KV 操作后，因为我们的最终目标是实现分布式 KV 系统，那么，就让我们回到分布式系统最本源的一个问题上，如何实现分布式集群？\n\n## 如何实现分布式集群？\n\n我想说的是，正如在 09 讲中提到的，我推荐使用 Raft 算法实现分布式集群。而实现一个 Raft 集群，我们首先要考虑的是如何创建集群，为了简单起见，我们暂时不考虑节点的移除和替换等。\n\n**创建集群**\n\n在 Raft 算法中，我们可以这样创建集群。\n\n先将第一个节点，通过 Bootstrap 的方式启动，并作为领导者节点。\n\n其他节点与领导者节点通讯，将自己的配置信息发送给领导者节点，然后领导者节点调用 AddVoter() 函数，将新节点加入到集群中。\n\n创建了集群后，在集群运行中，因为 Raft 集群的领导者不是固定不变的，而写请求是必须要在领导者节点上处理的，那么如何实现写操作，来保证写请求都会发给领导者呢？\n\n**写操作**\n\n一般而言，有 2 种方法来实现写操作。我来具体说说。\n\n**方法 1：**跟随者接收到客户端的写请求后，拒绝处理这个请求，并将领导者的地址信息返回给客户端，然后客户端直接访问领导者节点，直到该领导者退位，就像下图的样子。\n\n![image-20230927222211496](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927222211496.png)\n\n**方法 2：**跟随者接收到客户端的写请求后，将写请求转发给领导者，并将领导者处理后的结果返回给客户端，也就是说，这时跟随者在扮演“代理”的角色，就像下图的样子。\n\n![image-20230927222224551](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927222224551.png)\n\n在我看来，虽然第一种方法需要客户端的配合，但实现起来复杂度不高；另外，第二种方法，虽然能降低客户端的复杂度，客户端像访问一个黑盒一样，访问系统，对领导者变更完全无感知。\n\n但是这个方法会引入一个中间节点（跟随者），增加了问题分析排查的复杂度。而且，一般情况下，在绝大部分的时间内（比如 Google Chubby 团队观察到的值是数天），领导者是处于稳定状态的，某个节点一直是领导者，那么引入中间节点，就会增加大量的不必要的消息和性能消耗。所以，综合考虑，我推荐方法 1。\n\n学习了 Raft 算法后，我们知道，相比写操作（只要在领导者节点执行就可以了）而言，读操作要复杂些，因为如何实现读操作，关乎着一致性的实现，也就是说，怎么实现读操作，决定了客户端是否会读取到旧数据。那么如何实现读操作呢？\n\n**读操作**\n\n其实，在实际系统中，并不是实现了强一致性就是最好的，因为实现了强一致性，必然会限制集群的整体性能。也就是说，我们需要根据实际场景特点进行权衡折中，这样，才能设计出最适合该场景特点的读操作。比如，我们可以实现类似 Consul 的 3 种读一致性模型。\n\ndefault：偶尔读到旧数据。\n\nconsistent：一定不会读到旧数据。\n\nstale：会读到旧数据。\n\n如果你不记得这 3 种模型的含义了，你可以去 09 讲回顾下，在这里，我就不啰嗦了。\n\n也就是说，我们可以实现多种读一致性模型，将最终的一致性选择权交给用户，让用户去选择，就像下面的样子。\n\n```sh\ncurl -XGET http://raft-cluster-host02:8091/key/foo?level=consistent  -L\n\n```\n\n## 内容小结\n\n本节课我主要带你了解了一个基本的分布式 KV 系统的架构，和需要权衡折中的技术细节，我希望你明确的重点如下。\n\n1. 在设计 KV 操作时，更确切的说，在实现 Raft 指令时，一定要考虑冥等性，因为 Raf 指令是可能会被重复提交和执行。\n2. 推荐你采用这种方式来实现写操作：跟随者接收到客户端的写请求时，拒绝该请求并返回领导者的地址信息给客户端，然后客户端直接访问领导者。\n3. 在 Raft 集群中，如何实现读操作，关乎一致性的实现，推荐实现 default、consistent、stale 三种一致性模型，将一致性的选择权交给用户，让用户根据实际业务特点，按需选择，灵活使用。\n\n最后，我想说的是，这个基本的分布式 KV 系统，除了适合入门学习外，也比较适合配置中心、名字服务等小数据量的系统。另外我想补充一下，对于数据层组件，不仅性能重要，成本也很重要，而决定数据层组件的成本的最关键的一个理念是冷热分离，一般而言，可以这么设计三级缓存：\n\n热数据：经常被访问到的数据，我们可以将它们放在内存中，提升访问效率。\n\n冷数据：有时会被访问到的数据，我们可以将它们放在 SSD 硬盘上，访问起来也比较快。\n\n陈旧数据：偶尔会被访问到的数据，我们可以将它们放在普通磁盘上，节省存储成本。\n\n在实际系统中，你可以统计热数据的命中率，并根据命中率来动态调整冷热模型。在这里，我想强调的是，冷热分离理念在设计海量数据存储系统时尤为重要，比如，自研 KV 存储的成本仅为 Redis 数十分之一，其中系统设计时非常重要的一个理念就是冷热分离。希望你能重视这个理念，在实际场景中活学活用。\n\n## 课堂思考\n\n我提到了其他节点与领导者节点通讯，将自己的配置信息发送给领导者节点，然后领导者节点调用 addVoter() 函数，将新节点加入到集群中，那么，你不妨思考一下，当节点故障时，如何替换一个节点呢？欢迎在留言区分享你的看法，与我一同讨论。\n\n最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/217049\" > </iframe>\n\n","categories":["分布式协议与算法实战"]},{"title":"18丨Hashicorp Raft（二）：如何以“集群节点”为中心使用API？","url":"/posts/3051083458.html","content":"\n\n\n你好，我是韩健。\n\n上一讲结束后，相信有的同学已经跃跃欲试，想把 Hashicorp Raft 使用起来了。不过，也有一些同学跟我反馈，说自己看到 Hashicorp Raft 的Godoc，阅读完接口文档后，感觉有些不知所措，无从下手，Hashicorp Raft 支持了那么多的函数，自己却不知道如何将这些函数使用起来。\n\n这似乎是一个共性的问题，在我看来，之所以出现这个问题，是因为文档里虽然提到了 API 的功能，但并没有提如何在实际场景中使用这些 API，每个 API 都是孤立的点，缺乏一些场景化的线将它们串联起来。\n\n所以，为了帮你更好地理解 Hashicorp Raft 的 API 接口，在实践中将它们用起来，我以“集群节点”为核心，通过创建、增加、移除集群节点，查看集群节点状态这 4 个典型的场景，具体聊一聊在 Hashicorp Raft 中，通过哪些 API 接口能创建、增加、移除集群节点，查看集群节点状态。这样一来，我们会一步一步，循序渐进地彻底吃透 Hashicorp Raft 的 API 接口用法。\n\n我们知道，开发实现一个 Raft 集群的时候，首先要做的第一个事情就是创建 Raft 节点，那么在 Hashicorp Raft 中如何创建节点呢？\n\n## 如何创建 Raft 节点\n\n在 Hashicorp Raft 中，你可以通过 NewRaft() 函数，来创建 Raft 节点。我强调一下，NewRaft() 是非常核心的函数，是 Raft 节点的抽象实现，NewRaft() 函数的原型是这样的：\n\n\n\n```go\nfunc NewRaft(\n        conf *Config, \n        fsm FSM, \n        logs LogStore, \n        stable StableStore, \n        snaps SnapshotStore, \n        trans Transport) (*Raft, error)\n```\n\n\n\n你可以从这段代码中看到，NewRaft() 函数有这么几种类型的参数，它们分别是：\n\nConfig（节点的配置信息）；\n\nFSM（有限状态机）；\n\nLogStore（用来存储 Raft 的日志）；\n\nStableStore（稳定存储，用来存储 Raft 集群的节点信息等）；\n\nSnapshotStore（快照存储，用来存储节点的快照信息）；\n\nTransport（Raft 节点间的通信通道）。\n\n这 6 种类型的参数决定了 Raft 节点的配置、通讯、存储、状态机操作等核心信息，所以我带你详细了解一下，在这个过程中，你要注意是如何创建这些参数信息的。\n\nConfig 是节点的配置信息，可通过函数 DefaultConfig() 来创建默认配置信息，然后按需修改对应的配置项。一般情况下，使用默认配置项就可以了。不过，有时你可能还是需要根据实际场景，调整配置项的，比如：\n\n如果在生产环境中部署的时候，你可以将 LogLevel 从 DEBUG 调整为 WARM 或 ERROR；\n\n如果部署环境中网络拥堵，你可以适当地调大 HeartbeatTimeout 的值，比如，从 1s 调整为 1.5s，避免频繁的领导者选举；\n\n那么 FSM 又是什么呢？它是一个 interface 类型的数据结构，借助 Golang Interface 的泛型编程能力，应用程序可以实现自己的 Apply(*Log)、Snapshot()、Restore(io.ReadCloser) 3 个函数，分别实现将日志应用到本地状态机、生成快照和根据快照恢复数据的功能。FSM 是日志处理的核心实现，原理比较复杂，不过不是咱们本节课的重点，现在你只需要知道这 3 个函数就可以了。在 20 讲，我会结合实际代码具体讲解的。\n\n第三个参数 LogStore 存储的是 Raft 日志，你可以用raft-boltdb来实现底层存储，持久化存储数据。在这里我想说的是，raft-boltdb 是 Hashicorp 团队专门为 Hashicorp Raft 持久化存储，而开发设计的，使用广泛，打磨充分。具体用法是这样的：\n\n\n\n```go\nlogStore, err := raftboltdb.NewBoltStore(filepath.Join(raftDir, \"raft-log.db\"))\n```\n\n\n\nNewBoltStore() 函数只支持一个参数，也就是文件路径。\n\n第四个参数 StableStore 存储的是节点的关键状态信息，比如，当前任期编号、最新投票时的任期编号等，同样，你也可以采用 raft-boltdb 来实现底层存储，持久化存储数据。\n\n\n\n```go\nstableStore, err := raftboltdb.NewBoltStore(filepath.Join(raftDir, \"raft-stable.db\"))\n```\n\n\n\n第五个参数 SnapshotStore 存储的是快照信息，也就是压缩后的日志数据。在 Hashicorp Raft 中提供了 3 种快照存储方式，它们分别是：\n\nDiscardSnapshotStore（不存储，忽略快照，相当于 /dev/null，一般来说用于测试）；\n\nFileSnapshotStore（文件持久化存储）；\n\nInmemSnapshotStore（内存存储，不持久化，重启程序后，数据会丢失）。\n\n**这 3 种方式，在生产环境中，建议你采用 FileSnapshotStore 实现快照， 使用文件持久化存储，避免因程序重启，导致快照数据丢失。**具体代码实现如下：\n\n```go\nsnapshots, err := raft.NewFileSnapshotStore(raftDir, retainSnapshotCount, os.Stderr)\n\n```\n\nNewFileSnapshotStore() 函数支持 3 个参数。也就是说，除了指定存储路径（raftDir），还要指定需要保留的快照副本的数量 (retainSnapshotCount)，以及日志输出的方式。**一般而言，将日志输出到标准错误 IO 就可以了。**\n\n最后一个 Transport 指的是 Raft 集群内部节点之间的通信机制，节点之间需要通过这个通道来进行日志同步、领导者选举等等。Hashicorp Raft 支持两种方式：\n\n一种是基于 TCP 协议的 TCPTransport，可以跨机器跨网络通信的；\n\n另一种是基于内存的 InmemTransport，不走网络，在内存里面通过 Channel 来通信。\n\n**在生产环境中，我建议你使用 TCPTransport，**使用 TCP 进行网络通讯，突破单机限制，提升集群的健壮性和容灾能力。具体代码实现如下：\n\n```go\naddr, err := net.ResolveTCPAddr(\"tcp\", raftBind)\ntransport, err := raft.NewTCPTransport(raftBind, addr, maxPool, timeout, os.Stderr)\n\n```\n\nNewTCPTransport() 函数支持 5 个参数，也就是，指定创建连接需要的信息。比如，要绑定的地址信息（raftBind、addr）、连接池的大小（maxPool）、超时时间（timeout），以及日志输出的方式，一般而言，将日志输出到标准错误 IO 就可以了。\n\n以上就是这 6 个参数的详细内容了，既然我们已经了解了这些基础信息，那么如何使用 NewRaft() 函数呢？其实，你可以在代码中直接调用 NewRaft() 函数，创建 Raft 节点对象，就像下面的样子：\n\n\n\n```go\nraft, err := raft.NewRaft(config, (*storeFSM)(s), logStore, stableStore, snapshots, transport)\n\n```\n\n\n\n接口清晰，使用方便，你可以亲手试一试。\n\n现在，我们已经创建了 Raft 节点，打好了基础，但是我们要实现的是一个多节点的集群，所以，创建一个节点是不够的，另外，创建了节点后，你还需要让节点启动，当一个节点启动后，你还需要创建新的节点，并将它加入到集群中，那么具体怎么操作呢？\n\n## 如何增加集群节点\n\n集群最开始的时候，只有一个节点，我们让第一个节点通过 bootstrap 的方式启动，它启动后成为领导者：\n\n```go\nraftNode.BootstrapCluster(configuration)\n\n```\n\nBootstrapCluster() 函数只支持一个参数，也就是 Raft 集群的配置信息，因为此时只有一个节点，所以配置信息为这个节点的地址信息。\n\n后续的节点在启动的时候，可以通过向第一个节点发送加入集群的请求，然后加入到集群中。具体来说，先启动的节点（也就是第一个节点）收到请求后，获取对方的地址（指 Raft 集群内部通信的 TCP 地址），然后调用 AddVoter() 把新节点加入到集群就可以了。具体代码如下：\n\n```go\nraftNode.AddVoter(id,  \n            addr, prevIndex, timeout)\n```\n\nAddVoter() 函数支持 4 个参数，使用时，一般只需要设置服务器 ID 信息和地址信息 ，其他参数使用默认值 0，就可以了：\n\nid（服务器 ID 信息）；\n\naddr（地址信息）；\n\nprevIndex（前一个集群配置的索引值，一般设置为 0，使用默认值）；\n\ntimeout（在完成集群配置的日志项添加前，最长等待多久，一般设置为 0，使用默认值）。\n\n当然了，也可以通过 AddNonvoter()，将一个节点加入到集群中，但不赋予它投票权，让它只接受日志记录，这个函数平时用不到，你只需知道有这么函数，就可以了。\n\n在这里，我想补充下，早期版本中的用于增加集群节点的函数，AddPeer() 函数，已废弃，不再推荐使用。\n\n你看，在创建集群或者扩容时，我们尝试着增加了集群节点，但一旦出现不可恢复性的机器故障或机器裁撤时，我们就需要移除节点，进行节点替换，那么具体怎么做呢？\n\n## 如何移除集群节点\n\n我们可以通过 RemoveServer() 函数来移除节点，具体代码如下：\n\n```go\nraftNode.RemoveServer(id, prevIndex, timeout)\n\n```\n\nRemoveServer() 函数支持 3 个参数，使用时，一般只需要设置服务器 ID 信息 ，其他参数使用默认值 0，就可以了：\n\nid（服务器 ID 信息）；\n\nprevIndex（前一个集群配置的索引值，一般设置为 0，使用默认值）；\n\ntimeout（在完成集群配置的日志项添加前，最长等待多久，一般设置为 0，使用默认值）。\n\n我要强调一下，RemoveServer() 函数必须在领导者节点上运行，否则就会报错。这一点，很多同学在实现移除节点功能时会遇到，所以需要注意一下。\n\n最后，我想补充下，早期版本中的用于移除集群节点的函数，RemovePeer() 函数也已经废弃了，不再推荐使用。\n\n关于如何移除集群节点的代码实现，也比较简单易用，通过服务器 ID 信息，就可以将对应的节点移除了。除了增加和移除集群节点，在实际场景中，我们在运营分布式系统时，有时需要查看节点的状态。那么该如何查看节点状态呢？\n\n## 如何查看集群节点状态\n\n在分布式系统中，日常调试的时候，节点的状态信息是很重要的，比如在 Raft 分布式系统中，如果我们想抓包分析写请求，那么必须知道哪个节点是领导者节点，它的地址信息是多少，因为在 Raft 集群中，只有领导者能处理写请求。\n\n那么在 Hashicorp Raft 中，如何查看节点状态信息呢？\n\n我们可以通过 Raft.Leader() 函数，查看当前领导者的地址信息，也可以通过 Raft.State() 函数，查看当前节点的状态，是跟随者、候选人，还是领导者。不过你要注意，Raft.State() 函数返回的是 RaftState 格式的信息，也就是 32 位无符号整数，适合在代码中使用。**如果想在日志或命令行接口中查看节点状态信息，我建议你使用 RaftState.String() 函数，**通过它，你可以查看字符串格式的当前节点状态。\n\n为了便于你理解，我举个例子。比如，你可以通过下面的代码，判断当前节点是否是领导者节点：\n\n```go\nfunc isLeader() bool {\n       return raft.State() == raft.Leader\n}\n```\n\n了解了节点状态，你就知道了当前集群节点之间的关系，以及功能和节点的对应关系，这样一来，你在遇到问题，需要调试跟踪时，就知道登录到哪台机器，去调试分析了。\n\n## 内容小结\n\n本节课我主要以“集群节点”为核心，带你了解了 Hashicorp Raft 的常用 API 接口，我希望你明确的重点如下：\n\n除了提到的 raft-boltdb 做作为 LogStore 和 StableStore，也可以调用 NewInmemStore() 创建内存型存储，在测试时比较方便，重新执行程序进行测试时，不需要手动清理数据存储。\n\n你还可以通过 NewInmemTransport() 函数，实现内存型通讯接口，在测试时比较方便，将集群通过内存进行通讯，运行在一台机器上。\n\n你可以通过 Raft.Stats() 函数，查看集群的内部统计信息，比如节点状态、任期编号、节点数等，这在调试或确认节点运行状况的时候很有用。\n\n我以集群节点为核心，讲解了 Hashicorp Raft 常用的 API 接口，相信现在你已经掌握这些接口的用法了，对如何开发一个分布式系统，也有了一定的感觉。既然学习是为了使用，那么我们学完这些内容，也应该用起来才是，所以，为了帮你更好地掌握 Raft 分布式系统的开发实战技巧，我会用接下来两节课的时间，以分布式 KV 系统开发实战为例，带你了解 Raft 的开发实战技巧。\n\n## 课堂思考\n\n我提到了一些常用的 API 接口，比如创建 Raft 节点、增加集群节点、移除集群节点、查看集群节点状态等，你不妨思考一下，如何创建一个支持 InmemTransport 的 Raft 节点呢？欢迎在留言区分享你的看法，与我一同讨论。\n\n最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/215116\" > </iframe>","categories":["分布式协议与算法实战"]},{"title":"17丨Hashicorp Raft（一）：如何跨过理论和代码之间的鸿沟？","url":"/posts/2916810521.html","content":"\n\n\n你好，我是韩健。\n\n很多同学在开发系统的时候，都会有这样的感觉：明明自己看了很多资料，掌握了技术背后的原理，可在开发和调试的时候还是很吃力，这是为什么呢？\n\n答案很简单，因为理论和实践本来就是两回事，实践不仅需要掌握 API 接口的用法，还需要理解 API 背后的代码实现。\n\n所以，如果你在使用 Raft 开发分布式系统的时候，仅仅阅读 Raft 论文或者 Raft 实现的 API 手册，是远远不够的。你还要吃透 API 背后的代码实现，“不仅知其然，也要知其所以然”，这样才能“一切尽在掌握中”，从而开发实现能稳定运行的分布式系统。那么怎么做才能吃透 Raft 的代码实现呢？\n\n要知道，任何 Raft 实现都承载了两个目标：实现 Raft 算法的原理，设计易用的 API 接口。所以，你不仅要从算法原理的角度理解代码实现，而且要从场景使用的角度理解 API 接口的用法。\n\n而我会用两节课的时间，**从代码实现和接口使用两个角度，**带你循序渐进地掌握当前流行的一个 Raft 实现：Hashicorp Raft（以最新稳定版 v1.1.1 为例）。希望你在这个过程中集中注意力，勾划重点，以便提高学习效率，吃透原理对应的技术实现，彻底掌握 Raft 算法的实战技巧。\n\n本节课，我会从算法原理的角度，聊一聊 Raft 算法的核心功能（领导者选举和日志复制）在 Hashicorp Raft 中是如何实现的。（如果 Raft 算法的原理你已经忘得差不多了，那你可以先回顾下 7～9 讲，加深印象之后，再进入今天的学习。）\n\n## Hashicorp Raft 如何实现领导者选举？\n\n**在我看来，阅读源码的关键，在于找到代码的入口函数，**比如在 Golang 代码中，程序的入口函数一般为 main() 函数，那么领导者选举的入口函数是哪个呢？\n\n我们知道，典型的领导者选举在本质上是节点状态的变更。具体到 Hashicorp Raft 源码中，领导者选举的入口函数 run()，在 raft.go 中以一个单独的协程运行，来实现节点状态变迁，就像下面的样子：\n\n```sh\nfunc (r *Raft) run() {\n        for {\n                select {\n                // 关闭节点\n                case <-r.shutdownCh:\n                        r.setLeader(\"\")\n                        return\n                default:\n                }\n                switch r.getState() {\n                // 跟随者\n                case Follower:\n                        r.runFollower()\n                // 候选人\n                case Candidate:\n                        r.runCandidate()\n                // 领导者\n                case Leader:\n                        r.runLeader()\n                }\n        }\n}\n```\n\n从上面这段代码中，你能看到，Follower（跟随者）、Candidate（候选人）、Leader（领导者）三个节点状态对应的功能，都被抽象成一个函数，分别是 runFollower()、runCandidate() 和 runLeader()。\n\n### 数据结构\n\n在07 讲中，我们先学习了节点状态，不过主要侧重理解节点状态的功能作用（比如说，跟随者相当于普通群众，领导者是霸道总裁），并没有关注它在实际代码中是如何实现的，所以我们先来看看在 Hashicorp Raft 中是如何实现节点状态的。\n\n节点状态相关的数据结构和函数，是在 state.go 中实现的。跟随者、候选人和领导者的 3 个状态，是由 RaftState 定义的，一个无符号 32 位的只读整型数值（uint32）：\n\n```sh\ntype RaftState uint32\nconst (\n        // 跟随者\n        Follower RaftState = iota\n        // 候选人\n        Candidate\n        // 领导者\n        Leader\n        // 关闭状态\n        Shutdown\n)\n```\n\n需要注意的是，**也存在一些需要使用字符串格式的节点状态的场景（比如日志输出），**这时你可以使用 RaftState.String() 函数。\n\n你应该还记得，每个节点都有属于本节点的信息（比如任期编号），那么在代码中如何实现这些信息呢？这就要说到 raftState 数据结构了。\n\nraftState 属于结构体类型，是表示节点信息的一个大数据结构，里面包含了只属于本节点的信息，比如节点的当前任期编号、最新提交的日志项的索引值、存储中最新日志项的索引值和任期编号、当前节点的状态等，就像下面的样子：\n\n```sh\ntype raftState struct {\n        // 当前任期编号\n        currentTerm uint64\n        // 最大被提交的日志项的索引值\n        commitIndex uint64\n        // 最新被应用到状态机的日志项的索引值\n        lastApplied uint64\n        // 存储中最新的日志项的索引值和任期编号  \n        lastLogIndex uint64\n        lastLogTerm  uint64\n        // 当前节点的状态\n        state RaftState\n        ......\n}\n```\n\n\n\n节点状态与节点信息的定义就是这么简单，这里我就不多说了。而在分布式系统中要实现领导者选举，更重要的一层内容是实现 RPC 消息，因为领导者选举的过程，就是一个 RPC 通讯的过程。\n\n在理论篇中我说过，Raft 算法中支持多种 RPC 消息（比如请求投票 RPC 消息、日志复制 RPC 消息）。所以接下来我们看一看，在 Hashicorp Raft 中又是怎样实现 RPC 消息的。又因为在一个 RPC 消息中，最重要的部分就是消息的内容，所以我们先来看一看 RPC 消息对应的数据结构。\n\nRPC 消息相关的数据结构是在 commands.go 中定义的，比如，日志复制 RPC 的请求消息，对应的数据结构为 AppendEntriesRequest。而 AppendEntriesRequest 是一个结构体类型，里面包含了 Raft 算法论文中约定的字段，比如以下这些内容。\n\nTerm：当前的任期编号。\n\nPrevLogEntry：表示当前要复制的日志项，前面一条日志项的索引值。\n\nPrevLogTerm：表示当前要复制的日志项，前面一条日志项的任期编号。\n\nEntries：新日志项。\n\n具体的结构信息，就像下面的样子：\n\n```sh\ntype AppendEntriesRequest struct {\n        // 当前的任期编号，和领导者信息（包括服务器ID和地址信息）\n        Term   uint64\n        Leader []byte\n        // 当前要复制的日志项，前面一条日志项的索引值和任期编号\n        PrevLogEntry uint64\n        PrevLogTerm  uint64\n        // 新日志项\n        Entries []*Log\n        // 领导者节点上的已提交的日志项的最大索引值\n        LeaderCommitIndex uint64\n}\n```\n\n我建议你可以采用上面的思路，对照着算法原理去学习其他 RPC 消息的实现，这样一来你就能掌握独立学习的能力了。其他 RPC 消息的数据结构我就不一一描述了（如果你遇到问题，可以在留言区留言）。\n\n现在，你已经了解了节点状态和 RPC 消息的格式，掌握了这些基础知识后，我们继续下一步，看看在 Hashicorp Raft 中是如何进行领导者选举的。\n\n### 选举领导者\n\n首先，在初始状态下，集群中所有的节点都处于跟随者状态，函数 runFollower() 运行，大致的执行步骤，就像下图的样子：\n\n\n\n![image-20230928183141669](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928183141669.png)\n\n\n\n我带你走一遍这五个步骤，便于你加深印象。\n\n根据配置中的心跳超时时长，调用 randomTimeout() 函数来获取一个随机值，用以设置心跳超时时间间隔。\n\n进入到 for 循环中，通过 select 实现多路 IO 复用，周期性地获取消息和处理。如果步骤 1 中设置的心跳超时时间间隔发生了超时，执行步骤 3。\n\n如果等待心跳信息未超时，执行步骤 4，如果等待心跳信息超时，执行步骤 5。\n\n执行 continue 语句，开始一次新的 for 循环。\n\n设置节点状态为候选人，并退出 runFollower() 函数。\n\n当节点推举自己为候选人之后，函数 runCandidate() 执行，大致的执行步骤，如图所示：\n\n\n\n![image-20230928183151191](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928183151191.png)\n\n\n\n同样的，我们走一遍这个过程，加深一下印象。\n\n首先调用 electSelf() 发起选举，给自己投一张选票，并向其他节点发送请求投票 RPC 消息，请求他们选举自己为领导者。然后调用 randomTimeout() 函数，获取一个随机值，设置选举超时时间。\n\n进入到 for 循环中，通过 select 实现多路 IO 复用，周期性地获取消息和处理。如果发生了选举超时，执行步骤 3，如果得到了投票信息，执行步骤 4。\n\n发现了选举超时，退出 runCandidate() 函数，然后再重新执行 runCandidate() 函数，发起新一轮的选举。\n\n如果候选人在指定时间内赢得了大多数选票，那么候选人将当选为领导者，调用 setState() 函数，将自己的状态变更为领导者，并退出 runCandidate() 函数。\n\n当节点当选为领导者后，函数 runLeader() 就执行了：\n\n\n\n![image-20230928183200325](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928183200325.png)\n\n\n\n整个过程，主要有 4 个步骤。\n\n调用 startStopReplication()，执行日志复制功能。\n\n然后启动新的协程，调用 replicate() 函数，执行日志复制功能。\n\n接着在 replicate() 函数中，启动一个新的协程，调用 heartbeat() 函数，执行心跳功能。\n\n在 heartbeat() 函数中，周期性地发送心跳信息，通知其他节点，我是领导者，我还活着，不需要你们发起新的选举。\n\n其实，在 Hashicorp Raft 中实现领导者选举并不难，你只要充分理解上述步骤，并记住，领导者选举本质上是节点状态变迁，跟随者、候选人、领导者对应的功能函数分别为 runFollower()、runCandidate()、runLeader()，就可以了。\n\n## Hashicorp Raft 如何复制日志？\n\n学习08讲之后，你应该知道了日志复制的重要性，因为 Raft 是基于强领导者模型和日志复制，最终实现强一致性的。那么你该如何学习日志复制的代码实现呢？和学习“如何实现领导者选举”一样，你需要先了解了日志相关的数据结构，阅读日志复制相关的代码。\n\n学习了理论篇后，你应该还记得日志复制是由领导者发起的，跟随者来接收的。可能有同学已经想到了，领导者复制日志和跟随者接收日志的入口函数，应该分别在 runLeader() 和 runFollower() 函数中调用的。赞！理解正确！\n\n领导者复制日志的入口函数为 startStopReplication()，在 runLeader() 中，以 r.startStopReplication() 形式被调用，作为一个单独协程运行。\n\n跟随者接收日志的入口函数为 processRPC()，在 runFollower() 中以 r.processRPC(rpc) 形式被调用，来处理日志复制 RPC 消息。\n\n不过，在分析日志复制的代码实现之前，咱们先来聊聊日志相关的数据结构，便于你更好地理解代码实现。\n\n### 数据结构\n\n08 讲中我提到过，一条日志项主要包含了 3 种信息，分别是指令、索引值、任期编号，而在 Hashicorp Raft 实现中，日志对应的数据结构和函数接口是在 log.go 中实现的，其中，日志项对应的数据结构是结构体类型的，就像下面的样子：\n\n```sh\ntype Log struct {\n        // 索引值\n        Index uint64\n        // 任期编号\n        Term uint64\n        // 日志项类别\n        Type LogType\n        // 指令\n        Data []byte\n        // 扩展信息\n        Extensions []byte\n}\n```\n\n\n\n我强调一下，与协议中的定义不同，日志项对应的数据结构中，包含了 LogType 和 Extensions 两个额外的字段：\n\nLogType 可用于标识不同用途的日志项，比如，使用 LogCommand 标识指令对应的日志项，使用 LogConfiguration 表示成员变更配置对应的日志项。\n\nExtensions 可用于在指定日志项中存储一些额外的信息。**这个字段使用的比较少，在调试等场景中可能会用到，你知道有这么个字段就可以了。**\n\n说完日志复制对应的数据结构，我们分步骤看一下，在 Hashicorp Raft 中是如何实现日志复制的。\n\n### 领导者复制日志\n\n日志复制是由领导者发起，在 runLeader() 函数中执行的，主要有这样几个步骤。\n\n\n\n![image-20230928183220997](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928183220997.png)\n\n\n\n在 runLeader() 函数中，调用 startStopReplication() 函数，执行日志复制功能。\n\n启动一个新协程，调用 replicate() 函数，执行日志复制相关的功能。\n\n在 replicate() 函数中，调用 replicateTo() 函数，执行步骤 4，如果开启了流水线复制模式，执行步骤 5。\n\n在 replicateTo() 函数中，进行日志复制和日志一致性检测，如果日志复制成功，则设置 s.allowPipeline = true，开启流水线复制模式。\n\n调用 pipelineReplicate() 函数，采用更高效的流水线方式，进行日志复制。\n\n在这里我强调一下，在什么条件下开启了流水线复制模式，很多同学可能会在这一块儿产生困惑，因为代码逻辑上有点儿绕。**你可以这么理解，是在不需要进行日志一致性检测，复制功能已正常运行的时候，开启了流水线复制模式，**目标是在环境正常的情况下，提升日志复制性能，如果在日志复制过程中出错了，就进入 RPC 复制模式，继续调用 replicateTo() 函数，进行日志复制。\n\n### 跟随者接收日志\n\n领导者复制完日志后，跟随者会接收日志并开始处理日志。跟随者接收和处理日志，是在 runFollower() 函数中执行的，主要有这样几个步骤。\n\n\n\n![image-20230928183230986](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928183230986.png)\n\n\n\n在 runFollower() 函数中，调用 processRPC() 函数，处理接收到的 RPC 消息。\n\n在 processRPC() 函数中，调用 appendEntries() 函数，处理接收到的日志复制 RPC 请求。\n\nappendEntries() 函数，是跟随者处理日志的核心函数。在步骤 3.1 中，比较日志一致性；在步骤 3.2 中，将新日志项存放在本地；在步骤 3.3 中，根据领导者最新提交的日志项索引值，来计算当前需要被应用的日志项，并应用到本地状态机。\n\n讲到这儿，你应该可以了解日志复制的代码实现了吧。关于更多的 Raft 原理的代码实现，你可以继续阅读源码来学习，如果在学习过程中有疑问，欢迎给我留言。\n\n## 内容小结\n\n本节课我主要带你了解了如何从算法原理的角度理解 Hashicorp Raft 实现，有几个重点我想强调一下：\n\n跟随者、候选人、领导者 3 种节点状态都有分别对应的功能函数，当需要查看各节点状态相关的功能实现时（比如，跟随者如何接收和处理日志），都可以将对应的函数作为入口函数，来阅读代码和研究功能实现。\n\nraft.go 是 Hashicorp Raft 的核心代码文件，大部分的核心功能都是在这个文件中实现的，平时可以多研究这个文件中的代码，直到彻底吃透，掌握。\n\n在 Hashicorp Raft 中，支持两种节点间通讯机制，内存型和 TCP 协议型，其中，内存型通讯机制，主要用于测试，2 种通讯机制的代码实现，分别在文件 inmem_transport.go 和 tcp_transport.go 中。\n\nHashicorp Raft 实现，是常用的 Golang 版 Raft 算法的实现，被众多流行软件使用，如 Consul、InfluxDB、IPFS 等，相信你对它并不陌生。其他的实现还有Go-Raft、LogCabin、Willemt-Raft等，不过我建议你在后续开发分布式系统时，优先考虑 Hashicorp Raft，因为 Hashicorp Raft 实现，功能完善、代码简洁高效、流行度高，可用性和稳定性被充分打磨。\n\n最后，关于如何高效地阅读源码，我还想多说一说。在我看来，高效阅读源码的关键在于抓住重点，要有“底线”，不要芝麻和西瓜一把抓，什么都想要，最终陷入到枝节琐碎的细节中出不来。什么是重点呢？我认为重点是数据结构和关键的代码执行流程，比如在 Hashicorp Raft 源码中，日志项对应的数据结构、RPC 消息对应的数据结构、选举领导者的流程、日志复制的流程等，这些就是重点。\n\n有的同学可能还有疑问：在阅读源码的时候，如果遇到不是很明白的代码，该怎么办呢？我建议你可以通过打印日志或 GDB 单步调试的方式，查看上下文中的变量的内容、代码执行逻辑等，帮助理解。\n\n## 课堂思考\n\n在 Hashicorp Raft 实现中，我讲了如何实现选举领导者，以及如何复制日志等，那么在 Hashicorp Raft 中，网络通讯是如何实现的呢？欢迎在留言区分享你的看法，与我一同讨论。\n\n最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。\n\n\n\n\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/213872\" > </iframe>","categories":["分布式协议与算法实战"]},{"title":"16丨InfluxDB企业版一致性实现剖析：他山之石，可以攻玉","url":"/posts/1602580574.html","content":"\n\n\n你好，我是韩健。\n\n学习了前面 15 讲的内容后，我们了解了很多常用的理论和算法（比如 CAP 定理、Raft 算法等）。是不是理解了这些内容，就能够游刃有余地处理实际系统的问题了呢？\n\n在我看来，还远远不够，因为理论和实践的中间是存在鸿沟的，比如，你可能有这样的感受，提到编程语言的语法或者分布式算法的论文，你说起来头头是道，但遇到实际系统时，还是无法写程序，开发分布式系统。\n\n而我常说，实战是学习的最终目的。为了帮你更好地掌握前面的理论和算法，接下来，我用 5 讲的时间，分别以 InfluxDB 企业版一致性实现、Hashicorp Raft、KV 系统开发实战为例，带你了解如何在实战中使用技术，掌握分布式的实战能力。\n\n今天这一讲，我就以 InfluxDB 企业版为例，带你看一看系统是如何实现一致性的。有的同学可能会问了：为什么是 InfluxDB 企业版呢？因为它是排名第一的时序数据库，相比其他分布式系统（比如 KV 存储），时序数据库更加复杂，因为我们要分别设计 2 个完全不一样的一致性模型。当你理解了这样一个复杂的系统实现后，就能更加得心应手地处理简单系统的问题了。\n\n那么为了帮你达到这个目的。我会先介绍一下时序数据库的背景知识，因为技术是用来解决实际场景的问题的，正如我之前常说的“要根据场景特点，权衡折中来设计系统”。所以当你了解了这些背景知识后，就能更好的理解为什么要这么设计了。\n\n## 什么是时序数据库\n\n时序数据库，就是存储时序数据的数据库，就像 MySQL 是存储关系型数据的数据库。而时序数据，就是按照时间顺序记录系统、设备状态变化的数据，比如 CPU 利用率、某一时间的环境温度等，就像下面的样子\n\n```sh\n> insert cpu_usage,host=server01,location=cn-sz user=23.0,system=57.0\n> select * from cpu_usage\nname: cpu_usage\ntime                host     location system user\n1557834774258860710 server01 cn-sz    55     25\n>\n```\n\n在我看来，时序数据最大的特点是数据量很大，可以不夸张地说是海量。时序数据主要来自监控（监控被称为业务之眼），而且在不影响业务运行的前提下，监控埋点是越多越好，这样才能及时发现问题、复盘故障。\n\n**那么作为时序数据库，InfluxDB 企业版的架构是什么样子呢？**\n\n你可能已经了解过，它是由 META 节点和 DATA 节点 2 个逻辑单元组成的，而且这两个节点是 2 个单独的程序。那你也许会问了，为什么不能合成到一个程序呢？答案是场景不同。\n\nMETA 节点存放的是系统运行的关键元信息，比如数据库（Database）、表（Measurement）、保留策略（Retention policy）等。它的特点是一致性敏感，但读写访问量不高，需要一定的容错能力。\n\nDATA 节点存放的是具体的时序数据。它有这样几个特点：最终一致性、面向业务、性能越高越好，除了容错，还需要实现水平扩展，扩展集群的读写性能。\n\n我想说的是，对于 META 节点来说，节点数的多少代表的是容错能力，一般 3 个节点就可以了，因为从实际系统运行观察看，能容忍一个节点故障就可以了。但对 DATA 节点而言，节点数的多少则代表了读写性能，一般而言，在一定数量以内（比如 10 个节点）越多越好，因为节点数越多，读写性能也越高，但节点数量太多也不行，因为查询时就会出现访问节点数过多而延迟大的问题。\n\n所以，基于不同场景特点的考虑，2 个单独程序更合适。如果 META 节点和 DATA 节点合并为一个程序，因读写性能需要，设计了一个 10 节点的 DATA 节点集群，这就意味着 META 节点集群（Raft 集群）也是 10 个节点。在学了 Raft 算法之后，你应该知道，这时就会出现消息数多、日志提交慢的问题，肯定不行了。（对 Raft 日志复制不了解的同学，可以回顾一下08 讲）\n\n现在你了解时序数据库，以及 InfluxDB 企业版的 META 节点和 DATA 节点了吧？那么怎么实现 META 节点和 DATA 节点的一致性呢？\n\n## 如何实现 META 节点一致性？\n\n你可以这样想象一下，META 节点存放的是系统运行的关键元信息，那么当写操作发生后，就要立即读取到最新的数据。比如，创建了数据库“telegraf”，如果有的 DATA 节点不能读取到这个最新信息，那就会导致相关的时序数据写失败，肯定不行。\n\n所以，META 节点需要强一致性，实现 CAP 中的 CP 模型（对 CAP 理论不熟悉的同学，可以先回顾下02 讲）。\n\n那么，InfluxDB 企业版是如何实现的呢？\n\n因为 InflxuDB 企业版是闭源的商业软件，通过官方文档，我们可以知道它使用 Raft 算法实现 META 节点的一致性（一般推荐 3 节点的集群配置）。那么说完 META 节点的一致性实现之后，我接着说一说 DATA 节点的一致性实现。\n\n## 如何实现 DATA 节点一致性？\n\n我们刚刚提到，DATA 节点存放的是具体的时序数据，对一致性要求不高，实现最终一致性就可以了。但是，DATA 节点也在同时作为接入层直接面向业务，考虑到时序数据的量很大，要实现水平扩展，所以必须要选用 CAP 中的 AP 模型，因为 AP 模型不像 CP 模型那样采用一个算法（比如 Raft 算法）就可以实现了，也就是说，AP 模型更复杂，具体有这样几个实现步骤。\n\n### 自定义副本数\n\n首先，你需要考虑冗余备份，也就是同一份数据可能需要设置为多个副本，当部分节点出问题时，系统仍然能读写数据，正常运行。\n\n那么，该如何设置副本呢？答案是实现自定义副本数。\n\n关于自定义副本数的实现，我们在12 讲介绍了，在这里就不啰嗦了。不过，我想补充一点，相比 Raft 算法节点和副本必须一一对应，也就是说，集群中有多少个节点就必须有多少个副本，你看，自定义副本数，是不是更灵活呢？\n\n学到这里，有同学可能已经想到了，当集群支持多副本时，必然会出现一个节点写远程节点时，RPC 通讯失败的情况，那么怎么处理这个问题呢？\n\n### Hinted-handoff\n\n我想说的是，一个节点接收到写请求时，需要将写请求中的数据转发一份到其他副本所在的节点，那么在这个过程中，远程 RPC 通讯是可能会失败的，比如网络不通了，目标节点宕机了，等等，就像下图的样子。\n\n\n\n![image-20230928182944100](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182944100.png)\n\n\n\n那么如何处理这种情况呢？答案是实现 Hinted-handoff。在 InfluxDB 企业版中，Hinted-handoff 是这样实现的:\n\n写失败的请求，会缓存到本地硬盘上 ;\n\n周期性地尝试重传 ;\n\n相关参数信息，比如缓存空间大小 (max-szie)、缓存周期（max-age）、尝试间隔（retry-interval）等，是可配置的。\n\n在这里我想补充一点，除了网络故障、节点故障外，在实际场景中，临时的突发流量也会导致系统过载，出现 RPC 通讯失败的情况，这时也需要 Hinted-handoff 能力。\n\n虽然 Hinted-handoff 可以通过重传的方式来处理数据不一致的问题，但当写失败请求的数据大于本地缓存空间时，比如某个节点长期故障，写请求的数据还是会丢失的，最终的节点的数据还是不一致的，那么怎么实现数据的最终一致性呢？答案是反熵。\n\n### 反熵\n\n需要你注意的是，时序数据虽然一致性不敏感，能容忍短暂的不一致，但如果查询的数据长期不一致的话，肯定就不行了，因为这样就会出现“Flapping Dashboard”的现象，也就是说向不同节点查询数据，生成的仪表盘视图不一样，就像图 2 和图 3 的样子。\n\n\n\n![image-20230928182959062](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182959062.png)\n\n\n\n![image-20230928183006885](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928183006885.png)\n\n\n\n从上面的 2 个监控视图中你可以看到，同一份数据，查询不同的节点，生成的视图是不一样的。那么，如何实现最终一致性呢？\n\n答案就是咱们刚刚说的反熵，而我在11 讲以自研 InfluxDB 系统为例介绍过反熵的实现，InfluxDB 企业版类似，所以在这里就不啰嗦了。\n\n不过有的同学可能会存在这样的疑问，实现反熵是以什么为准来修复数据的不一致呢？我想说的是，时序数据像日志数据一样，创建后就不会再修改了，一直存放在那里，直到被删除。\n\n所以，数据副本之间的数据不一致，是因为数据写失败导致数据丢失了，也就是说，存在的都是合理的，缺失的就是需要修复的。这时我们可以采用两两对比、添加缺失数据的方式，来修复各数据副本的不一致了。\n\n### Quorum NWR\n\n最后，有同学可能会说了，我要在公司官网上展示的监控数据的仪表板（Dashboard），是不能容忍视图不一致的情况的，也就是无法容忍任何“Flapping Dashboard”的现象。那么怎么办呢？这时我们就要实现强一致性（Werner Vogels 提到的强一致性），也就是每次读操作都要能读取最新数据，不能读到旧数据。\n\n那么在一个 AP 型的分布式系统中，如何实现强一致性呢？\n\n答案是实现 Quorum NWR。同样，关于 Quorum NWR 的实现，我们在 12 讲已介绍，在这里也就不啰嗦了。\n\n最后我想说的是，你可以看到，实现 AP 型分布式系统，比实现 CP 型分布式要复杂的。另外，通过上面的内容学习，我希望你能注意到，技术是用来解决场景需求的，没有十全十美的技术，在实际工作中，需要我们深入研究场景特点，提炼场景需求，然后根据场景特点权衡折中，设计出适合该场景特点的分布式系统。\n\n## 内容小结\n\n本节课我主要带你了解时序数据库、META 节点一致性的实现、DATA 节点一致性的实现。以一个复杂的实际系统为例，带你将前面学习到的理论串联起来，让你知道它们如何在实际场景中使用。我希望你明确的重点如下：\n\nCAP 理论是一把尺子，能辅助我们分析问题、总结归纳问题，指导我们如何做妥协折中。所以，我建议你在实践中多研究多思考，一定不能认为某某技术“真香”，十全十美了，要根据场景特点活学活用技术。\n\n通过 Raft 算法，我们能实现强一致性的分布式系统，能保证写操作完成后，后续所有的读操作，都能读取到最新的数据。\n\n通过自定义副本数、Hinted-handoff、反熵、Quorum NWR 等技术，我们能实现 AP 型分布式系统，还能通过水平扩展，高效扩展集群的读写能力。\n\n最后，我想再强调下，技术是用来解决场景的需求的，只有当你吃透技术，深刻理解场景的需求，才能开发出适合这个场景的分布式系统。另外我还想让你知道的是，InfluxDB 企业版一年的 License 费高达 1.5 万美刀，为什么它值这个价钱？就是因为技术带来的高性能和成本优势。比如：\n\n相比 OpenTSDB，InfluxDB 的写性能是它的 9.96 倍，存储效率是它的 8.69 倍，查询效率是它的 7.38 倍。\n\n相比 Graphite，InfluxDB 的写性能是它的 12 倍，存储效率是 6.3 倍，查询效率是 9 倍。\n\n在这里我想说的是，数倍或者数量级的性能优势其实就是钱，而且业务规模越大，省钱效果越突出。\n\n另外我想说的是，尽管 influxdb-comparisons 的测试比较贴近实际场景，比如它的 DevOps 测试模型，与我们观察到常见的实际场景是一致的。但从实际效果看，InfluxDB 的优势更加明显，成本优势更加突出。因为传统的时序数据库不仅仅是性能低，而且在海量数据场景下，接入和查询的痛点突出。为了缓解这些痛点，引入和堆砌了更多的开源软件。比如：\n\n往往需要引入 Kafka 来缓解，因突发接入流量导致的丢数据问题；\n\n需要引入 Storm、Flink 来缓解，时序数据库计算性能差的问题；\n\n需要做热数据的内存缓存，来解决查询超时的问题。\n\n所以在实施中，除了原有的时序数据库会被替换掉，还有大量的开源软件会被省掉，成本优势突出。在这里我想说的是，从实际实施看（自研 InfluxDB 系统），性能优势和成本优势也是符合这个预期的。\n\n最后我想说的是，我反对堆砌开源软件，建议谨慎引入 Kafka 等缓存中间件。老话说，在计算机中，任何问题都可以通过引入一个中间层来解决。这句话是正确的，但背后的成本是不容忽视的，尤其是在海量系统中。**我的建议是直面问题，通过技术手段在代码和架构层面解决它，而不是引入和堆砌更多的开源软件。**其实，InfluxDB 团队也是这么做，比如他们两次重构存储引擎。\n\n## 课堂思考\n\n我提到没有十全十美的技术，而是需要根据场景特点，权衡折中，设计出适合场景特点的分布式系统。那么你试着思考一下，假设有这样一个场景，一个存储系统，访问它的写请求不多（比如 1K QPS），但访问它的读请求很多（比如 1M QPS），而且客户端查询时，对数据的一致性敏感，也就是需要实现强一致性，那么我们该如何设计这个系统呢？为什么呢？欢迎在留言区分享你的看法，与我一同讨论。\n\n最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。\n\n\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/212394\" > </iframe>","categories":["分布式协议与算法实战"]},{"title":"15丨ZAB协议：如何实现操作的顺序性？","url":"/posts/3813020379.html","content":"\n\n\n你好，我是韩健。\n\n很多同学应该使用过 ZooKeeper，它是一个开源的分布式协调服务，比如你可以使用它进行配置管理、名字服务等等。在 ZooKeeper 中，数据是以节点的形式存储的。如果你要用 ZooKeeper 做配置管理，那么就需要在里面创建指定配置，假设创建节点\"/geekbang\"和\"/geekbang/time\"，步骤如下：\n\n```sh\n[zk: localhost:2181(CONNECTED) 7] create /geekbang 123     \nCreated /geekbang\n[zk: localhost:2181(CONNECTED) 8] create /geekbang/time 456\nCreated /geekbang/time\n```\n\n\n\n我们分别创建了配置\"/geekbang\" 和\"/geekbang/time\"，对应的值分别为 123 和 456。那么在这里我提个问题：你觉得在 ZooKeeper 中，能用兰伯特的 Multi-Paxos 实现各节点数据的共识和一致吗？\n\n当然不行。因为兰伯特的 Multi-Paxos，虽然能保证达成共识后的值不再改变，但它不管关心达成共识的值是什么，也无法保证各值（也就是操作）的顺序性。这是为什么呢？这个问题是 ZAB 协议着力解决的，也是理解 ZAB 协议的关键。\n\n不过，虽然大家都在提 ZAB 协议，但是在我看来，ZAB 协议和 ZooKeeper 代码耦合在一起，也就是说，你是无法单独使用 ZAB 协议的，所以一般而言，只需要理解 ZAB 协议的架构和基础原理就可以了，不需要对代码和细节做太多的深究。所以，我会从 ZAB 协议的最核心设计目标（如何实现操作的顺序性）出发，带你了解它的基础原理。\n\n## 为什么 Multi-Paxos 无法实现操作顺序性？\n\n兰伯特的 Multi-Paxos 解决的是一系列值如何达成共识的问题，它关心的是，对于指定序号的位置，最多只有一个指令（Command）会被选定，但它不关心选定的是哪个指令，也就是说，它不关心指令的顺序性（也就是操作的顺序性）。\n\n这么说可能比较抽象，为了方便你理解，我举个具体的例子演示一下（一个 3 节点的 Multi-Paxos 集群），为了演示方便，我们假设当前所有节点被选定的指令的最大序号为 100，也就是说，新提议的指令对应的序号将为 101。\n\n![image-20230927221251695](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927221251695.png)\n\n首先节点 A 是领导者，提议了指令 X、Y，但是因为网络故障，指令只成功复制到了节点 A\n\n![image-20230927221304781](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927221304781.png)\n\n\n\n假设这时节点 A 故障了，新当选的领导者为节点 B。节点 B 当选领导者后，需要先作为学习者了解目前已被选定的指令。节点 B 学习之后，发现当前被选定指令的最大序号为 100（因为节点 A 故障了，它被选定指令的最大序号 102，无法被节点 B 发现），那么它可以从序号 101 开始提议新的指令。这时它接收到客户端请求，并提议了指令 Z，指令 Z 被成功复制到节点 B、C。\n\n![image-20230927221316938](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927221316938.png)\n\n这时节点 B 故障了，节点 A 恢复了，选举出领导者 C 后，节点 B 故障也恢复了。节点 C 当选领导者后，需要先作为学习者，了解目前已被选定的指令，这时它执行 Basic Paxos 的准备阶段，就会发现之前选定的值（比如 Z、Y），然后发送接受请求，最终在序号 101、102 处达成共识的指令是 Z、Y。就像下图的样子。\n\n![image-20230927221329435](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927221329435.png)\n\n在这里，你可以看到，原本预期的指令是 X、Y，最后变成了 Z、Y，也就是说，虽然 Multi-Paxos 能就一系列值达成共识，但它不关心达成共识后的值是什么，这显然不是我们想要的结果。\n\n比如，假设在 ZooKeeper 中直接使用了兰伯特的 Multi-Paxos，这时咱们创建节点\"/geekbang\"和\"/geekbang/time\"，那么就可能出现，系统先创建了节点\"/geekbang/time\"，这样肯定就出错了：\n\n```sh\n[zk: localhost:2181(CONNECTED) 6] create /geekbang/time 456\nNode does not exist: /geekbang/time\n```\n\n\n\n因为创建节点\"/geekbang/time\"时，找不到节点\"/geekbang\"，所以就会创建失败。\n\n在这里我多说几句，兰伯特有很多关于分布式的理论，这些理论都很经典（比如拜占庭将军问题、Paxos），但也因为太早了，与实际场景结合的不多，所以后续的众多算法是在这个基础之上做了大量的改进（比如，PBFT、Raft 等）。关于这一点，我在13 讲也强调过，你需要注意。\n\n另外我还想补充一下，在我看来，在ZAB 论文中，关于 Paxos 问题（Figure 1 ）的分析是有争议的。因为 ZooKeeper 当时应该考虑的是 Multi-Paxos，而不是有多个提议者的 Basic Paxos。对于 Multi-Paxos 而言，领导者作为唯一提议者，不存在同时多个提议者的情况。也就是说，Multi-Paxos 无法保证操作的顺序性的问题是存在的，但原因不是文中演示的原因，**本质上是因为 Multi-Paxos 实现的是一系列值的共识，不关心最终达成共识的值是什么，不关心各值的顺序。**\n\n既然 Multi-Paxos 不行，ZooKeeper 怎么实现操作的顺序性的呢? 答案是它实现了 ZAB 协议。\n\n你可能会说了：Multi-Paxos 无法实现操作的顺序性，但 Raft 可以啊，为什么 ZooKeeper 不用 Raft 呢？这个问题其实比较简单，因为 Raft 出来的比较晚，直到 2013 年才正式提出，在 2007 年开发 ZooKeeper 的时候，还没有 Raft 呢。\n\n## ZAB 是如何保证操作的顺序性的？\n\n与兰伯特的 Multi-Paxos 不同，ZAB 不是共识算法，不基于状态机，而是基于主备模式的原子广播协议，最终实现了操作的顺序性。\n\n这里我说的主备，就是 Master-Slave 模型，一个主节点和多个备份节点，所有副本的数据都以主节点为准，主节点采用二阶段提交，向备份节点同步数据，如果主节点发生故障，数据最完备的节点将当选主节点。而原子广播协议，你可以理解成广播一组消息，消息的顺序是固定的。\n\n需要你注意的是，ZAB 在这里做了个优化，为了实现分区容错能力，将数据复制到大多数节点后（也就是如果大多数节点准备好了），领导者就会进入提交执行阶段，通知备份节点执行提交操作。**在这一点上，Raft 和 ZAB 是类似的，我建议你可以对比着 Raft 算法来理解 ZAB。**\n\n讲到这儿我再多说一句，前面几讲的留言中有同学问状态机的事情：在 Multi-Paxos、Raft 中为什么需要状态机？这是一个很棒的问题，为你的深入思考点个赞！所以咱们先来看一下这个问题。\n\n### 什么是状态机？\n\n本质上来说，状态机指的是有限状态机，它是一个数学模型。你可以这么理解：状态机是一个功能模块，用来处理一系列请求，最大的特点就是确定性，也就是说，对于相同的输入，不管重复运行多少次，最终的内部状态和输出都是相同的。\n\n就像你敲击键盘，在 Word 文档上打字一样，你敲击键盘的顺序决定了 Word 文档上的文字，你按照相同的顺序敲击键盘，一定能敲出相同的文字，这就是一个现实版的状态机。\n\n那么为什么在 Multi-Paxos、Raft 中需要状态机呢？\n\n你想一下，Multi-Paxos、Raft 都是共识算法，而共识算法是就一系列值达成共识的，达成共识后，这个值就不能改了。但有时候我们是需要更改数据的值的，比如 KV 存储，我们肯定需要更改指定 key（比如 X）对应的值，这时我们就可以通过状态机来解决这个问题。\n\n比如，如果你想把 X 的值改为 7，那你可以提议一个新的指令“SET X = 7”，当这个指令被达成共识并提交到状态机后，你查询到的值就是 7 了，也就成功修改了 X 的值。\n\n讲到这儿，你应该理解什么是状态机，为什共识算法需要状态机了吧？在解决这个问题之后，咱们说回刚刚的话题：ZAB 协议如何保证操作的顺序性？\n\n### 如何实现操作的顺序性？\n\n首先，ZAB 实现了主备模式，也就是所有的数据都以主节点为准：\n\n![image-20230927221403951](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927221403951.png)\n\n其次，ZAB 实现了 FIFO 队列，保证消息处理的顺序性。\n\n另外，ZAB 还实现了当主节点崩溃后，只有日志最完备的节点才能当选主节点，因为日志最完备的节点包含了所有已经提交的日志，所以这样就能保证提交的日志不会再改变。\n\n你看，ZAB 协议通过这几个特性就能保证后来的操作不会比当前的操作先执行，也就能保证节点\"/geekbang\"会在节点\"/geekbang/time\"之前创建。\n\n学到这里，想必你已经发现了，这些特性好像和 Raft 很像。是的，因为在前面几讲，我们已经学习了 Raft 算法，所以你可以类比 Raft 来理解，在 Raft 中：\n\n- 所有日志以领导者的为准；\n- 领导者接收到客户端请求后，会基于请求中的指令，创建日志项，并将日志项缓存在本地，然后按照顺序，复制到其他节点和提交 ;\n- 在 Raft 中，也是日志最完备的节点才能当选领导者。\n\n## 内容小结\n\n本节课我主要带你了解了状态机、为什么 Multi-Paxos 无法实现操作的顺序性，以及 ZAB 协议如何保证操作的顺序性。我希望你明确这样几个重点。\n\n状态机最大的特点是确定性，对于相同的输入不管运行多少次，最终的内部状态和输出都是相同的。需要你注意的是，在共识算法中，我们可以通过提议新的指令，达成共识后，提交给状态机执行，来达到修改指定内容的效果，比如修改 KV 存储中指定 key 对应的值。\n\nZAB 是通过“一切以领导者为准”的强领导者模型和严格按照顺序提交日志，来实现操作的顺序性的，这一点和 Raft 是一样的。\n\n最后我想说的是，兰伯特的 Multi-Paxos 只考虑了如何实现共识，也就是，如何就一系列值达成共识，未考虑如何实现各值（也就是操作）的顺序性。最终 ZooKeeper 实现了基于主备模式的原子广播协议，保证了操作的顺序性，而且，ZAB 协议的实现，影响到了后来的共识算法，也就是 Raft 算法，Raft 除了能就一些值达成共识，还能保证各值的顺序性。\n\n学习完本讲内容后，你可以看到，Raft 算法和 ZAB 协议很类似，比如主备模式（也就是领导者、跟随者模型）、日志必须是连续的、以领导者的日志为准是日志一致等等。你可以想一下，那为什么它们会比较类似呢？\n\n我的看法是，“英雄所见略同”。比如 ZAB 协议要实现操作的顺序性，而 Raft 的设计目标，不仅仅是操作的顺序性，而是线性一致性，这两个目标，都决定了它们不能允许日志不连续，要按照顺序提交日志，那么，它们就要通过上面的方法实现日志的顺序性，并保证达成共识（也就是提交）后的日志不会再改变。\n\n## 课堂思考\n\n我提到在 ZAB 中，写操作必须在主节点上执行，主节点是通过简化版的二阶段提交向备份节点同步数据。那么如果读操作访问的是备份节点，能保证每次都能读到最新的数据吗？为什么呢？欢迎在留言区分享你的看法，与我一同讨论。\n\n最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=1000px src=\"https://time.geekbang.org/comment/nice/211954\" > </iframe>\n\n","categories":["分布式协议与算法实战"]},{"title":"14丨PoW算法：有办法黑比特币吗？","url":"/posts/4021567135.html","content":"\n\n\n你好，我是韩健。\n\n谈起比特币，你应该再熟悉不过了，比特币是基于区块链实现的，而区块链运行在因特网上，这就存在有人试图作恶的情况。学完01 讲和13 讲之后，有些同学可能已经发现了，口信消息型拜占庭问题之解、PBFT 算法虽然能防止坏人作恶，但只能防止少数的坏人作恶，也就是 (n - 1) / 3 个坏人 (其中 n 为节点数)。可如果区块链也只能防止一定比例的坏人作恶，那就麻烦了，因为坏人可以不断增加节点数，轻松突破 (n - 1) / 3 的限制。\n\n那区块链是如何改进这个问题的呢？答案就是 PoW 算法。\n\n在我看来，区块链通过工作量证明（Proof of Work）增加了坏人作恶的成本，以此防止坏人作恶。比如，如果坏人要发起 51% 攻击，需要控制现网 51% 的算力，成本是非常高昂的。为啥呢？因为根据 Cryptoslate 估算，对比特币进行 51% 算力攻击需要上百亿人民币！\n\n那么为了帮你更好地理解和掌握 PoW 算法，我会详细讲解它的原理和 51% 攻击的本质。希望让你在理解 PoW 算法的同时，也了解 PoW 算法的局限。\n\n首先我来说说 PoW 的原理，换句话说，就是 PoW 是如何运行的。\n\n## 如何理解工作量证明？\n\n什么是工作量证明 (Proof Of Work，简称 PoW) 呢？你可以这么理解：就是一份证明，用来确认你做过一定量的工作。比如，你的大学毕业证书就是一份工作量证明，证明你通过 4 年的努力完成了相关课程的学习。\n\n那么回到计算机世界，具体来说就是，客户端需要做一定难度的工作才能得出一个结果，验证方却很容易通过结果来检查出客户端是不是做了相应的工作。\n\n比如小李来 BAT 面试，说自己的编程能力很强，那么他需要做一定难度的工作（比如做个编程题）。根据做题结果，面试官可以判断他是否适合这个岗位。你看，小李做个编程题，面试官核验做题结果，这就是一个现实版的工作量证明。\n\n具体的工作量证明过程，就像下图中的样子：\n\n\n\n![image-20230928182659581](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182659581.png)\n\n\n\n请求方做了一些运算，解决了某个问题，然后把运算结果发送给验证方，进行核验，验证方根据运算结果，就能判断请求方是否做了相关的工作。\n\n需要你注意的是，这个算法具有不对称性，也就是说，工作对于请求方是有难度的，对于验证方则是比较简单的，易于验证的。\n\n既然工作量证明是通过指定的结果，来证明自己做过了一定量的工作。那么在区块链的 PoW 算法中需要做哪些工作呢？答案是哈希运算。\n\n区块链是通过执行哈希运算，然后通过运算后的结果值，证明自己做过了相关工作。为了帮你更好地理解哈希运算，在介绍哈希运算之前，咱们先来聊一聊哈希函数。\n\n哈希函数（Hash Function），也叫散列函数。就是说，你输入一个任意长度的字符串，哈希函数会计算出一个长度相同的哈希值。假设我们对任意长度字符串（比如\"geektime\"）执行 SHA256 哈希运算，就会得到一个 32 字节的哈希值，就像下面的样子：\n\n\n\n```sh\n$ echo -n \"geektime\" | sha256sum\nbb2f0f297fe9d3b8669b6b4cec3bff99b9de596c46af2e4c4a504cfe1372dc52  -\n```\n\n\n\n那我们如何通过哈希函数进行哈希运算，从而证明工作量呢？为了帮你理解这部分内容，我举个具体的例子。\n\n我们给出的工作量要求是，基于一个基本的字符串（比如\"geektime\"），你可以在这个字符串后面添加一个整数值，然后对变更后（添加整数值) 的字符串进行 SHA256 哈希运算，如果运算后得到的哈希值（16 进制形式）是以\"0000\"开头的，就验证通过。为了达到这个工作量证明的目标，我们需要不停地递增整数值，一个一个试，对得到的新字符串进行 SHA256 哈希运算。\n\n按照这个规则，我们需要经过 35024 次计算，才能找到恰好前 4 位为 0 的哈希值。\n\n```sh\n\"geektime0\" => 01f28c5df06ef0a575fd0e529be9a6f73b1290794762de014ec84182081e118e\n\"geektime1\" => a2567c06fdb5775cb1e3ce17b72754cf146fcc6da75c8f1d87d7ab6a1b8c4523\n...\n\"geektime35022\" =>\n8afc85049a9e92fe0b6c98b02b27c09fb869fbfe273d0ab84ad8c5ac17b8627e\n\"geektime35023\" =>\n0000ec5927ba10ea45a6822dcc205050ae74ae1ad2d9d41e978e1ec9762dc404\n```\n\n\n\n通过这个示例你可以看到，工作量证明是通过执行哈希运算，经过一段时间的计算后，得到符合条件的哈希值。也就是说，可以通过这个哈希值，来证明我们的工作量。\n\n关于这个规则，我也想多说几句，这个规则不是固定的，在实际场景中，你可以根据场景特点，制定不同的规则，比如，你可以试试分别运行多少次，才能找到恰好前 3 位和前 5 位为 0 的哈希值。\n\n现在，你对工作量证明的原理应该有一定的了解了，那么有同学肯定好奇了，在区块链中是如何实现工作量证明的呢？\n\n## 区块链如何实现 PoW 算法的？\n\n区块链也是通过 SHA256 来执行哈希运算的，通过计算出符合指定条件的哈希值，来证明工作量的。因为在区块链中，PoW 算法是基于区块链中的区块信息，进行哈希运算的，所以我先带你回顾一下区块链的相关知识。\n\n区块链的区块，是由区块头、区块体 2 部分组成的，就像下图中的样子。\n\n区块头（Block Head）：区块头主要由上一个区块的哈希值、区块体的哈希值、4 字节的随机数（nonce）等组成的。\n\n区块体（Block Body）：区块包含的交易数据，其中的第一笔交易是 Coinbase 交易，这是一笔激励矿工的特殊交易。\n\n\n\n![image-20230928182812113](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182812113.png)\n\n\n\n我想说的是，拥有 80 字节固定长度的区块头，就是用于区块链工作量证明的哈希运算中输入字符串，而且通过双重 SHA256 哈希运算（也就是对 SHA256 哈希运算的结果，再执行一次哈希运算），计算出的哈希值，只有小于目标值（target），才是有效的，否则哈希值是无效的，必须重算。\n\n学到这儿你可以看到，在区块链中是通过对区块头执行 SHA256 哈希运算，得到小于目标值的哈希值，来证明自己的工作量的。\n\n计算出符合条件的哈希值后，矿工就会把这个信息广播给集群中所有其他节点，其他节点验证通过后，会将这个区块加入到自己的区块链中，最终形成一串区块链，就像下图的样子：\n\n\n\n![image-20230928182820900](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182820900.png)\n\n\n\n最后，我想说的是，算力越强，系统大概率会越先计算出这个哈希值。这也就意味着，如果坏人们掌握了 51% 的算力，就可以发起 51% 攻击，比如，实现双花（Double Spending），也就是说，同一份钱花 2 次。\n\n具体说的话，就是攻击者掌握了较多的算力，能挖掘一条比原链更长的攻击链，并将攻击链向全网广播，这时呢，按照约定，节点将接受更长的链，也就是攻击链，丢弃原链。就像下图的样子：\n\n\n\n![image-20230928182828900](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182828900.png)\n\n\n\n需要你注意的是，即使攻击者只有 30% 的算力，他也有可能连续计算出多个区块的哈希值，挖掘出更长的攻击链，发动攻击； 另外，即使攻击者拥有 51% 的算力，他也有可能半天无法计算出一个区块的哈希值，也就是攻击失败。也就是说，能否计算出符合条件的哈希值，有一定的概率性，但长久来看，攻击者攻击成功的概率等同于攻击者算力的权重。\n\n## 内容小结\n\n以上就是本节课的全部内容了，本节课我主要带你了解了 PoW 算法的原理，和 51% 攻击，我希望你明确这样几个重点。\n\n在比特币的区块链中，PoW 算法，是通过 SHA256 进行哈希运算，计算出符合指定条件的哈希值，来证明工作量的。\n\n51% 攻击，本质是因为比特币的区块链约定了“最长链胜出，其它节点在这条链基础上扩展”，攻击者可以通过优势算力实现对最长链的争夺。\n\n除了通过 PoW 算法，增加坏人作恶的成本，比特币还通过“挖矿得币”奖励好人，最终保持了整个系统的运行稳定。\n\n因为本讲是拜占庭容错算法的最后一讲，我想多说几句：学完了 01 讲的同学，应该还记得，我们提到 Raft 算法是非拜占庭容错算法。那么如果我们把 Raft 算法用于拜占庭场景中，会怎么样呢？\n\n比如，在比特币中，我们采用了 Raft 算法实现共识，而不是基于 PoW 算法的区块链，那么，就会出现这样的情况，当恶意节点当选为领导者后，他可以不断地告诉其他节点，这些比特币都是我的，按照 Raft 的约定，其他节点也就只能接受这种情况，谁让恶意节点是领导者呢？**最终就会出现，所有的比特币都被恶意节点盗走的情况**，完全乱套了。\n\n另外我想说的是，因为拜占庭容错算法（比如 PoW 算法、PBFT 算法），能容忍一定比例的作恶行为，所以它在相对开放的场景中应用广泛，比如公链、联盟链。非拜占庭容错算法（比如 Raft）无法对作恶行为进行容错，主要用于封闭、绝对可信的场景中，比如私链、公司内网的 DevOps 环境。我希望你能准确理解 2 类算法之间的差异，根据场景特点，选择合适的算法，保障业务高效、稳定的运行。\n\n## 课堂思考\n\n既然，我提了如何通过计算得到\"0000\"开头的哈希值，来做实现工作量证明，那么你不妨思考下，如果约定是更多“0”开头的哈希值，比如“00000000”，工作量是增加了还是减少了，为什么呢？欢迎在留言区分享你的看法，与我一同讨论。\n\n最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。\n\n\n\n\n\n\n\n\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/210887\" > </iframe>","categories":["分布式协议与算法实战"]},{"title":"13丨PBFT算法：有人作恶，如何达成共识？","url":"/posts/3262029384.html","content":"\n\n\n你好，我是韩健。\n\n学完了01 讲的拜占庭将军问题之后，有同学在留言中表达了自己的思考和困惑：口信消息型拜占庭问题之解在实际项目中是如何落地的呢？先给这位同学点个赞，很棒！你能在学习的同时思考落地实战。\n\n不过事实上，它很难在实际项目落地，因为口信消息型拜占庭问题之解是一个非常理论化的算法，没有和实际场景结合，也没有考虑如何在实际场景中落地和实现。\n\n比如，它实现的是在拜占庭错误场景下，忠将们如何在叛徒干扰时，就一致行动达成共识。但是它并不关心结果是什么，这会出现一种情况：现在适合进攻，但将军们达成的最终共识却是撤退。\n\n很显然，这不是我们想要的结果。因为在实际场景中，我们需要就提议的一系列值（而不是单值），即使在拜占庭错误发生的时候也能被达成共识。那你要怎么做呢？答案就是掌握 PBFT 算法。\n\nPBFT 算法非常实用，是一种能在实际场景中落地的拜占庭容错算法，它在区块链中应用广泛（比如 Hyperledger Sawtooth、Zilliqa）。为了帮助你更好地理解 PBFT 算法，在今天的内容中，我除了带你了解 PBFT 达成共识的原理之外，还会介绍口信消息型拜占庭问题之解的局限。相信学习完本讲内容后，你不仅能理解 PBFT 达成共识的基本原理，还能理解算法背后的演化和改进。\n\n老规矩，在开始今天的学习之前，咱们先看一道思考题：\n\n假设苏秦再一次带队抗秦，这一天，苏秦和 4 个国家的 4 位将军赵、魏、韩、楚商量军机要事，结果刚商量完没多久苏秦就接到了情报，情报上写道：联军中可能存在一个叛徒。这时，苏秦要如何下发作战指令，保证忠将们正确、一致地执行下发的作战指令，而不是被叛徒干扰呢？\n\n![image-20230928182504234](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182504234.png)\n\n\n\n带着这个问题，我们正式进入今天的学习。\n\n首先，咱们先来研究一下，为什么口信消息型拜占庭问题之解很难在实际场景中落地，除了我在开篇提到的非常理论化，没有和实际的需求结合之外，还有其他的原因么？\n\n其实，这些问题是后续众多拜占庭容错算法在努力改进和解决的，理解了这些问题，能帮助你更好地理解后来的拜占庭容错算法（包括 PBFT 算法）。\n\n## 口信消息型拜占庭问题之解的局限\n\n我想说的是，这个算法有个非常致命的缺陷。如果将军数为 n、叛将数为 f，那么算法需要递归协商 f+1 轮，消息复杂度为 O(n ^ (f + 1))，消息数量指数级暴增。你可以想象一下，如果叛将数为 64，消息数已经远远超过 **int64** 所能表示的了，这是无法想象的，肯定不行啊。\n\n另外，尽管对于签名消息，不管叛将数（比如 f）是多少，经过 f + 1 轮的协商，忠将们都能达成一致的作战指令，但是这个算法同样存在“理论化”和“消息数指数级暴增”的痛点。\n\n讲到这儿，你肯定明白为什么这个算法很难在实际场景中落地了。可技术是不断发展的，算法也是在解决实际场景问题中不断改进的。那么 PBFT 算法的原理是什么呢？为什么它能在实际场景中落地呢？\n\n## PBFT 是如何达成共识的？\n\n我们先来看看如何通过 PBFT 算法，解决苏秦面临的共识问题。先假设苏秦制定的作战指令是进攻，而楚是叛徒（为了演示方便）：\n\n\n\n![image-20230928182515760](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182515760.png)\n\n\n\n需要你注意的是，所有的消息都是签名消息，也就是说，消息发送者的身份和消息内容都是无法伪造和篡改的（比如，楚无法伪造一个假装来自赵的消息）。\n\n首先，苏秦联系赵，向赵发送包含作战指令“进攻”的请求（就像下图的样子）。\n\n\n\n![image-20230928182524785](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182524785.png)\n\n\n\n当赵接收到苏秦的请求之后，会执行三阶段协议（Three-phase protocol）。\n\n赵将进入预准备（Pre-prepare）阶段，构造包含作战指令的预准备消息，并广播给其他将军（魏、韩、楚）。\n\n![image-20230928182533606](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182533606.png)\n\n那么在这里，我想问你一个问题：魏、韩、楚，收到消息后，能直接执行指令吗？\n\n答案是不能，因为他们不能确认自己接收到指令和其他人接收到的指令是相同的。比如，赵可能是叛徒，赵收到了 2 个指令，分别是“进攻”和“准备 30 天的粮草”，然后他给魏发送的是“进攻”，给韩、楚发送的是“准备 30 天粮草”，这样就会出现无法一致行动的情况。那么他们具体怎么办呢？我接着说一下。\n\n接收到预准备消息之后，魏、韩、楚将进入准备（Prepare）阶段，并分别广播包含作战指令的准备消息给其他将军。比如，魏广播准备消息给赵、韩、楚（如图所示）。为了方便演示，我们假设叛徒楚想通过不发送消息，来干扰共识协商（你能看到，图中的楚是没有发送消息的）。\n\n![image-20230928182543069](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182543069.png)\n\n\n\n然后，当某个将军收到 2f 个一致的包含作战指令的准备消息后，会进入提交（Commit）阶段（这里的 2f 包括自己，其中 f 为叛徒数，在我的演示中是 1）。在这里，我也给你提一个问题：这个时候该将军（比如魏）可以直接执行指令吗？\n\n答案还是不能，因为魏不能确认赵、韩、楚是否收到了 2f 个一致的包含作战指令的准备消息。也就是说，魏这时无法确认赵、韩、楚是否准备好了执行作战指令。那么怎么办呢？别着急，咱们继续往下看。\n\n进入提交阶段后，各将军分别广播提交消息给其他将军，也就是告诉其他将军，我已经准备好了，可以执行指令了。\n\n![image-20230928182552036](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182552036.png)\n\n\n\n最后，当某个将军收到 2f + 1 个验证通过的提交消息后（包括自己，其中 f 为叛徒数，在我的演示中为 1），也就是说，大部分的将军们已经达成共识，这时可以执行作战指令了，那么该将军将执行苏秦的作战指令，执行完毕后发送执行成功的消息给苏秦。\n\n![image-20230928182601843](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182601843.png)\n\n\n\n最后，当苏秦收到 f+1 个相同的响应（Reply）消息时，说明各位将军们已经就作战指令达成了共识，并执行了作战指令（其中 f 为叛徒数，在我的演示中为 1）。\n\n你看，经过了三轮协商，是不是就指定的作战指令达成了共识，并执行了作战指令了呢？\n\n在这里，苏秦采用的就是**简化版的 PBFT 算法**。在这个算法中：\n\n你可以将赵、魏、韩、楚理解为分布式系统的四个节点，其中赵是主节点（Primary node），魏、韩、楚是从节点（Secondary node）；\n\n将苏秦理解为业务，也就是客户端；\n\n将消息理解为网络消息；\n\n将作战指令“进攻”，理解成客户端提议的值，也就是希望被各节点达成共识，并提交给状态机的值。\n\n**在这里我想说的是，** PBFT 算法是通过签名（或消息认证码 MAC）约束恶意节点的行为，也就是说，每个节点都可以通过验证消息签名确认消息的发送来源，一个节点无法伪造另外一个节点的消息。最终，基于大多数原则（2f + 1）实现共识的。\n\n需要你注意的是，最终的共识是否达成，客户端是会做判断的，如果客户端在指定时间内未收到请求对应的 f + 1 相同响应，就认为集群出故障了，共识未达成，客户端会重新发送请求。\n\n另外需要你注意的是，PBFT 算法通过视图变更（View Change）的方式，来处理主节点作恶，当发现主节点在作恶时，会以“轮流上岗”方式，推举新的主节点。\n\n最后我想说的是，尽管 PBFT 算法相比口信消息型拜占庭之解已经有了很大的优化，将消息复杂度从 O(n ^ (f + 1)) 降低为 O(n ^ 2)，能在实际场景中落地，并解决实际的共识问题。但 PBFT 还是需要比较多的消息。比如在 13 节点集群中（f 为 4）。\n\n请求消息：1\n\n预准备消息：3f = 12\n\n准备消息：3f * (3f - f) = 96\n\n提交消息：(3f - f + 1) * (3f + 1)= 117\n\n回复消息：3f - 1 = 11\n\n也就是说，一次共识协商需要 237 个消息，你看，消息数还是蛮多的，所以我推荐你，在中小型分布式系统中使用 PBFT 算法。\n\n## 内容小结\n\n以上就是本节课的全部内容了，本节课我主要带你了解了口信消息型拜占庭问题之解的局限和 PBFT 的原理，我希望你明确这样几个重点。\n\n不管口信消息型拜占庭问题之解，还是签名消息型拜占庭问题之解，都是非常理论化的，未考虑实际场景的需求，而且协商成本非常高，指数级的消息复杂度是很难在实际场景中落地，和解决实际场景问题的。\n\nPBFT 算法是通过签名（或消息认证码 MAC）约束恶意节点的行为，采用三阶段协议，基于大多数原则达成共识的。另外，与口信消息型拜占庭问题之解（以及签名消息型拜占庭问题之解）不同的是，PBFT 算法实现的是一系列值的共识，而不是单值的共识。\n\n最后，我想说的是，相比 Raft 算法完全不适应有人作恶的场景，PBFT 算法能容忍 (n - 1)/3 个恶意节点 (也可以是故障节点)。另外，相比 PoW 算法，PBFT 的优点是不消耗算力，所以在日常实践中，PBFT 比较适用于相对“可信”的场景中，比如联盟链。\n\n需要你注意的是，PBFT 算法与 Raft 算法类似，也存在一个“领导者”（就是主节点），同样，集群的性能也受限于“领导者”。另外，O(n ^ 2) 的消息复杂度，以及随着消息数的增加，网络时延对系统运行的影响也会越大，这些都限制了运行 PBFT 算法的分布式系统的规模，也决定了 PBFT 算法适用于中小型分布式系统。\n\n## 课堂思考\n\n当客户端在收到了 f + 1 个结果，就认为共识达成了，那么为什么这个值不能小于 f + 1 呢？欢迎在留言区分享你的看法，与我一同讨论。\n\n最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/209450\" > </iframe>","categories":["分布式协议与算法实战"]},{"title":"12丨QuorumNWR算法：想要灵活地自定义一致性，没问题！","url":"/posts/3451445473.html","content":"\n\n\n你好，我是韩健。\n\n不知道你在工作中有没有遇到这样的事儿：你开发实现了一套 AP 型的分布式系统（我在04 讲提到了 AP 型系统的特点，你可以回顾一下），实现了最终一致性。业务也接入了，运行正常，一起看起来都那么美好。\n\n可是，突然有同事说，我们要拉这几个业务的数据做实时分析，希望数据写入成功后，就能立即读取到新数据，也就是要实现强一致性（Werner Vogels 提出的客户端侧一致性模型，不是指线性一致性），数据更改后，要保证用户能立即查询到。这时你该怎么办呢？首先你要明确最终一致性和强一致性有什么区别。\n\n强一致性能保证写操作完成后，任何后续访问都能读到更新后的值；\n\n最终一致性只能保证如果对某个对象没有新的写操作了，最终所有后续访问都能读到相同的最近更新的值。也就是说，写操作完成后，后续访问可能会读到旧数据。\n\n其实，在我看来，为了一个临时的需求，我们重新开发一套系统，或者迁移数据到新系统，肯定是不合适的。因为工作量比较大，而且耗时也长，而我建议你通过 Quorum NWR 解决这个问题。\n\n也就是说，在原有系统上开发实现一个新功能，就可以满足业务同学的需求了。因为通过 Quorum NWR，你可以自定义一致性级别，通过临时调整写入或者查询的方式，当 W + R > N 时，就可以实现强一致性了。\n\n其实，在 AP 型分布式系统中（比如 Dynamo、Cassandra、InfluxDB 企业版的 DATA 节点集群），Quorum NWR 是通常都会实现的一个功能，很常用。对你来说，掌握 Quorum NWR，不仅是掌握一种常用的实现一致性的方法，更重要的是，后续用户可以根据业务的特点，灵活地指定一致性级别。\n\n为了帮你掌握 Quorum NWR，除了带你了解它的原理外，我还会以 InfluxDB 企业版的实现为例，带你看一下它在实际场景中的实现，这样你可以在理解原理的基础上，掌握 Quorum NWR 的实战技巧。\n\n首先，你需要了解 Quorum NWR 中的三个要素，N、W、R。因为它们是 Quorum NWR 的核心内容，我们就是通过组合这三个要素，实现自定义一致性级别的。\n\n## Quorum NWR 的三要素\n\nN 表示副本数，又叫做复制因子（Replication Factor）。也就是说，N 表示集群中同一份数据有多少个副本，就像下图的样子：\n\n![image-20230928182318383](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182318383.png)\n\n\n\n从图中你可以看到，在这个三节点的集群中，DATA-1 有 2 个副本，DATA-2 有 3 个副本，DATA-3 有 1 个副本。也就是说，副本数可以不等于节点数，不同的数据可以有不同的副本数。\n\n需要你注意的是，在实现 Quorum NWR 的时候，你需要实现自定义副本的功能。也就是说，用户可以自定义指定数据的副本数，比如，用户可以指定 DATA-1 具有 2 个副本，DATA-2 具有 3 个副本，就像图中的样子。\n\n当我们指定了副本后，就可以对副本数据进行读写操作了。那么这么多副本，你要如何执行读写操作呢？先来看一看写操作，也就是 W。\n\nW，又称写一致性级别（Write Consistency Level），表示成功完成 W 个副本更新，才完成写操作：\n\n![image-20230928182331589](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182331589.png)\n\n\n\n从图中你可以看到，DATA-2 的写副本数为 2，也就说，对 DATA-2 执行写操作时，完成了 2 个副本的更新（比如节点 A、C），才完成写操作。\n\n那么有的同学会问了，DATA-2 有 3 个数据副本，完成了 2 副本的更新，就完成了写操作，那么如何实现强一致性呢？如果读到了第三个数据副本（比如节点 B），不就可能无法读到更新后的值了吗？别急，我讲完如何执行读操作后，你就明白了。\n\nR，又称读一致性级别（Read Consistency Level），表示读取一个数据对象时需要读 R 个副本。你可以这么理解，读取指定数据时，要读 R 副本，然后返回 R 个副本中最新的那份数据：\n\n![image-20230928182342268](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182342268.png)\n\n\n\n从图中你可以看到，DATA-2 的读副本数为 2。也就是说，客户端读取 DATA-2 的数据时，需要读取 2 个副本中的数据，然后返回最新的那份数据。\n\n这里需要你注意的是，无论客户端如何执行读操作，哪怕它访问的是写操作未强制更新副本数据的节点（比如节点 B），但因为 W(2) + R(2) > N(3)，也就是说，访问节点 B，执行读操作时，因为要读 2 份数据副本，所以除了节点 B 上的 DATA-2，还会读取节点 A 或节点 C 上的 DATA-2，就像上图的样子（比如节点 C 上的 DATA-2），而节点 A 和节点 C 的 DATA-2 数据副本是强制更新成功的。这个时候，返回给客户端肯定是最新的那份数据。\n\n你看，通过设置 R 为 2，即使读到前面问题中的第三份副本数据（比如节点 B），也能返回更新后的那份数据，实现强一致性了。\n\n除此之外，关于 NWR 需要你注意的是，N、W、R 值的不同组合，会产生不同的一致性效果，具体来说，有这么两种效果：\n\n当 W + R > N 的时候，对于客户端来讲，整个系统能保证强一致性，一定能返回更新后的那份数据。\n\n当 W + R < N 的时候，对于客户端来讲，整个系统只能保证最终一致性，可能会返回旧数据。\n\n你可以看到，Quorum NWR 的原理并不复杂，也相对比较容易理解，但在这里，我想强调一下，掌握它的关键在于如何根据不同的场景特点灵活地实现 Quorum NWR，所以接下来，我带你具体问题具体分析，以 InfluxDB 企业版为例讲解一下。\n\n## 如何实现 Quorum NWR？\n\n在 InfluxDB 企业版中，可以在创建保留策略时，设置指定数据库（Database）对应的副本数，具体的命令，就像下面的样子：\n\ncreate retention policy “rp_one_day” on “telegraf” duration 1d replication 3\n\n通过 replication 参数，指定了数据库 telegraf 对应的副本数为 3。\n\n需要你注意的，在 InfluxDB 企业版中，副本数不能超过节点数据。你可以这么理解，多副本的意义在于冗余备份，如果副本数超过节点数，就意味着在一个节点上会存在多个副本，那么这时冗余备份的意义就不大了。比如机器故障时，节点上的多个副本是同时被影响的。\n\nInfluxDB 企业版，支持“any、one、quorum、all”4 种写一致性级别，具体的含义是这样的。\n\nany：任何一个节点写入成功后，或者接收节点已将数据写入 Hinted-handoff 缓存（也就是写其他节点失败后，本地节点上缓存写失败数据的队列）后，就会返回成功给客户端。\n\none：任何一个节点写入成功后，立即返回成功给客户端，不包括成功写入到 Hinted-handoff 缓存。\n\nquorum：当大多数节点写入成功后，就会返回成功给客户端。此选项仅在副本数大于 2 时才有意义，否则等效于 all。\n\nall：仅在所有节点都写入成功后，返回成功。\n\n我想强调一下，对时序数据库而言，读操作常会拉取大量数据，查询性能是挑战，是必须要考虑优化的，因此，在 InfluxDB 企业版中，不支持读一致性级别，只支持写一致性级别。另外，我们可以通过设置写一致性级别为 all，来实现强一致性。\n\n你看，如果我们像 InfluxDB 企业版这样，实现了 Quorum NWR，那么在业务临时需要实现强一致性时，就可以通过设置写一致性级别为 all，来实现了。\n\n## 内容小结\n\n以上就是本节课的全部内容了，本节课我主要带你了解了 Quorum NWR 的原理、InfluxDB 企业版的 Quorum NWR 实现。我希望你明确这样几个重点。\n\n一般而言，不推荐副本数超过当前的节点数，因为当副本数据超过节点数时，就会出现同一个节点存在多个副本的情况。当这个节点故障时，上面的多个副本就都受到影响了。\n\n当 W + R > N 时，可以实现强一致性。另外，如何设置 N、W、R 值，取决于我们想优化哪方面的性能。比如，N 决定了副本的冗余备份能力；如果设置 W = N，读性能比较好；如果设置 R = N，写性能比较好；如果设置 W = (N + 1) / 2、R = (N + 1) / 2，容错能力比较好，能容忍少数节点（也就是 (N - 1) / 2）的故障。\n\n最后，我想说的是，Quorum NWR 是非常实用的一个算法，能有效弥补 AP 型系统缺乏强一致性的痛点，给业务提供了按需选择一致性级别的灵活度，建议你的开发实现 AP 型系统时，也实现 Quorum NWR。\n\n## 课堂思考\n\n我提到实现 Quorum NWR 时，需要实现自定义副本的能力，那么，一般设置几个副本就可以了，为什么呢？欢迎在留言区分享你的看法，与我一同讨论。\n\n最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。\n\n\n\n\n\n\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/209130\" > </iframe>","categories":["分布式协议与算法实战"]},{"title":"11丨Gossip协议：流言蜚语，原来也可以实现一致性","url":"/posts/2182109993.html","content":"\n\n\n你好，我是韩健。\n\n有一部分同学的业务在可用性上比较敏感，比如监控主机和业务运行的告警系统。这个时候，相信你希望自己的系统能在极端情况下（比如集群中只有一个节点在运行）也能运行。回忆了二阶段提交协议和 Raft 算法之后，你发现它们都需要全部节点或者大多数节点正常运行，才能稳定运行，那么它们就不适合了。而根据 Base 理论，你需要实现最终一致性，怎么样才能实现最终一致性呢？\n\n在我看来，你可以通过 Gossip 协议实现这个目标。\n\nGossip 协议，顾名思义，就像流言蜚语一样，利用一种随机、带有传染性的方式，将信息传播到整个网络中，并在一定时间内，使得系统内的所有节点数据一致。对你来说，掌握这个协议不仅能很好地理解这种最常用的，实现最终一致性的算法，也能在后续工作中得心应手地实现数据的最终一致性。\n\n为了帮你彻底吃透 Gossip 协议，掌握实现最终一致性的实战能力，我会先带你了解 Gossip 三板斧，因为这是 Gossip 协议的核心内容，也是实现最终一致性的常用三种方法。然后以实际系统为例，带你了解在实际系统中是如何实现反熵的。接下来，就让我们开始今天的内容吧。\n\n## Gossip 的三板斧\n\nGossip 的三板斧分别是：直接邮寄（Direct Mail）、反熵（Anti-entropy）和谣言传播（Rumor mongering）。\n\n直接邮寄：就是直接发送更新数据，当数据发送失败时，将数据缓存下来，然后重传。从图中你可以看到，节点 A 直接将更新数据发送给了节点 B、D。\n\n\n\n![image-20230928181908022](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928181908022.png)\n\n\n\n在这里我想补充一点，直接邮寄虽然实现起来比较容易，数据同步也很及时，但可能会因为缓存队列满了而丢数据。也就是说，只采用直接邮寄是无法实现最终一致性的，这一点我希望你能注意到。\n\n那如何实现最终一致性呢？答案就是反熵。本质上，反熵是一种通过异步修复实现最终一致性的方法（关于异步修复，你可以回顾一下04 讲）。常见的最终一致性系统（比如 Cassandra），都实现了反熵功能。\n\n反熵指的是集群中的节点，每隔段时间就随机选择某个其他节点，然后通过互相交换自己的所有数据来消除两者之间的差异，实现数据的最终一致性：\n\n\n\n![image-20230928181920098](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928181920098.png)\n\n\n\n从图 2 中你可以看到，节点 A 通过反熵的方式，修复了节点 D 中缺失的数据。那具体怎么实现的呢？\n\n**其实，在实现反熵的时候，主要有推、拉和推拉三种方式。**我将以修复下图中，2 个数据副本的不一致为例，具体带你了解一下。\n\n\n\n![image-20230928181931519](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928181931519.png)\n\n\n\n推方式，就是将自己的所有副本数据，推给对方，修复对方副本中的熵：\n\n![image-20230928181942547](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928181942547.png)\n\n\n\n拉方式，就是拉取对方的所有副本数据，修复自己副本中的熵：\n\n![image-20230928181953642](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928181953642.png)\n\n\n\n理解了推和拉之后，推拉这个方式就很好理解了，这个方式就是同时修复自己副本和对方副本中的熵：\n\n\n\n![image-20230928182003067](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182003067.png)\n\n\n\n也许有很多同学，会觉得反熵是一个很奇怪的名词。其实，你可以这么来理解，反熵中的熵是指混乱程度，反熵就是指消除不同节点中数据的差异，提升节点间数据的相似度，降低熵值。\n\n另外需要你注意的是，因为反熵需要节点两两交换和比对自己所有的数据，执行反熵时通讯成本会很高，所以我不建议你在实际场景中频繁执行反熵，并且可以通过引入校验和（Checksum）等机制，降低需要对比的数据量和通讯消息等。\n\n虽然反熵很实用，但是执行反熵时，相关的节点都是已知的，而且节点数量不能太多，如果是一个动态变化或节点数比较多的分布式环境（比如在 DevOps 环境中检测节点故障，并动态维护集群节点状态），这时反熵就不适用了。**那么当你面临这个情况要怎样实现最终一致性呢？答案就是谣言传播。**\n\n谣言传播，广泛地散播谣言，它指的是当一个节点有了新数据后，这个节点变成活跃状态，并周期性地联系其他节点向其发送新数据，直到所有的节点都存储了该新数据：\n\n\n\n![image-20230928182015029](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182015029.png)\n\n\n\n从图中你可以看到，节点 A 向节点 B、D 发送新数据，节点 B 收到新数据后，变成活跃节点，然后节点 B 向节点 C、D 发送新数据。其实，谣言传播非常具有传染性，它适合动态变化的分布式系统。\n\n## 如何使用 Anti-entropy 实现最终一致\n\n在分布式存储系统中，实现数据副本最终一致性，最常用的方法就是反熵了。为了帮你彻底理解和掌握在实际环境中实现反熵的方法，我想以自研 InfluxDB 的反熵实现为例，具体带你了解一下。\n\n在自研 InfluxDB 中，一份数据副本是由多个分片组成的，也就是实现了数据分片，三节点三副本的集群，就像下图的样子：\n\n![image-20230928182025051](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182025051.png)\n\n\n\n反熵的目标是确保每个 DATA 节点拥有元信息指定的分片，而且不同节点上，同一分片组中的分片都没有差异。比如说，节点 A 要拥有分片 Shard1 和 Shard2，而且，节点 A 的 Shard1 和 Shard2，与节点 B、C 中的 Shard1 和 Shard2，是一样的。\n\n那么，在 DATA 节点上，存在哪些数据缺失的情况呢？也就说，我们需要解决哪些问题呢？\n\n我们将数据缺失，分为这样 2 种情况。\n\n缺失分片：也就是说，在某个节点上整个分片都丢失了。\n\n节点之间的分片不一致：也就是说，节点上分片都存在，但里面的数据不一样，有数据丢失的情况发生。\n\n第一种情况修复起来不复杂，我们只需要将分片数据，通过 RPC 通讯，从其他节点上拷贝过来就可以了：\n\n![image-20230928182038797](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182038797.png)\n\n\n\n你需要注意的是第二种情况，因为第二种情况修复起来要复杂一些。我们需要设计一个闭环的流程，按照一个顺序修复，执行完流程后，也就是实现了一致性了。具体是怎么设计的呢？\n\n它是按照一定顺序来修复节点的数据差异，先随机选择一个节点，然后循环修复，每个节点生成自己节点有、下一个节点没有的差异数据，发送给下一个节点，进行修复（为了方便演示，假设 Shard1、Shard2 在各节点上是不一致的）：\n\n\n\n![image-20230928182048814](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230928182048814.png)\n\n\n\n从图中你可以看到，数据修复的起始节点为节点 A，数据修复是按照顺时针顺序，循环修复的。需要你注意的是，最后节点 A 又对节点 B 的数据执行了一次数据修复操作，因为只有这样，节点 C 有、节点 B 缺失的差异数据，才会同步到节点 B 上。\n\n学到这里你可以看到，在实现反熵时，实现细节和最初算法的约定有些不同。比如，不是一个节点不断随机选择另一个节点，来修复副本上的熵，而是设计了一个闭环的流程，一次修复所有节点的副本数据不一致。\n\n为什么这么设计呢？因为我们希望能在一个确定的时间范围内实现数据副本的最终一致性，而不是基于随机性的概率，在一个不确定的时间范围内实现数据副本的最终一致性。\n\n这样做能减少数据不一致对监控视图影响的时长。而我希望你能注意到，技术是要活学活用的，要能根据场景特点权衡妥协，设计出最适合这个场景的系统功能。**最后需要你注意的是，因为反熵需要做一致性对比，很消耗系统性能，所以建议你将是否启用反熵功能、执行一致性检测的时间间隔等，做成可配置的，能在不同场景中按需使用。**\n\n## 内容小结\n\n以上就是本节课的全部内容了，本节课我主要带你了解了 Gossip 协议、如何在实际系统中实现反熵等。我希望你明确这样几个重点：\n\n作为一种异步修复、实现最终一致性的协议，反熵在存储组件中应用广泛，比如 Dynamo、InfluxDB、Cassandra，我希望你能彻底掌握反熵的实现方法，在后续工作中，需要实现最终一致性时，优先考虑反熵。\n\n因为谣言传播具有传染性，一个节点传给了另一个节点，另一个节点又将充当传播者，传染给其他节点，所以非常适合动态变化的分布式系统，比如 Cassandra 采用这种方式动态管理集群节点状态。\n\n在实际场景中，实现数据副本的最终一致性时，一般而言，直接邮寄的方式是一定要实现的，因为不需要做一致性对比，只是通过发送更新数据或缓存重传，来修复数据的不一致，性能损耗低。在存储组件中，节点都是已知的，一般采用反熵修复数据副本的一致性。当集群节点是变化的，或者集群节点数比较多时，这时要采用谣言传播的方式，同步更新数据，实现最终一致。\n\n## 课堂思考\n\n既然使用反熵实现最终一致性时，需要通过一致性检测发现数据副本的差异，如果每次做一致性检测时都做数据对比的话，肯定是比较消耗性能的，那有什么办法降低一致性检测时的性能消耗呢？欢迎在留言区分享你的看法，与我一同讨论。\n\n最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/208182\" > </iframe>\n\n","categories":["分布式协议与算法实战"]},{"title":"10丨一致哈希算法：如何分群，突破集群的“领导者”限制？","url":"/posts/4126319489.html","content":"\n\n\n你好，我是韩健。\n\n学完前面几讲后，有些同学可能有这样的疑问：如果我们通过 Raft 算法实现了 KV 存储，虽然领导者模型简化了算法实现和共识协商，但写请求只能限制在领导者节点上处理，导致了集群的接入性能约等于单机，那么随着业务发展，集群的性能可能就扛不住了，会造成系统过载和服务不可用，这时该怎么办呢？\n\n其实这是一个非常常见的问题。在我看来，这时我们就要通过分集群，突破单集群的性能限制了。\n\n说到这儿，有同学可能会说了，分集群还不简单吗？加个 Proxy 层，由 Proxy 层处理来自客户端的读写请求，接收到读写请求后，通过对 Key 做哈希找到对应的集群就可以了啊。\n\n是的，哈希算法的确是个办法，但它有个明显的缺点：当需要变更集群数时（比如从 2 个集群扩展为 3 个集群），这时大部分的数据都需要迁移，重新映射，数据的迁移成本是非常高的。那么如何解决哈希算法，数据迁移成本高的痛点呢？答案就是一致哈希（Consistent Hashing）。\n\n为了帮你更好地理解如何通过哈希寻址实现 KV 存储的分集群，我除了会带你了解哈希算法寻址问题的本质之外，还会讲一下一致哈希是如何解决哈希算法数据迁移成本高这个痛点，以及如何实现数据访问的冷热相对均匀。\n\n对你来说，学完本讲内容之后，不仅能理解一致哈希的原理，还能掌握通过一致哈希实现数据访问冷热均匀的实战能力。\n\n老规矩，在正式开始学习之前，我们先看一道思考题。\n\n假设我们有一个由 A、B、C 三个节点组成（为了方便演示，我使用节点来替代集群）的 KV 服务，每个节点存放不同的 KV 数据：\n\n![image-20230925160255582](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925160255582.png)\n\n那么，使用哈希算法实现哈希寻址时，到底有哪些问题呢？带着这个问题，让我们开始今天的内容吧。\n\n## 使用哈希算法有什么问题？\n\n通过哈希算法，每个 key 都可以寻址到对应的服务器，比如，查询 key 是 key-01，计算公式为 hash(key-01) % 3 ，经过计算寻址到了编号为 1 的服务器节点 A（就像图 2 的样子）。\n\n![image-20230925160309671](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925160309671.png)\n\n但如果服务器数量发生变化，基于新的服务器数量来执行哈希算法的时候，就会出现路由寻址失败的情况，Proxy 无法找到之前寻址到的那个服务器节点，这是为什么呢？\n\n想象一下，假如 3 个节点不能满足业务需要了，这时我们增加了一个节点，节点的数量从 3 变化为 4，那么之前的 hash(key-01) % 3 = 1，就变成了 hash(key-01) % 4 = X，因为取模运算发生了变化，所以这个 X 大概率不是 1（可能 X 为 2），这时你再查询，就会找不到数据了，因为 key-01 对应的数据，存储在节点 A 上，而不是节点 B：\n\n![image-20230925160323371](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925160323371.png)\n\n同样的道理，如果我们需要下线 1 个服务器节点（也就是缩容），也会存在类似的可能查询不到数据的问题。\n\n而解决这个问题的办法，在于我们要迁移数据，基于新的计算公式 hash(key-01) % 4 ，来重新对数据和节点做映射。需要你注意的是，数据的迁移成本是非常高的。\n\n为了便于你理解，我举个例子，对于 1000 万 key 的 3 节点 KV 存储，如果我们增加 1 个节点，变为 4 节点集群，则需要迁移 75% 的数据。\n\n```go\n$ go run ./hash.go  -keys 10000000 -nodes 3 -new-nodes 4\n\n74.999980%\n```\n\n\n\n**从示例代码的输出，你可以看到，迁移成本是非常高昂的，这在实际生产环境中也是无法想象的。**\n\n那我们如何通过一致哈希解决这个问题呢？\n\n## 如何使用一致哈希实现哈希寻址？\n\n一致哈希算法也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而一致哈希算法是对 2^32 进行取模运算。你可以想象下，一致哈希算法，将整个哈希值空间组织成一个虚拟的圆环，也就是哈希环：\n\n![image-20230925160408288](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925160408288.png)\n\n\n\n从图 4 中你可以看到，哈希环的空间是按顺时针方向组织的，圆环的正上方的点代表 0，0 点右侧的第一个点代表 1，以此类推，2、3、4、5、6……直到 2^32-1，也就是说 0 点左侧的第一个点代表 2^32-1。\n\n在一致哈希中，你可以通过执行哈希算法（为了演示方便，假设哈希算法函数为“c-hash()”），将节点映射到哈希环上，比如选择节点的主机名作为参数执行 c-hash()，那么每个节点就能确定其在哈希环上的位置了：\n\n![image-20230925160424730](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925160424730.png)\n\n当需要对指定 key 的值进行读写的时候，你可以通过下面 2 步进行寻址：\n\n首先，将 key 作为参数执行 c-hash() 计算哈希值，并确定此 key 在环上的位置；\n\n然后，从这个位置沿着哈希环顺时针“行走”，遇到的第一节点就是 key 对应的节点。\n\n为了帮助你更好地理解如何通过一致哈希进行寻址，我举个例子。假设 key-01、key-02、key-03 三个 key，经过哈希算法 c-hash() 计算后，在哈希环上的位置就像图 6 的样子：\n\n![image-20230925160439430](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925160439430.png)\n\n那么根据一致哈希算法，key-01 将寻址到节点 A，key-02 将寻址到节点 B，key-03 将寻址到节点 C。讲到这儿，你可能会问：“老韩，那一致哈希是如何避免哈希算法的问题呢？”\n\n别着急，接下来我分别以增加节点和移除节点为例，具体说一说一致哈希是如何避免上面的问题的。假设，现在有一个节点故障了（比如节点 C）：\n\n![image-20230925160453831](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925160453831.png)\n\n\n\n你可以看到，key-01 和 key-02 不会受到影响，只有 key-03 的寻址被重定位到 A。一般来说，在一致哈希算法中，如果某个节点宕机不可用了，那么受影响的数据仅仅是，会寻址到此节点和前一节点之间的数据。比如当节点 C 宕机了，受影响的数据是会寻址到节点 B 和节点 C 之间的数据（例如 key-03），寻址到其他哈希环空间的数据（例如 key-01），不会受到影响。\n\n那如果此时集群不能满足业务的需求，需要扩容一个节点（也就是增加一个节点，比如 D）：\n\n![image-20230925160506970](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925160506970.png)\n\n你可以看到，key-01、key-02 不受影响，只有 key-03 的寻址被重定位到新节点 D。一般而言，在一致哈希算法中，如果增加一个节点，受影响的数据仅仅是，会寻址到新节点和前一节点之间的数据，其它数据也不会受到影响。\n\n让我们一起来看一个例子。使用一致哈希的话，对于 1000 万 key 的 3 节点 KV 存储，如果我们增加 1 个节点，变为 4 节点集群，只需要迁移 24.3% 的数据：\n\n```go\n$ go run ./consistent-hash.go  -keys 10000000 -nodes 3 -new-nodes 4\n\n24.301550% \n```\n\n\n\n**你看，使用了一致哈希后，我们需要迁移的数据量仅为使用哈希算法时的三分之一，是不是大大提升效率了呢？**\n\n总的来说，使用了一致哈希算法后，扩容或缩容的时候，都只需要重定位环空间中的一小部分数据。**也就是说，一致哈希算法具有较好的容错性和可扩展性。**\n\n\n\n**需要你注意的是，在哈希寻址中常出现这样的问题：**客户端访问请求集中在少数的节点上，出现了有些机器高负载，有些机器低负载的情况，那么在一致哈希中，有什么办法能让数据访问分布的比较均匀呢？答案就是虚拟节点。\n\n在一致哈希中，如果节点太少，容易因为节点分布不均匀造成数据访问的冷热不均，也就是说大多数访问请求都会集中少量几个节点上：\n\n![image-20230925160534980](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925160534980.png)\n\n\n\n你能从图中看到，虽然有 3 个节点，但访问请求主要集中的节点 A 上。**那如何通过虚拟节点解决冷热不均的问题呢？**\n\n其实，就是对每一个服务器节点计算多个哈希值，在每个计算结果位置上，都放置一个虚拟节点，并将虚拟节点映射到实际节点。比如，可以在主机名的后面增加编号，分别计算 “Node-A-01”“Node-A-02”“Node-B-01”“Node-B-02”“Node-C-01”“Node-C-02”的哈希值，于是形成 6 个虚拟节点：\n\n![image-20230925160547824](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925160547824.png)\n\n\n\n你可以从图中看到，增加了节点后，节点在哈希环上的分布就相对均匀了。这时，如果有访问请求寻址到“Node-A-01”这个虚拟节点，将被重定位到节点 A。你看，这样我们就解决了冷热不均的问题。\n\n最后我想说的是，可能有同学已经发现了，当节点数越多的时候，使用哈希算法时，需要迁移的数据就越多，使用一致哈希时，需要迁移的数据就越少：\n\n```go\n$ go run ./hash.go  -keys 10000000 -nodes 3 -new-nodes 4\n74.999980%\n$ go run ./hash.go  -keys 10000000 -nodes 10 -new-nodes 11\n90.909000%\n$ go run ./consistent-hash.go  -keys 10000000 -nodes 3 -new-nodes 4\n24.301550%\n$ go run ./consistent-hash.go  -keys 10000000 -nodes 10 -new-nodes 11\n6.479330% \n```\n\n从示例代码的输出中你可以看到，当我们向 10 个节点集群中增加节点时，**如果使用了哈希算法，需要迁移高达 90.91% 的数据，使用一致哈希的话，只需要迁移 6.48% 的数据。**\n\n我希望你能注意到这个规律，使用一致哈希实现哈希寻址时，可以通过增加节点数降低节点宕机对整个集群的影响，以及故障恢复时需要迁移的数据量。后续在需要时，你可以通过增加节点数来提升系统的容灾能力和故障恢复效率。\n\n## 内容小结\n\n以上就是本节课的全部内容了，本节课我主要带你了解了哈希算法的缺点、一致哈希的原理等内容。我希望你明确这样几个重点。\n\n一致哈希是一种特殊的哈希算法，在使用一致哈希算法后，节点增减变化时只影响到部分数据的路由寻址，也就是说我们只要迁移部分数据，就能实现集群的稳定了。\n\n当节点数较少时，可能会出现节点在哈希环上分布不均匀的情况。这样每个节点实际占据环上的区间大小不一，最终导致业务对节点的访问冷热不均。需要你注意的是，这个问题可以通过引入更多的虚拟节点来解决。\n\n最后我想说的是，一致哈希本质上是一种路由寻址算法，适合简单的路由寻址场景。比如在 KV 存储系统内部，它的特点是简单，不需要维护路由信息。\n\n## 课堂思考\n\nRaft 集群具有容错能力，能容忍少数的节点故障，那么在多个 Raft 集群组成的 KV 系统中，如何设计一致哈希，实现当某个集群的节点出现了故障时，整个系统还能稳定运行呢？欢迎在留言区分享你的看法，与我一同讨论。\n\n最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。\n\n\n\n\n\n<iframe width=\"100%\" frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/207426\" > </iframe>","categories":["分布式协议与算法实战"]},{"title":"09丨Raft算法（三）：如何解决成员变更的问题？","url":"/posts/3109798557.html","content":"\n\n\n你好，我是韩健。\n\n在日常工作中，你可能会遇到服务器故障的情况，这时你就需要替换集群中的服务器。如果遇到需要改变数据副本数的情况，则需要增加或移除集群中的服务器。总的来说，在日常工作中，集群中的服务器数量是会发生变化的。\n\n讲到这儿，也许你会问：“老韩，Raft 是共识算法，对集群成员进行变更时（比如增加 2 台服务器），会不会因为集群分裂，出现 2 个领导者呢？”\n\n在我看来，的确会出现这个问题，因为 Raft 的领导者选举，建立在“大多数”的基础之上，那么当成员变更时，集群成员发生了变化，就可能同时存在新旧配置的 2 个“大多数”，出现 2 个领导者，破坏了 Raft 集群的领导者唯一性，影响了集群的运行。\n\n而关于成员变更，不仅是 Raft 算法中比较难理解的一部分，非常重要，也是 Raft 算法中唯一被优化和改进的部分。比如，最初实现成员变更的是联合共识（Joint Consensus），但这个方法实现起来难，后来 Raft 的作者就提出了一种改进后的方法，单节点变更（single-server changes）。\n\n为了帮你掌握这块内容，今天我除了带你了解成员变更问题的本质之外，还会讲一下如何通过单节点变更的方法，解决成员变更的问题。学完本讲内容之后，你不仅能理解成员变更的问题和单节点变更的原理，也能更好地理解 Raft 源码实现，掌握解决成员变更问题的方法。\n\n在开始今天内容之前，我先介绍一下“配置”这个词儿。因为常听到有同学说，自己不理解配置（Configuration）的含义，从而不知道如何理解论文中的成员变更。\n\n的确，配置是成员变更中一个非常重要的概念，我建议你这么理解：它就是在说集群是哪些节点组成的，是集群各节点地址信息的集合。比如节点 A、B、C 组成的集群，那么集群的配置就是[A, B, C]集合。\n\n理解了这一点之后，咱们先来看一道思考题。\n\n假设我们有一个由节点 A、B、C 组成的 Raft 集群，现在我们需要增加数据副本数，增加 2 个副本（也就是增加 2 台服务器），扩展为由节点 A、B、C、D、E， 5 个节点组成的新集群：\n\n![image-20230927183622728](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183622728.png)\n\n\n\n那么 Raft 算法是如何保障在集群配置变更时，集群能稳定运行，不出现 2 个领导者呢？带着这个问题，我们正式进入今天的学习。\n\n老话说得好，“认识问题，才能解决问题”。为了帮你更好地理解单节点变更的方法，我们先来看一看，成员变更时，到底会出现什么样的问题？\n\n## 成员变更的问题\n\n在我看来，在集群中进行成员变更的最大风险是，可能会同时出现 2 个领导者。比如在进行成员变更时，节点 A、B 和 C 之间发生了分区错误，节点 A、B 组成旧配置中的“大多数”，也就是变更前的 3 节点集群中的“大多数”，那么这时的领导者（节点 A）依旧是领导者。\n\n另一方面，节点 C 和新节点 D、E 组成了新配置的“大多数”，也就是变更后的 5 节点集群中的“大多数”，它们可能会选举出新的领导者（比如节点 C）。那么这时，就出现了同时存在 2 个领导者的情况。\n\n![image-20230927183633678](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183633678.png)\n\n如果出现了 2 个领导者，那么就违背了“领导者的唯一性”的原则，进而影响到集群的稳定运行。你要如何解决这个问题呢？也许有的同学想到了一个解决方法。\n\n因为我们在启动集群时，配置是固定的，不存在成员变更，在这种情况下，Raft 的领导者选举能保证只有一个领导者。也就是说，这时不会出现多个领导者的问题，那我可以先将集群关闭再启动新集群啊。也就是先把节点 A、B、C 组成的集群关闭，然后再启动节点 A、B、C、D、E 组成的新集群。\n\n**在我看来，这个方法不可行。** 为什么呢？因为你每次变更都要重启集群，意味着在集群变更期间服务不可用，肯定不行啊，太影响用户体验了。想象一下，你正在玩王者荣耀，时不时弹出一个对话框通知你：系统升级，游戏暂停 3 分钟。这体验糟糕不糟糕？\n\n既然这种方法影响用户体验，根本行不通，那到底怎样解决成员变更的问题呢？**最常用的方法就是单节点变更。**\n\n## 如何通过单节点变更解决成员变更的问题？\n\n单节点变更，就是通过一次变更一个节点实现成员变更。如果需要变更多个节点，那你需要执行多次单节点变更。比如将 3 节点集群扩容为 5 节点集群，这时你需要执行 2 次单节点变更，先将 3 节点集群变更为 4 节点集群，然后再将 4 节点集群变更为 5 节点集群，就像下图的样子。\n\n![image-20230927183646282](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183646282.png)\n\n\n\n现在，让我们回到开篇的思考题，看看如何用单节点变更的方法，解决这个问题。为了演示方便，我们假设节点 A 是领导者：\n\n\n\n![image-20230927183656268](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183656268.png)\n\n\n\n目前的集群配置为[A, B, C]，我们先向集群中加入节点 D，这意味着新配置为[A, B, C, D]。成员变更，是通过这么两步实现的：\n\n第一步，领导者（节点 A）向新节点（节点 D）同步数据；\n\n第二步，领导者（节点 A）将新配置[A, B, C, D]作为一个日志项，复制到新配置中所有节点（节点 A、B、C、D）上，然后将新配置的日志项提交到本地状态机，完成单节点变更。\n\n![image-20230927183706912](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183706912.png)\n\n\n\n在变更完成后，现在的集群配置就是[A, B, C, D]，我们再向集群中加入节点 E，也就是说，新配置为[A, B, C, D, E]。成员变更的步骤和上面类似：\n\n第一步，领导者（节点 A）向新节点（节点 E）同步数据；\n\n第二步，领导者（节点 A）将新配置[A, B, C, D, E]作为一个日志项，复制到新配置中的所有节点（A、B、C、D、E）上，然后再将新配置的日志项提交到本地状态机，完成单节点变更。\n\n![image-20230927183717172](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183717172.png)\n\n\n\n这样一来，我们就通过一次变更一个节点的方式，完成了成员变更，保证了集群中始终只有一个领导者，而且集群也在稳定运行，持续提供服务。\n\n我想说的是，在正常情况下，**不管旧的集群配置是怎么组成的，旧配置的“大多数”和新配置的“大多数”都会有一个节点是重叠的。** 也就是说，不会同时存在旧配置和新配置 2 个“大多数”：\n\n\n\n![image-20230927183733150](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183733150.png)\n\n![image-20230927183739277](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183739277.png)\n\n![image-20230927183744759](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183744759.png)\n\n![image-20230927183750026](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183750026.png)\n\n从上图中你可以看到，不管集群是偶数节点，还是奇数节点，不管是增加节点，还是移除节点，新旧配置的“大多数”都会存在重叠（图中的橙色节点）。\n\n需要你注意的是，在分区错误、节点故障等情况下，如果我们并发执行单节点变更，那么就可能出现一次单节点变更尚未完成，新的单节点变更又在执行，导致集群出现 2 个领导者的情况。\n\n如果你遇到这种情况，可以在领导者启动时，创建一个 NO_OP 日志项（也就是空日志项），只有当领导者将 NO_OP 日志项提交后，再执行成员变更请求。这个解决办法，你记住就可以了，可以自己在课后试着研究下。具体的实现，可参考 Hashicorp Raft 的源码，也就是 runLeader() 函数中：\n\n```\nnoop := &logFuture{\n        log: Log{\n               Type: LogNoop,\n        },\n}\nr.dispatchLogs([]*logFuture{noop})\n```\n\n当然，有的同学会好奇“联合共识”，在我看来，因为它难以实现，很少被 Raft 实现采用。比如，除了 Logcabin 外，未见到其他常用 Raft 实现采用了它，所以这里我就不多说了。如果你有兴趣，可以自己去阅读论文，加深了解。\n\n## 内容小结\n\n以上就是本节课的全部内容了，本节课我主要带你了解了成员变更的问题和单节点变更的方法，我希望你明确这样几个重点。\n\n成员变更的问题，主要在于进行成员变更时，可能存在新旧配置的 2 个“大多数”，导致集群中同时出现两个领导者，破坏了 Raft 的领导者的唯一性原则，影响了集群的稳定运行。\n\n单节点变更是利用“一次变更一个节点，不会同时存在旧配置和新配置 2 个‘大多数’”的特性，实现成员变更。\n\n因为联合共识实现起来复杂，不好实现，所以绝大多数 Raft 算法的实现，采用的都是单节点变更的方法（比如 Etcd、Hashicorp Raft）。其中，Hashicorp Raft 单节点变更的实现，是由 Raft 算法的作者迭戈·安加罗（Diego Ongaro）设计的，很有参考价值。\n\n除此之外，考虑到本节课是 Raft 算法的最后一讲，所以在这里，我想多说几句，帮助你更好地理解 Raft 算法。\n\n有很多同学把 Raft 当成一致性算法，其实 Raft 不是一致性算法而是共识算法，是一个 Multi-Paxos 算法，实现的是如何就一系列值达成共识。并且，Raft 能容忍少数节点的故障。虽然 Raft 算法能实现强一致性，也就是线性一致性（Linearizability），但需要客户端协议的配合。在实际场景中，我们一般需要根据场景特点，在一致性强度和实现复杂度之间进行权衡。比如 Consul 实现了三种一致性模型。\n\ndefault：客户端访问领导者节点执行读操作，领导者确认自己处于稳定状态时（在 leader leasing 时间内），返回本地数据给客户端，否则返回错误给客户端。在这种情况下，客户端是可能读到旧数据的，比如此时发生了网络分区错误，新领导者已经更新过数据，但因为网络故障，旧领导者未更新数据也未退位，仍处于稳定状态。\n\nconsistent：客户端访问领导者节点执行读操作，领导者在和大多数节点确认自己仍是领导者之后返回本地数据给客户端，否则返回错误给客户端。在这种情况下，客户端读到的都是最新数据。\n\nstale：从任意节点读数据，不局限于领导者节点，客户端可能会读到旧数据。\n\n一般而言，在实际工程中，Consul 的 consistent 就够用了，可以不用线性一致性，只要能保证写操作完成后，每次读都能读到最新值就可以了。比如为了实现冥等操作，我们使用一个编号 (ID) 来唯一标记一个操作，并使用一个状态字段（nil/done）来标记操作是否已经执行，那么只要我们能保证设置了 ID 对应状态值为 done 后，能立即和一直读到最新状态值就可以了，也就通过防止操作的重复执行，实现了冥等性。\n\n总的来说，Raft 算法能很好地处理绝大部分场景的一致性问题，我推荐你在设计分布式系统时，优先考虑 Raft 算法，当 Raft 算法不能满足现有场景需求时，再去调研其他共识算法。\n\n比如我负责过多个 QQ 后台的海量服务分布式系统，其中配置中心、名字服务以及时序数据库的 META 节点，采用了 Raft 算法。在设计时序数据库的 DATA 节点一致性时，基于水平扩展、性能和数据完整性等考虑，就没采用 Raft 算法，而是采用了 Quorum NWR、失败重传、反熵等机制。这样安排不仅满足了业务的需求，还通过尽可能采用最终一致性方案的方式，实现系统的高性能，降低了成本。\n\n## 课堂思考\n\n在最后，我给你留了一个思考题，强领导者模型会限制集群的写性能，那你想想看，有什么办法能突破 Raft 集群的写性能瓶颈呢？欢迎在留言区分享你的看法，与我一同讨论。\n\n最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。\n\n\n\n\n\n<iframe width=\"100%\" frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/206274\" > </iframe>","categories":["分布式协议与算法实战"]},{"title":"08丨Raft算法（二）：如何复制日志？","url":"/posts/2671809515.html","content":"\n\n\n你好，我是韩健。\n\n通过上一讲的学习，你应该知道 Raft 除了能实现一系列值的共识之外，还能实现各节点日志的一致，不过你也许会有这样的疑惑：“什么是日志呢？它和我的业务数据有什么关系呢？”\n\n想象一下，一个木筏（Raft）是由多根整齐一致的原木（Log）组成的，而原木又是由木质材料组成，所以你可以认为日志是由多条日志项（Log entry）组成的，如果把日志比喻成原木，那么日志项就是木质材料。\n\n在 Raft 算法中，副本数据是以日志的形式存在的，领导者接收到来自客户端写请求后，处理写请求的过程就是一个复制和提交日志项的过程。\n\n那 Raft 是如何复制日志的呢？又如何实现日志的一致的呢？这些内容是 Raft 中非常核心的内容，也是我今天讲解的重点，我希望你不懂就问，多在留言区提出你的想法。首先，咱们先来理解日志，这是你掌握如何复制日志、实现日志一致的基础。\n\n## 如何理解日志？\n\n刚刚我提到，副本数据是以日志的形式存在的，日志是由日志项组成，日志项究竟是什么样子呢？\n\n其实，日志项是一种数据格式，它主要包含用户指定的数据，也就是指令（Command），还包含一些附加信息，比如索引值（Log index）、任期编号（Term）。那你该怎么理解这些信息呢？\n\n![image-20230927183344759](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183344759.png)\n\n指令：一条由客户端请求指定的、状态机需要执行的指令。你可以将指令理解成客户端指定的数据。\n\n索引值：日志项对应的整数索引值。它其实就是用来标识日志项的，是一个连续的、单调递增的整数号码。\n\n任期编号：创建这条日志项的领导者的任期编号。\n\n从图中你可以看到，一届领导者任期，往往有多条日志项。而且日志项的索引值是连续的，这一点你需要注意。\n\n讲到这儿你可能会问：不是说 Raft 实现了各节点间日志的一致吗？那为什么图中 4 个跟随者的日志都不一样呢？日志是怎么复制的呢？又该如何实现日志的一致呢？别着急，接下来咱们就来解决这几个问题。先来说说如何复制日志。\n\n## 如何复制日志？\n\n你可以把 Raft 的日志复制理解成一个优化后的二阶段提交（将二阶段优化成了一阶段），减少了一半的往返消息，也就是降低了一半的消息延迟。那日志复制的具体过程是什么呢？\n\n首先，领导者进入第一阶段，通过日志复制（AppendEntries）RPC 消息，将日志项复制到集群其他节点上。\n\n接着，如果领导者接收到大多数的“复制成功”响应后，它将日志项提交到它的状态机，并返回成功给客户端。如果领导者没有接收到大多数的“复制成功”响应，那么就返回错误给客户端。\n\n学到这里，有同学可能有这样的疑问了，领导者将日志项提交到它的状态机，怎么没通知跟随者提交日志项呢？\n\n这是 Raft 中的一个优化，领导者不直接发送消息通知其他节点提交指定日志项。因为领导者的日志复制 RPC 消息或心跳消息，包含了当前最大的，将会被提交的日志项索引值。所以通过日志复制 RPC 消息或心跳消息，跟随者就可以知道领导者的日志提交位置信息。\n\n因此，当其他节点接受领导者的心跳消息，或者新的日志复制 RPC 消息后，就会将这条日志项提交到它的状态机。而这个优化，降低了处理客户端请求的延迟，将二阶段提交优化为了一段提交，降低了一半的消息延迟。\n\n为了帮你理解，我画了一张过程图，然后再带你走一遍这个过程，这样你可以更加全面地掌握日志复制。\n\n![image-20230927183359655](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183359655.png)\n\n\n\n接收到客户端请求后，领导者基于客户端请求中的指令，创建一个新日志项，并附加到本地日志中。\n\n领导者通过日志复制 RPC，将新的日志项复制到其他的服务器。\n\n当领导者将日志项，成功复制到大多数的服务器上的时候，领导者会将这条日志项提交到它的状态机中。\n\n领导者将执行的结果返回给客户端。\n\n当跟随者接收到心跳信息，或者新的日志复制 RPC 消息后，如果跟随者发现领导者已经提交了某条日志项，而它还没提交，那么跟随者就将这条日志项提交到本地的状态机中。\n\n不过，这是一个理想状态下的日志复制过程。在实际环境中，复制日志的时候，你可能会遇到进程崩溃、服务器宕机等问题，这些问题会导致日志不一致。那么在这种情况下，Raft 算法是如何处理不一致日志，实现日志的一致的呢？\n\n## 如何实现日志的一致？\n\n在 Raft 算法中，领导者通过强制跟随者直接复制自己的日志项，处理不一致日志。也就是说，Raft 是通过以领导者的日志为准，来实现各节点日志的一致的。具体有 2 个步骤。\n\n首先，领导者通过日志复制 RPC 的一致性检查，找到跟随者节点上，与自己相同日志项的最大索引值。也就是说，这个索引值之前的日志，领导者和跟随者是一致的，之后的日志是不一致的了。\n\n然后，领导者强制跟随者更新覆盖的不一致日志项，实现日志的一致。\n\n我带你详细地走一遍这个过程（为了方便演示，我们引入 2 个新变量）。\n\nPrevLogEntry：表示当前要复制的日志项，前面一条日志项的索引值。比如在图中，如果领导者将索引值为 8 的日志项发送给跟随者，那么此时 PrevLogEntry 值为 7。\n\nPrevLogTerm：表示当前要复制的日志项，前面一条日志项的任期编号，比如在图中，如果领导者将索引值为 8 的日志项发送给跟随者，那么此时 PrevLogTerm 值为 4。\n\n![image-20230927183424700](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183424700.png)\n\n领导者通过日志复制 RPC 消息，发送当前最新日志项到跟随者（为了演示方便，假设当前需要复制的日志项是最新的），这个消息的 PrevLogEntry 值为 7，PrevLogTerm 值为 4。\n\n如果跟随者在它的日志中，找不到与 PrevLogEntry 值为 7、PrevLogTerm 值为 4 的日志项，也就是说它的日志和领导者的不一致了，那么跟随者就会拒绝接收新的日志项，并返回失败信息给领导者。\n\n这时，领导者会递减要复制的日志项的索引值，并发送新的日志项到跟随者，这个消息的 PrevLogEntry 值为 6，PrevLogTerm 值为 3。\n\n如果跟随者在它的日志中，找到了 PrevLogEntry 值为 6、PrevLogTerm 值为 3 的日志项，那么日志复制 RPC 返回成功，这样一来，领导者就知道在 PrevLogEntry 值为 6、PrevLogTerm 值为 3 的位置，跟随者的日志项与自己相同。\n\n领导者通过日志复制 RPC，复制并更新覆盖该索引值之后的日志项（也就是不一致的日志项），最终实现了集群各节点日志的一致。\n\n从上面步骤中你可以看到，领导者通过日志复制 RPC 一致性检查，找到跟随者节点上与自己相同日志项的最大索引值，然后复制并更新覆盖该索引值之后的日志项，实现了各节点日志的一致。需要你注意的是，跟随者中的不一致日志项会被领导者的日志覆盖，而且领导者从来不会覆盖或者删除自己的日志。\n\n## 内容小结\n\n本节课我主要带你了解了在 Raft 中什么是日志、如何复制日志、以及如何处理不一致日志等内容。我希望你明确这样几个重点。\n\n在 Raft 中，副本数据是以日志的形式存在的，其中日志项中的指令表示用户指定的数据。\n\n兰伯特的 Multi-Paxos 不要求日志是连续的，但在 Raft 中日志必须是连续的。而且在 Raft 中，日志不仅是数据的载体，日志的完整性还影响领导者选举的结果。也就是说，日志完整性最高的节点才能当选领导者。\n\nRaft 是通过以领导者的日志为准，来实现日志的一致的。\n\n学完本节课你可以看到，值的共识和日志的一致都是由领导者决定的，领导者的唯一性很重要，那么如果我们需要对集群进行扩容或缩容，比如将 3 节点集群扩容为 5 节点集群，这时候是可能同时出现两个领导者的。这是为什么呢？在 Raft 中，又是如何解决这个问题的呢？我会在下一讲带你了解。\n\n## 课堂思考\n\n我提到，领导者接收到大多数的“复制成功”响应后，就会将日志提交到它自己的状态机，然后返回“成功”响应客户端。如果此时有个节点不在“大多数”中，也就是说它接收日志项失败，那么在这种情况下，Raft 会如何处理实现日志的一致呢？欢迎在留言区分享你的看法，与我一同讨论。\n\n最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。\n\n\n\n\n\n<iframe width=\"100%\" frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/205784\" > </iframe>","categories":["分布式协议与算法实战"]},{"title":"07丨Raft算法（一）：如何选举领导者？","url":"/posts/4252620551.html","content":"\n\n\n你好，我是韩健。\n\n通过前两节课，我带你打卡了 Paxos 算法，今天我想和你聊聊最常用的共识算法，Raft 算法。\n\nRaft 算法属于 Multi-Paxos 算法，它是在兰伯特 Multi-Paxos 思想的基础上，做了一些简化和限制，比如增加了日志必须是连续的，只支持领导者、跟随者和候选人三种状态，在理解和算法实现上都相对容易许多。\n\n**除此之外，Raft 算法是现在分布式系统开发首选的共识算法。**绝大多数选用 Paxos 算法的系统（比如 Cubby、Spanner）都是在 Raft 算法发布前开发的，当时没得选；而全新的系统大多选择了 Raft 算法（比如 Etcd、Consul、CockroachDB）。\n\n对你来说，掌握这个算法，可以得心应手地处理绝大部分场景的容错和一致性需求，比如分布式配置系统、分布式 NoSQL 存储等等，轻松突破系统的单机限制。\n\n**如果要用一句话概括 Raft 算法，我觉得是这样的：从本质上说，Raft 算法是通过一切以领导者为准的方式，实现一系列值的共识和各节点日志的一致。**这句话比较抽象，我来做个比喻，领导者就是 Raft 算法中的霸道总裁，通过霸道的“一切以我为准”的方式，决定了日志中命令的值，也实现了各节点日志的一致。\n\n我会用三讲的时间，分别以领导者选举、日志复制、成员变更为核心，讲解 Raft 算法的原理，在实战篇中，会带你进一步剖析 Raft 算法的实现，介绍基于 Raft 算法的分布式系统开发实战。那么我希望从原理到实战，在帮助你掌握分布式系统架构设计技巧和开发实战能力的同时，加深你对 Raft 算法的理解。\n\n在课程开始之前，我们先来看一道思考题。\n\n假设我们有一个由节点 A、B、C 组成的 Raft 集群（如图所示），因为 Raft 算法一切以领导者为准，所以如果集群中出现了多个领导者，就会出现不知道谁来做主的问题。在这样一个有多个节点的集群中，在节点故障、分区错误等异常情况下，Raft 算法如何保证在同一个时间，集群中只有一个领导者呢？带着这个问题，我们正式进入今天的学习。\n\n![image-20230927182954489](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927182954489.png)\n\n既然要选举领导者，那要从哪些成员中选举呢？除了领导者，Raft 算法还支持哪些成员身份呢？这部分内容是你需要掌握的，最基础的背景知识。\n\n## 有哪些成员身份？\n\n成员身份，又叫做服务器节点状态，**Raft 算法支持领导者（Leader）、跟随者（Follower）和候选人（Candidate） 3 种状态。**为了方便讲解，我们使用不同的图形表示不同的状态。在任何时候，每一个服务器节点都处于这 3 个状态中的 1 个。\n\n![image-20230927183008266](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183008266.png)\n\n\n\n跟随者：就相当于普通群众，默默地接收和处理来自领导者的消息，当等待领导者心跳信息超时的时候，就主动站出来，推荐自己当候选人。\n\n候选人：候选人将向其他节点发送请求投票（RequestVote）RPC 消息，通知其他节点来投票，如果赢得了大多数选票，就晋升当领导者。\n\n领导者：蛮不讲理的霸道总裁，一切以我为准，平常的主要工作内容就是 3 部分，处理写请求、管理日志复制和不断地发送心跳信息，通知其他节点“我是领导者，我还活着，你们现在不要发起新的选举，找个新领导者来替代我。”\n\n**需要你注意的是，Raft 算法是强领导者模型，集群中只能有一个“霸道总裁”。**\n\n## 选举领导者的过程\n\n那么这三个成员是怎么选出来领导者的呢？为了方便你理解，我以图例的形式演示一个典型的领导者选举过程。\n\n首先，在初始状态下，集群中所有的节点都是跟随者的状态。\n\n![image-20230927183031184](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183031184.png)\n\nRaft 算法实现了随机超时时间的特性。也就是说，每个节点等待领导者节点心跳信息的超时时间间隔是随机的。通过上面的图片你可以看到，集群中没有领导者，而节点 A 的等待超时时间最小（150ms），它会最先因为没有等到领导者的心跳信息，发生超时。\n\n这个时候，节点 A 就增加自己的任期编号，并推举自己为候选人，先给自己投上一张选票，然后向其他节点发送请求投票 RPC 消息，请它们选举自己为领导者。\n\n![image-20230927183046110](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183046110.png)\n\n\n\n如果其他节点接收到候选人 A 的请求投票 RPC 消息，在编号为 1 的这届任期内，也还没有进行过投票，那么它将把选票投给节点 A，并增加自己的任期编号。\n\n\n\n![image-20230927183059248](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183059248.png)\n\n\n\n如果候选人在选举超时时间内赢得了大多数的选票，那么它就会成为本届任期内新的领导者。\n\n\n\n![image-20230927183110727](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183110727.png)\n\n\n\n节点 A 当选领导者后，他将周期性地发送心跳消息，通知其他服务器我是领导者，阻止跟随者发起新的选举，篡权。\n\n\n\n![image-20230927183122907](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183122907.png)\n\n\n\n讲到这儿，你是不是发现领导者选举很容易理解？与现实中的议会选举也蛮类似？当然，你可能还是对一些细节产生一些疑问：\n\n节点间是如何通讯的呢？\n\n什么是任期呢？\n\n选举有哪些规则？\n\n随机超时时间又是什么？\n\n## 选举过程四连问\n\n老话说，细节是魔鬼。这些细节也是很多同学在学习 Raft 算法的时候比较难掌握的，所以我认为有必要具体分析一下。咱们一步步来，先来看第一个问题。\n\n#### 节点间如何通讯？\n\n在 Raft 算法中，服务器节点间的沟通联络采用的是远程过程调用（RPC），在领导者选举中，需要用到这样两类的 RPC：\n\n1. 请求投票（RequestVote）RPC，是由候选人在选举期间发起，通知各节点进行投票；\n2. 日志复制（AppendEntries）RPC，是由领导者发起，用来复制日志和提供心跳消息。\n\n我想强调的是，日志复制 RPC 只能由领导者发起，这是实现强领导者模型的关键之一，希望你能注意这一点，后续能更好地理解日志复制，理解日志的一致是怎么实现的。\n\n#### 什么是任期？\n\n我们知道，议会选举中的领导者是有任期的，领导者任命到期后，要重新开会再次选举。Raft 算法中的领导者也是有任期的，每个任期由单调递增的数字（任期编号）标识，比如节点 A 的任期编号是 1。任期编号是随着选举的举行而变化的，这是在说下面几点。\n\n跟随者在等待领导者心跳信息超时后，推举自己为候选人时，会增加自己的任期号，比如节点 A 的当前任期编号为 0，那么在推举自己为候选人时，会将自己的任期编号增加为 1。\n\n如果一个服务器节点，发现自己的任期编号比其他节点小，那么它会更新自己的编号到较大的编号值。比如节点 B 的任期编号是 0，当收到来自节点 A 的请求投票 RPC 消息时，因为消息中包含了节点 A 的任期编号，且编号为 1，那么节点 B 将把自己的任期编号更新为 1。\n\n我想强调的是，与现实议会选举中的领导者的任期不同，Raft 算法中的任期不只是时间段，而且任期编号的大小，会影响领导者选举和请求的处理。\n\n在 Raft 算法中约定，如果一个候选人或者领导者，发现自己的任期编号比其他节点小，那么它会立即恢复成跟随者状态。比如分区错误恢复后，任期编号为 3 的领导者节点 B，收到来自新领导者的，包含任期编号为 4 的心跳消息，那么节点 B 将立即恢复成跟随者状态。\n\n还约定如果一个节点接收到一个包含较小的任期编号值的请求，那么它会直接拒绝这个请求。比如节点 C 的任期编号为 4，收到包含任期编号为 3 的请求投票 RPC 消息，那么它将拒绝这个消息。\n\n在这里，你可以看到，Raft 算法中的任期比议会选举中的任期要复杂。同样，在 Raft 算法中，选举规则的内容也会比较多。\n\n#### 选举有哪些规则\n\n在议会选举中，比成员的身份、领导者的任期还要重要的就是选举的规则，比如一人一票、弹劾制度等。“无规矩不成方圆”，在 Raft 算法中，也约定了选举规则，主要有这样几点。\n\n1、领导者周期性地向所有跟随者发送心跳消息（即不包含日志项的日志复制 RPC 消息），通知大家我是领导者，阻止跟随者发起新的选举。\n\n2、如果在指定时间内，跟随者没有接收到来自领导者的消息，那么它就认为当前没有领导者，推举自己为候选人，发起领导者选举。\n\n3、在一次选举中，赢得大多数选票的候选人，将晋升为领导者。\n\n4、在一个任期内，领导者一直都会是领导者，直到它自身出现问题（比如宕机），或者因为网络延迟，其他节点发起一轮新的选举。\n\n5、在一次选举中，每一个服务器节点最多会对一个任期编号投出一张选票，并且按照“先来先服务”的原则进行投票。比如节点 C 的任期编号为 3，先收到了 1 个包含任期编号为 4 的投票请求（来自节点 A），然后又收到了 1 个包含任期编号为 4 的投票请求（来自节点 B）。那么节点 C 将会把唯一一张选票投给节点 A，当再收到节点 B 的投票请求 RPC 消息时，对于编号为 4 的任期，已没有选票可投了。\n\n\n\n![image-20230927183142579](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183142579.png)\n\n当任期编号相同时，日志完整性高的跟随者（也就是最后一条日志项对应的任期编号值更大，索引号更大），拒绝投票给日志完整性低的候选人。比如节点 B、C 的任期编号都是 3，节点 B 的最后一条日志项对应的任期编号为 3，而节点 C 为 2，那么当节点 C 请求节点 B 投票给自己时，节点 B 将拒绝投票。\n\n![image-20230927183215748](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230927183215748.png)\n\n\n\n我想强调的是，选举是跟随者发起的，推举自己为候选人；大多数选票是指集群成员半数以上的选票；大多数选票规则的目标，是为了保证在一个给定的任期内最多只有一个领导者。\n\n其实在选举中，除了选举规则外，我们还需要避免一些会导致选举失败的情况，比如同一任期内，多个候选人同时发起选举，导致选票被瓜分，选举失败。那么在 Raft 算法中，如何避免这个问题呢？答案就是随机超时时间。\n\n#### 如何理解随机超时时间\n\n在议会选举中，常出现未达到指定票数，选举无效，需要重新选举的情况。在 Raft 算法的选举中，也存在类似的问题，那它是如何处理选举无效的问题呢？\n\n其实，Raft 算法巧妙地使用随机选举超时时间的方法，把超时时间都分散开来，在大多数情况下只有一个服务器节点先发起选举，而不是同时发起选举，这样就能减少因选票瓜分导致选举失败的情况。\n\n我想强调的是，**在 Raft 算法中，随机超时时间是有 2 种含义的，这里是很多同学容易理解出错的地方，需要你注意一下：**\n\n1. 跟随者等待领导者心跳信息超时的时间间隔，是随机的；\n2. 当没有候选人赢得过半票数，选举无效了，这时需要等待一个随机时间间隔，也就是说，等待选举超时的时间间隔，是随机的。\n\n## 内容小结\n\n以上就是本节课的全部内容了，本节课我主要带你了解了 Raft 算法的特点、领导者选举等。我希望你明确这样几个重点。\n\nRaft 算法和兰伯特的 Multi-Paxos 不同之处，主要有 2 点。首先，在 Raft 中，不是所有节点都能当选领导者，只有日志最完整的节点，才能当选领导者；其次，在 Raft 中，日志必须是连续的。\n\nRaft 算法通过任期、领导者心跳消息、随机选举超时时间、先来先服务的投票原则、大多数选票原则等，保证了一个任期只有一位领导，也极大地减少了选举失败的情况。\n\n本质上，Raft 算法以领导者为中心，选举出的领导者，以“一切以我为准”的方式，达成值的共识，和实现各节点日志的一致。\n\n在本讲，我们使用 Raft 算法在集群中选出了领导者节点 A，那么选完领导者之后，领导者需要处理来自客户的写请求，并通过日志复制实现各节点日志的一致（下节课我会重点带你了解这一部分内容）。\n\n## 课堂思考\n\n既然我提到，Raft 算法实现了“一切以我为准”的强领导者模型，那么你不妨思考，这个设计有什么限制和局限呢？欢迎在留言区分享你的看法，与我一同讨论。\n\n最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。\n\n\n\n\n\n\n\n\n\n<iframe width=\"100%\" frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/204472\" > </iframe>\n\n","categories":["分布式协议与算法实战"]},{"title":"06 | AI 模型的构建过程是怎样的？（上）","url":"/posts/1651781864.html","content":"\n\n\n你好，我是海丰。\n\n上节课，我们说 AI 产品经理一定要知道算法模型构建的过程，但这并不意味着，AI 产品经理要参与研发，而是说我们要基于对需求和业务的理解，配合算法同学进行数据集的准备、模型训练、参数调优等等，及时跟进模型的目标优化，针对突发问题做出调整和决策。\n\n当然，了解模型构建这个环节还有另一个好处，那就是当模型构建的进展出现问题，需要延期或者其他资源支持的时候，我们就能按照自己的理解，把算法构建过程中的技术原理以及出现的问题，用非技术语言传达给公司领导和客户，这更容易获得他们的支持和认可。\n\n为了让你更清晰地了解到模型构建环节中算法同学的具体工作，我会结合上节课用户流失预测的例子，用两节课的时间为你讲解一个 AI 模型构建的过程。模型构建主要包括 5 个阶段，分别为**模型设计、特征工程、模型训练、模型验证、模型融合。**今天，我们先讲前 2 个阶段，下节课，我们再讲其他 3 个。\n\n![image-20231025173621410](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20231025173621410.png)\n\n","categories":["成为AI产品经理"]},{"title":"06丨Paxos算法（二）：Multi-Paxos不是一个算法，而是统称","url":"/posts/391286059.html","content":"\n\n\n你好，我是韩健。\n\n经过上节课的学习，你应该知道，Basic Paxos 只能就单个值（Value）达成共识，一旦遇到为一系列的值实现共识的时候，它就不管用了。虽然兰伯特提到可以通过多次执行 Basic Paxos 实例（比如每接收到一个值时，就执行一次 Basic Paxos 算法）实现一系列值的共识。但是，很多同学读完论文后，应该还是两眼摸黑，虽然每个英文单词都能读懂，但还是不理解兰伯特提到的 Multi-Paxos，为什么 Multi-Paxos 这么难理解呢？\n\n在我看来，兰伯特并没有把 Multi-Paxos 讲清楚，只是介绍了大概的思想，缺少算法过程的细节和编程所必须的细节（比如缺少选举领导者的细节）。这也就导致每个人实现的 Multi-Paxos 都不一样。不过从本质上看，大家都是在兰伯特提到的 Multi-Paxos 思想上补充细节，设计自己的 Multi-Paxos 算法，然后实现它（比如 Chubby 的 Multi-Paxos 实现、Raft 算法、ZAB 协议等）。\n\n所以在这里，我补充一下：**兰伯特提到的 Multi-Paxos 是一种思想，不是算法。而 Multi-Paxos 算法是一个统称，它是指基于 Multi-Paxos 思想，通过多个 Basic Paxos 实例实现一系列值的共识的算法（比如 Chubby 的 Multi-Paxos 实现、Raft 算法等）。** 这一点尤其需要你注意。\n\n为了帮你掌握 Multi-Paxos 思想，我会先带你了解，对于 Multi-Paxos 兰伯特是如何思考的，也就是说，如何解决 Basic Paxos 的痛点问题；然后我再以 Chubby 的 Multi-Paxos 实现为例，具体讲解一下。为啥选它呢？因为 Chubby 的 Multi-Paxos 实现，代表了 Multi-Paxos 思想在生产环境中的真正落地，它将一种思想变成了代码实现。\n\n## 兰伯特关于 Multi-Paxos 的思考\n\n熟悉 Basic Paxos 的同学（可以回顾一下05 讲）可能还记得，Basic Paxos 是通过二阶段提交来达成共识的。在第一阶段，也就是准备阶段，接收到大多数准备响应的提议者，才能发起接受请求进入第二阶段（也就是接受阶段）：\n\n![image-20230926094924160](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230926094924160.png)\n\n而如果我们直接通过多次执行 Basic Paxos 实例，来实现一系列值的共识，就会存在这样几个问题：\n\n如果多个提议者同时提交提案，可能出现因为提案冲突，在准备阶段没有提议者接收到大多数准备响应，协商失败，需要重新协商。你想象一下，一个 5 节点的集群，如果 3 个节点作为提议者同时提案，就可能发生因为没有提议者接收大多数响应（比如 1 个提议者接收到 1 个准备响应，另外 2 个提议者分别接收到 2 个准备响应）而准备失败，需要重新协商。\n\n2 轮 RPC 通讯（准备阶段和接受阶段）往返消息多、耗性能、延迟大。你要知道，分布式系统的运行是建立在 RPC 通讯的基础之上的，因此，延迟一直是分布式系统的痛点，是需要我们在开发分布式系统时认真考虑和优化的。\n\n那么如何解决上面的 2 个问题呢？可以通过引入领导者和优化 Basic Paxos 执行来解决，咱们首先聊一聊领导者。\n\n### 领导者（Leader）\n\n我们可以通过引入领导者节点，也就是说，领导者节点作为唯一提议者，这样就不存在多个提议者同时提交提案的情况，也就不存在提案冲突的情况了：\n\n![image-20230926094936392](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230926094936392.png)\n\n在这里，我补充一点：**在论文中，兰伯特没有说如何选举领导者，需要我们在实现 Multi-Paxos 算法的时候自己实现。** 比如在 Chubby 中，主节点（也就是领导者节点）是通过执行 Basic Paxos 算法，进行投票选举产生的。\n\n那么，如何解决第二个问题，也就是如何优化 Basic Paxos 执行呢？\n\n### 优化 Basic Paxos 执行\n\n我们可以采用“当领导者处于稳定状态时，省掉准备阶段，直接进入接受阶段”这个优化机制，优化 Basic Paxos 执行。也就是说，领导者节点上，序列中的命令是最新的，不再需要通过准备请求来发现之前被大多数节点通过的提案，领导者可以独立指定提案中的值。这时，领导者在提交命令时，可以省掉准备阶段，直接进入到接受阶段：\n\n![image-20230926094950357](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230926094950357.png)\n\n你看，和重复执行 Basic Paxos 相比，Multi-Paxos 引入领导者节点之后，因为只有领导者节点一个提议者，只有它说了算，所以就不存在提案冲突。另外，当主节点处于稳定状态时，就省掉准备阶段，直接进入接受阶段，所以在很大程度上减少了往返的消息数，提升了性能，降低了延迟。\n\n讲到这儿，你可能会问了：在实际系统中，该如何实现 Multi-Paxos 呢？接下来，我以 Chubby 的 Multi-Paxos 实现为例，具体讲解一下。\n\n## Chubby 的 Multi-Paxos 实现\n\n既然兰伯特只是大概的介绍了 Multi-Paxos 思想，那么 Chubby 是如何补充细节，实现 Multi-Paxos 算法的呢？\n\n首先，它通过引入主节点，实现了兰伯特提到的领导者（Leader）节点的特性。也就是说，主节点作为唯一提议者，这样就不存在多个提议者同时提交提案的情况，也就不存在提案冲突的情况了。\n\n另外，在 Chubby 中，主节点是通过执行 Basic Paxos 算法，进行投票选举产生的，并且在运行过程中，主节点会通过不断续租的方式来延长租期（Lease）。比如在实际场景中，几天内都是同一个节点作为主节点。如果主节点故障了，那么其他的节点又会投票选举出新的主节点，也就是说主节点是一直存在的，而且是唯一的。\n\n其次，在 Chubby 中实现了兰伯特提到的，“当领导者处于稳定状态时，省掉准备阶段，直接进入接受阶段”这个优化机制。\n\n最后，在 Chubby 中，实现了成员变更（Group membership），以此保证节点变更的时候集群的平稳运行。\n\n最后，我想补充一点：**在 Chubby 中，为了实现了强一致性，读操作也只能在主节点上执行。** 也就是说，只要数据写入成功，之后所有的客户端读到的数据都是一致的。具体的过程，就是下面的样子。\n\n所有的读请求和写请求都由主节点来处理。当主节点从客户端接收到写请求后，作为提议者，执行 Basic Paxos 实例，将数据发送给所有的节点，并且在大多数的服务器接受了这个写请求之后，再响应给客户端成功：\n\n![image-20230926095005099](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230926095005099.png)\n\n当主节点接收到读请求后，处理就比较简单了，主节点只需要查询本地数据，然后返回给客户端就可以了：\n\n![image-20230926095049079](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230926095049079.png)\n\nChubby 的 Multi-Paxos 实现，尽管是一个闭源的实现，但这是 Multi-Paxos 思想在实际场景中的真正落地，Chubby 团队不仅编程实现了理论，还探索了如何补充细节。其中的思考和设计非常具有参考价值，不仅能帮助我们理解 Multi-Paxos 思想，还能帮助我们理解其他的 Multi-Paxos 算法（比如 Raft 算法）。\n\n## 内容小结\n\n本节课我主要带你了解了 Basic Paxos 的局限，以及 Chubby 的 Multi-Paxos 实现。我希望你明确的重点如下：\n\n兰伯特提到的 Multi-Paxos 是一种思想，不是算法，而且还缺少算法过程的细节和编程所必须的细节，比如如何选举领导者等，这也就导致了每个人实现的 Multi-Paxos 都不一样。而 Multi-Paxos 算法是一个统称，它是指基于 Multi-Paxos 思想，通过多个 Basic Paxos 实例实现一系列数据的共识的算法（比如 Chubby 的 Multi-Paxos 实现、Raft 算法等）。\n\nChubby 实现了主节点（也就是兰伯特提到的领导者），也实现了兰伯特提到的 “当领导者处于稳定状态时，省掉准备阶段，直接进入接受阶段” 这个优化机制，省掉 Basic Paxos 的准备阶段，提升了数据的提交效率，但是所有写请求都在主节点处理，限制了集群处理写请求的并发能力，约等于单机。\n\n因为在 Chubby 的 Multi-Paxos 实现中，也约定了“大多数原则”，也就是说，只要大多数节点正常运行时，集群就能正常工作，所以 Chubby 能容错（n - 1）/2 个节点的故障。\n\n本质上而言，“当领导者处于稳定状态时，省掉准备阶段，直接进入接受阶段”这个优化机制，是通过减少非必须的协商步骤来提升性能的。这种方法非常常用，也很有效。比如，Google 设计的 QUIC 协议，是通过减少 TCP、TLS 的协商步骤，优化 HTTPS 性能。我希望你能掌握这种性能优化思路，后续在需要时，可以通过减少非必须的步骤，优化系统性能。\n\n最后，我想说的是，我个人比较喜欢 Paxos 算法（兰伯特的 Basic Paxos 和 Multi-Paxos），虽然 Multi-Paxos 缺失算法细节，但这反而给我们提供了思考空间，让我们可以反复思考和考据缺失的细节，比如在 Multi-Paxos 中到底需不需要选举领导者，再比如如何实现提案编号等等。\n\n但我想强调，Basic Paxos 是经过证明的，而 Multi-Paxos 是一种思想，缺失实现算法的必须编程细节，这就导致，Multi-Paxos 的最终算法实现，是建立在一个未经证明的基础之上的，正确性是个问号。\n\n与此同时，实现 Multi-Paxos 算法，最大的挑战是如何证明它是正确的。 比如 Chubby 的作者做了大量的测试，和运行一致性检测脚本，验证和观察系统的健壮性。在实际使用时，我不推荐你设计和实现新的 Multi-Paxos 算法，而是建议优先考虑 Raft 算法，因为 Raft 的正确性是经过证明的。当 Raft 算法不能满足需求时，你再考虑实现和优化 Multi-Paxos 算法。\n\n## 课堂思考\n\n既然，我提了 Chubby 只能在主节点上执行读操作，那么在最后，我给你留了一个思考题，这个设计有什么局限呢？欢迎在留言区分享你的看法，与我一同讨论。\n\n\n\n<iframe width=\"100%\" frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/202772\" > </iframe>\n\n","categories":["分布式协议与算法实战"]},{"title":"05 | 通过一个 AI 产品的落地，掌握产品经理工作全流程","url":"/posts/1647108520.html","content":"\n\n\n你好，我是海丰。\n\n对于任何一家互联网公司来说，用户流失都是我们必须要关注的一个问题。就拿我们公司的电商平台来说，一个很常见的问题就是，新用户的增长逐年缓慢，同时还伴随着老用户的不断流失。当遇到这种情况的时候，作为产品经理，我们该采取哪些措施，来降低用户的流失率呢？\n\n今天，我就通过我曾经主导过的一个预测用户流失的项目，带你了解一个 AI 产品从筹备到上线的全流程。从中，你可以体会到 AI 产品经理的完整工作流程是什么，每一个环节都有什么角色参与，每个角色需要做什么工作，他们的产出又都是什么。这能让你明白自身能力和岗位之间的差距，也是你自己主导一个 AI 产品的时候，可以用来借鉴和参考的。\n\n不过，我今天讲的上线流程是基于我们公司的业务场景和经验总结出来的，不能保证和所有公司的流程都一致，但无论如何，我们做事的底层逻辑都是一样的。\n\n话不多说，我们正式开始今天的课程吧！\n\n## 业务背景\n\n我们公司是一个电商平台，有段时间我们发现，每个月老用户流失的数量已经远高于新用户的拉新数量，为了防止这个缺口越来越大，我们决定对可能流失的用户做提前预警，同时采取一些措施来挽留这些用户，实现这个目标的前提就是要开发一套用于预测流失用户的产品。\n\n那具体怎么做呢？我先把我们当时开发这个产品的流程放在下面。接下来，我再分步骤给你详细讲讲，每一步我们都是怎么做的，以及要重点注意什么。\n\n![image-20231025172824435](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20231025172824435.png)\n\n## 产品定义\n\n当决定实现这个产品之后，首先我们要做的就是定义产品需求，明确做这件事情的背景、价值、以及预期目标都是什么。\n\n在这个环节中，我们会和业务方共同沟通，来决定我们的业务预期目标是什么，期望什么时候上线。这里，我提到的业务方可能是运营同学，也可能是商务同学，这和你是一个 ToC 还是 ToB 的产品经理相关。\n\n在这个预测用户流失的项目中，我的业务方就是运营，我们的期望是通过算法找出高流失可能性的人群，对这些人进行定向发券召回。这个项目的最终目标是，通过对高流失可能性的人群进行干预，让他们和没被干预过的人群相比，流失率降低 5%。\n\n同时，由于我们运营计划是按月为节奏的，所以这个模型可以定义为离线模型，按月更新，每月月初预测一批流失人群。并且，我还期望这个模型的覆盖率能够达到 100%，让它可以对我们业务线所有用户进行预测。这些就是我们对模型的更新周期、离线 / 实时模式、覆盖率等相关要求了，我们需要把它们都记录到一份需求文档中。\n\n## 技术预研\n\n需求确定之后，产品经理需要和算法同学进行沟通，请算法同学对需求进行预判。具体来说，就是要判断目前积累的数据和沉淀的算法，是否可以达到我们的业务需求。如果现有数据量和数据维度不能满足算法模型的训练要求，那产品经理还需要协助算法同学进行数据获取，也就是后面我们要说的数据准备工作。\n\n当然，**即使数据达到算法的需求，产品经理也还是需要协助算法同学做数据准备，因为垂直业务线的产品经理更了解本领域的数据。**\n\n另外，在这个环节中，你可能还需要根据算法的预估，对需求的内容进行调整。比如，我们原定覆盖率为 100%，但是和算法同学沟通后发现，有部分刚刚注册的新用户是没有任何数据的。对于这部分人，算法无法正常打分，而且新用户也不在流失用户干预范围内，所以，我们后面会根据目前新老用户比例得到新的覆盖率指标，再把它放到需求中去。\n\n## 数据准备\n\n然后，我们就进入数据准备的环节了。这个环节，我们需要根据模型预研的结果以及公司的实际情况，帮助算法同学准备数据。\n\n原因我们刚才也说了，就是因为产品经理基于对业务的理解，能判断哪些数据集更具备代表性。而算法同学，只能根据现有的数据去分析这些数据对模型是否有用，因为有些业务数据算法同学是想不到，所以自然不会去申请相关数据权限，也就不会分析这部分数据存在的特征。\n\n比如说，我们在过去的用户调研中发现，用户一旦有过客诉并且没有解决，那么大概率会流失。如果出现了客诉，用户问题得到了很好地解决，反而可能成为高粘性的客户。这时候，我们就会把客诉数据提供给算法同学，请他们去申请数据表权限，评估数据是否可用。反之，如果我们没有把这些信息同步给算法同学，那么很可能我们就缺失了一个重要的特征。\n\n在数据准备的部分，由于数据的不同，我们的获取方式也会有很大的差别。总的来说，数据可以分为三类，分别是内部业务数据、跨部门集团内数据以及外部采购的数据。接下来，我就分别说说这些数据怎么获取。\n\n **1. 获取内部业务数据** \n\n内部数据是指部门内的业务数据，如我们的订单数据、访问日志，这些都可以直接从数仓中获取。当然还有一些情况是，我们想要的数据目前没有，你可以提需求让工程研发同学留存相关数据，比如，之前有些用户的行为数据没有留存，那我们就需要增加埋点将这些数据留存下来。\n\n **2. 获取跨部门集团内数据** \n\n跨部门集团内数据指的是其他部门的业务数据，或者是统一的中台数据，这些数据需要我们根据公司数据管理规范按流程提取。在提取数据的时候，我们需要注意结合业务情况去判断该提取哪些数据。\n\n **3. 获取外采数据** \n\n最后是外采数据的获取。在公司自己的数据不足以满足建模要求时候，我们可以考虑购买外部公司数据，或者直接去其他拥有数据的公司进行联合建模。\n\n这个时候 ，我们就需要知道市场上不同的公司都能够提供什么。比如极光、友盟提供的是开发者服务，所以它们可以提供一些和 App 相关的用户画像等数据服务，再比如运营商可以提供和手机通话、上网流量、话费等相关数据等等。\n\n直接采购外部数据非常方便，但我们一定要注意，出于对数据安全和消费者隐私保护的考虑，我们和第三方公司的所有合作都需要经过公司法务的审核，避免采购到不合规的数据产品，对自己的业务和公司造成不好的影响。比如说，在用户流失预测模型这个项目中，我们可以去调研自己的用户近期是否下载了竞品的 App，或者经常使用竞品 App，这都可以作为用户可能流失的一个特征。\n\n当然，**在数据准备的环节中，我希望你不仅能根据算法的要求，做一些数据准备的协助工作，还能够根据自己的经验积累，给到算法同学一些帮助，提供一些你认为可能会帮助到模型提升的特征。**\n\n具体到预测用户流失的产品上，我们可以根据经验提出用户可能流失的常见情况，比如我们可以参考客诉表，看看有哪些用户在客诉之后，问题没有解决或者解决得还不满意，那这些用户我们大概率就流失了，或者我们也可以分析用户的评价数据 ，如果用户评价中负面信息比较多，那他们也可能会流失等等。\n\n## 模型的构建、宣讲及验收\n\n完成数据准备之后，就到了模型构建的环节。这个环节会涉及整个模型的构建流程，包括模型设计、特征工程、模型训练、模型验证、模型融合。\n\n![image-20231025173224468](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20231025173224468.png)\n\n\n\n即便你不需要进行模型构建的实际工作，你也需要知道这个流程是怎么进行的，这方便你了解算法同学的工作，以便评估整个项目的进度。这就好比互联网产品经理不需要写代码，但也要知道研发的开发流程是怎么样的。\n\n不过，今天我们不会重点来讲具体的过程，我先卖个关子，你今天先记住这几个关键节点的名称，下节课我们再详细来讲。\n\n**模型构建完成之后，你需要组织算法同学对模型进行宣讲**，让他们为你讲明白这个产品选择的算法是什么，为什么选择这个算法，都使用了哪些特征，模型的建模样本、测试样本都是什么，以及这个模型的测试结果是怎么样的。\n\n对于流失预测模型来说，我需要知道它的主要特征是什么，选择了哪些样本进行建模，尤其是测试结果是否能够满足业务需求。当看到流失预测模型的测试结果的时候，我们发现模型召回率、KS 值都达到了标准，但是模型覆盖度只有 70%，比预期低了不少。但是，由于我们业务侧也只需要找到一部分流失用户进行挽留操作，所以，暂时不能覆盖全量人群我们也是可以接受的。像这样的问题，都是你在模型宣讲环节需要去注意并且去评估的。\n\n**在模型宣讲之后，你还需要对模型进行评估验收，从产品经理的角度去评判模型是否满足上线的标准。**那在这个流失用户预测的项目上，我们就需要重点关注模型的准确率，是否模型预测的用户在一定周期后，确实发生了流失。如果模型准确率较低，将一些优惠券错配到了没有流失意愿的用户身上，就会造成营销预算的浪费。\n\n模型宣讲环节的具体内容，以及模型宣讲后，我们对模型进行评估验收的具体指标都有哪些，我会在模型验收的章节和你细说，这里你先不用着急，你只要知道有模型宣讲和模型评估验收这两个环节，以及它们的整体流程，让自己对 AI 产品经理的工作流程有一个整体的理解就可以了。\n\n## 工程开发及产品上线运营\n\n模型通过了验收之后，我们就可以进入工程开发的环节了。其实在实际工作中，工程开发工作通常会和算法模型构建同步进行。毕竟，算法同学和工程同学分属两个团队，只要模型的输入输出确定之后，双方约定好 API 就满足了工程同学开发的条件了。\n\n工程开发完成之后，就可以进行工程测试验收了。这和传统的互联网产品上线流程区别不大，也就是测试同学进行测试，发现 BUG 后提交给工程同学进行修复，再当测试同学测试通过之后，产品经理验收，或者叫做产品上线前走查，这里我就不再多说了。\n\n另外，在工程上线之后，为了评估 AI 产品整体的效果，我们可以通过对上线后的系统做 AB 测试对比传统方案，进而量化 AI 产品的效果提升。这时候，我们需要关注在产品定义阶段对于产品的指标和目标期望。\n\n相比于一般的互联网产品经理，AI 产品经理在产品上线之后，还需要持续观测数据的表现（模型效果）。因为 AI 模型效果表现会随着时间而缓慢衰减，你需要去监控模型表现，出现衰减后需要分析发生衰减的原因，判断是否需要模型进行迭代。\n\n## 小结\n\n一个 AI 产品构建的整个流程是从产品定义，到技术预研、数据准备、模型构建，再到模型验收和工程开发上线。其中，有三个节点是我们需要重要关注的，因为这三个节点和互联网产品开发流程完全不同，它们分别是产品定义、数据准备和模型构建。\n\n在产品定义的阶段，我们需要搞清楚三个问题，这个产品背后的需求是什么，是否需要 AI 技术支持，以及通过 AI 能力可以达到什么样的业务目标。这需要我们和业务方深入沟通，拆解他们的真实需求。除此之外，我们还要根据自己对 AI 技术的理解，去判断这个项目的可行性，制定相应的目标。\n\n因为数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已，所以数据特征是否全面，数据量是否足够对于算法同学来说是非常重要的。在数据准备阶段，我们不仅需要帮助算法同学获取更多高质量的数据，来提升模型的整体效果，也可以从业务的角度，给出算法同学一些建议，比如哪些特征可能有帮助等等。\n\n数据准备好，就可以进行模型的构建以及评估验收了。模型的构建我们可能没有什么可以介入的地方，但模型的评估验收是一个非常重要的节点，因为模型是一个偏黑盒的工作，它的输出可能只有一个指标值或者分数。\n\n但是，很多产品经理会认为：模型好坏是算法工程师的职责范围，反正自己也不太懂算法，只要算法交付了，对方说达到模型指标就可以了。如果你也这么想，那么你可能最后就变成一个协调性或者执行层的产品经理了，最后整个项目就变成算法主导了，所以我们一定要重视模型评估。\n\n## 课后讨论\n\n你觉得，AI 产品经理的工作流程和你现在的工作流程最大的不同是什么？为什么会产生这些不同呢？\n\n期待在留言区看到你对工作流程的思考与复盘，我们下节课见！\n\n---\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/322733\" > </iframe>\n\n\n\n","categories":["成为AI产品经理"]},{"title":"05丨Paxos算法（一）：如何在多个节点间确定某变量的值？","url":"/posts/97654580.html","content":"\n\n\nPaxos：帕克索斯\n\n你好，我是韩健。\n\n提到分布式算法，就不得不提 Paxos 算法，在过去几十年里，它基本上是分布式共识的代名词，因为当前最常用的一批共识算法都是基于它改进的。比如，Fast Paxos 算法、Cheap Paxos 算法、Raft 算法、ZAB 协议等等。而很多同学都会在准确和系统理解 Paxos 算法上踩坑，比如，只知道它可以用来达成共识，但不知道它是如何达成共识的。\n\n这其实侧面说明了 Paxos 算法有一定的难度，可分布式算法本身就很复杂，Paxos 算法自然也不会例外，当然了，除了这一点，还跟兰伯特有关。\n\n兰伯特提出的 Paxos 算法包含 2 个部分：\n\n一个是 Basic Paxos 算法，描述的是多节点之间如何就某个值（提案 Value）达成共识；\n\n另一个是 Multi-Paxos 思想，描述的是执行多个 Basic Paxos 实例，就一系列值达成共识。\n\n可因为兰伯特提到的 Multi-Paxos 思想，缺少代码实现的必要细节（比如怎么选举领导者），所以在理解上比较难。\n\n为了让你理解 Paxos 算法，接下来我会用 2 节课的时间，分别以 Basic Paxos 和 Multi-Paxos 为核心，带你了解 Basic Paxos 如何达成共识，以及针对 Basic Paxos 的局限性 Multi-Paxos 又是如何改进的。今天咱们先来聊聊 Basic Paxos。\n\n在我看来，Basic Paxos 是 Multi-Paxos 思想的核心，说白了，Multi-Paxos 就是多执行几次 Basic Paxos。所以掌握它之后，你能更好地理解后几讲基于 Multi-Paxos 思想的共识算法（比如 Raft 算法），还能掌握分布式共识算法的最核心内容，当现在的算法不能满足业务需求，进行权衡折中，设计自己的算法。\n\n**来看一道思考题。**\n\n假设我们要实现一个分布式集群，这个集群是由节点 A、B、C 组成，提供只读 KV 存储服务。你应该知道，创建只读变量的时候，必须要对它进行赋值，而且这个值后续没办法修改。因此一个节点创建只读变量后就不能再修改它了，所以所有节点必须要先对只读变量的值达成共识，然后所有节点再一起创建这个只读变量。\n\n那么，当有多个客户端（比如客户端 1、2）访问这个系统，试图创建同一个只读变量（比如 X），客户端 1 试图创建值为 3 的 X，客户端 2 试图创建值为 7 的 X，这样要如何达成共识，实现各节点上 X 值的一致呢？带着这个问题，我们进入今天的学习。\n\n![image-20230925164100146](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925164100146.png)\n\n\n\n在一些经典的算法中，你会看到一些既形象又独有的概念（比如二阶段提交协议中的协调者），Basic Paxos 算法也不例外。为了帮助人们更好地理解 Basic Paxos 算法，兰伯特在讲解时，也使用了一些独有而且比较重要的概念，提案、准备（Prepare）请求、接受（Accept）请求、角色等等，其中最重要的就是“角色”。因为角色是对 Basic Paxos 中最核心的三个功能的抽象，比如，由接受者（Acceptor）对提议的值进行投票，并存储接受的值。\n\n\n\n```mermaid\ngraph LR\n\nR[角色]\nR-P[提议者 Proposer]\nR-A[接受者 Acceptor]\nR-L[学习者 Learner]\n\nR --> R-P\nR --> R-A\nR --> R-L\n\n\n```\n\n\n\n\n\n## 你需要了解的三种角色\n\n在 Basic Paxos 中，有提议者（Proposer）、接受者（Acceptor）、学习者（Learner）三种角色，他们之间的关系如下：\n\n![image-20230925165234259](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925165234259.png)\n\n看着是不是有些复杂，其实并不难理解：\n\n**提议者（Proposer）**：提议一个值，用于投票表决。为了方便演示，你可以把图 1 中的客户端 1 和 2 看作是提议者。但在绝大多数场景中，集群中收到客户端请求的节点，才是提议者（图 1 这个架构，是为了方便演示算法原理）。这样做的好处是，对业务代码没有入侵性，也就是说，我们不需要在业务代码中实现算法逻辑，就可以像使用数据库一样访问后端的数据。\n\n**接受者（Acceptor）**：对每个提议的值进行投票，并存储接受的值，比如 A、B、C 三个节点。 一般来说，集群中的所有节点都在扮演接受者的角色，参与共识协商，并接受和存储数据。\n\n讲到这儿，你可能会有疑惑：前面不是说接收客户端请求的节点是提议者吗？这里怎么又是接受者呢？这是因为一个节点（或进程）可以身兼多个角色。想象一下，一个 3 节点的集群，1 个节点收到了请求，那么该节点将作为提议者发起二阶段提交，然后这个节点和另外 2 个节点一起作为接受者进行共识协商，就像下图的样子：\n\n![image-20230925165250037](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925165250037.png)\n\n**学习者（Learner）**：被告知投票的结果，接受达成共识的值，存储保存，不参与投票的过程。一般来说，学习者是数据备份节点，比如“Master-Slave”模型中的 Slave，被动地接受数据，容灾备份。\n\n其实，这三种角色，在本质上代表的是三种功能：\n\n提议者代表的是接入和协调功能，收到客户端请求后，发起二阶段提交，进行共识协商；\n\n接受者代表投票协商和存储数据，对提议的值进行投票，并接受达成共识的值，存储保存；\n\n学习者代表存储数据，不参与共识协商，只接受达成共识的值，存储保存。\n\n因为一个完整的算法过程是由这三种角色对应的功能组成的，所以理解这三种角色，是你理解 Basic Paxos 如何就提议的值达成共识的基础。那么接下来，咱们看看如何使用 Basic Paxos 达成共识，解决开篇提到的那道思考题。\n\n## 如何达成共识？\n\n和2PC类似，也是分为两个阶段\n\n```mermaid\ngraph LR\n达成共识 --> 准备Prepare阶段\n达成共识 --> 接受Accept阶段\n```\n\n\n\n想象这样一个场景，现在疫情这么严重，每个村的路都封得差不多了，就你的村委会不作为，迟迟没有什么防疫的措施。你决定给村委会提交个提案，提一些防疫的建议，除了建议之外，为了和其他村民的提案做区分，你的提案还得包含一个提案编号，来起到唯一标识的作用。\n\n与你的做法类似，在 Basic Paxos 中，兰伯特也使用提案代表一个提议。不过在提案中，除了提案编号，还包含了提议值。为了方便演示，我使用[n, v]表示一个提案，其中 n 为提案编号，v 为提议值。\n\n我想强调一下，整个共识协商是分 2 个阶段进行的（也就是我在 03 讲提到的二阶段提交）。那么具体要如何协商呢？\n\n我们假设客户端 1 的提案编号为 1，客户端 2 的提案编号为 5，并假设节点 A、B 先收到来自客户端 1 的准备请求，节点 C 先收到来自客户端 2 的准备请求。\n\n### 准备（Prepare）阶段\n\n先来看第一个阶段，首先客户端 1、2 作为提议者，分别向所有接受者发送包含提案编号的准备请求：\n\n![image-20230925165414400](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925165414400.png)\n\n\n\n**你要注意，在准备请求中是不需要指定提议的值的，只需要携带提案编号就可以了，这是很多同学容易产生误解的地方。**\n\n接着，当节点 A、B 收到提案编号为 1 的准备请求，节点 C 收到提案编号为 5 的准备请求后，将进行这样的处理：\n\n![image-20230925165429704](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925165429704.png)\n\n\n\n由于之前没有通过任何提案，所以节点 A、B 将返回一个 “尚无提案”的响应。也就是说节点 A 和 B 在告诉提议者，我之前没有通过任何提案呢，并承诺以后不再响应提案编号小于等于 1 的准备请求，不会通过编号小于 1 的提案。\n\n节点 C 也是如此，它将返回一个 “尚无提案”的响应，并承诺以后不再响应提案编号小于等于 5 的准备请求，不会通过编号小于 5 的提案。\n\n另外，当节点 A、B 收到提案编号为 5 的准备请求，和节点 C 收到提案编号为 1 的准备请求的时候，将进行这样的处理过程：\n\n![image-20230925165449931](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925165449931.png)\n\n当节点 A、B 收到提案编号为 5 的准备请求的时候，因为提案编号 5 大于它们之前响应的准备请求的提案编号 1，而且两个节点都没有通过任何提案，所以它将返回一个 “尚无提案”的响应，并承诺以后不再响应提案编号小于等于 5 的准备请求，不会通过编号小于 5 的提案。\n\n当节点 C 收到提案编号为 1 的准备请求的时候，由于提案编号 1 小于它之前响应的准备请求的提案编号 5，所以丢弃该准备请求，不做响应。\n\n### 接受（Accept）阶段\n\n第二个阶段也就是接受阶段，首先客户端 1、2 在收到大多数节点的准备响应之后，会分别发送接受请求：\n\n![image-20230925165509807](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925165509807.png)\n\n\n\n当客户端 1 收到大多数的接受者（节点 A、B）的准备响应后，根据响应中提案编号最大的提案的值，设置接受请求中的值。因为该值在来自节点 A、B 的准备响应中都为空（也就是图 5 中的“尚无提案”），所以就把自己的提议值 3 作为提案的值，发送接受请求[1, 3]。\n\n当客户端 2 收到大多数的接受者的准备响应后（节点 A、B 和节点 C），根据响应中提案编号最大的提案的值，来设置接受请求中的值。因为该值在来自节点 A、B、C 的准备响应中都为空（也就是图 5 和图 6 中的“尚无提案”），所以就把自己的提议值 7 作为提案的值，发送接受请求[5, 7]。\n\n当三个节点收到 2 个客户端的接受请求时，会进行这样的处理：\n\n![image-20230925165525142](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925165525142.png)\n\n当节点 A、B、C 收到接受请求[1, 3]的时候，由于提案的提案编号 1 小于三个节点承诺能通过的提案的最小提案编号 5，所以提案[1, 3]将被拒绝。\n\n当节点 A、B、C 收到接受请求[5, 7]的时候，由于提案的提案编号 5 不小于三个节点承诺能通过的提案的最小提案编号 5，所以就通过提案[5, 7]，也就是接受了值 7，三个节点就 X 值为 7 达成了共识。\n\n讲到这儿我想补充一下，如果集群中有学习者，当接受者通过了一个提案时，就通知给所有的学习者。当学习者发现大多数的接受者都通过了某个提案，那么它也通过该提案，接受该提案的值。\n\n通过上面的演示过程，你可以看到，最终各节点就 X 的值达成了共识。那么在这里我还想强调一下，Basic Paxos 的容错能力，源自“大多数”的约定，你可以这么理解：当少于一半的节点出现故障的时候，共识协商仍然在正常工作。\n\n## 内容小结\n\n本节课我主要带你了解了 Basic Paxos 的原理和一些特点，我希望你明确这样几个重点。\n\n你可以看到，Basic Paxos 是通过二阶段提交的方式来达成共识的。二阶段提交是达成共识的常用方式，如果你需要设计新的共识算法的时候，也可以考虑这个方式。\n\n除了共识，Basic Paxos 还实现了容错，在少于一半的节点出现故障时，集群也能工作。它不像分布式事务算法那样，必须要所有节点都同意后才提交操作，因为“所有节点都同意”这个原则，在出现节点故障的时候会导致整个集群不可用。也就是说，“大多数节点都同意”的原则，赋予了 Basic Paxos 容错的能力，让它能够容忍少于一半的节点的故障。\n\n本质上而言，提案编号的大小代表着优先级，你可以这么理解，根据提案编号的大小，接受者保证**三个承诺**，具体来说：如果准备请求的提案编号，**小于等于**接受者已经响应的准备请求的提案编号，那么接受者将承诺不响应这个准备请求；如果接受请求中的提案的提案编号，**小于**接受者已经响应的准备请求的提案编号，那么接受者将承诺不通过这个提案；如果接受者之前有通过提案，那么接受者将承诺，会在准备请求的响应中，包含**已经通过的最大编号的提案信息**。\n\n## 课堂思考\n\n在示例中，如果节点 A、B 已经通过了提案[5, 7]，节点 C 未通过任何提案，那么当客户端 3 提案编号为 9 时，通过 Basic Paxos 执行“SET X = 6”，最终三个节点上 X 值是多少呢？为什么呢？欢迎在留言区分享你的看法，与我一同讨论。\n\n最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。\n\n\n\n## 自我思考\n\nLamport为了讲述这个算法，假想了一个叫做Paxos的希腊城邦进行选举的情景，这个算法也是因此而得名。在他的假想中，这个城邦要采用民主提议和投票的方式选出一个最终的决议，但由于城邦的居民没有人愿意把全部时间和精力放在这种事情上，所以他们只能不定时的来参加提议，不定时来了解提议、投票进展，不定时的表达自己的投票意见。Paxos算法的目标就是让他们按照少数服从多数的方式，最终达成一致意见，但是和传统选举不同的是：每一个参与者的目的不是选出最好的，而是要最快的选出来。 \n\n\n\n<iframe width=\"100%\" frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/201700\" > </iframe>","categories":["分布式协议与算法实战"]},{"title":"04 | 过来人讲：成为AI产品经理的两条路径","url":"/posts/812818166.html","content":"\n\n\n你好，我是刘海丰。\n\n通过前面几节课，你已经知道了 AI 领域的发展现状，AI 产品落地的工作全流程，以及 AI 产品经理的能力模型。这些都是你成为或者说是转型成为一个 AI 产品经理之前，必须要储备的知识。\n\n掌握了这些之后，想要真正成为 AI 产品经理，你还需要一些切实可行的落地路径。我觉得，我们在做出每一个职业转变的决定之后，都必须要制定好相应的实现路径，这不仅能帮助我们明晰每个阶段的目标，还能让我们坚定不移地走向终点。\n\n今天，我就结合自己的转型经验，给你梳理出两条切实可行的转型路径。而且，我会把我踩过的“坑”都总结出来，当你真正去走的时候，就能少走很多弯路啦。\n\n## 内部转岗：从下到上，由点及面\n\n首先，我们来看这样一种情况。公司突然要上线一个 AI 项目，领导希望你能从产品经理转变成一个 AI 产品经理去推动这个项目。当然，目前这种情况并不多见，但随着越来越多的公司认识到 AI 的重要性，并且建立了算法团队，这种情况就会变得很普遍。我就是在这样的情况下转型成功的，如果你也正面临这种情况，我建议你参考我当时的经历。\n\n我最初是产品和研发的总负责人，做的是传统的互联网业务。当时机缘巧合，我们服务的客户让我们帮他们做一个用于金融风控场景的用户信用评分产品。这种产品，其实底层就是基于大数据和机器学习算法，来对贷款人的还款能力和还款意愿进行预测。我就通过这样一个契机主导了这个 AI 产品，走上了 AI 产品经理之路。\n\n但是由于之前完全没有接触过算法，我在最初接触这个产品的时候，一直都是“懵”的。还好，当时有一个算法团队的负责人协助我来完成相关工作。但是这样一来，我就从一个产研负责人变成了算法配合人。整个产品的交付形式、节奏、上线标准，基本都是由算法负责人决定，我只能做一些执行层面的事情。\n\n当然，为了项目能够顺利上线，短暂去协助算法做支持是可以的，但我不可能一直处于被动的局面中，所以我当时的做法是 “**从下到上，由点及面**”。那我具体是怎么做的呢？我其实就是从底层知识和细节问题入手，去拓展学习整个知识体系和相关知识点。这里，我就和你分享两个例子。\n\n比如，在项目周会上，大家介绍项目进展的时候，算法同学经常会提到，我们本周做了洗数工作，或者我们在筛选特征。那我就会带着具体的问题去进行补课，像是 “洗数怎么做的， 筛选特征怎么做的，等到有拿不准的问题再去请教算法同学，基本上他们都会倾囊相授。这样一来，我再把这些碎片化的知识梳理出来，慢慢地就形成了一个相对完整的知识体系。\n\n再比如，我知道有个算法叫做 GBDT，也知道有个算法叫做 LR。但我根本不知道它们代表什么意思，都是做什么的，对我来说算法就是个黑盒子，可为了能带领整个 AI 项目团队，我又一定要弄懂这些知识。\n\n所以，我先是向算法同学学习，再加上自己上网查询资料，去了解机器学习算法的几种分类，以及每种分类下的常用算法。其中 LR 是逻辑回归，GBDT 是优化后的决策树，它们都是用于解决分类问题的算法。就这样，我慢慢梳理出来了一棵和**算法相关的知识树**。\n\n除了学习和算法相关的知识之外，数学、统计学，概率论这些和 AI 相关的名词，我也进行了解和学习。因为在和算法同学沟通需求的时候，他们经常会提到这类名词概念，所以我就将这些名词概念组织整理出来，慢慢向上汇总，形成了一棵和**数学相关的知识树**。\n\n另外，既然涉足了 AI 领域，我觉得有必要对整个行业有所了解，比如算法同学都关注了哪些行业会议和业界大牛。根据我的经验，这些 AI 技术视野相关的东西，不需要集中学习，随着我们的关注慢慢补充就可以了。\n\n以上，就是我当时如何一点点弥补我在 AI 技术知识上的不足的，并最终转型 AI 产品经理的全部过程。**如果你与我类似，都是在工作中遇到了做 AI 产品的机会，我建议你可以参考我的路径，暂时让算法同学去主导项目，同时由点及面地去学习，补充知识和积累经验**。\n\n## 外部求职：从上到下，从面到点\n\n但如果你就是一个刚毕业的学生，想要踏足 AI 行业，或者是一个技术同学，希望成为一个 AI 产品经理，那我建议你采用 “**从上到下，从面到点**”的学习路径。这句话的意思是，你要先了解全局，从全局中挑出一条线，再抓住这条线的一端，一点点地深入到具体细节的知识点。\n\n这么说还是太抽象了，我给这个路径总结了 4 个步骤，下面我再详细说说。\n\n**第一步，对 AI 行业有全局的认识，持续了解 AI 发展。**\n\n作为产品经理，我们要站在一定的高度上去看整个行业，了解整个行业的全景，产业链条，商业模式，人才结构，甚至是每个方向的头部公司情况。除了对全局的把控之外，还需要实时去关注行业的变化，技术的更迭，只有站在行业的前沿，我们才有可能抓到新的机会点。\n\n我建议你可以参加一些 AI 产业相关的会议，你可以从类似于 “活动行” 等 App 上面搜索这些会议的信息再报名，也可以找一些 AI 产业相关的公众号，看看能不能从上面发现这些会议信息，再积极报名。\n\n说到公众号，我认为在刚开始决定转型的时候，你可以不用关注那种技术导向非常强的公众号，上来就看非常深的技术文章。因为可能还没有了解到行业新闻，你就已经被一些数学公式或算法模型给打败了。\n\n我推荐你关注类似《AI 前线》这样的公众号，它是面向 AI 爱好者、开发者和产品经理的，它关注的领域比较广泛，涉及国内外的 AI 相关公司、技术的资讯，内容也不算太过于技术化，作为入门 AI 产品经理的信息来源足够了。\n\n除了公众号，我建议你去知乎上看看和 AI 相关的专栏和问题，再买一些入门的书籍。只要你善于发现，好的学习资源是非常多的。\n\n查看这些资料只是我们了解行业的第一步，最重要的是，你一定要对这些信息进行**归纳总结，提炼出自己的思考**。你可以尝试自己去搭建一个行业的框架，框架中可以包括很多方面，我把它们进行了总结：\n\n行业专有名词、基本术语\n\n行业的整体规模，未来的发展空间\n\n整个行业的生命周期，当前处于哪个阶段\n\n行业的产业链，上下游供应商情况\n\n行业中不同企业的商业模式\n\n行业整体的人才结构分布情况\n\n当前行业中头尾部企业\n\n这样的话，当你去面试 AI 产品这个岗位的时候，因为你之前对整个行业做过充分的总结，就可以很有结构地表达出你对这个行业的看法，你的答案也会比其他竞争者更有高度。这对你提高面试通过率，甚至是面试定级都非常有帮助。\n\n**第二步，给自己定方向。**\n\n对于整个行业的全景有了基础的认识之后，你除了要持续去跟进这些信息，接下来就需要开始评估自己的兴趣偏好和能力优势，为自己确定方向了。\n\n首先，你要分析自己的兴趣偏好，更倾向于商业化去做 ToB 服务，还是更倾向于底层的技术或技术上层的应用，通过自己的兴趣偏好选出自己心仪的行业和公司。\n\n其次，你也要考虑自身的能力优势，对于自己心仪的公司，你有多大的差距。\n\n如果差距实在太大，比如你喜欢寒武纪这样做 AI 芯片服务的公司，可是自己对 AI 技术完全不懂，也从来没有做过硬件相关的产品。那你就可以考虑曲线救国，尝试先去对技术要求没有那么高的公司试试，让自己踏入这个行业再说，或者，你也可以考虑这家公司对技术要求没有那么高的岗位，之后再寻求技术转岗。\n\n当然，如果你非要一步到位，可能难度比较高，但也不是不可能，你要做好充足的技能储备，有着坚定的信心。\n\n最后，在确定了自己的方向之后，你可以定向分析一下这个细分方向上的几个头部企业，它们的商业模式、上下游企业、可提供的岗位，以及每个岗位的职责要求，再去定向地补足自己的差距。\n\n另外，除了分析头部企业之外，我建议你再看看这个行业中尾部的一两个企业，分析它们为什么会处于行业尾部，是入场时间太晚，还是商业方向不确定，又或者是相关资源不足。这也能够让你对这个细分领域有整体的了解。\n\n**第三步，补足技术。**\n\n在确定了自己的未来方向之后，你就可以有针对性地去补足技术上的短板了。\n\n如果你倾向于去做机器学习平台的产品经理，就去重点学习模型建模的过程，甚至要自己尝试去使用一些公共的机器学习平台，去创建一个算法模型。比如阿里云的 PAI、百度的 EasyDL，它们都是很优秀的建模平台。\n\n如果你想做大数据风控方向的 AI 产品经理，就需要知道机器学习模型内部逻辑，甚至要了解一下算法的逻辑是怎么样的。\n\n在学习技术知识方面，我建议你可以购买一些入门的课程，可以先从简单的内容学起，再慢慢深入。在选择课程的时候，我建议你避开一些包含大量数学公式的课程，不是因为这些课不好，而是因为它们主要面向数据工程师或者算法工程师，对产品经理来说学起来太困难。\n\n**第四步，总结、输出、实践。**\n\n总结、输出、实践，这几个词你肯定听过很多遍，但我还是要说，你可别嫌我啰嗦。\n\n**学习这件事，去学习只是第一步，更重要的是做总结。但只是总结还不够，我希望你还能借着这些总结去做输出，强迫自己整理出一篇文章，或者给其他人分享。当你可以用浅显的语言把复杂的知识讲解清楚的时候，就说明你对这个知识真正掌握了。**\n\n基础知识掌握之后，你就可以开始实践了。我建议你先尝试去面试一些 AI 公司，感受一下具体 AI 企业关注求职者哪些技能，他们都会提出哪些问题，再去迭代自己的技能。这样，去心仪的公司面试成功的几率就会更高。\n\n## 总结\n\n今天，我和你分享了两条转型 AI 产品经理的路径，这里我们再一起对里面涉及的方法做个总结。\n\n如果你是内部转岗，我建议你采用从下到上，由点及面的学习方式，可以暂时先让算法同学主导整个项目，但是对于工作中任何一个细节问题你都不要放过，想办法去补充相关知识，建立自己的知识体系。\n\n如果你是外部求职，我建议你采用从上到下，从面到点的学习方式。总的来说，就是先了解 AI 行业，再给自己定好方向，然后补足技术，最后做总结多输出，多实践。\n\n这两条路径总结起来很简单，但是里面涉及的每一点，实现起来都不容易。总的来说，我希望你能记住一句话，多总结、多输出，然后用以教促学的方式来迭代自己对 AI 知识的领悟。\n\n## 课后讨论\n\n目前，对于行业的知识，产品经理的岗位职责以及转型准备上，你还有什么疑问吗？你能根据自己的理解再加上收集的一些信息，去搭建一个行业框架呢？当然，如果你能整理出一个脑图出来，那就再好不过了。\n\n如果你的朋友也正在为不知道怎么转型 AI 产品经理而苦恼，那就快把这节课分享给他吧！如果你不想自己去找学习资源的话，课程的最后，我还整理出了一些我认为值得关注和学习的公众号、图书和视频课程，如果你有兴趣可以参考一下。我们下节课见！\n\n\n\n## 拓展阅读\n\n我把我在转型时关注的一些网站和资料梳理出来了，你可以根据你的情况进行选择。\n\n1. 行业知识 \n\n你可以关注《爱分析》这个公众号，它会发布一些类似《智慧医院厂商全景报告》、《2020 爱分析中国人工智能厂商全景报告》、《中国知识图谱应用趋势报告》的行业报告，也会组织一些类似《2020 爱分析金融机构数字化论坛》的线下论坛。\n\n另外，你也可以关注艾瑞咨询这样的网站，上面有一些类似《2020 年中国 AI+ 零售行业发展研究报告》的行业报告。这些信息相对体系化，可以帮你梳理整个行业框架的思路。\n\n除此之外，你也可以关注 《36 氪》这样的新闻网站，用一些及时的碎片化新闻，来实时了解当前行业动态。\n\n2. 技术基础\n\n你可以关注一些技术类的公众号，比如《大数据文摘》、《大数据分析与人工智能》、《机器之心》、《AI 启蒙者》等等。另外，你也可以关注我自己的公众号《成为 AI 产品经理》，我在上面分享了很多关于转型 AI 产品经理的心得。\n\n3. 技术进阶\n\n如果想提高技术能力，我建议你可以学习这两个视频课程：李宏毅的《Machine Learning》和吴恩达的《机器学习》课程。这两门课程的老师讲解细致，内容通俗易懂，也是机器学习的经典课程，非常推荐你学习。\n\n除了一些视频教程之外，你还需要阅读一些技术书籍。我首先推荐的是李航的《统计学习方法》，这是我在最开始接触 AI 时候，我们算法团队负责人推荐给我的，可以作为算法学习的基础。不过，因为它的专业性比较强，非技术出身的产品经理看起来可能有些难度，你可以选择性地学习。\n\n另外一个就是周志华的《机器学习》，也就是我们俗称的西瓜书。这本书覆盖面广，有大量的实例可供参考，对于非技术人员来说比较友好。\n\n---\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/322714\" > </iframe>\n","categories":["成为AI产品经理"]},{"title":"04丨BASE理论：CAP的碱，追求可用性","url":"/posts/321910727.html","content":"\n\n\n你好，我是韩健。\n\n很多同学可能喜欢使用事务型的分布式系统，或者是强一致性的分布式系统，因为使用起来很方便，不需要考虑太多，就像使用单机系统一样。但是学了 CAP 理论后，你肯定知道在分布式系统中要实现强一致性必然会影响可用性。比如，在采用两阶段提交协议的集群系统中，因为执行提交操作，需要所有节点确认和投票。\n\n所以，集群的可用性是每个节点可用性的乘积，比如，假设 3 个节点的集群，每个节点的可用性为 99.9％，那么整个集群的可用性为 99.7％，也就是说，每个月约宕机 129.6 分钟，**这是非常严重的问题。** 而解决可用性低的关键在于，根据实际场景，尽量采用可用性优先的 AP 模型。\n\n讲到这儿，可能会有一些同学“举手提问”：这也太难了，难道没有现成的库或者方案，来实现合适的 AP 模型？是的，的确没有。因为它是一个动态模型，是基于业务场景特点妥协折中后设计实现的。不过，你可以借助 BASE 理论帮助你达成目的。\n\n在我看来，BASE 理论是 CAP 理论中的 AP 的延伸，是对互联网大规模分布式系统的实践总结，强调可用性。几乎所有的互联网后台分布式系统都有 BASE 的支持，这个理论很重要，地位也很高。一旦掌握它，你就能掌握绝大部分场景的分布式系统的架构技巧，设计出适合业务场景特点的、高可用性的分布式系统。\n\n而它的核心就是基本可用（Basically Available）和最终一致性（Eventually consistent）。也有人会提到软状态（Soft state），在我看来，软状态描述的是实现服务可用性的时候系统数据的一种过渡状态，也就是说不同节点间，数据副本存在短暂的不一致。你只需要知道软状态是一种过渡状态就可以了，我们不多说。\n\n那么基本可用以及最终一致性到底是什么呢？你又如何在实践中使用 BASE 理论提升系统的可用性呢？这些就是本节课的重点了，而我建议你集中注意力，认真学习本节课的内容，学以致用，将 BASE 理论应用到日常工作中。\n\n## 实现基本可用的 4 板斧\n\n在我看来，基本可用是说，当分布式系统在出现不可预知的故障时，允许损失部分功能的可用性，保障核心功能的可用性。就像弹簧一样，遇到外界的压迫，它不是折断，而是变形伸缩，不断适应外力，实现基本的可用。\n\n具体说的话，你可以把基本可用理解成，当系统节点出现大规模故障的时候，比如专线的光纤被挖断、突发流量导致系统过载（出现了突发事件，服务被大量访问），这个时候可以通过服务降级，牺牲部分功能的可用性，保障系统的核心功能可用。\n\n就拿 12306 订票系统基本可用的设计为例，这个订票系统在春运期间，因为开始售票后先到先得的缘故，会出现极其海量的请求峰值，如何处理这个问题呢？\n\n咱们可以在不同的时间，出售不同区域的票，将访问请求错开，削弱请求峰值。比如，在春运期间，深圳出发的火车票在 8 点开售，北京出发的火车票在 9 点开售。**这就是我们常说的流量削峰。**\n\n另外，你可能已经发现了，在春运期间，自己提交的购票请求，往往会在队列中排队等待处理，可能几分钟或十几分钟后，系统才开始处理，然后响应处理结果，**这就是你熟悉的延迟响应。** 你看，12306 订票系统在出现超出系统处理能力的突发流量的情况下，会通过牺牲响应时间的可用性，保障核心功能的运行。\n\n而 12306 通过流量削峰和延迟响应，是不是就实现了基本的可用呢？现在它不会再像最初的时候那样，常常 404 了吧？\n\n再比如，你正负责一个互联网系统，突然出现了网络热点事件，好多用户涌进来，产生了海量的突发流量，系统过载了，大量图片因为网络超时无法显示。那么这个时候你可以通过哪些方法，保障系统的基本可用呢？\n\n**相信你马上就能想到体验降级，** 比如用小图片来替代原始图片，通过降低图片的清晰度和大小，提升系统的处理能力。\n\n**然后你还能想到过载保护，** 比如把接收到的请求放在指定的队列中排队处理，如果请求等待时间超时了（假设是 100ms），这个时候直接拒绝超时请求；再比如队列满了之后，就清除队列中一定数量的排队请求，保护系统不过载，实现系统的基本可用。\n\n**你看，和 12306 的设计类似，只不过你负责的互联网系统是通过牺牲部分功能的可用性，保障核心功能的运行。**\n\n我说了这么多，主要是想强调：基本可用在本质上是一种妥协，也就是在出现节点故障或系统过载的时候，通过牺牲非核心功能的可用性，保障核心功能的稳定运行。\n\n我希望你能在后续的分布式系统的开发中，**不仅掌握流量削峰、延迟响应、体验降级、过载保护这 4 板斧**，更能理解这 4 板斧背后的妥协折中，从而灵活地处理不可预知的突发问题。\n\n带你了解了基本可用之后，我再来说说 BASE 理论中，另一个非常核心的内容：最终一致性。\n\n## 最终的一致\n\n在我看来，最终一致性是说，系统中所有的数据副本在经过一段时间的同步后，最终能够达到一个一致的状态。也就是说，在数据一致性上，存在一个短暂的延迟。\n\n几乎所有的互联网系统采用的都是最终一致性，只有在实在无法使用最终一致性，才使用强一致性或事务，比如，对于决定系统运行的敏感元数据，需要考虑采用强一致性，对于与钱有关的支付系统或金融系统的数据，需要考虑采用事务。\n\n你可以将强一致性理解为最终一致性的特例，也就是说，你可以把强一致性看作是不存在延迟的一致性。**在实践中，你也可以这样思考：** 如果业务的某功能无法容忍一致性的延迟（比如分布式锁对应的数据），需要实现的是强一致性；如果能容忍短暂的一致性的延迟（比如 QQ 状态数据），就可以考虑最终一致性。\n\n那么如何实现最终一致性呢？你首先要知道它以什么为准，因为这是实现最终一致性的关键。一般来说，在实际工程实践中有这样几种方式：\n\n以最新写入的数据为准，比如 AP 模型的 KV 存储采用的就是这种方式；\n\n以第一次写入的数据为准，如果你不希望存储的数据被更改，可以以它为准。\n\n那实现最终一致性的具体方式是什么呢？常用的有这样几种。\n\n读时修复：在读取数据时，检测数据的不一致，进行修复。比如 Cassandra 的 Read Repair 实现，具体来说，在向 Cassandra 系统查询数据的时候，如果检测到不同节点的副本数据不一致，系统就自动修复数据。\n\n写时修复：在写入数据，检测数据的不一致时，进行修复。比如 Cassandra 的 Hinted Handoff 实现。具体来说，Cassandra 集群的节点之间远程写数据的时候，如果写失败就将数据缓存下来，然后定时重传，修复数据的不一致性。\n\n异步修复：这个是最常用的方式，通过定时对账检测副本数据的一致性，并修复。\n\n在这里，我想强调的是因为写时修复不需要做数据一致性对比，性能消耗比较低，对系统运行影响也不大，所以我推荐你在实现最终一致性时优先实现这种方式。而读时修复和异步修复因为需要做数据的一致性对比，性能消耗比较多，在开发实际系统时，你要尽量优化一致性对比的算法，降低性能消耗，避免对系统运行造成影响。\n\n另外，我还想补充一点，在实现最终一致性的时候，**我推荐同时实现自定义写一致性级别（All、Quorum、One、Any），** 让用户可以自主选择相应的一致性级别，比如可以通过设置一致性级别为 All，来实现强一致性。\n\n现在，想必你了解了 BASE 理论的核心内容了吧？不过这是理论层面上的，那么在实践中，该如何使用 BASE 理论的呢？\n\n## 如何使用 BASE 理论\n\n我以自研 InfluxDB 系统中 DATA 节点的集群实现为例，带你来使用 BASE 理论。咱们先来看看如何保障基本可用。\n\nDATA 节点的核心功能是读和写，所以基本可用是指读和写的基本可用。那么我们可以通过分片和多副本，实现读和写的基本可用。也就是说，将同一业务的数据先分片，然后再以多份副本的形式分布在不同的节点上。比如下面这张图，这个 3 节点 2 副本的集群，除非超过一半的节点都故障了，否则是能保障所有数据的读写的。\n\n![image-20230925144649788](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925144649788.png)\n\n那么如果实现最终一致性呢？就像我上文提到的样子，我们可以通过写时修复和异步修复实现最终一致性。另外，还实现自定义写一致性级别，支持 All、Quorum、One、Any 4 种写一致性级别，用户在写数据的时候，可以根据业务数据的特点，设置不同的写一致性级别。\n\n## 内容小结\n\n本节课我主要带你了解了 BASE 理论，以及 BASE 理论的应用，我希望你明确几个重点：\n\nBASE 理论是对 CAP 中一致性和可用性权衡的结果，它来源于对大规模互联网分布式系统实践的总结，是基于 CAP 定理逐步演化而来的。它的核心思想是，如果不是必须的话，不推荐实现事务或强一致性，鼓励可用性和性能优先，根据业务的场景特点，来实现非常弹性的基本可用，以及实现数据的最终一致性。\n\nBASE 理论主张通过牺牲部分功能的可用性，实现整体的基本可用，也就是说，通过服务降级的方式，努力保障极端情况下的系统可用性。\n\nACID 理论是传统数据库常用的设计理念，追求强一致性模型。BASE 理论支持的是大型分布式系统，通过牺牲强一致性获得高可用性。BASE 理论在很大程度上，解决了事务型系统在性能、容错、可用性等方面痛点。另外我再多说一句，BASE 理论在 NoSQL 中应用广泛，是 NoSQL 系统设计的事实上的理论支撑。\n\n最后我强调一下，对于任何集群而言，不可预知的故障的最终后果，都是系统过载。如何设计过载保护，实现系统在过载时的基本可用，是开发和运营互联网后台的分布式系统的重中之重。那么我建议你，在开发实现分布式系统，要充分考虑如何实现基本可用。\n\n## 课堂思考\n\n我在文章中提了一些实现基本可用的方法，比如流量削峰、延迟响应、体验降级、过载保护等，那么你不妨思考一下，还有哪些方法可以用来实现基本可用呢？欢迎在留言区分享你的看法，与我一同讨论。\n\n最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。\n\n<iframe width=\"100%\" frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/200717\" > </iframe>","categories":["分布式协议与算法实战"]},{"title":"03丨技术视角：AI产品经理需要懂的技术全景图","url":"/posts/3884234976.html","content":"\n\n\n你好，我是海丰。今天，我想和你聊聊 AI 产品经理需要懂的技术有哪些。\n\n在转型成为 AI 产品经理之前，你一定最关心技术问题。这也是很多同学的疑问，比如：AI 产品经理要不要懂技术？现在市面上 AI 的课程特别多，但都面向算法工程师，内容太复杂，我到底要掌握到哪种程度呢？\n\n这些疑问我现在就能给你一个肯定的回答：AI 产品经理一定要懂技术。这就像一个产品经理要懂研发技术是一样的道理。但是，我们具体要掌握哪些技术，掌握到什么程度，是不是要像技术人员一样去学习市面上那些 AI 课程呢？这就是我们今天要解决的问题。\n\n这节课，我会站在 AI 产品经理的视角，结合一张 AI 技术全景图，来帮你解决学什么技术和学到什么程度的问题。让你能够和算法工程师同频沟通，知道该如何去管控 AI 项目进度，让你最终有能力去牵头主导一个 AI 项目。\n\n![image-20231024193521705](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20231024193521705.png)\n\n\n\n总的来说，AI 产品经理需要知道五方面的技术知识，分别是数学统计学相关的基本概念，模型构建的整个流程，常见算法的原理和应用场景，模型验收的具体指标和方法，以及模型相关的技术名词。其中，模型的构建流程、算法的技术知识和模型的验收标准这三项知识非常重要，它们也是 AI 产品经理必备的核心能力，所以我还会在后面的课程中单独来讲。\n\n\n\n## 数学统计学基础概念\n\n首先，我们来看产品经理需要学习的数学统计学知识。你可能会奇怪，作为一个产品经理，为什么还要学数学呢？\n\n因为今天的各种人工智能技术都是建立在数学模型基础之上的，必备的数学统计学知识是理解人工智能的基础，所以作为 AI 产品经理来说，这些基础知识也是必须要学习的。\n\n只不过，**对于 AI 产品经理来说，虽然不需要了解数学公式，以及公式背后的逻辑，但我们需要知道数学统计学的基本概念，以及概念的落地应用**。所以，我不会给你讲导数和偏导数的公式，也不会讲贝叶斯推导，我只会把我在工作中接触到的，比较多的数学和统计学概念整理出来。了解这些概念，知道它们的作用，对我们来说就足够了。\n\n这些数学和统计学的知识可以分成两大类：一类是线性代数中的基础名词，如标量、向量、张量；另一类是概率统计中的常见分布，如正态分布、伯努利分布。接下来，我们先从线性代数中的基础名词讲起。\n\n### 线性代数\n\n我们拿起笔，先在本子上画上一个个小圆点，每个这样的点可以代表一个整数、实数或者复数。这样一个单独的数，在线性代数中我们叫它**标量**（Scalar）。\n\n如果我们把这些标量按一定顺序组成一个序列数，如 {x1 , x2 , x3 ,..., xn}，这样的数列就叫做**向量**（Vector）。你也可以理解成，我们给一个个单独的数（标量）增加了一个维度，它就变成了一个数组（向量），所以向量可以看做标量的扩展。\n$$\nx = \n\\left[\n\\matrix{\n x_1\\\\\n x_2\\\\\n ...\\\\\n x_n\n}\n\\right]\n$$\n\n\n又因为每个向量都由若干标量构成，如果我们把向量中所有标量都替换成相同规格的向量，就会得到一个**矩阵**（Matrix）。同样的，矩阵也可以看作是向量的扩展，是我们给原始的向量增加了一个维度，让它变成了一个二维数组。\n$$\nx = \n\\left[\n\\matrix{\n  x_{11} & x_{12} & x_{13}\\\\\n  x_{21} & x_{22} & x_{23}\\\\\n  x_{31} & x_{32} & x_{33}\n}\n\\right]\n$$\n\n\n到这你是不是有点迷糊了？这样一来，矩阵和标量又有什么关系呢？\n\n比如说，我们可以把矩阵看成一个灰度图像，如果一张灰度图像是由 32*32 个像素点组成，那我们就可以把这个图像看成是一个32*32 的矩阵，里面的每一个像素点就是由灰度值（0 到 255）组成的标量。\n\n再比如说，在我们做用户画像的时候，如果有 N 个用户，每个用户有 M 个特征，利用它们，我们就会得到一个用户画像。它可以看成是一个 N*M 的矩阵，矩阵中的每一个点，都是某一个用户对应的某个特征，是一个具体的数值，也就是标量了。\n\n如果我们将矩阵中的每个标量元素再替换成为向量的话，就会得到一个**张量**（Tensor）。这个时候，张量就可以看作是矩阵的扩展，是给原始的矩阵增加了一个或多个维度之后得到的。我们也可以把张量理解成是矩阵向任意维度的扩展，它是深度学习框架中的基本概念。\n\n到这里，你可能想问，概念这么多，怎么才能记得住啊？这里我再教你一个小技巧。我们可以把标量看成是零阶张量，向量看成是一阶张量（一维数组），矩阵看成是二阶张量（二维数组），而且任意一张彩色图片都可以表示成一个三阶张量。\n\n### 概率统计\n\n在概率统计中，我们最需要掌握的就是概率的分布。举个例子，我们在做一个预测用户评分的时候，这个分数可能是购买倾向，也可能是信用评分。按照经验，这个评分结果应该是符合正态分布的。这个时候，如果算法同学的模型预测出来的结果不符合正态分布，我们就必须对这个结果进行质疑，让他们给出合理的解释。\n\n从这个例子中我们知道，**概率分布是我们用来评估特征数据和模型结果的武器。** 那产品经理怎么才能利用好这个武器呢？**首先，我们要掌握常用的概率分布的类型。其次，我们还要知道业务场景下的特征数据和模型结果的分布，以及它们应该符合哪种分布类型。这样，产品经理就可以把概率分布应用于日常的工作中。**\n\n因为概率的分布和随机变量的类型相关，随机变量又可以分为离散型随机变量和连续性随机变量两种。为了方便你查看，我把这两种变量对应的概率分布的类型都总结在了下面这张图里。\n\n![image-20231024194600296](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20231024194600296.png)\n\n这其中，最常见的概率分布包括伯努利分布、二项分布、泊松分布和正态分布，这也是我们要重点掌握的。下面，我们一一来讲。\n\n**伯努利分布**也可以叫做零一分布。如果我们只进行一次实验，并且这个实验只有两个结果，分别记为 0、1，这就符合伯努利分布。比如在电商场景下，我们设计一个抽奖游戏，某个用户有没有中奖，这个结果就应该符合伯努利分布。\n\n如果重复多次伯努利实验，并且让每次实验都相互独立，让结果只有 0、1 这两种。那 n 次伯努利实验中，结果为 0 的次数的离散概率分布就是**二项分布**。你也可以理解为，抛 n 次硬币，出现正面次数的概率的分布。\n\n**泊松分布描述的是单位时间内，随机事件发生的次数。** 比如，我们的频道页平均每分钟就有 2000 次访问，那如果让我们计算出下一分钟能够有 4000 次访问的概率，这个结果就是泊松分布。\n\n最后，我们来看正态分布，它也叫**高斯分布**。正态分布的曲线特点是**两头低、中间高，左右对称**，所以我们也经常叫它钟形曲线。下图就是一个标准的正态分布图，你看到之后一定会觉得非常熟悉。\n\n![image-20231024194625595](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20231024194625595.png)\n\n\n\n在现实生活中，人的很多特质都符合正态分布，比如人的身高、体重、运动量、智力、收入、甚至信用情况等等。\n\n## 模型构建、算法知识以及模型验收\n\n课程一开始的时候，我就说了，今天对于建模流程、算法知识以及模型验收这三部分内容，只要做到大概的印象就可以，因为这些是后面课程的重点内容。\n\n所以接下来，我会总结出一个知识结构图，给你讲解其中的重要节点，来帮助你形成一个大体的知识框架。这样，当你后面进行学习的时候，再把具体的知识填充到里面，就能形成自己的知识体系树了。\n\n![image-20231024194728779](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20231024194728779.png)\n\n对于模型构建来说，**我们一定要知道模型的建模流程都有哪些节点，这些节点都牵扯了哪些角色，每个角色又承担了什么工作，每个节点的产出物是什么，以及每个节点合理的工作周期又应该是多长时间。**\n\n一个模型构建的整体流程，它一共包括五个阶段，分别为模型设计、特征工程、模型训练、模型验证，以及模型融合。这五个阶段完成之后，模型就会交付到产品端了。\n\n建模的过程实际上就是应用某个算法技术来实现一个模型的过程，这其中最重要的，就是我们选择的是什么算法。所以，作为 AI 产品经理，你要知道目前的技术现状能解决什么问题，在什么场景下有哪些机器学习算法，以及每种算法适合解决哪类问题。\n\n我也按照常用的算法分类方式，把一些常用算法整理在了脑图里。因为算法是未来你区别于普通产品经理的重要抓手，所以我后面会花一整个章节来为你讲解当前主流的算法。\n\n至于模型验收的工作，我也会单独用一个模块来和你详细讲讲。其中，模型验收涉及的评估手段和指标，评估指标背后的计算逻辑，以及怎么选择合适样本进行测试的方法，你都一定要掌握好。\n\n## 模型相关技术名词\n\n在我刚开始转做 AI 产品经理的时候，遇到过这么一件事儿，我们的用户年龄预测模型训练时候 的 KS 值（模型中用于区分预测正负样本分隔程度的评价指标）很高，但是 OOT 测试的时候 KS 还不足 10。当我拿着结果去找算法同学沟通的时候，他就说了一句，“可能是过拟合了，我再改改”。\n\n我刚才提到的 KS、OOT 测试和过拟合你都知道是什么意思吗？如果你知道，说明你的技术基础还不错，如果你还不知道也没关系，当时的我就不知道。\n\n就因为不知道什么是过拟合，所以我什么问题都提不出来，只能自己回去翻书，恶补基础。不过，现在我的算法工程师再和我说出现过拟合问题，我就不会轻易放他离开。因为这明显是模型样本选择出了问题，还有模型验证的时候他也没有认真做，不然这个问题根本不应该到我这里才被发现。他们应该在模型验证的时候就发现这个问题，并且处理掉。\n\n因此，了解一些算法相关的技术名词是非常有必要的，这能帮助我们和算法工程师站在一个频率上对话，提高协作效率和项目效果。\n\n### 过拟合和欠拟合\n\n我们和算法同学聊某个模型表现的时候，他们常常会提到过拟合和欠拟合。它们是什么意思呢？想要理解它们，我们还得先说说偏差和方差是什么。\n\n**偏差**指的是模型的预测结果和实际的结果的偏离程度。如果偏差比较大，就说明模型的拟合程度比较差，也就是**欠拟合**（高偏差），说的直白一些就是模型预测不准。造成欠拟合的原因可能是特征少或者模型训练不足。\n\n而**方差**指的是模型在不同测试样本上表现的稳定程度。假设一个分类模型，在不同样本上测试，得到的 KS 值有时候是 20，有时候是 40，这就说明这个模型方差偏大，模型效果不稳定，在一部分数据上表现好，在另一部分数据上表现差，也就是**过拟合**（高方差）。造成过拟合的原因可能是特征过多或者训练集不够。\n\n### 特征清洗、数据变换、**训练集、验证集和测试集**\n\n除了欠拟合、过拟合之外，我们还经常听到算法工程师提到当前特征数据质量不好，他们需要花时间进行**特征清洗**。特征数据清洗简单来说，就是对数据进行清洗去掉重复值、干扰数据，以及填充缺失值。一般来说，数据清洗需要反复进行很多次，也会持续很多天，当然具体的工作量也要视数据质量和量级决定。\n\n除此之外，数据有时候还需要进行**数据变换**，处理成方便模型使用的数据形式。举个例子，我们需要使用用户的身高作为模型特征，但是有的数据是用厘米作单位，有的数据会使用米作单位。这个时候，我们就需要使用归一化，把数据的单位统一成米或者厘米。归一化也是数据变换最主要的手段。\n\n最后，关于模型训练我们还需要知道三个概念，**训练集、验证集和测试集**。训练集是让机器学习的样本集合，用来拟合模型。验证集是模型训练过程中，用来对模型性能做初步的评估，用于模型参数调优。测试集是最终用来评估模型效果的。\n\n### 跨时间测试和回溯测试\n\n模型训练结束，我们就要对模型进行测试了。模型测试阶段，我们需要掌握两个关键概念，分别是跨时间测试和回溯测试\n\n**跨时间测试也叫 OOT 测试**，是测量模型在时间上的稳定性。**回溯测试**就是用真实的、过去一段时间的数据，构造出一个模拟的环境（回溯环境），让模型在历史的那段环境中运行，得到历史某个时间点的模型结果。回溯测试在量化投资中的应用比较广泛。\n\n总的来说，跨时间测试是在模型上线之前就应该要做的事情，回溯测试是指模型已经存在并且已经上线了，我们想要看模型在历史某个时间点的数据表现怎么样的时候，才会进行的测试。\n\n### 联合建模与联邦学习\n\n联合建模和联邦学习的概念你可能还比较陌生，它们经常会在金融领域会用到，而且也是未来建模的一个发展方向。\n\n所谓联合建模，就是使用三方公司（如银联、运营商、电商）的数据，在对方的环境下部署一个模型，然后我们通过接口调用这个模型的结果，再把结果融合到我们自己的模型上。通过 这种方式，可以弥补我们自有业务中数据不足的问题。\n\n但是联合建模会有一个弊端，就是当我们使用三方公司的数据建模之后，在调用的时候，必须传入一个主键来获得模型结果，这个主键如果是用户手机号，身份证号等敏感信息，就会有个人信息泄露的风险。\n\n这个时候，联邦学习就有了用武之地。你可以把联邦学习理解成是特殊的联合建模，或者一种分布式的模型部署方式。使用联邦学习之后，我们调用部署在第三方模型的时候，输入的就不是具体的业务数据而是模型参数，这样就不会有个人信息外传的风险了。目前，蚂蚁、腾讯、京东、微众银行，它们各自都有很成熟的联邦学习解决方案了。\n\n总的来说，如果以后你的业务要使用三方数据，就可以考虑做联合建模。如果想要避免个人信息外传的风险，就可以考虑使用联邦学习技术。\n\n## 总结\n\n今天，我带你了解了 AI 产品经理应该懂的技术，以及这些技术需要掌握到的程度。\n\n对于数学统计学基础，我们只要掌握今天讲的概念定义就可以； 对于模型构建过程、算法知识和模型验收，你一定要深入了解，知道它们具体的内容和原理；对于模型相关的技术名词，你只要理解我今天列举的常用名词就够了，后面在工作中你可以再慢慢积累，形成你自己的知识体系。\n\n最后，我还想再多说几句，有些同学一看到技术知识，就很容易一头扎进去。但是这些名词在转行初期，你只需要做到知其然就可以。**因为产品经理的职责是善于把技术作为工具和手段，所以我们学习这些专业名词的目的也是为了更好地沟通和推进工作，更好地完成业务目标**，实在没必要把它们的来龙去脉研究透彻。\n\n当然，成功转型后，这些技术知识我们也要进行精进。不过，那个时候，在具体业务的场景下，你就会有更明确的学习方向了。同时，有了算法同学的帮助，你的学习效果也会事半功倍。\n\n![image-20231024194831124](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20231024194831124.png)\n\n## 课后讨论\n\n结合你自己的工作经验，你觉得哪些业务场景属于泊松分布，哪些业务场景属于正态分布呢？\n\n期待在留言区看到你的思考和提问，我们下节课见！\n\n\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/322393\" > </iframe>","categories":["成为AI产品经理"]},{"title":"03丨ACID理论：CAP的酸，追求一致性","url":"/posts/2876362069.html","content":"\n\n\n你好，我是韩健。\n\n提到 ACID，我想你并不陌生，很多同学也会觉得它容易理解，在单机上实现 ACID 也不难，比如可以通过锁、时间序列等机制保障操作的顺序执行，让系统实现 ACID 特性。但是，一说要实现分布式系统的 ACID 特性，很多同学就犯难了。那么问题来了，为什么分布式系统的 ACID 特性在实现上，比较难掌握呢？\n\n在我看来，ACID 理论是对事务特性的抽象和总结，方便我们实现事务。你可以理解成：如果实现了操作的 ACID 特性，那么就实现了事务。而大多数人觉得比较难，是因为分布式系统涉及多个节点间的操作。加锁、时间序列等机制，只能保证单个节点上操作的 ACID 特性，无法保证节点间操作的 ACID 特性。\n\n那么怎么做才会让实现不那么难呢？答案是你要掌握分布式事务协议，比如二阶段提交协议和 TCC（Try-Confirm-Cancel）。这也是我接下来重点和你分享的内容。\n\n不过在带你了解二阶段提交协议和 TCC 之前，咱们先继续看看苏秦的故事，看这回苏秦又遇到了什么事儿。\n\n最近呢，秦国按捺不住自己躁动的心，开始骚扰魏国边境，魏王头疼，向苏秦求助，苏秦认为“三晋一家亲”，建议魏王联合赵、韩一起对抗秦国。但是这三个国家实力都很弱，需要大家都同意联合，一致行动，如果有任何一方不方便行动，就取消整个计划。\n\n根据侦查情况，明天发动反攻胜算比较大。苏秦想协调赵、魏、韩，明天一起行动。**那么对苏秦来说，他面临的问题是，如何高效协同赵、魏、韩一起行动，并且保证当有一方不方便行动时，取消整个计划。**\n\n![image-20230925143003398](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925143003398.png)\n\n苏秦面对的这个新问题，就是典型的如何实现分布式事务的问题，**赵、魏、韩明天攻打秦国，这三个操作组成一个分布式事务，要么全部执行，要么全部不执行。**\n\n了解了这个问题之后，我们看看如何通过二阶段提交协议和 TCC，来帮助苏秦解决这个难题。\n\n## 二阶段提交协议\n\n二阶段提交协议，顾名思义，就是通过二阶段的协商来完成一个提交操作，那么具体是怎么操作的呢？\n\n首先，苏秦发消息给赵，赵接收到消息后就扮演协调者（Coordinator）的身份，由赵联系魏和韩，发起二阶段提交：\n\n![image-20230925143026212](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925143026212.png)\n\n赵发起二阶段提交后，先进入**提交请求阶段（又称投票阶段）。** 为了方便演示，我们先假设赵、魏、韩明天都能去攻打秦国：\n\n![image-20230925143102424](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925143102424.png)\n\n\n\n也就是说，第一步，赵分别向魏、韩发送消息：“明天攻打秦国，方便吗？”\n\n第二步，赵、魏、韩，分别评估明天能否去攻打秦国，如果能，就预留时间并锁定，不再安排其他军事活动。\n\n第三步，赵得到全部的回复结果（包括他自己的评估结果），都是 YES。\n\n赵收到所有回复后，进入**提交执行阶段（又称完成阶段），** 也就是具体执行操作了，大致步骤如下：\n\n![image-20230925143115912](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925143115912.png)\n\n首先，赵按照“要么全部执行，要么放弃”的原则，统计投票结果，因为所有的回复结果都是 YES，所以赵决定执行分布式事务，明天攻打秦国。\n\n然后，赵通知魏、韩：“明天攻打秦国。”\n\n接到通知之后，魏、韩执行事务，明天攻打秦国。\n\n最后，魏、韩将执行事务的结果返回给赵。\n\n这样一来，赵就将事务执行的结果（也就是赵、魏、韩明天一起攻打秦国），返回给苏秦，那么，这时苏秦就解决了问题，协调好了明天的作战计划。\n\n在这里，赵采用的方法就是二阶段提交协议。在这个协议中：\n\n你可以将“赵明天攻打秦国、魏明天攻打秦国、韩明天攻打秦国”，理解成一个分布式事务操作；\n\n将赵、魏、韩理解为分布式系统的三个节点，其中，赵是协调者（Coordinator），将苏秦理解为业务，也就是客户端；\n\n将消息理解为网络消息；\n\n将“明天能否攻打秦国，预留时间”，理解为评估事务中需要操作的对象和对象状态，是否准备好，能否提交新操作。\n\n需要注意的是，在第一个阶段，每个参与者投票表决事务是放弃还是提交。一旦参与者投票要求提交事务，那么就不允许放弃事务。也就是说，**在一个参与者投票要求提交事务之前，它必须保证能够执行提交协议中它自己那一部分，即使参与者出现故障或者中途被替换掉。** 这个特性，是我们需要在代码实现时保障的。\n\n还需要你注意的是，在第二个阶段，事务的每个参与者执行最终统一的决定，提交事务或者放弃事务。这个约定，是为了实现 ACID 中的原子性。\n\n二阶段提交协议最早是用来实现数据库的分布式事务的，不过现在最常用的协议是 XA 协议。这个协议是 X/Open 国际联盟基于二阶段提交协议提出的，也叫作 X/Open Distributed Transaction Processing（DTP）模型，比如 MySQL 就是通过 MySQL XA 实现了分布式事务。\n\n但是不管是原始的二阶段提交协议，还是 XA 协议，都存在一些问题：\n\n在提交请求阶段，需要预留资源，在资源预留期间，其他人不能操作（比如，XA 在第一阶段会将相关资源锁定）；\n\n数据库是独立的系统。\n\n因为上面这两点，我们无法根据业务特点弹性地调整锁的粒度，而这些都会影响数据库的并发性能。那用什么办法可以解决这些问题呢？答案就是 TCC。\n\n## TCC（Try-Confirm-Cancel）\n\nTCC 是 Try（预留）、Confirm（确认）、Cancel（撤销） 3 个操作的简称，它包含了预留、确认或撤销这 2 个阶段。那么你如何使用 TCC 协议，解决苏秦面临的问题呢？\n\n首先，我们先**进入到预留阶段**，大致的步骤如下：\n\n![image-20230925143222966](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925143222966.png)\n\n第一步，苏秦分别发送消息通知赵、魏、韩，让他们预留明天的时间和相关资源。然后苏秦实现确认操作（明天攻打秦国），和撤销操作（取消明天攻打秦国）。\n\n第二步，苏秦收到赵、魏、韩的预留答复，都是 OK。\n\n如果预留阶段的执行都没有问题，就进入**确认阶段**，大致步骤如下：\n\n![image-20230925143238739](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925143238739.png)\n\n第一步，苏秦执行确认操作，通知赵、魏、韩明天攻打秦国。\n\n第二步，收到确认操作的响应，完成分布式事务。\n\n如果预留阶段执行出错，比如赵的一部分军队还在赶来的路上，无法出兵，那么就进入撤销**阶段**，大致步骤如下：\n\n![image-20230925143259304](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925143259304.png)\n\n第一步，苏秦执行撤销操作，通知赵、魏、韩取消明天攻打秦国的计划。\n\n第二步，收到撤销操作的响应。\n\n你看，在经过了预留和确认（或撤销）2 阶段的协商，苏秦实现这个分布式事务：赵、魏、韩三国，要么明天一起进攻，要么明天都按兵不动。\n\n其实在我看来，TCC 本质上是补偿事务，**它的核心思想是针对每个操作都要注册一个与其对应的确认操作和补偿操作（也就是撤销操作）。** 它是一个业务层面的协议，你也可以将 TCC 理解为编程模型，TCC 的 3 个操作是需要在业务代码中编码实现的，为了实现一致性，确认操作和补偿操作必须是等幂的，因为这 2 个操作可能会失败重试。\n\n另外，TCC 不依赖于数据库的事务，而是在业务中实现了分布式事务，这样能减轻数据库的压力，但对业务代码的入侵性也更强，实现的复杂度也更高。所以，我推荐在需要分布式事务能力时，优先考虑现成的事务型数据库（比如 MySQL XA），当现有的事务型数据库不能满足业务的需求时，再考虑基于 TCC 实现分布式事务。\n\n## 内容小结\n\n本节课我主要带你了解了实现分布式系统 ACID 特性的方法，二阶段提交协议和 TCC，我希望你明确这样几个重点。\n\n二阶段提交协议，不仅仅是协议，也是一种非常经典的思想。二阶段提交在达成提交操作共识的算法中应用广泛，比如 XA 协议、TCC、Paxos、Raft 等。我希望你不仅能理解二阶段提交协议，更能理解协议背后的二阶段提交的思想，当后续需要时，能灵活地根据二阶段提交思想，设计新的事务或一致性协议。\n\n幂等性，是指同一操作对同一系统的任意多次执行，所产生的影响均与一次执行的影响相同，不会因为多次执行而产生副作用。常见的实现方法有 Token、索引等。它的本质是通过唯一标识，标记同一操作的方式，来消除多次执行的副作用。\n\nPaxos、Raft 等强一致性算法，也采用了二阶段提交操作，在“提交请求阶段”，只要大多数节点确认就可以，而具有 ACID 特性的事务，则要求全部节点确认可以。所以可以将具有 ACID 特性的操作，理解为最强的一致性。\n\n另外，我想补充一下，三阶段提交协议，虽然针对二阶段提交协议的“协调者故障，参与者长期锁定资源”的痛点，通过引入了询问阶段和超时机制，来减少资源被长时间锁定的情况，不过这会导致集群各节点在正常运行的情况下，使用更多的消息进行协商，增加系统负载和响应延迟。也正是因为这些问题，三阶段提交协议很少被使用，所以，你只要知道有这么个协议就可以了，但如果你想继续研究，可以参考《Concurrency Control and Recovery in Database Systems》来学习。\n\n最后我想强调的是，你可以将 ACID 特性理解为 CAP 中一致性的边界，最强的一致性，也就是 CAP 的酸（Acid）。根据 CAP 理论，如果在分布式系统中实现了一致性，可用性必然受到影响。比如，如果出现一个节点故障，则整个分布式事务的执行都是失败的。实际上，绝大部分场景对一致性要求没那么高，短暂的不一致是能接受的，另外，也基于可用性和并发性能的考虑，**建议在开发实现分布式系统，如果不是必须，尽量不要实现事务，可以考虑采用强一致性或最终一致性**。\n\n## 课堂思考\n\n既然我提了一些实现分布式事务的方法，比如二阶段提交协议、TCC 等，那么你不妨思考一下，事务型分布式系统有哪些优点，哪些缺点呢？欢迎在留言区分享你的看法，与我一同讨论。\n\n最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。\n\n<iframe width=\"100%\" frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/199663\" > </iframe>","categories":["分布式协议与算法实战"]},{"title":"02丨个人视角：成为AI产品经理，要先搞定这两个问题","url":"/posts/3137460286.html","content":"\n你好，我是海丰。今天，我们来聊聊 AI 产品经理的工作职责与能力要求。\n\n假设，你正在参加一个 AI 产品岗的面试，面试官问了你这两个问题，你会怎么回答：\n\n你觉得 AI 产品经理和传统产品经理有什么区别？\n\n在你看来 AI 产品经理的工作职责是什么？\n\n你可别小瞧这两个问题，这实际上是面试官在考察面试者对 AI 产品经理这个岗位的理解程度，以及你到底有没有相关的实战经验，甚至在工作中有没有独立的思考。\n\n因此，这两个问题如果能回答好，我们肯定能给面试官留下一个好的印象。而且，搞清楚这两个问题，也能帮助你在转型时更清楚这个岗位的要求，能够有的放矢地去补足自己的短处，发挥自己的优势。\n\n## AI 产品经理和传统产品经理有什么区别？\n\n我们先来看看，AI 产品经理和传统产品经理的区别。从 “AI 产品经理” 这个词来看，它可以分解为“产品经理” + “AI”，AI 产品经理作为产品经理，核心职责和底层能力与传统产品经理是一致的，仍然是通过技术手段实现业务目标，但是它们在面向的对象，使用的技术，以及岗位边界这三个方面却大有不同，不同在哪呢？接下来，我详细给你讲讲。\n\n首先，我们来看**面向对象上的不同**。传统的产品经理更多活跃在 C 端，他们面向的是用户，比如电商产品经理、策略产品经理、社区产品经理等等。但是 AI 产品经理更多活跃在 B 端，面向的是各大企业，而且 AI 产品更多应用在 B 端的场景下，比如云从科技的人脸识别产品，大多是给到银行，应用于银行的自动柜员机开户等场景。\n\n之所以有这些不同，主要是 C 端场景的产品，前期大部分都需要烧钱获客。但是对当前市场来说，线上流量越来越贵，C 端产品想要有所突破越来越难，倒不如去做 B 端服务，通过给企业服务的方式完成 AI 产品商业化。\n\n其次，是**实现产品目标的技术手段不同**。传统产品经理对接的是研发工程师，需要通过研发工程师的代码，来完成产品的功能实现，那他们使用的就是研发技术。\n\n而 AI 产品经理对接的是算法工程师和研发工程师，需要对接算法工程师完成具体的模型，再对接研发工程师进行工程开发联调和上线。最终，我们得到的产品形态可能是一个 API 接口，没有所谓的页面。比如，腾讯的人脸识别产品，对外暴露的就是一个 HTTP 接口，接口名称为人脸检测与分析，接口描述是识别上传图像上面的人脸信息，API 地址为 https://api.ai.qq.com/fcgi-bin/face/face_detectface。\n\n基于这种情况，**AI 产品经理除了要懂一些基本的研发技术之外，也需要深入学习算法知识**，比如工作中常用到哪些算法，以及它们的实现逻辑等等。甚至，由于整个 AI 行业仍处于早期阶段，也就是技术驱动的阶段，因此 AI 产品经理需要了解更多的技术知识。\n\n只有当整个 AI 行业趋于成熟，技术壁垒逐渐打破的时候，AI 产品经理才可以对技术只要做到了解就够用了。至于 AI 相关的技术，以及这些技术你需要掌握到什么程度，我会在后面的课程中和你详细说。\n\n最后，我们再来看看 **AI 产品经理在岗位边界上的不同。这个边界可以分为两个方面，一个是岗位要求的边界，一个是和技术人员协作的边界**。\n\n我们先来看传统产品经理的岗位要求。传统产品经理的岗位要求非常清晰，一般来说，电商产品经理需要懂得电商业务、供应链、电商后端设计，了解用户裂变、营销活动设计，社区产品经理要有社区、社交产品经验。而且每一家企业相同岗位的 JD （职位描述）差别不会太大。但 AI 产品经理的岗位要求非常模糊，同样是 AI 产品岗位，有的公司会要求你具有行业经验，不要求你懂技术，而有的公司会要求你必须懂技术，甚至要求你能看懂 Python 代码。\n\n为什么 AI 产品经理的岗位要求这么模糊和混乱呢？这主要是因为 AI 产品岗位比较新，很多公司还不能确定这个岗位要做的事情。有些技术导向型的公司就希望产品经理懂技术，甚至是研发转岗过来的，有些偏业务导向的，则希望产品经理有丰富的行业经验。当然，也不排除有些公司对这个岗位自己都没有想法，只是从网站上抄袭 JD。\n\n对于这种情况，我的建议是，你要先确定你的目标与能力项，再去根据 JD 内容挑选合适的岗位，但也不要被 JD 迷惑，觉得有些公司要求技术很复杂，你就要去学习如何做机器学习算法模型。当然，如果你本身就是一个技术极客，有这方面的热忱，那就正好可以去这样的企业试试。\n\n岗位要求的边界说完了，我们再来看看和技术人员协作的边界。这里说的不同主要体现在，传统产品经理和研发协作时候，只需要提供 PRD 文档（产品需求文档），对需求进行讲解，有问题及时提供解答就可以了。但是 AI 产品经理很难产出一个 ROI（投资回报率） 指标明确的 PRD 文档，以及我们和算法同学的沟通也不是一次需求宣讲就能完成的，通常我们需要进行多次的沟通确认，并且在沟通中逐渐清晰对于算法目标范围的设定。\n\n这里有点绕，我来举个例子，我曾经给算法同学提过需求，要求他们做一个细分场景的信用评分模型。这个时候，我没有办法明确说你的模型区分度要达到 30 还是 31。我只能要求，这个模型在我们自己的业务样本下，模型区分度应达到 35 以上，毕竟算法本身同样具有不确定性。\n\n## AI 产品经理的工作职责和能力要求是什么？\n\n正是因为 AI 产品经理和传统产品经理之间有这些不同，所以他们在工作职责和能力要求上也会有所不同。AI 产品经理需要知道，**你在什么场景下，可以通过什么样的技术来解决问题，解决到什么程度。**比如，在智能客服场景，你可以通过自然语言理解技术让机器去回复一些标准的问答，来减轻人工客服的压力，但对于强个性化的用户问题，还是需要人工介入来解决的。\n\n接下来，我就通过 AI 产品上线的过程，来和你详细讲讲 AI 产品经理的工作职责。一般来说，一个 AI 产品上线的流程大致可以分为，需求定义、方案设计、算法预研、模型构建、模型评估、工程开发、测试上线等几个步骤。这其中，产品经理需要主导的节点有定义产品方向、设计产品方案、跟进产品开发和产品验收评估，那我们重点关注这四个步骤。\n\n### 1. 产品经理对产品方向进行定义\n\n![image-20231020162938548](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20231020162938548.png)\n\n\n\n在我们决定做一个 AI 产品的时候，不管是处于基础层还是技术层或者是应用层的 AI 产品经理，首要的职责都应该是去定义一个 AI 产品。这包括，搞清楚这个行业的方向，这个行业通过 AI 技术可以解决的问题，这个 AI 产品具体的应用场景，需要的成本和它能产生的价值。\n\n这就要求 AI 产品经理除了具备互联网产品经理的基础知识之外，还需要了解 AI 技术的边界，以及通过 AI 技术能够解决的问题是什么。\n\n### 2. 产品经理给出产品的设计方案\n\n![image-20231020162955891](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20231020162955891.png)\n\n\n\n完成了产品定义之后，产品经理需要给出产品的设计方案。产品的设计方案会根据产品形态不同而不同，比如硬件和软件结合的 AI 产品，会包括外观结构的设计，机器学习平台的产品需要包括大量的交互设计，模型类的产品（推荐系统、用户画像）更多的是对于模型上线的业务指标的要求。\n\n在这个阶段， AI 产品经理需要了解，现在市场主流算法都有哪些，不同的算法应用场景是什么，算法的技术边界在哪里。\n\n比如，我们要从 0 到 1 做一个推荐系统，并且希望它能尽快上线，但如果模型同学打算用某种创新的深度学习模型去做就不合适了。因为深度学习的模型不仅技术难度高，而且模型训练时间久，需要的算力也更多，还有关键的一点是在推荐系统的 0 到 1 阶段，业务方领导会要求模型具有可解释性，所以创新模型就不如简单地协同过滤，加逻辑回归实现起来方便快捷。\n\n只是对于技术人员来说，他们更希望用新技术去解决问题，如果我们完全不懂技术，用了深度学习模型之后，可能推荐系统上线周期不但增加了不少，而且效果也不一定会比传统的机器学习方式好多少。这个时候，产品经理就需要通过自己掌握的技术知识去把控技术和业务的平衡了。\n\n另外还有一种更常见的情况，产品经理在和算法同学沟通方案的时候，他们会说，“这个模型我打算用 XGBoost 去做”，或者“目前很多数据没有结构化，我们需要先把一些数据结构化并且做归一化处理”等等。\n\n相信很多同学看到这里都会有些懵，什么是 XGBoost，什么又是归一化？如果产品经理不停地去问算法同学这些问题，估计没有几个算法同学会愿意一点点去解释这些基础名词。\n\n所以，对于 AI 产品经理来说，此阶段的能力要求为，**基本的技术知识是必须要了解的。这些包括基本的统计学概率论知识，主流算法的基本原理和应用场景，以及这些算法可以帮助我们达成什么样的产品目标**。\n\n### 3. 产品经理跟进产品上线\n\n![image-20231020163011460](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20231020163011460.png)\n\n产品设计完成之后，就到了工程和算法同学分别进行开发的环节了。在这个过程中，你需要承担一些项目经理的职责，去跟进项目的上线进度，协调项目资源。\n\n因此，这个阶段**产品经理至少要知道模型的构建过程是怎么样的**，否则产品经理怎么能够评估当前进度到哪里了呢？另外，**产品经理还需要知道模型构建过程中，每个节点的产出物，以及它的上下游关系**。只有这样，产品经理才可以清楚评估项目进度，遇到需要协调资源的时候，也知道产品在这个阶段需要的是什么。\n\n### 4. 产品评估\n\n![image-20231020163028039](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20231020163028039.png)\n\n产品开发完成之后，产品经理还需要验收产品是否满足业务需求。\n\n在这个阶段，产品经理的能力要求是，**需要知道如何去评估一个模型，评估模型的指标都有哪些，具体评估的过程是怎么样的，以及评估结果在什么范围内是合理的**。比如，你的算法工程师告诉你，这个模型的区分度是 40，那你至少要知道区分度是怎么计算的，40 是不是一个合理的数字。只有这样，产品经理才算对产品有完整的了解和把控。\n\n## 总结\n\n今天，我们先从三个方面一起讨论， AI 产品经理和传统产品经理的不同，它们主要是面向的对象、实现的技术手段和岗位的边界。具体的不同你可以看我整理出的表格。\n\n![image-20231020163043392](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20231020163043392.png)\n\n\n\n总体来说，不管是处于哪个层级的产品经理，除了互联网产品经理的基础能力之外，还需要掌握的能力是：\n\n了解 AI 技术的边界，知道 AI 能力可以做什么，不能做什么；\n\n懂得基本的统计学、概率论知识，了解市场上主流的算法和原理，知道它们适合的应用场景；\n\n知道模型的构建流程是怎么样的，构建过程中每个节点产出物是什么，以及其中的上下游关系；\n\n要有能力去评估一个模型，知道模型评估的标准、评估的方法，评估结果的合理范围。\n\n除此之外，我还想给你一点建议，如果你希望成为一个 AI 产品经理，除了在工作中积累行业、业务知识，还需要尽快补齐技术部分的知识。这样不管是内部转岗，还是去寻找外部机会，面试官都会认为你是有备而来，这是很大的加分项。\n\n## 课后讨论\n\n相对技术转型的同学来说，你觉得你的优势和劣势分别在哪？你想要怎么改进？\n\n欢迎把你的困惑写到留言区，我们一起讨论。\n\n---\n\n\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/321318\" > </iframe>","categories":["成为AI产品经理"]},{"title":"02丨CAP理论：分布式系统的PH试纸，用它来测酸碱度","url":"/posts/972094249.html","content":"\n\n\n你好，我是韩健。\n\n很多同学可能都有这样的感觉，每次要开发分布式系统的时候，就会遇到一个非常棘手的问题，那就是如何根据业务特点，为系统设计合适的分区容错一致性模型，以实现集群能力。这个问题棘手在当发生分区错误时，应该如何保障系统稳定运行，不影响业务。\n\n这和我之前经历的一件事比较像，当时，我负责自研 InfluxDB 系统的项目，接手这个项目后，**我遇到的第一个问题就是，如何为单机开源版的 InfluxDB 设计分区容错一致性模型。** 因为 InfluxDB 有 META 和 DATA 两个节点，它们的功能和数据特点不同，所以我还需要考虑这两个逻辑单元的特点，然后分别设计分区容错一致性模型。\n\n那个时候，我想到了 CAP 理论，并且在 CAP 理论的帮助下，成功地解决了问题。讲到这儿，你可能会问了：为什么 CAP 理论可以解决这个问题呢？\n\n因为在我看来，CAP 理论是一个很好的思考框架，它对分布式系统的特性做了高度抽象，比如抽象成了一致性、可用性和分区容错性，并对特性间的冲突（也就是 CAP 不可能三角）做了总结。一旦掌握它，你就像拥有了引路人，自然而然就能根据业务场景的特点进行权衡，设计出适合的分区容错一致性模型。\n\n那么问题来了：我说的一致性、可用性和分区容错性是什么呢？它们之间有什么关系？你又该如何使用 CAP 理论来思考和设计分区容错一致性模型呢？这些问题就是我们本节课所要讲的重点了。我建议你集中注意力，认真学习内容，还能学以致用，把 CAP 理论应用到日常工作中。\n\n## CAP 三指标\n\n我刚刚提到，CAP 理论对分布式系统的特性做了高度抽象，形成了三个指标：\n\n一致性（Consistency）\n\n可用性（Availability）\n\n分区容错性（Partition Tolerance）\n\n一致性说的是客户端的每次读操作，不管访问哪个节点，要么读到的都是同一份最新的数据，要么读取失败。\n\n你可以把一致性看作是分布式系统对访问本系统的客户端的一种承诺：不管你访问哪个节点，要么我给你返回的都是绝对一致的数据，要么你都读取失败。**你可以看到，一致性强调的不是数据完整，而是各节点间的数据一致。**\n\n为了帮你理解一致性这个指标，我给你举一个具体的例子。比如，2 个节点的 KV 存储，原始的 KV 记录为“X = 1”。\n\n![image-20230925142135528](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925142135528.png)\n\n\n\n紧接着，客户端向节点 1 发送写请求“SET X = 2”。\n\n![image-20230925142142979](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925142142979.png)\n\n如果节点 1 收到写请求后，只将节点 1 的 X 值更新为 2，然后返回成功给客户端，这个时候节点 2 的 X 值还是 1，那么两个节点是非一致性的。\n\n![image-20230925142149407](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925142149407.png)\n\n如果节点 1 收到写请求后，通过节点间的通讯，同时将节点 1 和节点 2 的 X 值都更新为 2，然后返回成功给客户端，那么在完成写请求后，两个节点的数据就是一致的了，之后，不管客户端访问哪个节点，读取到的都是同一份最新数据。\n\n![image-20230925142155526](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925142155526.png)\n\n一致性这个指标，描述的是分布式系统非常重要的一个特性，强调的是数据的一致。也就是说，在客户端看来，集群和单机在数据一致性上是一样的。\n\n不过集群毕竟不是单机，当发生分区故障的时候，有时不能仅仅因为节点间出现了通讯问题，节点中的数据会不一致，就拒绝写入新数据，之后在客户端查询数据时，就一直返回给客户端出错信息。这句话怎么理解呢？我来举个例子。\n\n业务集群中的一些关键系统，比如名字路由系统，如果仅仅因为发生了分布故障，节点中的数据会不一致，集群就拒绝写入新的路由信息，之后，当客户端查询相关路由信息时，系统就一直返回给客户端出错信息，那么相关的服务都将因为获取不到指定路由信息而不可用、瘫痪，这可以说是灾难性的故障了。\n\n这个时候，我们就需要牺牲数据的一致性，每个节点使用本地数据来响应客户端请求，来保证服务可用，**这就是我要说的另外一个指标，可用性。**\n\n可用性说的是任何来自客户端的请求，不管访问哪个节点，都能得到响应数据，但不保证是同一份最新数据。你也可以把可用性看作是分布式系统对访问本系统的客户端的另外一种承诺：我尽力给你返回数据，不会不响应你，但是我不保证每个节点给你的数据都是最新的。**这个指标强调的是服务可用，但不保证数据的一致。**\n\n我还是用一个例子，帮助你理解一下。比如，用户可以选择向节点 1 或节点 2 发起读操作，如果不管节点间的数据是否一致，只要节点服务器收到请求，就响应 X 的值，那么，2 个节点的服务是满足可用性的。\n\n![image-20230925142206510](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925142206510.png)\n\n最后的分区容错性说的是，当节点间出现任意数量的消息丢失或高延迟的时候，系统仍然可以继续提供服务。也就是说，分布式系统在告诉访问本系统的客户端：不管我的内部出现什么样的数据同步问题，我会一直运行，提供服务。**这个指标，强调的是集群对分区故障的容错能力。**\n\n来看下面的图，当节点 1 和节点 2 通信出问题的时候，如果系统仍能提供服务，那么，2 个节点是满足分区容错性的。\n\n![image-20230925142233320](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925142233320.png)\n\n因为分布式系统与单机系统不同，它涉及到多节点间的通讯和交互，节点间的分区故障是必然发生的，**所以我要提醒你，在分布式系统中分区容错性是必须要考虑的。**\n\n现在你了解了一致性、可用性和分区容错性，那么你在设计分布式系统时，是选择一致性？还是可用性？还是分区容错性？还是都可以选择呢？这三个特性有什么冲突么？这些问题就与我接下来要讲的“CAP 不可能三角”有关了。\n\n## CAP 不可能三角\n\nCAP 不可能三角说的是对于一个分布式系统而言，一致性（Consistency）、可用性（Availability）、分区容错性（Partition Tolerance）3 个指标不可兼得，只能在 3 个指标中选择 2 个。\n\n![image-20230925142256130](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925142256130.png)\n\nCAP 不能三角最初是埃里克·布鲁尔（Eric Brewer）基于自己的工程实践，提出的一个猜想，后被赛斯·吉尔伯特（Seth Gilbert）和南希·林奇（Nancy Lynch）证明，证明过程可以参考论文《Brewer’s conjecture and the feasibility of consistent, available, partition-tolerant web services》，你记住结论就好了。不过，为了帮你阅读论文，我补充一点：\n\n基于证明严谨性的考虑，赛斯·吉尔伯特（Seth Gilbert）和南希·林奇（Nancy Lynch）对指标的含义做了预设和限制，比如，将一致性限制为原子性。\n\n说了这么多，那么 CAP 理论是怎么解决我在开篇提到的问题呢？或者说，你要如何使用 CAP 理论来思考和设计分区容错一致性模型呢？\n\n\n\n## 如何使用 CAP 理论\n\n我们都知道，只要有网络交互就一定会有延迟和数据丢失，而这种状况我们必须接受，还必须保证系统不能挂掉。所以就像我上面提到的，节点间的分区故障是必然发生的。也就是说，分区容错性（P）是前提，是必须要保证的。\n\n现在就只剩下一致性（C）和可用性（A）可以选择了：要么选择一致性，保证数据绝对一致；要么选择可用性，保证服务可用。那么 CP 和 AP 的含义是什么呢？\n\n当选择了一致性（C）的时候，如果因为消息丢失、延迟过高发生了网络分区，部分节点无法保证特定信息是最新的，那么这个时候，当集群节点接收到来自客户端的写请求时，因为无法保证所有节点都是最新信息，所以系统将返回写失败错误，也就是说集群拒绝新数据写入。\n\n当选择了可用性（A）的时候，系统将始终处理客户端的查询，返回特定信息，如果发生了网络分区，一些节点将无法返回最新的特定信息，它们将返回自己当前的相对新的信息。\n\n**这里我想强调一点，大部分人对 CAP 理论有个误解，认为无论在什么情况下，分布式系统都只能在 C 和 A 中选择 1 个。** 其实，在不存在网络分区的情况下，也就是分布式系统正常运行时（这也是系统在绝大部分时候所处的状态），就是说在不需要 P 时，C 和 A 能够同时保证。只有当发生分区故障的时候，也就是说需要 P 时，才会在 C 和 A 之间做出选择。而且如果各节点数据不一致，影响到了系统运行或业务运行（也就是说会有负面的影响），推荐选择 C，否则选 A。\n\n那么我当时是怎么根据场景特点，进行 CAP 权衡，设计适合的分布式系统呢？为了便于你理解，我先来说说背景。\n\n开源版的 InfluxDB，缺乏集群能力和可用性，而且，InfluxDB 是由 META 节点和 DATA 节点 2 个逻辑单元组成，这 2 个节点的功能和数据特点不同，需要我们分别为它们设计分区容错一致性模型。\n\n\n\n![image-20230925142514125](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925142514125.png)\n\nInfluxDB 程序的逻辑架构示意图\n\n我具体是这么设计的：\n\n作为分布式系统，分区容错性是必须要实现的，不能因为节点间出现了分区故障，而出现整个系统不能用的情况。\n\n考虑到 META 节点保存的是系统运行的关键元信息，比如数据库名、表名、保留策略信息等，所以必须保持所有节点的一致性，这样才能避免由于各节点元信息不一致，导致时序数据记录不一致或者影响系统运行。比如，数据库 Telegraf 的信息在一些节点上存在，在另外一些节点上不存在，那么将导致向某些节点写入时序数据记录失败，所以，我选择 CAP 理论中的 C 和 P，采用 CP 架构。\n\nDATA 节点保存的是具体的时序数据记录，比如一条记录 CPU 负载的时序数据，“cpu_usage,host=server01,location=cn-sz user=23.0,system=57.0”。虽然不是系统运行相关的元信息，但服务会被访问频繁，水平扩展、性能、可用性等是关键，所以，我选择了 CAP 理论中的 A 和 P，采用 AP 架构。\n\n你看，我用 CAP 理论进行思考，并分别设计了 InfluxDB 的 META 节点和 DATA 节点的分区容错一致性模型，而你也可以采用类似的思考方法，设计出符合自己业务场景的分区容错一致性模型。\n\n那么假设我当时没有受到 CAP 理论的影响，或者对 CAP 理论理解不深入，DATA 节点不采用 AP 架构，而是直接使用了现在比较流行的分区容错一致性算法，比如使用 Raft 算法，会有什么痛点呢？\n\n\n受限于 Raft 的强领导者模型。所有请求都在领导者节点上处理，整个集群的性能等于单机性能。这样会造成集群接入性能低下，无法支撑海量或大数据量的时序数据。\n\n受限于强领导者模型，以及 Raft 的节点和副本一一对应的限制，无法实现水平扩展，分布式集群扩展了读性能，但写性能并没有提升。这样会出现写性能低下，和因为架构上的限制，无法提升写性能的问题。\n\nRaft 的“一切以领导者为准”的日志复制特性，会导致 DATA 节点丢数据，出现时序数据记录缺失的问题。\n\n关于 Raft 算法的一些细节（比如强领导模型），我会在 07 讲详细带你了解，这里你知道有这么回事儿就可以了。\n\n**最后我想再次强调的是，一致性不等同于完整性，** 有些技术团队基于数据完整性的考虑，使用 Raft 算法实现 DATA 节点的数据的分布式一致性容错，恰恰是这个设计，会导致 DATA 节点丢数据。我希望你能注意到这一点。\n\n那么在这里，我也想考考你：如果 META 节点采用 AP 架构，会有什么痛点呢？你可以思考一下。\n\n## 内容小结\n\n本节课我主要带你了解了 CAP 理论，以及 CAP 理论的应用，我希望你明确的重点如下：\n\nCA 模型，在分布式系统中不存在。因为舍弃 P，意味着舍弃分布式系统，就比如单机版关系型数据库 MySQL，如果 MySQL 要考虑主备或集群部署时，它必须考虑 P。\n\nCP 模型，采用 CP 模型的分布式系统，一旦因为消息丢失、延迟过高发生了网络分区，就影响用户的体验和业务的可用性。因为为了防止数据不一致，集群将拒绝新数据的写入，典型的应用是 ZooKeeper，Etcd 和 HBase。\n\nAP 模型，采用 AP 模型的分布式系统，实现了服务的高可用。用户访问系统的时候，都能得到响应数据，不会出现响应错误，但当出现分区故障时，相同的读操作，访问不同的节点，得到响应数据可能不一样。典型应用就比如 Cassandra 和 DynamoDB。\n\n在我看来，CAP 理论像 PH 试纸一样，可以用来度量分布式系统的酸碱值，帮助我们思考如何设计合适的酸碱度，在一致性和可用性之间进行妥协折中，设计出满足场景特点的分布式系统。关于酸（Acid）和碱（Base），我会在 03 和 04 讲带你了解。\n\n最后我想说的是，在当前分布式系统开发中，延迟是非常重要的一个指标，比如，在 QQ 后台的名字路由系统中，我们通过延迟评估服务可用性，进行负载均衡和容灾；再比如，在 Hashicorp/Raft 实现中，通过延迟评估领导者节点的服务可用性，以及决定是否发起领导者选举。所以，我希望你在分布式系统的开发中，也能意识到延迟的重要性，能通过延迟来衡量服务的可用性。\n\n## 课堂思考\n\n既然我提了 CAP 理论是一个很好的思考框架，能帮助我们思考，如何进行权衡，设计适合业务场景特性的分布式系统，那么你不妨思考一下，CP 模型的 KV 存储和 AP 模型的 KV 存储，分别适合怎样的业务场景呢？欢迎在留言区分享你的看法，与我一同讨论。\n\n最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。\n\n<iframe width=\"100%\" frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/195675\" > </iframe>","categories":["分布式协议与算法实战"]},{"title":"01丨行业视角：产品经理眼中的人工智能","url":"/posts/3293296664.html","content":"\n你好，我是海丰，很高兴能在这个专栏和你见面。\n\n随着人工智能的火热，越来越多的产品经理开始关注这个领域，希望借着风口转型成为 AI 产品经理，进而可以拓宽自己的职业道路。确实，这是一条很不错的出路，我本人就是一个转型的深度体验者和倡导者。\n\n对比传统的产品经理，AI 产品经理更加注重对于人工智能行业、场景算法，以及验收评估标准的理解。这节课，我们就来学习这些内容。不过在学习之前，我准备了 3 个问题，来测试一下你对这个领域的了解程度：\n\n你理解人工智能吗？\n\n它的产业发展现状如何？\n\n人工智能产品经理的人才结构是怎样的？\n\n接下来，我将从人工智能产品经理的角度，带你一起解答以上问题，让你对这个领域有一个整体的认知。这是基础，更是必学！\n\n## 理解人工智能\n\n对于人工智能的理解，网上的文章早已铺天盖地，如果要我概括一下，**我认为：如果一个系统可以像人类一样思考和行动，同时这些思考和行动都是理性的，那么这个系统我们就可以认为它是人工智能**（Artificial Intelligence，英文缩写为 AI，后面我会直接简称为 AI）。\n\n什么意思呢？举个例子。\n\n比如说，我们在浏览电商网站的时候，经常会发现自己看到的页面展示的商品和其他人不太一样，这是因为电商平台的推荐系统，会根据我们过去的浏览行为和下单情况，来预测我们可能喜欢的产品，再把它们展示出来。\n\n再比如说，我们都使用过类似小爱音箱这样的智能音箱，当我们跟它说：“嘿，小爱同学，明天早上 7 点叫我起床”，它就会为我们设置早上 7 点的闹钟。这是因为在小爱同学背后有一整套的系统，对我们发出的语音进行语义理解，再按照理解到的语义指令执行命令。\n\n从这两个例子中，我们能感受到这些产品不仅可以像人类一样去发现我们的喜好，推荐出我们喜欢的商品（精准推荐），还可以理解我们的语言（语义识别）去执行我们的命令（语音识别）。这些就是人工智能赋予它们的能力，也是人工智能应用越来越受欢迎，越来越多的原因。\n\n但是作为 AI 产品经理，我们需要注意，**目前 AI 技术可以解决的问题，一定是在某一个明确的特定业务领域内，且有特定目的的问题**，比如是搜索推荐、机器翻译、人脸识别等等。而我们在电影中看到的那些“无所不能”的 AI 机器人，它们属于通用人工智能领域，这离我们还很远。\n\n### 关于人工智能，你必须要掌握的概念\n\n理解了什么是人工智能和它的边界，我们再来看看人工智能领域的两个重点概念，机器学习和深度学习。这两个关键词时常出现在人工智能相关的新闻中，但还是有很多人不清楚这两者是什么，以及它们和人工智能是什么关系，甚至还有人把它们混为一谈。所以，我希望在正式开始咱们后面的学习之前，先带你扫除这些基础障碍。\n\n**我们先来看机器学习（Machine Learning）。**机器学习的核心是让机器有能力从数据中发现复杂的规律，并且通过这些规律对未来某些时刻的某些状况进行预测。这怎么理解呢？我们先来看一个简单的例子。\n\n假设，我们要通过机器学习预测未来几天内是否下雨，那我们需要筛选出过去一段时间内比较重要的天气特征数据，比如过去的平均气温、湿度、降水量等等，然后通过机器学习算法从这些历史数据中发现规律。\n\n这个所谓的规律就是算法工程师常说的模型，而发现这个规律的过程就是训练模型的过程。最终通过这个模型加上相应的气温、湿度等特征数据，我们就可以计算出未来几天内下雨的一个概率。\n\n我们可以用一句话来总结机器学习的过程：**机器学习就是让机器从过去已知的大量数据中进行学习，进而得到一个无限接近现实的规律，最后通过这个规律对未知数据进行预测。** 其中，我们使用的过去的数据就是我们说的样本，而气温、湿度这些属性就是特征，过去某一天是否下雨就是我们建模时用到的标签（结果数据）。\n\n如果在建模过程中，我们能够获得这些标签并使用它们训练模型，就叫做**有监督学习**（Supervised Learning）。如果没有标签，就叫做**无监督学习**（Unsupervised Learning）。像上面这种预测是否下雨，预测结果是“是 / 否”这样的问题，就是**分类问题**，如果是预测具体温度是多少，预测的结果是一个连续值的，就是**回归问题**。\n\n当然，这只是机器学习中一个很简单的例子，实际分析数据和预测的过程远比我们刚才描述的要复杂，而且实现预测能力的方式也不止一种，我们现阶段只要掌握这些就足够了。\n\n**接下来我们看第二个概念，深度学习（Deep Learning）。** 深度学习是一种特殊的机器学习，它借鉴了人脑由很多神经元组成的特性，而形成的一个框架或者说是方法论。**相对于普通的机器学习，深度学习在海量数据情况下的效果要比机器学习更为出色。**\n\n![image-20231020162334415](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20231020162334415.png)\n\n我们从上面的“人工智能技术发展时间线”图中也可以分析出来，深度学习是在互联网 DT 时代（数据处理技术时代，Data Technology）到来之后才逐渐火起来的，所以数据量对深度学习的重要性是非常高的。\n\n虽然深度学习的效果很好，但它也有局限，比如，深度学习对机器性能的要求会更高，算法模型训练时间相对更长等等。所以，我们需要根据实际业务的场景来选择是否应用深度学习的相关算法。\n\n### 人工智能产业现状\n\n理解了什么是人工智能之后，接着，我们再来看看人工智能的产业现状怎么样，从全局的视角来了解整个行业，这对我们知识体系的建立是非常有帮助的。对于人工智能的产业，我们可以基于产业链的上下游关系，把它分为基础层、技术层和应用层。\n\n我们先来看最下面的基础层，它按照服务的线条被划分成芯片服务、云服务、机器学习平台和数据服务，它们都是我们整个 AI 行业最底层服务提供者。这里面，讯飞的开放平台是我们接触比较多的机器学习平台，阿里云、百度云是做得比较好的云服务提供商。\n\n再上一层的技术层是 AI 技术的提供者，我按照技术类别对它进行了划分。这里面，我们比较熟悉的企业有商汤、依图，它们主要是提供计算机视觉服务，最常见的应用场景就是人脸识别了。\n\n最上面的应用层是 AI 技术对各行业的应用服务，就拿我们最熟悉的抖音来说，它通过 AI 技术不仅能实现短视频内容的个性化分发，把你感兴趣的内容展示出来，还能在拍摄短视频时候，让你变美变瘦，身体各个部位“收放自如”。\n\n除此之外，在整个 AI 产业链中，BAT 提供了全链条的服务，它们既做了最底层的基础服务，如云服务、机器学习平台，也做技术输出，如 BAT 会有自己的计算机视觉、语音识别等能力，同时也有对外的应用场景，所以我把它们放到了一列中。这个产业链上每一层的代表企业非常多，我就不细说了，你可以参考下面的全景图。\n\n![image-20231020162417982](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20231020162417982.png)\n\n上面的全景图告诉了我们，整个产业链的分层和每层的典型公司都有哪些。不过如果想要转到 AI 行业，你还需要多了解一些行业内的成熟应用。下面这张典型应用案例图就能帮到你。\n\n![image-20231020162440066](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20231020162440066.png)\n\n这里，我挑出了 4 个应用 AI 技术比较早，发展也相对成熟的行业，它们分别是金融风控，智能支付、智能安防以及智能客服。我会通过它们来给你讲讲，目前一些成熟的 AI 技术都是怎么应用的，应用它们对这些行业有什么帮助，以及这些行业中比较有代表性的企业和产品分别是什么。\n\n**金融风控行业** 主要是用机器学习技术把原本依赖人工的风险管理变为了依赖机器算法的方式，通过收集借款人的相关数据（收入、年龄、购物偏好、过往平台借贷情况和还款情况等）输入到机器学习模型中，来预测借款人的还款意愿和还款能力，判断是否对他放款。\n\nAI 技术的应用解决了原有人工信贷审核效率低下、无标准等问题。目前，市场上做金融风控的 AI 企业不只有老牌的百融云创、邦盛科技，还有蚂蚁集团、京东数科、度小满这样的大型互联网公司，还有冰鉴这样新型的创新型公司等等。\n\n而**智能支付行业**主要是通过人脸识别、指纹识别、声纹识别、虹膜识别等多种生物识别技术，帮助商户提高支付效率。像蚂蚁、京东数科、商汤和云从科技这些我们比较熟悉的企业，都属于智能支付行业。其中，云从科技、旷视科技、商汤科技和依图科技还一起被誉为 CV 界的四小龙。\n\n接着是**智能安防行业** 。互联网产品经理平时接触这个行业可能比较少，因为目前市场上主要做智能安防的企业有海康威视、大华股份、汉邦高科等，它们主要是通过人脸识别、多特征识别、姿态识别、行为分析、图像分析等相关技术融合业务场景的解决方案，来帮助企业、政府解决防控需求的。像我们都听说过，通过 AI 摄像头自动识别犯罪嫌疑人，通过深度学习技术检测车辆，并且识别出车牌号码等特征，用于停车场收费、交通执法等场景。\n\n最后是**智能客服行业**。这个行业主要是通过自然语言处理技术、知识图谱，对用户输入的问题进行识别分析，根据知识系统寻找答案，解决原有人工客服效率低下、成本高这样的问题。\n\n就像很多银行现在都采用智能客服，对它们的用户进行理财推荐，我就接到过不少这样的电话。但是一般来说，它们和真人的区别还是很明显的。目前市场上比较成熟的智能客服企业主要是环信、云知声、百度等等。\n\n好了，现在我们已经知道了什么是人工智能，以及整个产业的现状。**目前人工智能与各个行业还在不断融合，AI 也会继续向各个行业进行渗透。在我看来，AI 最终不会成为一个行业，而是会像移动互联网一样成为一个基础建设，赋能到整个互联网。**\n\n## AI 产品经理人才结构\n\n了解了人工智能的发展现状，我们就可以有针对性地看一下这些层级的公司对 AI 产品经理都有哪些要求了。\n\n### 人工智能商业模式\n\n![image-20231020162523801](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20231020162523801.png)\n\n在人工智能产业中，处于不同层级的企业，根据自身能力和方向的不同，都有自己的一套商业模式，充分了解 AI 公司的商业模式，可以成为我们转型 AI 产品经理的重要参考信息，也是我们进一步整理出 AI 产品经理的人才结构图的依据。\n\n总的来说，商业模式可以分为：**数据收集和治理、计算资源服务、AI 技术服务以及产品附加 AI 这四种**。下面，我们一一来看。\n\n首先，我们来看位于基础层的两类商业模式，数据收集和治理，以及计算资源服务。\n\n数据收集和治理类型的公司大多拥有自己的数据流量入口，致力于对于数据的收集和加工。比如数据堂，它主要提供数据采集（包括从特定设备，地点采集，采集范围包括图片、文字、视频等）、数据标注（主要是对图像进行标注，如标注人脸、动作等）服务。\n\n而计算资源服务类型的公司，又可以分成两类，一类致力于底层的芯片、传感器的研发服务，就像寒武纪这样的企业，它们作为一个人工智能芯片公司，主要的收入来自云端智能芯片加速卡业务、智能计算集群系统业务、智能处理器 IP 业务。另一类是 AI 计算服务，比如百度的 AI 开放平台，平台除了提供百度自有的 AI 能力之外，也为上下游合作伙伴提供了一个 AI 产品、技术展示与交易平台。\n\n接着，我们再来看位于技术层的 AI 技术服务类公司，它们为自己产品或者上游企业提供底层的 AI 技术服务，服务模式更多的是技术接口对接，比如人脸识别服务的服务模式主要就是 API 接口或者 SDK 部署的方式。\n\n最后是产品附加 AI，即应用层的大部分产品，它们都是通过 AI 技术叠加产品，赋能某个产业的模式。比如滴滴通过 AI 技术应用于自有的打车业务线，包括营销环节的智能发券、发单环节的订单预测、行车中的实时安全检测等等。\n\n### AI 产品经理所需技能\n\n通过上面的分析，我们不难发现，不同产业层级和商业模式都需要具有相应能力的 AI 产品经理。那这些产品经理究竟有什么区别呢？接下来，我就结合应用层、技术层和基础层这三个层级企业的特性，来给你讲讲不同层级产品经理所需的技能，同时给你一些具体的转型建议。\n\n首先是基础层。处于基础层的企业主要提供算力和数据服务，这些企业的特点是，偏硬件，偏底层技术，技术人员居多。这就要求 AI 产品经理了解如云计算、芯片、CPU/GPU/FPGA/ASIC 等硬件技术，以及行业数据收集处理等底层技术和框架。所以，原来从事底层硬件、技术平台、基础框架的产品经理，就比较适合转型到基础层了。\n\n而处于技术层的企业，主要的业务是为自己的业务或者上游企业提供相应的技术接口。这些企业的特点是技术能力强，大部分业务都是 ToB 服务。这个时候，AI 产品经理就必须要具备企业所在领域的技术知识，如语音识别（ASR）、语音合成（TTS）、计算机视觉（CV）、自然语言处理（NLP）等通用技术，最好还能了解 TensorFlow、Caffe、SciKit-learn 这样的机器学习框架。\n\n所以，技术层的 AI 产品经理本身必须具备一定的技术基础，最好还能是算法出身的工程师。但不管你属于哪一种，都一定要保有探索的热忱。\n\n最后，我们再来看应用层，这类型公司就是我们日常生活中接触最多的互联网公司，只是其中一些公司走的比较靠前，应用了 AI 技术来赋能自己的内部业务。比如滴滴使用 AI 技术做智能分单、智能补贴；京东数科是用 AI 技术做智能反欺诈，大数据风控。这一层是互联网产品经理转型最多，也是成功率最高的一层。\n\n处于应用层的企业，大多数直接面向 C 端用户，所以它们关注的是如何结合市场特点，来利用 AI 技术创造性地设计出符合市场需求的产品。所以这类型的产品经理不仅要求对所在行业有深刻的认识，同时也要对 AI 技术有一定的了解。能够与算法和研发工程师顺畅沟通与配合，能够判断算法同学交付的产品是否满足业务需求。\n\n总之，这一层的 AI 产品经理岗位，比较适合已经在某个领域具备了行业经验，打算转型做这个领域产品经理的同学。对于这样的同学，这一层的入门门槛比较低，在补充一定的 AI 技术知识后，获得一份 AI 产品经理的 Offer 相对来说会容易很多。\n\n## 总结\n\n今天，我从一个产品经理的角度，带你从全局了解了人工智能行业。在我看来，虽然人工智能可以让系统像人类一样进行理性的思考和行动，但它目前能够解决的问题还很有限。因此，人工智能未来是有无限潜力的。\n\n对于希望进入 AI 领域的产品经理来说，你只有对整个行业有一个全局的认识，才能结合自身的优势，找到最适合自己的领域和岗位。所以，这节课我们要牢牢掌握 AI 产业链的三个层级特点：\n\n基础层偏硬件，技术更底层，对人的技术能力要求最高；\n\n技术层多为 ToB 服务，对技术要求相对较高；\n\n应用层最接近现在的用户，更多的是利用 AI 技术服务业务，对技术要求相对最低，也是转行最容易的。\n\n总的来说，对于想要转型 AI 产品经理的同学，我想给你 3 条建议：\n\n如果你对硬件有足够的了解，那么可以尝试进入基础层发展；\n\n如果你本身就是一个算法工程师，精通一些算法或开发框架，就可以考虑进入技术层，你将有天然的优势；\n\n如果你和大多数的互联网产品经理一样，在自己所处的行业有足够的经验，但是对于 AI 技术了解还不够，那更适合来应用层发展，发挥自己对于业务的敏感度，发现行业的创新点。\n\n## 课后讨论\n\n根据你现在的经验和能力，你认为你更适合哪种类型的公司？目前你还需要补充哪些方面的能力？\n\n最后，我希望今天的课程能帮助你结合自己的兴趣、能力项，选择出适合自己的赛道。也欢迎把你对人工智能领域和 AI 产品经理的思考写到留言区，我们一起讨论。\n\n---\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/320974\" > </iframe>","categories":["成为AI产品经理"]},{"title":"01丨拜占庭将军问题：有叛徒的情况下，如何才能达成共识？","url":"/posts/3880415578.html","content":"\n\n\n你好，我是韩健。\n\n在日常工作中，我常听到有人吐槽“没看懂拜占庭将军问题”“中文的文章看不懂，英文论文更看不下去”。想必你也跟他们一样，有类似的感受。\n\n在我看来，拜占庭将军问题（The Byzantine Generals Problem），它其实是借拜占庭将军的故事展现了分布式共识问题，还探讨和论证了解决的办法。而大多数人觉得它难理解，除了因为分布式共识问题比较复杂之外，还与莱斯利·兰伯特（Leslie Lamport）的讲述方式有关，他在一些细节上（比如，口信消息型拜占庭问题之解的算法过程上）没有说清楚。\n\n实际上，它是分布式领域最复杂的一个容错模型，一旦搞懂它，你就能掌握分布式共识问题的解决思路，还能更深刻地理解常用的共识算法，在设计分布式系统的时候，也能根据场景特点选择适合的算法，或者设计适合的算法了。而我把拜占庭将军的问题放到第一讲，主要是因为它很好地抽象了分布式系统面临的共识问题，理解了这个问题，会为你接下来的学习打下基础。\n\n那么接下来，我就以战国时期六国抗秦的故事为主线串联起整篇文章，让你读懂、学透。\n\n## 苏秦的困境\n\n战国时期，齐、楚、燕、韩、赵、魏、秦七雄并立，后来秦国的势力不断强大起来，成了东方六国的共同威胁。于是，这六个国家决定联合，全力抗秦，免得被秦国各个击破。一天，苏秦作为合纵长，挂六国相印，带着六国的军队叩关函谷，驻军在了秦国边境，为围攻秦国作准备。但是，因为各国军队分别驻扎在秦国边境的不同地方，所以军队之间只能通过信使互相联系，这时，苏秦面临了一个很严峻的问题：如何统一大家的作战计划？\n\n万一一些诸侯国在暗通秦国，发送误导性的作战信息，怎么办？如果信使被敌人截杀，甚至被敌人间谍替换，又该怎么办？这些都会导致自己的作战计划被扰乱，然后出现有的诸侯国在进攻，有的诸侯国在撤退的情况，而这时，秦国一定会趁机出兵，把他们逐一击破的。\n\n**所以，如何达成共识，制定统一的作战计划呢？苏秦他很愁。**\n\n这个故事，是拜占庭将军问题的一个简化表述，苏秦面临的就是典型的共识难题，也就是如何在可能有误导信息的情况下，采用合适的通讯机制，让多个将军达成共识，制定一致性的作战计划？\n\n你可以先停下来想想，这个问题难在哪儿？我们又是否有办法，帮助诸侯国们达成共识呢？\n\n## 二忠一叛的难题\n\n为了便于你理解和层层深入，我先假设只有 3 个国家要攻打秦国，这三个国家的三位将军，咱们简单点儿，分别叫齐、楚、燕。同时，又因为秦国很强大，所以只有半数以上的将军参与进攻，才能击败敌人（注意，这里是假设哈，你别较真），在这个期间，将军们彼此之间需要通过信使传递消息，然后协商一致之后，才能在同一时间点发动进攻。\n\n举个例子，有一天，这三位将军各自一脸严肃地讨论明天是进攻还是撤退，并让信使传递信息，按照“少数服从多数”的原则投票表决，两个人意见一致就可以了，比如：\n\n齐根据侦查情况决定撤退；\n\n楚和燕根据侦查信息，决定进攻。\n\n那么按照原则，齐也会进攻。最终，3 支军队同时进攻，大败秦军。\n\n![image-20230925141508204](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925141508204.png)\n\n**可是，问题来了：** 一旦有人在暗通秦国，就会出现作战计划不一致的情况。比如齐向楚、燕分别发送了“撤退”的消息，燕向齐和楚发送了“进攻”的消息。**撤退：进攻 =1:1，无论楚投进攻还是撤退，都会成为 2:1，这个时候还是会形成一个一致性的作战方案。**\n\n但是，楚这个叛徒在暗中配合秦国，让信使向齐发送了“撤退”，向燕发送了“进攻”，那么：\n\n燕看到的是，撤退：进攻 =1:2；\n\n齐看到的是，撤退：进攻 =2:1。\n\n按照“少数服从多数”的原则，就会出现燕单独进攻秦军，当然，最后肯定是因为寡不敌众，被秦军给灭了。\n\n![image-20230925141521436](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925141521436.png)\n\n在这里，你可以看到，叛将楚通过发送误导信息，非常轻松地干扰了齐和燕的作战计划，导致这两位忠诚将军被秦军逐一击败。**这就是所说的二忠一叛难题。** 那么苏秦应该怎么解决这个问题呢？我们来帮苏秦出出主意。\n\n如果你觉得上面的逻辑有点绕的话，可以找张白纸，自己比划比划。\n\n## 苏秦该怎么办？\n\n#### 解决办法一：口信消息型拜占庭问题之解\n\n先来说说第一个解决办法。首先，三位将军都分拨一部分军队，由苏秦率领，苏秦参与作战计划讨论并执行作战指令。这样，3 位将军的作战讨论，就变为了 4 位将军的作战讨论，这能够增加讨论中忠诚将军的数量。\n\n然后呢，4 位将军还约定了，如果没有收到命令，就执行预设的默认命令，比如“撤退”。除此之外，还约定一些流程来发送作战信息、执行作战指令，比如，进行两轮作战信息协商。为什么要执行两轮呢？先卖个关子，你一会儿就知道了。\n\n**第一轮：**\n\n先发送作战信息的将军作为指挥官，其他的将军作为副官；\n\n指挥官将他的作战信息发送给每位副官；\n\n每位副官，将从指挥官处收到的作战信息，作为他的作战指令；如果没有收到作战信息，将把默认的“撤退”作为作战指令。\n\n**第二轮：**\n\n除了第一轮的指挥官外，剩余的 3 位将军将分别作为指挥官，向另外 2 位将军发送作战信息；\n\n然后，这 3 位将军按照“少数服从多数”，执行收到的作战指令。\n\n为了帮助你直观地理解苏秦的整个解决方案，我来演示一下作战信息协商过程。**而且，我会分别以忠诚将军和叛将先发送作战信息为例来演示，** 这样可以完整地演示叛将对作战计划干扰破坏的可能性。\n\n首先是 3 位忠诚的将军先发送作战信息的情况。\n\n为了演示方便，假设苏秦先发起作战信息，作战指令是“进攻”。那么在第一轮作战信息协商中，苏秦向齐、楚、燕发送作战指令“进攻”。\n\n![image-20230925141535291](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925141535291.png)\n\n第二轮作战信息协商中，齐、楚、燕分别作为指挥官，向另外 2 位发送作战信息“进攻”，因为楚已经叛变了，所以，为了干扰作战计划，他就对着干，发送“撤退”作战指令。\n\n![image-20230925141548792](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925141548792.png)\n\n\n\n最终，齐和燕收到的作战信息都是“进攻、进攻、撤退”，按照原则，齐和楚与苏秦一起执行作战指令“进攻”，实现了作战计划的一致性，保证了作战的胜利。\n\n那么，如果是叛徒楚先发送作战信息，干扰作战计划，结果会有所不同么？我们来具体看一看。在第一轮作战信息协商中，楚向苏秦发送作战指令“进攻”，向齐、燕发送作战指令“撤退”。\n\n![image-20230925141558621](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925141558621.png)\n\n然后，在第二轮作战信息协商中，苏秦、齐、燕分别作为指挥官，向另外两位发送作战信息。\n\n![image-20230925141608736](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925141608736.png)\n\n最终，苏秦、齐和燕收到的作战信息都是“撤退、撤退、进攻”，按照原则，苏秦、齐和楚一起执行作战指令“撤退”，实现了作战计划的一致性。也就是说，无论叛将楚如何捣乱，苏秦、齐和燕，都执行一致的作战计划，保证作战的胜利。\n\n这个解决办法，其实是兰伯特在论文《The Byzantine Generals Problem》中提到的口信消息型拜占庭问题之解：**如果叛将人数为 m，将军人数不能少于 3m + 1 ，那么拜占庭将军问题就能解决了。** 不过，作者在论文中没有讲清楚一些细节，为了帮助你阅读和理解论文，在这里我补充一点：\n\n**这个算法有个前提**，也就是叛将人数 m，或者说能容忍的叛将数 m，是已知的。在这个算法中，叛将数 m 决定递归循环的次数（也就是说，叛将数 m 决定将军们要进行多少轮作战信息协商），即 m+1 轮（所以，你看，只有楚是叛变的，那么就进行了两轮）。你也可以从另外一个角度理解：n 位将军，最多能容忍 (n - 1) / 3 位叛将。**关于这个公式，你只需要记住就好了，推导过程你可以参考论文。**\n\n不过，这个算法虽然能解决拜占庭将军问题，但它有一个限制：如果叛将人数为 m，那么将军总人数必须不小于 3m + 1。\n\n在二忠一叛的问题中，在存在 1 位叛将的情况下，必须增加 1 位将军，将 3 位将军协商共识，转换为 4 位将军协商共识，这样才能实现忠诚将军的一致性作战计划。那么有没有办法，在不增加将军人数的时候，直接解决二忠一叛的难题呢？\n\n#### 解决办法二：签名消息型拜占庭问题之解\n\n其实，苏秦还可以通过签名的方式，在不增加将军人数的情况下，解决二忠一叛的难题。首先，苏秦要通过印章、虎符等信物，实现这样几个特性：\n\n忠诚将军的签名无法伪造，而且对他签名消息的内容进行任何更改都会被发现；\n\n任何人都能验证将军签名的真伪。\n\n这时，如果忠诚的将军，比如齐先发起作战信息协商，一旦叛将小楚修改或伪造收到的作战信息，那么燕在接收到楚的作战信息的时候，会发现齐的作战信息被修改，楚已叛变，这时他执行齐发送的作战信息。\n\n![image-20230925141620462](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925141620462.png)\n\n如果叛变将军楚先发送误导的作战信息，那么齐和燕将发现楚发送的作战信息是不一致的，知道楚已经叛变。这个时候，他们可以先处理叛将，然后再重新协商作战计划。\n\n![image-20230925141631024](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20230925141631024.png)\n\n这个解决办法，是兰伯特在论文中提到的签名消息型拜占庭问题之解。而通过签名机制约束叛将的叛变行为，任何叛变行为都会被发现，也就会实现无论有多少忠诚的将军和多少叛将，忠诚的将军们总能达成一致的作战计划。\n\n我想，如果当时苏秦能够具备分布式系统设计的思维，掌握这几种算法，应该就不用担心作战计划被干扰了吧。\n\n## 内容小结\n\n本节课，为了帮助你理解拜占庭将军问题，我讲了苏秦协商作战的故事，现在让我们跳回现实世界，回到计算机世界的分布式场景中：\n\n故事里的各位将军，你可以理解为计算机节点；\n\n忠诚的将军，你可以理解为正常运行的计算机节点；\n\n叛变的将军，你可以理解为出现故障并会发送误导信息的计算机节点；\n\n信使被杀，可以理解为通讯故障、信息丢失；\n\n信使被间谍替换，可以理解为通讯被中间人攻击，攻击者在恶意伪造信息和劫持通讯。\n\n这样一来，你是不是就理解了计算机分布式场景中面临的问题，并且知道了解决的办法呢？\n\n那么我想强调的是，拜占庭将军问题描述的是最困难的，也是最复杂的一种分布式故障场景，除了存在故障行为，还存在恶意行为的一个场景。你要注意，在存在恶意节点行为的场景中（比如在数字货币的区块链技术中），必须使用拜占庭容错算法（Byzantine Fault Tolerance，BFT）。除了故事中提到两种算法，常用的拜占庭容错算法还有：PBFT 算法，PoW 算法（为了重点突出，这些内容我会在后面讲解）。\n\n而在计算机分布式系统中，最常用的是非拜占庭容错算法，即故障容错算法（Crash Fault Tolerance，CFT）。**CFT 解决的是分布式的系统中存在故障，但不存在恶意节点的场景下的共识问题。** 也就是说，这个场景可能会丢失消息，或者有消息重复，但不存在错误消息，或者伪造消息的情况。常见的算法有 Paxos 算法、Raft 算法、ZAB 协议（这些内容我同样会在后面讲解）。\n\n那么，如何在实际场景选择合适的算法类型呢？答案是：如果能确定该环境中各节点是可信赖的，不存在篡改消息或者伪造消息等恶意行为（例如 DevOps 环境中的分布式路由寻址系统），推荐使用非拜占庭容错算法；反之，推荐使用拜占庭容错算法，例如在区块链中使用 PoW 算法。\n\n## 课堂思考\n\n文中我提了两类容错算法，分别是拜占庭容错算法和非拜占庭容错算法，那么在常见的分布式软件系统中，哪些场景必须要使用拜占庭容错算法呢？哪些场景使用非拜占庭容错算法就可以了呢？欢迎在留言区分享你的看法，与我一同讨论。\n\n最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。\n\n<iframe width=\"100%\" frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/195662\" > </iframe>","categories":["分布式协议与算法实战"]},{"title":"00 | 开篇词丨你好，产品经理！你的未来价值壁垒在哪儿？","url":"/posts/3011702932.html","content":"\n你好，我是刘海丰。\n\n很高兴能和你在这个专栏中见面，跟你一起聊聊产品经理这个岗位，尤其是人工智能领域的产品经理，也叫 AI 产品经理。\n\n我先来介绍一下我自己吧。我现在是京东集团的高级架构师，负责京东生活服务事业群的数据模型与算法，主导过推荐系统、用户意图识别、高潜用户预测、商品内容生成等多款 AI 产品的设计落地。\n\n在来到京东之前，我曾经作为 AI 产研负责人带领整个产品和研发团队，为用户提供基于大数据和 AI 技术的产品解决方案。这段经历也让我既懂研发技术架构，又具备了产品思维和商业视角。\n\n但其实，我刚开始的工作也和 AI 产品没有关系，是在机缘巧合之下才转型的。当时，我们公司突然要上线一个 AI 项目，因为一时没有合适的 AI 产品经理接手，我才被动地成为这个 AI 项目的负责人，去组建和培养整个 AI 产品团队，同时还要带领算法团队。\n\n项目完成之后，我就继续在这个领域深耕，又成了京东的高级架构师。在这个过程中，我也帮助过团队中的很多产品经理成功转型 AI 产品经理。可以说，不管是我自己转型，还是帮助别人转型，我都踩过很多的“坑”，也总结了很多的经验。\n\n## 未来产品经理的价值壁垒\n\n其实，我们身边的很多人都会因为类似的情况而调换岗位，最终在这个岗位走得更远。那随着越来越多的公司认识到  AI  的重要性，去建立算法团队之后，传统产品经理转型  AI  产品经理的情况会越来越普遍。\n\n甚至我认为，**未来一两年后，人人都可能是 AI 产品经理。**\n\n听我这么一说，你在心里可能先白了我一眼，又是“人人”，而且还是“AI”，怎么可能呢？我这么说还真不是为了耸人听闻，故意抓眼球，听我跟你仔细说道说道。\n\n不知道你有没有听说过 “移动互联网产品经理” 这个岗位？其实现在已经没有这种岗位了，因为移动互联网已经成为整个互联网的基础建设，而移动互联网技术也已经深入到了各行各业，所有产品经理都是移动互联网产品经理。你看，这就是移动互联网技术的发展所带来的必然结果。\n\n现在呢，你是不是感觉  AI  好像也没有前几年那么热了，这其实是因为 AI 技术的落地越来越多了，大家已经过了谈论的阶段，而是实实在在地在使用它。所以我大胆预测，在不远的一两年后，AI 技术必将和移动互联网技术一样，成为互联网的基础建设。到那时候，我们的工作或多或少都要基于 AI 技术，AI 技术也会赋能于各行各业，也就没有所谓的 AI 产品经理这个岗位了，因为每一个产品经理都是 AI 产品经理。\n\n其实，我的预测还不真是空穴来风。如果你平时留心过  AI  领域的新闻肯定会发现，最近几年，不仅是以 AI 技术为主的创业公司越来越多，一些知名的互联网公司，甚至传统行业公司也都在设立自己的 AILab 或者 AI 事业部，并且联合各大院校设立 AI 实验室。而两年前，只有专门从事 AI 领域的企业或者 BATJ 这样的大厂才会设立这样的部门或岗位。\n\n因此，随着 AI 技术逐渐落地和市场认可度的不断提高，AI 产业岗位以及泛 AI 产业岗位在当今社会已经变得越来越走俏。我身边的一些产品经理也因此越来越关注 AI 领域，会越来越多地和我讨论一些 AI 相关的问题。我把它们都总结下来，大概有这么两类。\n\n一些传统行业的产品经理会问我，我适不适合转行去做 AI 产品经理啊？如果我要转行的话，需要做什么准备？还有 AI 产品经理要懂各种算法吗？这些算法太难了，我看不懂怎么办呀？\n\n还有一些刚刚成为 AI 产品经理的朋友会问我，现在工作上好多事儿我都搞不清楚。比如，我给算法团队提需求的时候总要沟通好多次，效果还不好，算法同学肯定也没少埋怨我。再比如，算法同学交付过来的模型，我发现效果不好，但他们说的原因我又听不懂，这项目推进起来感觉越来越难……\n\n对一些已经成为 AI 产品经理的同学，如果你也有类似的疑问，我建议你系统地学一些 AI 产品经理相关的课程。毕竟夯实基础，我们才能走得更远嘛。\n\n那对一些还不是产品经理的同学，如果你也对 AI 产品经理好奇，想要转型的话。我真的建议你尽早抓住 AI 这个破局点，趁着行业还没那么成熟，对 AI 产品经理的要求还不是那么高的时候，尽早进入这个行业。到时候随着 AI 发展，你作为这个行业中的先行者，自然更容易占得先机。\n\n总的来说，尽早为自己储备 AI 产品经理的知识，能帮助我们建立自身价值壁垒，也是我们抓住 AI 行业红利一次不错的机会。\n\n## 如何成为一名  AI  产品经理？\n\n那么我们该如何成为一名  AI  产品经理，或者更进一步，我们该如何成为一名优秀的产品经理呢？在这个专栏中，我把 AI 产品经理的知识体系梳理成 4 大板块，分别是**知己知彼、三大能力、落地实践和认知升级**。接下来，我就详细给你讲讲，每个板块我都是怎么设计的。\n\n![image-20231020152502422](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202310/image-20231020152502422.png)\n\n**板块一：知己知彼**\n\n想要转型  AI  产品经理，我们只有先搞清楚自己能不能转型，都有哪些方向和领域可以转型，才能确定自己要转去哪个方向，进而去做充足的准备。永远要记住一点：**选择对的跑道，比跑得快更为重要。**当然，这对初级 AI 产品经理同样适用。\n\n在这个板块中，我会分别从行业、个人、技术，以及过来人这四个视角，帮你全方位了解  AI  产品经理这个岗位，希望能让你少走弯路。\n\n**板块二： AI 产品经理的三大能力**\n\n清楚了自己转型的方向和应该具备的能力后，就到了夯实基础的时候。**掌握基础最快的办法就是把自己带入到对应的角色里，去处理真实的问题。**\n\n在一个 AI 产品落地的过程中，产品经理要负责产品开发周期和进度的管控，保证产品按时上线。因为 AI 产品经理和互联网产品经理在本质上的不同，就是会牵扯到算法团队，AI 产品经理需要和算法工程师进行多次专业的需求沟通，所以 AI 产品经理要听得懂他们说的技术词汇、算法实现，对整个算法有自己的判断，知道每个算法能解决什么问题，解决到什么程度，以及有能力对最后训练出的模型好坏进行评估。这样才能推动产品向前发展。\n\n因此，在第二个板块中，我把  AI  产品经理需要掌握的核心能力总结成了三个，分别是 **AI 项目管控能力、算法技术能力和模型验收能力。**\n\n首先，为了帮助你快速进入 AI 产品经理这个角色，我会结合 AI 产品的建设流程，告诉你怎么主导一个 AI 项目，怎么构建一个 AI 算法模型，以及这个过程中怎么和算法人员进行沟通。\n\n其次，我通过算法在真实案例中应用的方式，告诉你 AI 领域主流算法的逻辑和它们的应用场景。我会站在一个产品经理的角度，给你解释这些复杂的概念，让你掌握它们的优缺点和适用场景，保证你一定听得懂。\n\n最后，我还会带你学习如何检验一个 AI 模型的好坏，如何验收算法工程师的产出，为你梳理一套模型验收的知识体系和监控指标。\n\n这三大能力不仅和互联网经理要求的能力有很大区别，也是 AI 产品经理的核心技能壁垒。因此，这是我们转型 AI 产品经理必备的基础，更是我们从这个岗位脱颖而出的核心竞争力。\n\n**板块三：落地实践**\n\n掌握了成为 AI 产品经理的理论知识还不够，在实际工作中，我们还是会很难想到用哪些知识点去解决实际问题，或者提出的产品方案太理想化。\n\n所以，在第三个板块中，我会通过几个最常见的案例，比如**个性化推荐系统产品**、**用户复购意向预测产品**、信用评分产品，以及**智能客服**类产品，带你把学过的知识落地，让你知道它们是怎么在一个业务场景发挥作用的。希望这个板块结束之后，你能既懂理论又懂实践。\n\n**板块四：认知升级**\n\n最后我还希望，通过这个专栏你不只是收获了 AI 行业知识、技术知识，以及成为一个 AI 产品经理的方法，还能收获一份自我提升的指南。\n\n因为在我看来，入门容易，但入门之后的自我提升可不容易。而想要提升自身能力，就要先提升自己的认知能力，只有认知到了，才有提升的可能性。\n\n所以，在最后这个板块里，我会为你讲讲 AI 产品经理的认知升级。这里有我在研发、产品和管理上的多年经验，希望这些经验你能够好好利用起来，借助它们提升自己的认知，让自己的职业道路越走越宽。\n\n## 学习这个专栏的建议\n\n不过，在正式开始学习这个专栏之前，考虑到很多同学对 AI 领域的理解层次不一样，所以我还为你总结了一套有效学习这门课的方法论。\n\n第一阶段，形成对知识理解的**线性思维**，对 AI 产品经理课程体系有整体的认知。不管你是刚刚学习 AI 还是已经对  AI  有一定的了解，我都建议你先完整地跟着整个专栏的节奏学习一遍，对  AI  产品经理这个体系有一个系统性的认识。这不仅能帮助你查缺补漏，也能让你在工作中遇到相关问题的时候，快速找到解决办法。\n\n第二阶段，形成对知识理解的**结构化思维**，在头脑中描绘出自己在 AI 领域的知识体系。在你充分地学习和实践了第一阶段后，你需要从专栏中的每一个单一的知识点中“跳出来”，高屋建瓴地看问题，并逐步建立自己的 AI 知识体系，从知识点的学习到知识网络的补齐。\n\n第三阶段，形成对知识理解的**批判性思维**，打破固有知识体系，建立 AI 思维的底层逻辑。这个阶段，我希望你可以锻炼自己的批判性思维，既能合理地输入别人的意见，也能输出自己的独立认知，最后形成自己的 AI 底层思维，这样你就能驾驭 AI，真正让它变成你的工具。\n\n最后，我还想说，这个专栏包含了我转型和操盘 AI 产品的全部心得，这是书上和网上都搜索不到的。那我在极客时间把它们分享出来，就是不希望那些我踩过的“坑”、犯过的错，你再走一遍。所以，我希望在专栏更新的过程中，能够经常看到你的留言，不管是提问还是交作业，我都会认真回复。\n\nAI 时代属于产品经理的机会已经来了，如果你想用最低的成本转型到 AI 赛道，提高自己的价值壁垒，拓宽未来的发展道路，就快和我一起学习吧！\n\n---\n\n<iframe width=\"100%\"  frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/320980\" > </iframe>\n","categories":["成为AI产品经理"]},{"title":"00丨开篇词丨想成为分布式高手？那就先把协议和算法烂熟于心吧","url":"/posts/2547653008.html","content":"\n\n\n你好，我是韩健，你叫我“老韩”就可以了。\n\n在专栏开始之前，我想先和你聊聊自己的经历，加深彼此的了解。在重庆大学的软件工程专业毕业之后，我就开始和分布式系统打交道，至今有十多年了。早期，我接触了电信级分布式系统，比如内核态 HA Cluster，现在是互联网分布式系统，比如名字服务、NoSQL 存储、监控大数平台。\n\n我曾经做过创业公司的 CTO，后来加入腾讯之后，负责过 QQ 后台海量服务分布式中间件，以及时序数据库 InfluxDB 自研集群系统的架构设计和研发工作。\n\n你可能会问我，为什么要单独讲分布式协议和算法呢？（为了不啰嗦，咱们下文都简称分布式算法）在我看来，它其实就是决定分布式系统如何运行的核心规则和关键步骤。 **如果一个人想真正搞懂分布式技术，开发出一个分布式系统，最先需要掌握的就是这部分知识。**\n\n举个例子，学数学的时候，我们总是会学到很多公式或者定理，我上学的时候，还觉得这些定理枯燥至极。但后来我明白了，这些定理和公式其实就是前人花了很长时间思考、验证、总结出来的规律，如果我们能在这之上做事情，更容易快速地找到正确答案。同样，你学习咱们这个专栏也是这个道理。\n\n## 分布式算法是分布式技术中的核心\n\n可能有些同学会说：“老韩，你别忽悠我，我可是系统看过分布式领域的经典书的，比如《分布式系统：概念与设计》《分布式系统原理与范型》，这些书里分布式算法的篇幅可不多啊。”\n\n是的，这也是我奇怪的地方。不过，你可以看看网上关于分布式的提问，这里面点击量大的肯定与分布式算法有关，这是不是侧面说明了它的重要性呢？\n\n而且从我多年的经验来看，很多同学读了那几本厚重的经典书之后，在实际工作中还是云里雾里。我想，如果他们来问我，我会建议他们先把各种分布式算法搞清楚。**因为分布式系统里，最重要的事情，就是如何选择或设计适合的算法，解决一致性和可用性相关的问题了。**\n\n可尽管它是分布式技术中的核心与关键，但实际掌握的人或者公司却很少。我来说个真实的事儿。\n\n我刚刚提到的 InfluxDB 其实是一个开源的时序数据库系统，当然，开源的只是单机版本，如果你要使用集群功能，要么就是基于开源版本自研，要么就是购买人家的企业版本。\n\n而这里面，企业版本一个节点一年 License 授权费就是 1.5 万美刀，是不是很贵？那贵在哪里呢？相比于单机版本，企业版本的技术壁垒又是什么？\n\n在我自己折腾了一番 InfluxDB 系统后，我捂着胸口和你说，它的护城河就是**以分布式算法为核心的分布式集群能力。**\n\n我知道有很多技术团队曾经试图自己实现 InfluxDB 的企业版本功能，但最后还是放弃了，因为这里面坑太多了。比如，实现集群能力的时候，怎么支持基于时序进行分片？怎么支持水平扩展？甚至还有些人错误地将一致性等同于完整性，该使用反熵（Anti-Entropy）算法的时候，却用了 Raft 算法，让人哭笑不得。聊到这儿，我也想问问你：你是否也曾错误地把一致性理解为完整性了呢？\n\n可以看到，分布式系统的价值和意义的确很大，但如果不能准确理解分布式算法，可能不仅开发实现的分布式系统无法稳定运行，而且你还会因为种种现网故障，逐渐影响到职业发展，丧失职场竞争力。\n\n再说点儿更实际的，**现阶段，掌握分布式算法也是你面试架构师、技术专家等高端岗位时的敲门砖。** 你可以搜索看看，知名的公司在招聘架构师或者高级工程师时，岗位要求中是不是写着熟悉分布式算法相关理论等内容？不过从我作为面试官的经验来看，懂这部分的候选人实在是少之又少。\n\n别看啰嗦了这么多，我只是想强调，不管你是基于技术追求的考虑，还是基于长期职业发展和提升职场竞争力的考量，“分布式算法”都是你在这个时代应该掌握的基本功。\n\n当然了，我也知道，分布式算法虽然很重要，但是也比较难学，原因有这样几点。\n\n除了算法本身抽象，不容易理解之外，即使是非常经典的论文，也存在在一些关键细节上没有讲清楚的情况。比如，你比较熟悉的拜占庭将军问题，在阅读口信消息型拜占庭问题之解时，你是不是感到很吃力呢？那是因为论文没有说透彻，而我会在01 讲带你了解这些内容。\n\n信息时代资料丰富，但质量参差不齐，甚至有错误。网上信息大多是“复制粘贴”的结果，而且因为分布式领域的研究多以英文论文的形式出现，中文翻译内容的错误非常多，这也给自主学习带来很多不必要的障碍和误导。如果你没有足够的好奇心和探究精神，很难完全吃透关键细节。\n\n很多资料是为了讲解理论而讲解理论，无法站在“用”的角度，将理论和实战结合。最终，你只能在“嘴”上理解，而无法动手。\n\n## 方法得当，知识并不难学\n\n在我看来，要想掌握这部分内容，不仅要理解常用算法的原理、特点和局限，还要能根据场景特点选择适合的分布式算法。\n\n所以，为了更好地帮你轻松、透彻地搞懂分布式技术，理解其中最核心和最为精妙的内容，我希望将自己支撑海量互联网服务中的分布式算法实战心得分享给你。\n\n我将课程划分了三个模块，分别是理论篇、协议和算法篇以及实战篇。\n\n其中，理论篇，我会带你搞懂分布式架构设计核心且具有“实践指导性”的基础理论，这里面会涉及典型的分布式问题，以及如何认识分布式系统中相互矛盾的特性，帮助你在实战中根据场景特点选择适合的分布式算法。\n\n协议和算法篇，会让你掌握它们的原理、特点、适用场景和常见误区等。比如，你以为开发分布式系统使用 Raft 算法就可以了，其实它比较适合性能要求不高的强一致性场景；又比如在面试时，如果被问到“Paxos 和 Raft 的区别在哪里”，你都会在第二部分中找到答案。\n\n实战篇，教你如何将所学知识落地，我会带你掌握分布式基础理论和分布式算法在工程实践中的应用。比如，剖析 InfluxDB 企业版的 CP 架构和 AP 架构的设计和背后的思考，以及 Raft、Quorum NWR、Anti-Entropy 等分布式算法的具体实现。\n\n从实战篇中，你可以掌握如何根据场景特点选择适合的分布式算法，以及如何使用和实现分布式算法的实战技巧。这样，当你需要据场景特点选择适合的分布式算法时，就能举一反三，独立思考，设计开发了。\n\n除此之外，我还会带你剖析 Hashicorp Raft 的实现，并以一个分布式 KV 系统的开发实战为例，来聊聊如何使用 Raft 算法实际开发一个分布式系统，以此让你全面拥有分布式算法的实战能力。\n\n总体来说，学完这次课程，你会有以下几个收获：\n\n- 破除你对分布式协议和算法的困惑，帮助你建立信心；\n- 可落地的 4 大分布式基础理论； \n- 8 个最常用的分布式协议和算法；\n- 3 大实战案例手把手教学；\n- 以实战为中心的分布式内容体系。\n\n## 写在最后\n\n我承诺课程的每一讲都是干货，也会第一时间和你交流答疑，也请你监督。只要你紧跟脚步，不懂就问，课后多加思考和练习，相信你一定会学有所成。\n\n与此同时，我希望所有对技术有追求的工程师，都能在学完课程之后，顺利攻下这一关。再具体一点说，就是能够在工作中根据场景特点，灵活地设计架构和使用分布式算法开发出适合该场景的分布式系统，并且对架构设计的理解更上一层。姑且把这段话当成我们的教学目标吧。\n\n最后，欢迎你在留言区说一说自己在技术上的困惑，或者想通过这个专栏收获些什么，这样可以方便我在后续的备课中，针对性地讲解内容。重要的是，也能帮你在学完之后回顾这些疑难问题，感受到自己切实的进步和能力的提升。\n\n期待与你在这个课程中碰撞出更多的思维火花，未来的两个月里，让我们成为朋友，携手同行，共同进步！\n\n© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。\n\n<iframe width=\"100%\" frameborder=1 height=500px src=\"https://time.geekbang.org/comment/nice/195652\" > </iframe>\n","categories":["分布式协议与算法实战"]},{"url":"/posts/0.html","content":"# 02｜用LangChain快速构建基于“易速鲜花”本地知识库的智能问答系统\n你好，我是黄佳，欢迎来到LangChain实战课！\n\n在深入讲解LangChain的每一个具体组件之前，我想带着你从头完成一个很实用、很有意义的实战项目。目的就是让你直观感受一下LangChain作为一个基于大语言模型的应用开发框架，功能到底有多么强大。好的，现在就开始！\n\n## 项目及实现框架\n\n我们先来整体了解一下这个项目。\n\n**项目名称**：“易速鲜花”内部员工知识库问答系统。\n\n**项目介绍**：“易速鲜花”作为一个大型在线鲜花销售平台，有自己的业务流程和规范，也拥有针对员工的SOP手册。新员工入职培训时，会分享相关的信息。但是，这些信息分散于内部网和HR部门目录各处，有时不便查询；有时因为文档过于冗长，员工无法第一时间找到想要的内容；有时公司政策已更新，但是员工手头的文档还是旧版内容。\n\n基于上述需求，我们将开发一套基于各种内部知识手册的 “Doc-QA” 系统。这个系统将充分利用LangChain框架，处理从员工手册中产生的各种问题。这个问答系统能够理解员工的问题，并基于最新的员工手册，给出精准的答案。\n\n**开发框架**：下面这张图片描述了通过LangChain框架实现一个知识库文档系统的整体框架。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/c66995f1bf8575fb8fyye6293200eabf.jpg)\n\n整个框架分为这样三个部分。\n\n- 数据源（Data Sources）：数据可以有很多种，包括PDF在内的非结构化的数据（Unstructured Data）、SQL在内的结构化的数据（Structured Data），以及Python、Java之类的代码（Code）。在这个示例中，我们聚焦于对非结构化数据的处理。\n- 大模型应用（Application，即LLM App）：以大模型为逻辑引擎，生成我们所需要的回答。\n- 用例（Use-Cases）：大模型生成的回答可以构建出QA/聊天机器人等系统。\n\n**核心实现机制：** 这个项目的核心实现机制是下图所示的数据处理管道（Pipeline）。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/73a46eecd42038961db9067e75de3387.jpg)\n\n在这个管道的每一步中，LangChain都为我们提供了相关工具，让你轻松实现基于文档的问答功能。\n\n具体流程分为下面5步。\n\n1. Loading：文档加载器把Documents **加载** 为以LangChain能够读取的形式。\n2. Splitting：文本分割器把Documents **切分** 为指定大小的分割，我把它们称为“文档块”或者“文档片”。\n3. Storage：将上一步中分割好的“文档块”以“嵌入”（Embedding）的形式 **存储** 到向量数据库（Vector DB）中，形成一个个的“嵌入片”。\n4. Retrieval：应用程序从存储中 **检索** 分割后的文档（例如通过比较余弦相似度，找到与输入问题类似的嵌入片）。\n5. Output：把问题和相似的嵌入片传递给语言模型（LLM），使用包含问题和检索到的分割的提示 **生成答案**。\n\n上面5个环节的介绍都非常简单，有些概念（如嵌入、向量存储）是第一次出现，理解起来需要一些背景知识，别着急，我们接下来具体讲解这5步。\n\n## 数据的准备和载入\n\n“易速鲜花”的内部资料包括 pdf、word 和 txt 格式的各种文件，我已经放在 [这里](https://github.com/huangjia2019/langchain/tree/main/02_%E6%96%87%E6%A1%A3QA%E7%B3%BB%E7%BB%9F) 供你下载。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/b69956a706112266df404eee953459ff.jpg)\n\n其中一个文档的示例如下：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/931a55af4f0a3842a640d95c2c4bf224.jpg)\n\n我们首先用LangChain中的document\\_loaders来加载各种格式的文本文件。（这些文件我把它放在OneFlower这个目录中了，如果你创建自己的文件夹，就要调整一下代码中的目录。）\n\n在这一步中，我们从 pdf、word 和 txt 文件中加载文本，然后将这些文本存储在一个列表中。（注意：可能需要安装PyPDF、Docx2txt等库）\n\n代码如下：\n\n```plain\nimport os\nos.environ[\"OPENAI_API_KEY\"] = '你的Open AI API Key'\n\n# 1.Load 导入Document Loaders\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.document_loaders import Docx2txtLoader\nfrom langchain.document_loaders import TextLoader\n\n# 加载Documents\nbase_dir = '.\\OneFlower' # 文档的存放目录\ndocuments = []\nfor file in os.listdir(base_dir):\n    # 构建完整的文件路径\n    file_path = os.path.join(base_dir, file)\n    if file.endswith('.pdf'):\n        loader = PyPDFLoader(file_path)\n        documents.extend(loader.load())\n    elif file.endswith('.docx'):\n        loader = Docx2txtLoader(file_path)\n        documents.extend(loader.load())\n    elif file.endswith('.txt'):\n        loader = TextLoader(file_path)\n        documents.extend(loader.load())\n\n```\n\n这里我们首先导入了OpenAI的API Key。因为后面我们需要利用Open AI的两种不同模型做以下两件事：\n\n- 用OpenAI的Embedding模型为文档做嵌入。\n- 调用OpenAI的GPT模型来生成问答系统中的回答。\n\n当然了，LangChain所支持的大模型绝不仅仅是Open AI而已，你完全可以遵循这个框架，把Embedding模型和负责生成回答的语言模型都替换为其他的开源模型。\n\n在运行上面的程序时，除了要导入正确的Open AI Key之外，还要注意的是工具包的安装。使用LangChain时，根据具体的任务，往往需要各种不同的工具包（比如上面的代码需要PyPDF和Docx2txt工具）。它们安装起来都非常简单，如果程序报错缺少某个包，只要通过 `pip install` 安装相关包即可。\n\n## 文本的分割\n\n接下来需要将加载的文本分割成更小的块，以便进行嵌入和向量存储。这个步骤中，我们使用 LangChain中的RecursiveCharacterTextSplitter 来分割文本。\n\n```plain\n# 2.Split 将Documents切分成块以便后续进行嵌入和向量存储\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=10)\nchunked_documents = text_splitter.split_documents(documents)\n\n```\n\n现在，我们的文档被切成了一个个200字符左右的文档块。这一步，是为把它们存储进下面的向量数据库做准备。\n\n## 向量数据库存储\n\n紧接着，我们将这些分割后的文本转换成嵌入的形式，并将其存储在一个向量数据库中。在这个例子中，我们使用了 OpenAIEmbeddings 来生成嵌入，然后使用 Qdrant 这个向量数据库来存储嵌入（这里需要pip install qdrant-client）。\n\n如果文本的“嵌入”这个概念对你来说有些陌生的话，你可以看一下下面的说明。\n\n> 词嵌入（Word Embedding）是自然语言处理和机器学习中的一个概念，它将文字或词语转换为一系列数字，通常是一个向量。简单地说，词嵌入就是一个为每个词分配的数字列表。这些数字不是随机的，而是捕获了这个词的含义和它在文本中的上下文。因此，语义上相似或相关的词在这个数字空间中会比较接近。\n>\n> 举个例子，通过某种词嵌入技术，我们可能会得到：\n>\n> “国王” -\\> \\[1.2, 0.5, 3.1, …\\]\n>\n> “皇帝” -\\> \\[1.3, 0.6, 2.9, …\\]\n>\n> “苹果” -\\> \\[0.9, -1.2, 0.3, …\\]\n>\n> 从这些向量中，我们可以看到“国王”和“皇帝”这两个词的向量在某种程度上是相似的，而与“苹果”这个词相比，它们的向量则相差很大，因为这两个概念在语义上是不同的。\n>\n> 词嵌入的优点是，它提供了一种将文本数据转化为计算机可以理解和处理的形式，同时保留了词语之间的语义关系。这在许多自然语言处理任务中都是非常有用的，比如文本分类、机器翻译和情感分析等。\n\n你也可以对照下面的讲解学习一下向量数据库这个概念，它最近因为大语言模型的流行变得非常火爆。\n\n> 向量数据库，也称为矢量数据库或者向量搜索引擎，是一种专门用于存储和搜索向量形式的数据的数据库。在众多的机器学习和人工智能应用中，尤其是自然语言处理和图像识别这类涉及大量非结构化数据的领域，将数据转化为高维度的向量是常见的处理方式。这些向量可能拥有数百甚至数千个维度，是对复杂的非结构化数据如文本、图像的一种数学表述，从而使这些数据能被机器理解和处理。然而，传统的关系型数据库在存储和查询如此高维度和复杂性的向量数据时，往往面临着效率和性能的问题。因此，向量数据库被设计出来以解决这一问题，它具备高效存储和处理高维向量数据的能力，从而更好地支持涉及非结构化数据处理的人工智能应用。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/e3c7e244b15f9527a4eb811e550a8f16.png)\n\n向量数据库有很多种，比如Pinecone、Chroma和Qdrant，有些是收费的，有些则是开源的。\n\nLangChain中支持很多向量数据库，这里我们选择的是开源向量数据库Qdrant。（注意，需要安装qdrant-client）\n\n具体实现代码如下：\n\n```plain\n# 3.Store 将分割嵌入并存储在矢量数据库Qdrant中\nfrom langchain.vectorstores import Qdrant\nfrom langchain.embeddings import OpenAIEmbeddings\nvectorstore = Qdrant.from_documents(\n    documents=chunked_documents, # 以分块的文档\n    embedding=OpenAIEmbeddings(), # 用OpenAI的Embedding Model做嵌入\n    location=\":memory:\",  # in-memory 存储\n    collection_name=\"my_documents\",) # 指定collection_name\n\n```\n\n目前，易速鲜花的所有内部文档，都以“文档块嵌入片”的格式被存储在向量数据库里面了。那么，我们只需要查询这个向量数据库，就可以找到大体上相关的信息了。\n\n## 相关信息的获取\n\n当内部文档存储到向量数据库之后，我们需要根据问题和任务来提取最相关的信息。此时，信息提取的基本方式就是把问题也转换为向量，然后去和向量数据库中的各个向量进行比较，提取最接近的信息。\n\n向量之间的比较通常基于向量的距离或者相似度。在高维空间中，常用的向量距离或相似度计算方法有欧氏距离和余弦相似度。\n\n- **欧氏距离**：这是最直接的距离度量方式，就像在二维平面上测量两点之间的直线距离那样。在高维空间中，两个向量的欧氏距离就是各个对应维度差的平方和的平方根。\n- **余弦相似度**：在很多情况下，我们更关心向量的方向而不是它的大小。例如在文本处理中，一个词的向量可能会因为文本长度的不同，而在大小上有很大的差距，但方向更能反映其语义。余弦相似度就是度量向量之间方向的相似性，它的值范围在-1到1之间，值越接近1，表示两个向量的方向越相似。\n\n这两种方法都被广泛应用于各种机器学习和人工智能任务中，选择哪一种方法取决于具体的应用场景。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/32db77431433da86d9f818037752bd7a.png)\n\n当然这里你肯定会问了，那么到底什么时候选择欧式距离，什么时候选择余弦相似度呢？\n\n简单来说，关心数量等大小差异时用欧氏距离，关心文本等语义差异时用余弦相似度。\n\n具体来说，欧氏距离度量的是绝对距离，它能很好地反映出向量的绝对差异。当我们关心数据的绝对大小，例如在物品推荐系统中，用户的购买量可能反映他们的偏好强度，此时可以考虑使用欧氏距离。同样，在数据集中各个向量的大小相似，且数据分布大致均匀时，使用欧氏距离也比较适合。\n\n余弦相似度度量的是方向的相似性，它更关心的是两个向量的角度差异，而不是它们的大小差异。在处理文本数据或者其他高维稀疏数据的时候，余弦相似度特别有用。比如在信息检索和文本分类等任务中，文本数据往往被表示为高维的词向量，词向量的方向更能反映其语义相似性，此时可以使用余弦相似度。\n\n在这里，我们正在处理的是文本数据，目标是建立一个问答系统，需要从语义上理解和比较问题可能的答案。因此，我建议使用余弦相似度作为度量标准。通过比较问题和答案向量在语义空间中的方向，可以找到与提出的问题最匹配的答案。\n\n在这一步的代码部分，我们会创建一个聊天模型。然后需要创建一个 RetrievalQA 链，它是一个检索式问答模型，用于生成问题的答案。\n\n在RetrievalQA 链中有下面两大重要组成部分。\n\n- LLM是大模型，负责回答问题。\n- retriever（vectorstore.as\\_retriever()）负责根据问题检索相关的文档，找到具体的“嵌入片”。这些“嵌入片”对应的“文档块”就会作为知识信息，和问题一起传递进入大模型。本地文档中检索而得的知识很重要，因为 **从互联网信息中训练而来的大模型不可能拥有“易速鲜花”作为一个私营企业的内部知识**。\n\n具体代码如下：\n\n```plain\n# 4. Retrieval 准备模型和Retrieval链\nimport logging # 导入Logging工具\nfrom langchain.chat_models import ChatOpenAI # ChatOpenAI模型\nfrom langchain.retrievers.multi_query import MultiQueryRetriever # MultiQueryRetriever工具\nfrom langchain.chains import RetrievalQA # RetrievalQA链\n\n# 设置Logging\nlogging.basicConfig()\nlogging.getLogger('langchain.retrievers.multi_query').setLevel(logging.INFO)\n\n# 实例化一个大模型工具 - OpenAI的GPT-3.5\nllm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n\n# 实例化一个MultiQueryRetriever\nretriever_from_llm = MultiQueryRetriever.from_llm(retriever=vectorstore.as_retriever(), llm=llm)\n\n# 实例化一个RetrievalQA链\nqa_chain = RetrievalQA.from_chain_type(llm,retriever=retriever_from_llm)\n\n```\n\n现在我们已经为后续的步骤做好了准备，下一步就是接收来自系统用户的具体问题，并根据问题检索信息，生成回答。\n\n## 生成回答并展示\n\n这一步是问答系统应用的主要UI交互部分，这里会创建一个 Flask 应用（需要安装Flask包）来接收用户的问题，并生成相应的答案，最后通过 index.html 对答案进行渲染和呈现。\n\n在这个步骤中，我们使用了之前创建的 RetrievalQA 链来获取相关的文档和生成答案。然后，将这些信息返回给用户，显示在网页上。\n\n```plain\n# 5. Output 问答系统的UI实现\nfrom flask import Flask, request, render_template\napp = Flask(__name__) # Flask APP\n\n@app.route('/', methods=['GET', 'POST'])\ndef home():\n    if request.method == 'POST':\n\n        # 接收用户输入作为问题\n        question = request.form.get('question')\n\n        # RetrievalQA链 - 读入问题，生成答案\n        result = qa_chain({\"query\": question})\n\n        # 把大模型的回答结果返回网页进行渲染\n        return render_template('index.html', result=result)\n\n    return render_template('index.html')\n\nif __name__ == \"__main__\":\n    app.run(host='0.0.0.0',debug=True,port=5000)\n\n```\n\n相关HTML网页的关键代码如下：\n\n```plain\n<body>\n    <div class=\"container\">\n        <div class=\"header\">\n            <h1>易速鲜花内部问答系统</h1>\n            <img src=\"{{ url_for('static', filename='flower.png') }}\" alt=\"flower logo\" width=\"200\">\n        </div>\n        <form method=\"POST\">\n            <label for=\"question\">Enter your question:</label><br>\n            <input type=\"text\" id=\"question\" name=\"question\"><br>\n            <input type=\"submit\" value=\"Submit\">\n        </form>\n        {% if result is defined %}\n            <h2>Answer</h2>\n            <p>{{ result.result }}</p>\n        {% endif %}\n    </div>\n</body>\n\n```\n\n这个项目的目录结构如下：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/2110cd73ddb8677f9b188d41c589c73e.png)\n\n运行程序之后，我们跑起一个网页 [http://127.0.0.1:5000/](http://127.0.0.1:5000/)。与网页进行互动时，可以发现，问答系统完美生成了专属于异速鲜花内部资料的回答。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/46b5b08c5f022f2c4c5975436b3e2d17.png)\n\n## 总结时刻\n\n来回顾一下上面的流程。正如下图所示，我们先把本地知识切片后做Embedding，存储到向量数据库中，然后把用户的输入和从向量数据库中检索到的本地知识传递给大模型，最终生成所想要的回答。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/249c631211275e40f3e72d05dda976af.jpg)\n\n怎么样，你是不是觉得整个流程特别简单易懂？\n\n对了，LangChain+LLM的配置就是使原本复杂的东西变得特别简单，特别易于操作。而这个任务，在大模型和LangChain出现之前，要实现起来可不是这么简单的。\n\n如果这个示例让你了解到了LangChain的威力，那么这节课的目标也就完成了。除了流程图的回顾，我也为你准备了一个详细版的脑图，你可以对照着复习。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/78a4b0435639b4db8c4e024d830a2ac2.jpg)\n\n在后面几节课中，我们即将对LangChain的模型、链、内存、代理等组件进行详细拆解，我会带着你实现更多任务，开发出更奇妙的应用。\n\n## 思考题\n\n1. 请你用自己的话简述一下这个基于文档的QA（问答）系统的实现流程？\n2. LangChain支持很多种向量数据库，你能否用另一种常用的向量数据库Chroma来实现这个任务？\n3. LangChain支持很多种大语言模型，你能否用HuggingFace网站提供的开源模型 [google/flan-t5-x1](https://huggingface.co/google/flan-t5-xl) 代替GPT-3.5完成这个任务？\n\n题目较多，可以选择性尝试，期待在留言区看到你的分享。如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。\n\n## 延伸阅读\n\n1. LangChain官方文档对 [Document QA 系统](https://docs.langchain.com/docs/use-cases/qa-docs) 设计及实现的详细说明\n2. HuggingFace官网上的 [文档问答](https://huggingface.co/tasks/document-question-answering) 资源\n3. 论文 [开放式表格与文本问题回答](https://arxiv.org/abs/2010.10439)，Chen, W., Chang, M.-W., Schlinger, E., Wang, W., & Cohen, W. W. (2021). Open Question Answering over Tables and Text. ICLR 2021."},{"url":"/posts/1.html","content":"# 03｜模型I/O：输入提示、调用模型、解析输出\n你好，我是黄佳，欢迎来到LangChain实战课！\n\n从这节课开始，我们将对LangChain中的六大核心组件一一进行详细的剖析。\n\n模型，位于LangChain框架的最底层，它是基于语言模型构建的应用的 **核心元素**，因为所谓LangChain应用开发，就是以LangChain作为框架，通过API调用大模型来解决具体问题的过程。\n\n可以说，整个LangChain框架的逻辑都是由LLM这个发动机来驱动的。没有模型，LangChain这个框架也就失去了它存在的意义。那么这节课我们就详细讲讲模型，最后你会收获一个能够自动生成鲜花文案的应用程序。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/76619cf2f73ef200dd57cd16c0d55ec4.png)\n\n## Model I/O\n\n我们可以把对模型的使用过程拆解成三块，分别是 **输入提示**（对应图中的Format）、 **调用模型**（对应图中的Predict）和 **输出解析**（对应图中的Parse）。这三块形成了一个整体，因此在LangChain中这个过程被统称为 **Model I/O**（Input/Output）。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/ac67214287154dcfbbf12d81086c8023.png)\n\n在模型 I/O的每个环节，LangChain都为咱们提供了模板和工具，快捷地形成调用各种语言模型的接口。\n\n1. **提示模板**：使用模型的第一个环节是把提示信息输入到模型中，你可以创建LangChain模板，根据实际需求动态选择不同的输入，针对特定的任务和应用调整输入。\n2. **语言模型**：LangChain允许你通过通用接口来调用语言模型。这意味着无论你要使用的是哪种语言模型，都可以通过同一种方式进行调用，这样就提高了灵活性和便利性。\n3. **输出解析**：LangChain还提供了从模型输出中提取信息的功能。通过输出解析器，你可以精确地从模型的输出中获取需要的信息，而不需要处理冗余或不相关的数据，更重要的是还可以把大模型给回的非结构化文本，转换成程序可以处理的结构化数据。\n\n下面我们用示例的方式来深挖一下这三个环节。先来看看LangChain中提示模板的构建。\n\n## 提示模板\n\n语言模型是个无穷无尽的宝藏，人类的知识和智慧，好像都封装在了这个“魔盒”里面了。但是，怎样才能解锁其中的奥秘，那可就是仁者见仁智者见智了。所以，现在“提示工程”这个词特别流行，所谓Prompt Engineering，就是专门研究对大语言模型的提示构建。\n\n我的观点是，使用大模型的场景千差万别，因此肯定不存在那么一两个神奇的模板，能够骗过所有模型，让它总能给你最想要的回答。然而，好的提示（其实也就是好的问题或指示啦），肯定能够让你在调用语言模型的时候事半功倍。\n\n那其中的具体原则，不外乎吴恩达老师在他的 [提示工程课程](https://learn.deeplearning.ai/login?redirect_course=chatgpt-prompt-eng) 中所说的：\n\n1. 给予模型清晰明确的指示\n2. 让模型慢慢地思考\n\n说起来很简单，对吧？是的，道理总是简单，但是如何具体实践这些原则，又是个大问题。让我从创建一个简单的LangChain提示模板开始。\n\n这里，我们希望为销售的每一种鲜花生成一段简介文案，那么每当你的员工或者顾客想了解某种鲜花时，调用该模板就会生成适合的文字。\n\n这个提示模板的生成方式如下：\n\n```plain\n# 导入LangChain中的提示模板\nfrom langchain import PromptTemplate\n# 创建原始模板\ntemplate = \"\"\"您是一位专业的鲜花店文案撰写员。\\n\n对于售价为 {price} 元的 {flower_name} ，您能提供一个吸引人的简短描述吗？\n\"\"\"\n# 根据原始模板创建LangChain提示模板\nprompt = PromptTemplate.from_template(template)\n# 打印LangChain提示模板的内容\nprint(prompt)\n\n```\n\n提示模板的具体内容如下：\n\n```plain\ninput_variables=['flower_name', 'price']\noutput_parser=None partial_variables={}\ntemplate='/\\n您是一位专业的鲜花店文案撰写员。\n\\n对于售价为 {price} 元的 {flower_name} ，您能提供一个吸引人的简短描述吗？\\n'\ntemplate_format='f-string'\nvalidate_template=True\n\n```\n\n在这里，所谓“模板”就是一段描述某种鲜花的文本格式，它是一个 f-string，其中有两个变量 {flower\\_name} 和 {price} 表示花的名称和价格，这两个值是模板里面的占位符，在实际使用模板生成提示时会被具体的值替换。\n\n代码中的from\\_template是一个类方法，它允许我们直接从一个字符串模板中创建一个PromptTemplate对象。打印出这个PromptTemplate对象，你可以看到这个对象中的信息包括输入的变量（在这个例子中就是 `flower_name` 和 `price`）、输出解析器（这个例子中没有指定）、模板的格式（这个例子中为 `'f-string'`）、是否验证模板（这个例子中设置为 `True`）。\n\n因此PromptTemplate的from\\_template方法就是将一个原始的模板字符串转化为一个更丰富、更方便操作的PromptTemplate对象，这个对象就是LangChain中的提示模板。LangChain 提供了多个类和函数，也 **为各种应用场景设计了很多内置模板，使构建和使用提示变得容易**。我们下节课还会对提示工程的基本原理和LangChain中的各种提示模板做更深入的讲解。\n\n下面，我们将会使用这个刚刚构建好的提示模板来生成提示，并把提示输入到大语言模型中。\n\n## **语言模型**\n\nLangChain中支持的模型有三大类。\n\n1. 大语言模型（LLM） ，也叫Text Model，这些模型将文本字符串作为输入，并返回文本字符串作为输出。Open AI的text-davinci-003、Facebook的LLaMA、ANTHROPIC的Claude，都是典型的LLM。\n2. 聊天模型（Chat Model），主要代表Open AI的ChatGPT系列模型。这些模型通常由语言模型支持，但它们的 API 更加结构化。具体来说，这些模型将聊天消息列表作为输入，并返回聊天消息。\n3. 文本嵌入模型（Embedding Model），这些模型将文本作为输入并返回浮点数列表，也就是Embedding。而文本嵌入模型如OpenAI的text-embedding-ada-002，我们之前已经见过了。文本嵌入模型负责把文档存入向量数据库，和我们这里探讨的提示工程关系不大。\n\n然后，我们将调用语言模型，让模型帮我们写文案，并且返回文案的结果。\n\n```plain\n# 设置OpenAI API Key\nimport os\nos.environ[\"OPENAI_API_KEY\"] = '你的Open AI API Key'\n\n# 导入LangChain中的OpenAI模型接口\nfrom langchain import OpenAI\n# 创建模型实例\nmodel = OpenAI(model_name='text-davinci-003')\n# 输入提示\ninput = prompt.format(flower_name=[\"玫瑰\"], price='50')\n# 得到模型的输出\noutput = model(input)\n# 打印输出内容\nprint(output)\n\n```\n\n`input = prompt.format(flower_name=[\"玫瑰\"], price='50')` 这行代码的作用是将模板实例化，此时将 `{flower_name}` 替换为 `\"玫瑰\"`， `{price}` 替换为 `'50'`，形成了具体的提示：“您是一位专业的鲜花店文案撰写员。对于售价为 50 元的玫瑰，您能提供一个吸引人的简短描述吗？”\n\n接收到这个输入，调用模型之后，得到的输出如下：\n\n```plain\n让你心动！50元就可以拥有这支充满浪漫气息的玫瑰花束，让TA感受你的真心爱意。\n\n```\n\n复用提示模板，我们可以同时生成多个鲜花的文案。\n\n```plain\n# 导入LangChain中的提示模板\nfrom langchain import PromptTemplate\n# 创建原始模板\ntemplate = \"\"\"您是一位专业的鲜花店文案撰写员。\\n\n对于售价为 {price} 元的 {flower_name} ，您能提供一个吸引人的简短描述吗？\n\"\"\"\n# 根据原始模板创建LangChain提示模板\nprompt = PromptTemplate.from_template(template)\n# 打印LangChain提示模板的内容\nprint(prompt)\n\n# 设置OpenAI API Key\nimport os\nos.environ[\"OPENAI_API_KEY\"] = '你的Open AI API Key'\n\n# 导入LangChain中的OpenAI模型接口\nfrom langchain import OpenAI\n# 创建模型实例\nmodel = OpenAI(model_name='text-davinci-003')\n\n# 多种花的列表\nflowers = [\"玫瑰\", \"百合\", \"康乃馨\"]\nprices = [\"50\", \"30\", \"20\"]\n\n# 生成多种花的文案\nfor flower, price in zip(flowers, prices):\n    # 使用提示模板生成输入\n    input_prompt = prompt.format(flower_name=flower, price=price)\n\n    # 得到模型的输出\n    output = model(input_prompt)\n\n    # 打印输出内容\n    print(output)\n\n```\n\n模型的输出如下：\n\n```plain\n这支玫瑰，深邃的红色，传递着浓浓的深情与浪漫，令人回味无穷！\n百合：美丽的花朵，多彩的爱恋！30元让你拥有它！\n康乃馨—20元，象征爱的祝福，送给你最真挚的祝福。\n\n```\n\n你也许会问我，在这个过程中，使用LangChain的意义究竟何在呢？我直接调用Open AI的API，不是完全可以实现相同的功能吗？\n\n的确如此，让我们来看看直接使用Open AI API来完成上述功能的代码。\n\n```plain\nimport openai # 导入OpenAI\nopenai.api_key = 'Your-OpenAI-API-Key' # API Key\n\nprompt_text = \"您是一位专业的鲜花店文案撰写员。对于售价为{}元的{}，您能提供一个吸引人的简短描述吗？\" # 设置提示\n\nflowers = [\"玫瑰\", \"百合\", \"康乃馨\"]\nprices = [\"50\", \"30\", \"20\"]\n\n# 循环调用Text模型的Completion方法，生成文案\nfor flower, price in zip(flowers, prices):\n    prompt = prompt_text.format(price, flower)\n    response = openai.Completion.create(\n        engine=\"text-davinci-003\",\n        prompt=prompt,\n        max_tokens=100\n    )\n    print(response.choices[0].text.strip()) # 输出文案\n\n```\n\n上面的代码是直接使用Open AI和带有 {} 占位符的提示语，同时生成了三种鲜花的文案。看起来也是相当简洁。\n\n不过，如果你深入思考一下，你就会发现LangChain的优势所在。 **我们只需要定义一次模板，就可以用它来生成各种不同的提示。** 对比单纯使用 f-string 来格式化文本，这种方法更加简洁，也更容易维护。而LangChain在提示模板中，还整合了output\\_parser、template\\_format 以及是否需要validate\\_template等功能。\n\n更重要的是，使用LangChain提示模板，我们还可以很方便地把程序切换到不同的模型，而不需要修改任何提示相关的代码。\n\n下面，我们用完全相同的提示模板来生成提示，并发送给HuggingFaceHub中的开源模型来创建文案。（注意：需要注册HUGGINGFACEHUB\\_API\\_TOKEN）\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/c8c0d84349ebd2d1d82a2836383164ec.png)\n\n```plain\n# 导入LangChain中的提示模板\nfrom langchain import PromptTemplate\n# 创建原始模板\ntemplate = \"\"\"You are a flower shop assitiant。\\n\nFor {price} of {flower_name} ，can you write something for me？\n\"\"\"\n# 根据原始模板创建LangChain提示模板\nprompt = PromptTemplate.from_template(template)\n# 打印LangChain提示模板的内容\nprint(prompt)\nimport os\nos.environ['HUGGINGFACEHUB_API_TOKEN'] = '你的HuggingFace API Token'\n# 导入LangChain中的OpenAI模型接口\nfrom langchain import HuggingFaceHub\n# 创建模型实例\nmodel= HuggingFaceHub(repo_id=\"google/flan-t5-large\")\n# 输入提示\ninput = prompt.format(flower_name=[\"rose\"], price='50')\n# 得到模型的输出\noutput = model(input)\n# 打印输出内容\nprint(output)\n\n```\n\n输出：\n\n```plain\ni love you\n\n```\n\n真是一分钱一分货，当我使用较早期的开源模型T5，得到了很粗糙的文案 “i love you”（哦，还要注意T5还没有支持中文的能力，我把提示文字换成英文句子，结构其实都没变）。\n\n当然，这里我想要向你传递的信息是：你可以重用模板，重用程序结构，通过LangChain框架调用任何模型。如果你熟悉机器学习的训练流程的话，这LangChain是不是让你联想到PyTorch和TensorFlow这样的框架—— **模型可以自由选择、自主训练，而调用模型的框架往往是有章法、而且可复用的**。\n\n因此，使用LangChain和提示模板的好处是：\n\n1. 代码的可读性：使用模板的话，提示文本更易于阅读和理解，特别是对于复杂的提示或多变量的情况。\n2. 可复用性：模板可以在多个地方被复用，让你的代码更简洁，不需要在每个需要生成提示的地方重新构造提示字符串。\n3. 维护：如果你在后续需要修改提示，使用模板的话，只需要修改模板就可以了，而不需要在代码中查找所有使用到该提示的地方进行修改。\n4. 变量处理：如果你的提示中涉及到多个变量，模板可以自动处理变量的插入，不需要手动拼接字符串。\n5. 参数化：模板可以根据不同的参数生成不同的提示，这对于个性化生成文本非常有用。\n\n那我们就接着介绍模型 I/O的最后一步，输出解析。\n\n## **输出解析**\n\nLangChain提供的解析模型输出的功能，使你能够更容易地从模型输出中获取结构化的信息，这将大大加快基于语言模型进行应用开发的效率。\n\n为什么这么说呢？请你思考一下刚才的例子，你只是让模型生成了一个文案。这段文字是一段字符串，正是你所需要的。但是，在开发具体应用的过程中，很明显 **我们不仅仅需要文字，更多情况下我们需要的是程序能够直接处理的、结构化的数据**。\n\n比如说，在这个文案中，如果你希望模型返回两个字段：\n\n- description：鲜花的说明文本\n- reason：解释一下为何要这样写上面的文案\n\n那么，模型可能返回的一种结果是：\n\n**A**：“文案是：让你心动！50元就可以拥有这支充满浪漫气息的玫瑰花束，让TA感受你的真心爱意。为什么这样说呢？因为爱情是无价的，50元对应热恋中的情侣也会觉得值得。”\n\n上面的回答并不是我们在处理数据时所需要的，我们需要的是一个类似于下面的Python字典。\n\n**B**：{description: “让你心动！50元就可以拥有这支充满浪漫气息的玫瑰花束，让TA感受你的真心爱意。” ; reason: “因为爱情是无价的，50元对应热恋中的情侣也会觉得值得。”}\n\n那么从A的笼统言语，到B这种结构清晰的数据结构，如何自动实现？这就需要LangChain中的输出解析器上场了。\n\n下面，我们就通过LangChain的输出解析器来重构程序，让模型有能力生成结构化的回应，同时对其进行解析，直接将解析好的数据存入CSV文档。\n\n```plain\n# 通过LangChain调用模型\nfrom langchain import PromptTemplate, OpenAI\n\n# 导入OpenAI Key\nimport os\nos.environ[\"OPENAI_API_KEY\"] = '你的OpenAI API Key'\n\n# 创建原始提示模板\nprompt_template = \"\"\"您是一位专业的鲜花店文案撰写员。\n对于售价为 {price} 元的 {flower_name} ，您能提供一个吸引人的简短描述吗？\n{format_instructions}\"\"\"\n\n# 创建模型实例\nmodel = OpenAI(model_name='text-davinci-003')\n\n# 导入结构化输出解析器和ResponseSchema\nfrom langchain.output_parsers import StructuredOutputParser, ResponseSchema\n# 定义我们想要接收的响应模式\nresponse_schemas = [\n    ResponseSchema(name=\"description\", description=\"鲜花的描述文案\"),\n    ResponseSchema(name=\"reason\", description=\"问什么要这样写这个文案\")\n]\n# 创建输出解析器\noutput_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n\n# 获取格式指示\nformat_instructions = output_parser.get_format_instructions()\n# 根据原始模板创建提示，同时在提示中加入输出解析器的说明\nprompt = PromptTemplate.from_template(prompt_template,\n                partial_variables={\"format_instructions\": format_instructions})\n\n# 数据准备\nflowers = [\"玫瑰\", \"百合\", \"康乃馨\"]\nprices = [\"50\", \"30\", \"20\"]\n\n# 创建一个空的DataFrame用于存储结果\nimport pandas as pd\ndf = pd.DataFrame(columns=[\"flower\", \"price\", \"description\", \"reason\"]) # 先声明列名\n\nfor flower, price in zip(flowers, prices):\n    # 根据提示准备模型的输入\n    input = prompt.format(flower_name=flower, price=price)\n\n    # 获取模型的输出\n    output = model(input)\n\n    # 解析模型的输出（这是一个字典结构）\n    parsed_output = output_parser.parse(output)\n\n    # 在解析后的输出中添加“flower”和“price”\n    parsed_output['flower'] = flower\n    parsed_output['price'] = price\n\n    # 将解析后的输出添加到DataFrame中\n    df.loc[len(df)] = parsed_output\n\n# 打印字典\nprint(df.to_dict(orient='records'))\n\n# 保存DataFrame到CSV文件\ndf.to_csv(\"flowers_with_descriptions.csv\", index=False)\n\n```\n\n输出：\n\n```plain\n[{'flower': '玫瑰', 'price': '50', 'description': 'Luxuriate in the beauty of this 50 yuan rose, with its deep red petals and delicate aroma.', 'reason': 'This description emphasizes the elegance and beauty of the rose, which will be sure to draw attention.'},\n{'flower': '百合', 'price': '30', 'description': '30元的百合，象征着坚定的爱情，带给你的是温暖而持久的情感！', 'reason': '百合是象征爱情的花，写出这样的描述能让顾客更容易感受到百合所带来的爱意。'},\n{'flower': '康乃馨', 'price': '20', 'description': 'This beautiful carnation is the perfect way to show your love and appreciation. Its vibrant pink color is sure to brighten up any room!', 'reason': 'The description is short, clear and appealing, emphasizing the beauty and color of the carnation while also invoking a sense of love and appreciation.'}]\n\n```\n\n这段代码中，首先定义输出结构，我们希望模型生成的答案包含两部分：鲜花的描述文案（description）和撰写这个文案的原因（reason）。所以我们定义了一个名为response\\_schemas的列表，其中包含两个ResponseSchema对象，分别对应这两部分的输出。\n\n根据这个列表，我通过StructuredOutputParser.from\\_response\\_schemas方法创建了一个输出解析器。\n\n然后，我们通过输出解析器对象的get\\_format\\_instructions()方法获取输出的格式说明（format\\_instructions），再根据原始的字符串模板和输出解析器格式说明创建新的提示模板（这个模板就整合了输出解析结构信息）。再通过新的模板生成模型的输入，得到模型的输出。此时模型的输出结构将尽最大可能遵循我们的指示，以便于输出解析器进行解析。\n\n对于每一个鲜花和价格组合，我们都用 output\\_parser.parse(output) 把模型输出的文案解析成之前定义好的数据格式，也就是一个Python字典，这个字典中包含了description 和 reason 这两个字段的值。\n\n```plain\nparsed_output\n{'description': 'This 50-yuan rose is... feelings.', 'reason': 'The description is s...y emotion.'}\nlen(): 2\n\n```\n\n最后，把所有信息整合到一个pandas DataFrame对象中（需要安装Pandas库）。这个DataFrame对象中包含了flower、price、description 和 reason 这四个字段的值。其中，description 和 reason 是由 output\\_parser 从模型的输出中解析出来的，flower 和 price 是我们自己添加的。\n\n我们可以打印出DataFrame的内容，也方便地在程序中处理它，比如保存为下面的CSV文件。因为此时数据不再是模糊的、无结构的文本，而是结构清晰的有格式的数据。 **输出解析器在这个过程中的功劳很大**。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/3264157dc13f229641d87dcb34dafbf2.png)\n\n到这里，我们今天的任务也就顺利完成了。\n\n## 总结时刻\n\n这样，你就从头到尾利用大模型开发出来了一个能够自动生成鲜花文案的应用程序！怎么样，是不是感觉和我们平时所做的基于SQL和数据库表以及固定业务逻辑的应用开发很不一样？\n\n你看，每一次运行都有不同的结果，而我们完全不知道大模型下一次会给我们带来怎样的新东西。因此，基于大模型构建的应用可以说充满了创造力。\n\n总结一下使用LangChain框架的好处，你会发现它有这样几个优势。\n\n1. 模板管理：在大型项目中，可能会有许多不同的提示模板，使用 LangChain 可以帮助你更好地管理这些模板，保持代码的清晰和整洁。\n2. 变量提取和检查：LangChain 可以自动提取模板中的变量并进行检查，确保你没有忘记填充任何变量。\n3. 模型切换：如果你想尝试使用不同的模型，只需要更改模型的名称就可以了，无需修改代码。\n4. 输出解析：LangChain的提示模板可以嵌入对输出格式的定义，以便在后续处理过程中比较方便地处理已经被格式化了的输出。\n\n在下节课中，我们将继续深入探索LangChain中的提示模板，看一看如何通过高质量的提示工程让模型创造出更为精准、更高质量的输出。\n\n## 思考题\n\n1. 请你用自己的理解，简述LangChain调用大语言模型来做应用开发的优势。\n2. 在上面的示例中，format\\_instructions，也就是输出格式是怎样用output\\_parser构建出来的，又是怎样传递到提示模板中的？\n3. 加入了partial\\_variables，也就是输出解析器指定的format\\_instructions之后的提示，为什么能够让模型生成结构化的输出？你可以打印出这个提示，一探究竟。\n4. 使用输出解析器后，调用模型时有没有可能仍然得不到所希望的输出？也就是说，模型有没有可能仍然返回格式不够完美的输出？\n\n题目较多，可以选择性思考，期待在留言区看到你的分享。如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。\n\n## 延伸阅读\n\n1. 吴恩达老师的 [提示工程课程](https://learn.deeplearning.ai/login?redirect_course=chatgpt-prompt-eng)，吴老师也有LangChain的简单介绍课程呦！网上也有这些课程的中文翻译版！\n2. LangChain官方文档中，关于模型I/O的资料 [在此](https://python.langchain.com/docs/modules/model_io/)。"},{"url":"/posts/2.html","content":"# 04｜提示工程（上）：用少样本FewShotTemplate和ExampleSelector创建应景文案\n你好，我是黄佳，欢迎来到LangChain实战课！\n\n上节课我给你留了一个思考题： **在提示模板的构建过程中加入了partial\\_variables，也就是输出解析器指定的format\\_instructions之后，为什么能够让模型生成结构化的输出？**\n\n当你用print语句打印出最终传递给大模型的提示时，一切就变得非常明了。\n\n````plain\n您是一位专业的鲜花店文案撰写员。\n对于售价为 50 元的 玫瑰 ，您能提供一个吸引人的简短描述吗？\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n\n```json\n{\n        \"description\": string  // 鲜花的描述文案\n        \"reason\": string  // 问什么要这样写这个文案\n}\n\n````\n\n秘密在于，LangChain的输出解析器偷偷的在提示中加了一段话，也就是 {format\\_instructions} 中的内容。这段由LangChain自动添加的文字，就清楚地指示着我们希望得到什么样的回答以及回答的具体格式。提示指出，模型需要根据一个schema来格式化输出文本，这个schema从 \\`\\`\\`json 开始，到 \\`\\`\\` 结束。\n\n这就是在告诉模型，你就follow这个schema（schema，可以理解为对数据结构的描述）的格式，就行啦！\n\n这就是一个很棒、很典型的 **提示工程**。有了这样清晰的提示，智能程度比较高的模型（比如GPT3.5及以上版本），肯定能够输出可以被解析的数据结构，如JSON格式的数据。\n\n那么这节课我就带着你进一步深究，如何利用LangChain中的提示模板，做好提示工程。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/3b5584552720f22ac10e1ab1430f61fe.jpg)\n\n上节课我说过，针对大模型的提示工程该如何做，吴恩达老师在他的 [ChatGPT Prompt Engineering for Developers](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/) 公开课中，给出了两个大的原则：第一条原则是写出清晰而具体的指示，第二条原则是给模型思考的时间。\n\n无独有偶，在Open AI的官方文档 [GPT 最佳实践](https://platform.openai.com/docs/guides/gpt-best-practices/gpt-best-practices) 中，也给出了和上面这两大原则一脉相承的6大策略。分别是：\n\n1. 写清晰的指示\n2. 给模型提供参考（也就是示例）\n3. 将复杂任务拆分成子任务\n4. 给GPT时间思考\n5. 使用外部工具\n6. 反复迭代问题\n\n怎么样，这些原则和策略是不是都是大白话？这些原则其实不仅能够指导大语言模型，也完全能够指导你的思维过程，让你处理问题时的思路更为清晰。所以说，大模型的思维过程和我们人类的思维过程，还是蛮相通的。\n\n## 提示的结构\n\n当然了，从大原则到实践，还是有一些具体工作需要说明，下面我们先看一个实用的提示框架。\n\n![图片](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/b77a15cd83b66bba55032d711bcf3c16.png)\n\n在这个提示框架中：\n\n- **指令**（Instuction）告诉模型这个任务大概要做什么、怎么做，比如如何使用提供的外部信息、如何处理查询以及如何构造输出。这通常是一个提示模板中比较固定的部分。一个常见用例是告诉模型“你是一个有用的XX助手”，这会让他更认真地对待自己的角色。\n- **上下文**（Context）则充当模型的额外知识来源。这些信息可以手动插入到提示中，通过矢量数据库检索得来，或通过其他方式（如调用API、计算器等工具）拉入。一个常见的用例时是把从向量数据库查询到的知识作为上下文传递给模型。\n- **提示输入**（Prompt Input）通常就是具体的问题或者需要大模型做的具体事情，这个部分和“指令”部分其实也可以合二为一。但是拆分出来成为一个独立的组件，就更加结构化，便于复用模板。这通常是作为变量，在调用模型之前传递给提示模板，以形成具体的提示。\n- **输出指示器**（Output Indicator）标记​​要生成的文本的开始。这就像我们小时候的数学考卷，先写一个“解”，就代表你要开始答题了。如果生成 Python 代码，可以使用 “import” 向模型表明它必须开始编写 Python 代码（因为大多数 Python 脚本以import开头）。这部分在我们和ChatGPT对话时往往是可有可无的，当然LangChain中的代理在构建提示模板时，经常性的会用一个“Thought：”（思考）作为引导词，指示模型开始输出自己的推理（Reasoning）。\n\n下面，就让我们看看如何使用 LangChain中的各种提示模板做提示工程，将更优质的提示输入大模型。\n\n## LangChain 提示模板的类型\n\nLangChain中提供String（StringPromptTemplate）和Chat（BaseChatPromptTemplate）两种基本类型的模板，并基于它们构建了不同类型的提示模板：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/feefbb0a166f53f14f647b88e1025cyy.jpg)\n\n这些模板的导入方式如下：\n\n```plain\n\nfrom langchain.prompts.prompt import PromptTemplate\nfrom langchain.prompts import FewShotPromptTemplate\nfrom langchain.prompts.pipeline import PipelinePromptTemplate\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.prompts import (\n    ChatMessagePromptTemplate,\n    SystemMessagePromptTemplate,\n    AIMessagePromptTemplate,\n    HumanMessagePromptTemplate,\n)\n\n```\n\n我发现有时候不指定 .prompts，直接从LangChain包也能导入模板。\n\n```plain\nfrom langchain import PromptTemplate\n\n```\n\n下面我们通过示例来介绍上面这些模版，前两个我们简单了解就好，其中最典型的FewShotPromptTemplate会重点讲。至于PipelinePrompt和自定义模板，使用起来比较简单，请你参考LangChain文档自己学习。\n\n## 使用 PromptTemplate\n\n下面通过示例简单说明一下PromptTemplate的使用。\n\n```plain\nfrom langchain import PromptTemplate\n\ntemplate = \"\"\"\\\n你是业务咨询顾问。\n你给一个销售{product}的电商公司，起一个好的名字？\n\"\"\"\nprompt = PromptTemplate.from_template(template)\n\nprint(prompt.format(product=\"鲜花\"))\n\n```\n\n输出：\n\n```plain\n你是业务咨询顾问。\n你给一个销售鲜花的电商公司，起一个好的名字？\n\n```\n\n这个程序的主要功能是生成适用于不同场景的提示，对用户定义的一种产品或服务提供公司命名建议。\n\n在这里， `\"你是业务咨询顾问。你给一个销售{product}的电商公司，起一个好的名字？\"` 就是原始提示模板，其中 {product} 是占位符。\n\n然后通过PromptTemplate的from\\_template方法，我们创建了一个提示模板对象，并通过prompt.format方法将模板中的 {product} 替换为 `\"鲜花\"`。\n\n这样，就得到了一句具体的提示： _你是业务咨询顾问。你给一个销售鲜花的电商公司，起一个好的名字？_——这就要求大语言模型，要有的放矢。\n\n在上面这个过程中，LangChain中的模板的一个方便之处是from\\_template方法可以从传入的字符串中自动提取变量名称（如product），而无需刻意指定。 **上面程序中的product自动成为了format方法中的一个参数**。\n\n当然，也可以通过提示模板类的构造函数，在创建模板时手工指定input\\_variables，示例如下：\n\n```plain\nprompt = PromptTemplate(\n    input_variables=[\"product\", \"market\"],\n    template=\"你是业务咨询顾问。对于一个面向{market}市场的，专注于销售{product}的公司，你会推荐哪个名字？\"\n)\nprint(prompt.format(product=\"鲜花\", market=\"高端\"))\n\n```\n\n输出：\n\n```plain\n你是业务咨询顾问。对于一个面向高端市场的，专注于销售鲜花的公司，你会推荐哪个名字？\n\n```\n\n上面的方式直接生成了提示模板，并没有通过from\\_template方法从字符串模板中创建提示模板。二者效果是一样的。\n\n## 使用 ChatPromptTemplate\n\n对于OpenAI推出的ChatGPT这一类的聊天模型，LangChain也提供了一系列的模板，这些模板的不同之处是它们有对应的角色。\n\n下面代码展示了OpenAI的Chat Model中的各种消息角色。\n\n```plain\nimport openai\nopenai.ChatCompletion.create(\n  model=\"gpt-3.5-turbo\",\n  messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n    ]\n)\n\n```\n\nOpenAI对传输到gpt-3.5-turbo和GPT-4的messsage格式说明如下：\n\n> 消息必须是消息对象的数组，其中每个对象都有一个角色（系统、用户或助理）和内容。对话可以短至一条消息，也可以来回多次。\n>\n> 通常，对话首先由系统消息格式化，然后是交替的用户消息和助理消息。\n>\n> 系统消息有助于设置助手的行为。例如，你可以修改助手的个性或提供有关其在整个对话过程中应如何表现的具体说明。但请注意，系统消息是可选的，并且没有系统消息的模型的行为可能类似于使用通用消息，例如“你是一个有用的助手”。\n>\n> 用户消息提供助理响应的请求或评论。\n>\n> 助理消息存储以前的助理响应，但也可以由你编写以给出所需行为的示例。\n\nLangChain的ChatPromptTemplate这一系列的模板，就是 **跟着这一系列角色而设计的**。\n\n下面，我给出一个示例。\n\n```plain\n# 导入聊天消息类模板\nfrom langchain.prompts import (\n    ChatPromptTemplate,\n    SystemMessagePromptTemplate,\n    HumanMessagePromptTemplate,\n)\n# 模板的构建\ntemplate=\"你是一位专业顾问，负责为专注于{product}的公司起名。\"\nsystem_message_prompt = SystemMessagePromptTemplate.from_template(template)\nhuman_template=\"公司主打产品是{product_detail}。\"\nhuman_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\nprompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n\n# 格式化提示消息生成提示\nprompt = prompt_template.format_prompt(product=\"鲜花装饰\", product_detail=\"创新的鲜花设计。\").to_messages()\n\n# 下面调用模型，把提示传入模型，生成结果\nimport os\nos.environ[\"OPENAI_API_KEY\"] = '你的OpenAI Key'\nfrom langchain.chat_models import ChatOpenAI\nchat = ChatOpenAI()\nresult = chat(prompt)\nprint(result)\n\n```\n\n输出：\n\n```plain\ncontent='1. 花语创意\\n2. 花韵设计\\n3. 花艺创新\\n4. 花漾装饰\\n5. 花语装点\\n6. 花翩翩\\n7. 花语之美\\n8. 花馥馥\\n9. 花语时尚\\n10. 花之魅力'\nadditional_kwargs={}\nexample=False\n\n```\n\n好吧，尽管模型成功地完成了任务，但是感觉没有咱“易速鲜花”响亮！\n\n讲完上面两种简单易用的提示模板，下面开始介绍今天的重点内容，FewShotPromptTemplate。FewShot，也就是少样本这一概念，是提示工程中非常重要的部分，对应着OpenAI提示工程指南中的第2条——给模型提供参考（也就是示例）。\n\n## FewShot的思想起源\n\n讲解概念之前，我先分享个事儿哈，帮助你理解。\n\n今天我下楼跑步时，一个老爷爷教孙子学骑车，小孩总掌握不了平衡，蹬一两下就下车。\n\n- 爷爷说：“宝贝，你得有毅力！”\n- 孙子说：“爷爷，什么是毅力？”\n- 爷爷说：“你看这个叔叔，绕着楼跑了10多圈了，这就是毅力，你也得至少蹬个10几趟才能骑起来。”\n\n这老爷爷就是给孙子做了一个One-Shot学习。如果他的孙子第一次听说却上来就明白什么是毅力，那就神了，这就叫Zero-Shot，表明这孩子的语言天赋不是一般的高，从知识积累和当前语境中就能够推知新词的涵义。有时候我们把Zero-Shot翻译为“顿悟”，聪明的大模型，某些情况下也是能够做到的。\n\nFew-Shot（少样本）、One-Shot（单样本）和与之对应的 Zero-Shot（零样本）的概念都起源于机器学习。如何让机器学习模型在极少量甚至没有示例的情况下学习到新的概念或类别，对于许多现实世界的问题是非常有价值的，因为我们往往无法获取到大量的标签化数据。\n\n这几个重要概念并非在某一篇特定的论文中首次提出，而是在机器学习和深度学习的研究中逐渐形成和发展的。\n\n- 对于Few-Shot Learning，一个重要的参考文献是2016年Vinyals, O.的论文《小样本学习的匹配网络》。\n- 这篇论文提出了一种新的学习模型——匹配网络（Matching Networks），专门针对单样本学习（One-Shot Learning）问题设计， **而** **One-Shot Learning** **可以看作是一种最常见的** **Few-Shot** **学习的情况。**\n- 对于Zero-Shot Learning，一个代表性的参考文献是Palatucci, M.在2009年提出的《基于语义输出编码的零样本学习（Zero-Shot Learning with semantic output codes）》，这篇论文提出了零次学习（Zero-Shot Learning）的概念，其中的学习系统可以根据类的语义描述来识别之前未见过的类。\n\n在提示工程（Prompt Engineering）中，Few-Shot 和 Zero-Shot 学习的概念也被广泛应用。\n\n- 在Few-Shot学习设置中，模型会被给予几个示例，以帮助模型理解任务，并生成正确的响应。\n- 在Zero-Shot学习设置中，模型只根据任务的描述生成响应，不需要任何示例。\n\n而OpenAI在介绍GPT-3模型的重要论文《Language models are Few-Shot learners（语言模型是少样本学习者）》中，更是直接指出：GPT-3模型，作为一个大型的自我监督学习模型，通过提升模型规模，实现了出色的Few-Shot学习性能。\n\n这篇论文为大语言模型可以进行Few-Shot学习提供了扎实的理论基础。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/481yy45346cc28ec48269c752c3647bc.png)\n\n下图就是OpenAI的GPT-3论文给出的GPT-3在翻译任务中，通过FewShot提示完成翻译的例子。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/357e9ca0ce2b4699a24e3fe512c047ca.png)\n\n以上，就是ZeroShot、OneShot、FewShot这些重要概念的起源。\n\n## 使用 FewShotPromptTemplate\n\n下面，就让我们来通过LangChain中的FewShotPromptTemplate构建出最合适的鲜花文案。\n\n**1\\. 创建示例样本**\n\n首先，创建一些示例，作为提示的样本。其中每个示例都是一个字典，其中键是输入变量，值是这些输入变量的值。\n\n```plain\n# 1. 创建一些示例\nsamples = [\n  {\n    \"flower_type\": \"玫瑰\",\n    \"occasion\": \"爱情\",\n    \"ad_copy\": \"玫瑰，浪漫的象征，是你向心爱的人表达爱意的最佳选择。\"\n  },\n  {\n    \"flower_type\": \"康乃馨\",\n    \"occasion\": \"母亲节\",\n    \"ad_copy\": \"康乃馨代表着母爱的纯洁与伟大，是母亲节赠送给母亲的完美礼物。\"\n  },\n  {\n    \"flower_type\": \"百合\",\n    \"occasion\": \"庆祝\",\n    \"ad_copy\": \"百合象征着纯洁与高雅，是你庆祝特殊时刻的理想选择。\"\n  },\n  {\n    \"flower_type\": \"向日葵\",\n    \"occasion\": \"鼓励\",\n    \"ad_copy\": \"向日葵象征着坚韧和乐观，是你鼓励亲朋好友的最好方式。\"\n  }\n]\n\n```\n\nsamples这个列表，它包含了四个字典，每个字典代表了一种花的类型、适合的场合，以及对应的广告文案。 这些示例样本，就是构建FewShotPrompt时，作为例子传递给模型的参考信息。\n\n**2\\. 创建提示模板**\n\n配置一个提示模板，将一个示例格式化为字符串。这个格式化程序应该是一个PromptTemplate对象。\n\n```plain\n# 2. 创建一个提示模板\nfrom langchain.prompts.prompt import PromptTemplate\ntemplate=\"鲜花类型: {flower_type}\\n场合: {occasion}\\n文案: {ad_copy}\"\nprompt_sample = PromptTemplate(input_variables=[\"flower_type\", \"occasion\", \"ad_copy\"],\n                               template=template)\nprint(prompt_sample.format(**samples[0]))\n\n```\n\n提示模板的输出如下：\n\n```plain\n鲜花类型: 玫瑰\n场合: 爱情\n文案: 玫瑰，浪漫的象征，是你向心爱的人表达爱意的最佳选择。\n\n```\n\n在这个步骤中，我们创建了一个PromptTemplate对象。这个对象是根据指定的输入变量和模板字符串来生成提示的。在这里，输入变量包括 `\"flower_type\"`、 `\"occasion\"`、 `\"ad_copy\"`，模板是一个字符串，其中包含了用大括号包围的变量名，它们会被对应的变量值替换。\n\n到这里，我们就把字典中的示例格式转换成了提示模板，可以形成一个个具体可用的LangChain提示。比如我用samples\\[0\\]中的数据替换了模板中的变量，生成了一个完整的提示。\n\n**3\\. 创建 FewShotPromptTemplate 对象**\n\n然后，通过使用上一步骤中创建的prompt\\_sample，以及samples列表中的所有示例， 创建一个FewShotPromptTemplate对象，生成更复杂的提示。\n\n```plain\n# 3. 创建一个FewShotPromptTemplate对象\nfrom langchain.prompts.few_shot import FewShotPromptTemplate\nprompt = FewShotPromptTemplate(\n    examples=samples,\n    example_prompt=prompt_sample,\n    suffix=\"鲜花类型: {flower_type}\\n场合: {occasion}\",\n    input_variables=[\"flower_type\", \"occasion\"]\n)\nprint(prompt.format(flower_type=\"野玫瑰\", occasion=\"爱情\"))\n\n```\n\n输出：\n\n```plain\n鲜花类型: 玫瑰\n场合: 爱情\n文案: 玫瑰，浪漫的象征，是你向心爱的人表达爱意的最佳选择。\n\n鲜花类型: 康乃馨\n场合: 母亲节\n文案: 康乃馨代表着母爱的纯洁与伟大，是母亲节赠送给母亲的完美礼物。\n\n鲜花类型: 百合\n场合: 庆祝\n文案: 百合象征着纯洁与高雅，是你庆祝特殊时刻的理想选择。\n\n鲜花类型: 向日葵\n场合: 鼓励\n文案: 向日葵象征着坚韧和乐观，是你鼓励亲朋好友的最好方式。\n\n鲜花类型: 野玫瑰\n场合: 爱情\n\n```\n\n可以看到，FewShotPromptTemplate是一个更复杂的提示模板，它包含了多个示例和一个提示。这种模板可以使用多个示例来指导模型生成对应的输出。目前我们创建一个新提示，其中包含了根据指定的花的类型“野玫瑰”和场合“爱情”。\n\n**4\\. 调用大模型创建新文案**\n\n最后，把这个对象输出给大模型，就可以根据提示，得到我们所需要的文案了！\n\n```plain\n# 4. 把提示传递给大模型\nimport os\nos.environ[\"OPENAI_API_KEY\"] = '你的Open AI Key'\nfrom langchain.llms import OpenAI\nmodel = OpenAI(model_name='text-davinci-003')\nresult = model(prompt.format(flower_type=\"野玫瑰\", occasion=\"爱情\"))\nprint(result)\n\n```\n\n输出：\n\n```plain\n文案: 野玫瑰代表着爱情的坚贞，是你向心爱的人表达爱意的最佳礼物。\n\n```\n\n好！模型成功地模仿了我们的示例，写出了新文案，从结构到语气都蛮相似的。\n\n## 使用示例选择器\n\n如果我们的示例很多，那么一次性把所有示例发送给模型是不现实而且低效的。另外，每次都包含太多的Token也会浪费流量（OpenAI是按照Token数来收取费用）。\n\nLangChain给我们提供了示例选择器，来选择最合适的样本。（注意，因为示例选择器使用向量相似度比较的功能，此处需要安装向量数据库，这里我使用的是开源的Chroma，你也可以选择之前用过的Qdrant。）\n\n下面，就是使用示例选择器的示例代码。\n\n```plain\n# 5. 使用示例选择器\nfrom langchain.prompts.example_selector import SemanticSimilarityExampleSelector\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings import OpenAIEmbeddings\n\n# 初始化示例选择器\nexample_selector = SemanticSimilarityExampleSelector.from_examples(\n    samples,\n    OpenAIEmbeddings(),\n    Chroma,\n    k=1\n)\n\n# 创建一个使用示例选择器的FewShotPromptTemplate对象\nprompt = FewShotPromptTemplate(\n    example_selector=example_selector,\n    example_prompt=prompt_sample,\n    suffix=\"鲜花类型: {flower_type}\\n场合: {occasion}\",\n    input_variables=[\"flower_type\", \"occasion\"]\n)\nprint(prompt.format(flower_type=\"红玫瑰\", occasion=\"爱情\"))\n\n```\n\n输出：\n\n```plain\n鲜花类型: 玫瑰\n场合: 爱情\n文案: 玫瑰，浪漫的象征，是你向心爱的人表达爱意的最佳选择。\n\n鲜花类型: 红玫瑰\n场合: 爱情\n\n```\n\n在这个步骤中，它首先创建了一个SemanticSimilarityExampleSelector对象，这个对象可以根据语义相似性选择最相关的示例。然后，它创建了一个新的FewShotPromptTemplate对象，这个对象使用了上一步创建的选择器来选择最相关的示例生成提示。\n\n然后，我们又用这个模板生成了一个新的提示，因为我们的提示中需要创建的是红玫瑰的文案，所以，示例选择器example\\_selector会根据语义的相似度（余弦相似度）找到最相似的示例，也就是“玫瑰”，并用这个示例构建了FewShot模板。\n\n这样，我们就避免了把过多的无关模板传递给大模型，以节省Token的用量。\n\n## 总结时刻\n\n好的，到这里，今天这一讲就结束了。我们介绍了提示工程的原理，几种提示模板的用法，以及最重要的FewShot的思路。其实说白了，就是给模型一些示例做参考，模型才能明白你要什么。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/f46817a7ed56c6fef64a6aeee4c1yy0d.png)\n\n总的来说，提供示例对于解决某些任务至关重要，通常情况下，FewShot的方式能够显著提高模型回答的质量。不过，当少样本提示的效果不佳时，这可能表示模型在任务上的学习不足。在这种情况下，我们建议对模型进行微调或尝试更高级的提示技术。\n\n下一节课，我们将在探讨输出解析的同时，讲解另一种备受关注的提示技术，被称为“思维链提示”（Chain of Thought，简称CoT）。这种技术因其独特的应用方式和潜在的实用价值而引人注目。\n\n## 思考题\n\n1. 如果你观察LangChain中的prompt.py中的PromptTemplate的实现代码，你会发现除了我们使用过的input\\_variables、template等初始化参数之外，还有template\\_format、validate\\_template等参数。举例来说，template\\_format可以指定除了f-string之外，其它格式的模板，比如jinja2。请你查看LangChain文档，并尝试使用这些参数。\n\n```plain\ntemplate_format: str = \"f-string\"\n\"\"\"The format of the prompt template. Options are: 'f-string', 'jinja2'.\"\"\"\n\nvalidate_template: bool = True\n\"\"\"Whether or not to try validating the template.\"\"\"\n\n```\n\n1. 请你尝试使用PipelinePromptTemplate和自定义Template。\n\n2. 请你构想一个关于鲜花店运营场景中客户服务对话的少样本学习任务。在这个任务中，模型需要根据提供的示例，学习如何解答客户的各种问题，包括询问花的价格、推荐鲜花、了解鲜花的保养方法等。最好是用ChatModel完成这个任务。\n\n```plain\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain import PromptTemplate\nfrom langchain.prompts.chat import (\n    ChatPromptTemplate,\n    SystemMessagePromptTemplate,\n    AIMessagePromptTemplate,\n    HumanMessagePromptTemplate)\n\n```\n\n题目较多，可以选择性思考，期待在留言区看到你的分享。如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。\n\n## 延伸阅读\n\n1. 论文： Open AI的GPT-3模型： [大模型是少样本学习者](https://proceedings.neurips.cc/paper_files/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html)， Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., … & Agarwal, S. (2020). Language models are few-shot learners. arXiv preprint arXiv:2005.14165.\n2. 论文： [单样本学习的匹配网络](https://arxiv.org/abs/1606.04080)，Vinyals, O., Blundell, C., Lillicrap, T., & Wierstra, D. (2016). Matching networks for one shot learning. In Advances in neural information processing systems (pp. 3630-3638).\n3. 论文： [用语义输出编码做零样本学习](https://www.cs.toronto.edu/~hinton/absps/palatucci.pdf)，Palatucci, M., Pomerleau, D., Hinton, G. E., & Mitchell, T. M. (2009). Zero-shot learning with semantic output codes. In Advances in neural information processing systems (pp. 1410-1418).\n4. 论文： [对示例角色的重新思考：是什么使得上下文学习有效？](https://doi.org/10.48550/arXiv.2202.12837) Min, S., Lyu, X., Holtzman, A., Artetxe, M., Lewis, M., Hajishirzi, H., & Zettlemoyer, L. (2022). Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP 2022).\n5. 论文： [微调后的语言模型是零样本学习者](https://arxiv.org/pdf/2109.01652.pdf)，Wei, J., Bosma, M., Zhao, V. Y., Guu, K., Yu, A. W., Lester, B., Du, N., Dai, A. M., & Le, Q. V. (2022). Finetuned Language Models Are Zero-Shot Learners. Proceedings of the International Conference on Learning Representations (ICLR 2022)."},{"url":"/posts/3.html","content":"# 05｜提示工程（下）：用思维链和思维树提升模型思考质量\n你好，我是黄佳，欢迎来到LangChain实战课！\n\n我在 [第4课](https://time.geekbang.org/column/article/700699) 的结尾时说了，你可以尝试用思维链也就是CoT（Chain of Thought）的概念来引导模型的推理，让模型生成更详实、更完备的文案，今天我们就一起看一看CoT的使用。\n\n## 什么是 Chain of Thought\n\nCoT这个概念来源于学术界，是谷歌大脑的Jason Wei等人于2022年在论文《 [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf)（自我一致性提升了语言模型中的思维链推理能力）》中提出来的概念。它提出，如果生成一系列的中间推理步骤，就能够显著提高大型语言模型进行复杂推理的能力。\n\n### Few-Shot CoT\n\nFew-Shot CoT 简单的在提示中提供了一些链式思考示例（Chain-of-Thought Prompting），足够大的语言模型的推理能力就能够被增强。简单说，就是给出一两个示例，然后在示例中写清楚推导的过程。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/f27cec109dff8947d85507b34ce240a0.png)\n\n论文中给出了一个大模型通过思维链做数学题的示例。图左和图右，大模型都读入了OneShot示例，但是图左只给出了答案，而图右则在OneShot示例中给出了解题的具体思路。结果，只给出了答案的模型推理错误，而给出解题思路后，同一个模型生成了正确的答案。\n\n在三种大型语言模型的实验中，CoT在一系列的算术、常识和符号推理任务中都提高了性能。在GSM8K数学问题基准测试中，通过CoT指导后，大模型的表现可以达到当时最先进的准确性。\n\nCoT从概念上非常容易理解，从应用上非常容易操作。虽然简单，但这种思想可以给我们的开发过程带来很多启发。\n\n比如，假设我们正在开发一个AI花店助手，它的任务是帮助用户选择他们想要的花，并生成一个销售列表。在这个过程中，我们可以使用CoT来引导AI的推理过程。\n\n👉 整体指导：你需要跟着下面的步骤一步步的推理。\n\n1. 问题理解：首先，AI需要理解用户的需求。例如，用户可能会说：“今天要参加朋友的生日Party，想送束花祝福她。”我们可以给AI一个提示模板，里面包含示例：“ _**遇到XX问题，我先看自己有**_ _**没有**_ _**相关知识，有的话，就提供答案；没有，就调用工具搜索，有了知识后再试图解决。**_”—— 这就是给了AI一个思维链的示例。\n\n2. 信息搜索：接下来，AI需要搜索相关信息。例如，它可能需要查找哪些花最适合生日派对。\n\n3. 决策制定：基于收集到的信息，AI需要制定一个决策。我们可以通过思维链让他详细思考决策的流程，先做什么后做什么。例如，我们可以给它一个示例：“ _**遇到生日派对送花的情况，我先考虑用户的需求，然后查看鲜花的库存，最后决定推荐一些玫瑰和百合，因为这些花通常适合生日派对。**_”—— 那么有了生日派对这个场景做示例，大模型就能把类似的思维流程运用到其它场景。\n\n4. 生成销售列表：最后，AI使用OutputParser生成一个销售列表，包括推荐的花和价格。\n\n在这个过程中，整体上，思维链引导AI从理解问题，到搜索信息，再到制定决策，最后生成销售列表。这种方法不仅使AI的推理过程更加清晰，也使得生成的销售列表更加符合用户的需求。具体到每一个步骤，也可以通过思维链来设计更为详细的提示模板，来引导模型每一步的思考都遵循清晰准确的逻辑。\n\n其实LangChain的核心组件Agent的本质就是进行好的提示工程，并大量地使用预置的FewShot和CoT模板。这个在之后的课程学习中我们会理解得越来越透彻。\n\n### Zero-Shot CoT\n\n下面的这两个CoT提示模板的例子，来自于Google Research和东京大学的论文《 [大语言模型是零样本推理者](https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf)》。\n\n图中的（d）示例非常非常有意思，在Zero-Shot CoT中，你只要简单地告诉模型“ **让我们一步步的思考（Let’s think step by step）**”，模型就能够给出更好的答案！\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/09a48be47b3e0e9ec0ae7ebd483d868b.png)\n\n哈哈哈，这样太神奇了吧，这不由得让我联想起最简单的提示工程，角色设定——模型回答之前，先告诉它“你是一个很有经验的XX专家”，模型应该就会在开始胡说八道之前三思。\n\n简单总结一下：Few-Shot CoT，指的就是在带有示例的提示过程中，加入思考的步骤，从而引导模型给出更好的结果。而Zero-Shot CoT，就是直接告诉模型要一步一步地思考，慢慢地推理。\n\n## Chain of Thought 实战\n\n现在，就让我带着你完成一次Chain of Thought的LangChain应用开发实战。\n\n**项目需求**：在这个示例中，你正在开发一个AI运营助手，我们要展示AI如何根据用户的需求推理和生成答案。然后，AI根据当前的用户请求进行推理，提供了具体的花卉建议并解释了为什么选择这些建议。\n\n在这个过程中，AI需要理解客户的需求之后，按部就班的思考，然后给出最符合逻辑的回答。\n\n### CoT的模板设计\n\n针对这个聊天机器人的需求，我设计了下面这样的思维链模板。\n\n> 作为一个为花店电商公司工作的AI助手，我的目标是帮助客户根据他们的喜好做出明智的决定。\n>\n> 我会按部就班的思考，先理解客户的需求，然后考虑各种鲜花的涵义，最后根据这个需求，给出我的推荐。\n>\n> 同时，我也会向客户解释我这样推荐的原因。\n>\n> **示例 1：**\n>\n> 人类：我想找一种象征爱情的花。\n>\n> AI：首先，我理解你正在寻找一种可以象征爱情的花。在许多文化中，红玫瑰被视为爱情的象征，这是因为它们的红色通常与热情和浓烈的感情联系在一起。因此，考虑到这一点，我会推荐红玫瑰。红玫瑰不仅能够象征爱情，同时也可以传达出强烈的感情，这是你在寻找的。\n>\n> **示例 2：**\n>\n> 人类：我想要一些独特和奇特的花。\n>\n> AI：从你的需求中，我理解你想要的是独一无二和引人注目的花朵。兰花是一种非常独特并且颜色鲜艳的花，它们在世界上的许多地方都被视为奢侈品和美的象征。因此，我建议你考虑兰花。选择兰花可以满足你对独特和奇特的要求，而且，兰花的美丽和它们所代表的力量和奢侈也可能会吸引你。\n\nAI的模板开始于对其角色的阐述，并给出了一些先前的对话示例（Few-Shot Learning）来帮助AI理解如何处理这种类型的请求。这些示例展示了AI如何根据思维链进行思考，给出深思熟虑之后的答案。\n\n### 程序的完整框架\n\n程序的完整代码如下：\n\n```plain\n# 设置环境变量和API密钥\nimport os\nos.environ[\"OPENAI_API_KEY\"] = '你的OpenAI API Key'\n\n# 创建聊天模型\nfrom langchain.chat_models import ChatOpenAI\nllm = ChatOpenAI(temperature=0)\n\n# 设定 AI 的角色和目标\nrole_template = \"你是一个为花店电商公司工作的AI助手, 你的目标是帮助客户根据他们的喜好做出明智的决定\"\n\n# CoT 的关键部分，AI 解释推理过程，并加入一些先前的对话示例（Few-Shot Learning）\ncot_template = \"\"\"\n作为一个为花店电商公司工作的AI助手，我的目标是帮助客户根据他们的喜好做出明智的决定。\n\n我会按部就班的思考，先理解客户的需求，然后考虑各种鲜花的涵义，最后根据这个需求，给出我的推荐。\n同时，我也会向客户解释我这样推荐的原因。\n\n示例 1:\n  人类：我想找一种象征爱情的花。\n  AI：首先，我理解你正在寻找一种可以象征爱情的花。在许多文化中，红玫瑰被视为爱情的象征，这是因为它们的红色通常与热情和浓烈的感情联系在一起。因此，考虑到这一点，我会推荐红玫瑰。红玫瑰不仅能够象征爱情，同时也可以传达出强烈的感情，这是你在寻找的。\n\n示例 2:\n  人类：我想要一些独特和奇特的花。\n  AI：从你的需求中，我理解你想要的是独一无二和引人注目的花朵。兰花是一种非常独特并且颜色鲜艳的花，它们在世界上的许多地方都被视为奢侈品和美的象征。因此，我建议你考虑兰花。选择兰花可以满足你对独特和奇特的要求，而且，兰花的美丽和它们所代表的力量和奢侈也可能会吸引你。\n\"\"\"\nfrom langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\nsystem_prompt_role = SystemMessagePromptTemplate.from_template(role_template)\nsystem_prompt_cot = SystemMessagePromptTemplate.from_template(cot_template)\n\n# 用户的询问\nhuman_template = \"{human_input}\"\nhuman_prompt = HumanMessagePromptTemplate.from_template(human_template)\n\n# 将以上所有信息结合为一个聊天提示\nchat_prompt = ChatPromptTemplate.from_messages([system_prompt_role, system_prompt_cot, human_prompt])\n\nprompt = chat_prompt.format_prompt(human_input=\"我想为我的女朋友购买一些花。她喜欢粉色和紫色。你有什么建议吗?\").to_messages()\n\n# 接收用户的询问，返回回答结果\nresponse = llm(prompt)\nprint(response)\n\n```\n\n程序中，首先设置环境变量OpenAI的API密钥，以便能够使用OpenAI的GPT-4模型。然后创建聊天模型：通过调用 ChatOpenAI 类，创建了一个聊天模型。设置 temperature=0 可以让模型生成更确定性的回答，即输出更倾向于最可能的结果。\n\n接着定义了AI的角色和目标，该AI为花店电商公司的助手，其目标是根据客户的喜好来提供购买建议。紧接着，定义 CoT 模板，其中包括了AI的角色和目标描述、思考链条以及遵循思考链条的一些示例，显示了AI如何理解问题，并给出建议。\n\n之后，我使用了PromptTemplate的from\\_template方法，来生成相应的询问模板。其中包括用于指导模型的SystemMessagePromptTemplate和用于传递人类问题的HumanMessagePromptTemplate。\n\n然后，我使用了ChatPromptTemplate.from\\_messages方法，整合上述定义的角色，CoT模板和用户询问，生成聊天提示。\n\n最后，将生成的聊天提示输入模型中，获得模型的回答，并打印出来。\n\n在Few-Shot CoT提示的指引之下，模型针对我们的问题，从问题中的具体需求出发，返回了不错的建议。\n\n_**现在，根据你的需求：你正在寻找你的女朋友喜欢的粉色和紫色的花。**_\n\n_**首先，我从理解你的需求出发，只会推荐粉色或紫色，或者两者的组合的花。这些可能包括粉色的玫瑰，紫色的兰花，或者是粉色和紫色的花的混合花束。玫瑰是象征爱情和亲情的经典符号，而兰花象征着美丽和力量。这两种花都蕴含很棒的内涵。当然了，无论你选择哪种花卉，重要的是表达出你对她的爱和关心。记得附上一张温馨的贺卡，写下你的真挚祝福。**_\n\n## Tree of Thought\n\nCoT这种思想，为大模型带来了更好的答案，然而，对于需要探索或预判战略的复杂任务来说，传统或简单的提示技巧是不够的。基于CoT的思想，Yao和Long等人几乎在同一时间在论文《 [思维之树：使用大型语言模型进行深思熟虑的问题解决](https://arxiv.org/pdf/2305.10601.pdf)》和《 [大型语言模型指导的思维之树](https://arxiv.org/pdf/2305.08291.pdf)》中，进一步提出了思维树（Tree of Thoughts，ToT）框架，该框架基于思维链提示进行了总结，引导语言模型探索把思维作为中间步骤来解决通用问题。\n\nToT是一种解决复杂问题的框架，它在需要多步骤推理的任务中，引导语言模型搜索一棵由连贯的语言序列（解决问题的中间步骤）组成的思维树，而不是简单地生成一个答案。ToT框架的核心思想是：让模型生成和评估其思维的能力，并将其与搜索算法（如广度优先搜索和深度优先搜索）结合起来，进行系统性地探索和验证。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/6eec83ffe1a5f37d245520535d65f8a0.png)\n\nToT 框架为每个任务定义具体的思维步骤和每个步骤的候选项数量。例如，要解决一个数学推理任务，先把它分解为3个思维步骤，并为每个步骤提出多个方案，并保留最优的5个候选方案。然后在多条思维路径中搜寻最优的解决方案。\n\n这种方法的优势在于，模型可以通过观察和评估其自身的思维过程，更好地解决问题，而不仅仅是基于输入生成输出。这对于需要深度推理的复杂任务非常有用。此外，通过引入强化学习、集束搜索等技术，可以进一步提高搜索策略的性能，并让模型在解决新问题或面临未知情况时有更好的表现。\n\n下面我们应用ToT的思想，给出一个鲜花运营方面的示例。\n\n> 假设一个顾客在鲜花网站上询问：“我想为我的妻子购买一束鲜花，但我不确定应该选择哪种鲜花。她喜欢淡雅的颜色和花香。”\n>\n> AI（使用ToT框架）：\n>\n> **思维步骤1**：理解顾客的需求。\n>\n> 顾客想为妻子购买鲜花。\n>\n> 顾客的妻子喜欢淡雅的颜色和花香。\n>\n> **思维步骤2**：考虑可能的鲜花选择。\n>\n> 候选1：百合，因为它有淡雅的颜色和花香。\n>\n> 候选2：玫瑰，选择淡粉色或白色，它们通常有花香。\n>\n> 候选3：紫罗兰，它有淡雅的颜色和花香。\n>\n> 候选4：桔梗，它的颜色淡雅但不一定有花香。\n>\n> 候选5：康乃馨，选择淡色系列，它们有淡雅的花香。\n>\n> **思维步骤3**：根据顾客的需求筛选最佳选择。\n>\n> 百合和紫罗兰都符合顾客的需求，因为它们都有淡雅的颜色和花香。\n>\n> 淡粉色或白色的玫瑰也是一个不错的选择。\n>\n> 桔梗可能不是最佳选择，因为它可能没有花香。\n>\n> 康乃馨是一个可考虑的选择。\n>\n> **思维步骤4**：给出建议。\n>\n> “考虑到您妻子喜欢淡雅的颜色和花香，我建议您可以选择百合或紫罗兰。淡粉色或白色的玫瑰也是一个很好的选择。希望这些建议能帮助您做出决策！”\n\n这个例子，可以作为FewShot示例之一，传递给模型，让他学着实现ToT。\n\n通过在具体的步骤中产生多条思考路径，ToT 框架为解决复杂问题提供了一种新的方法，这种方法结合了语言模型的生成能力、搜索算法以及强化学习，以达到更好的效果。\n\n## 总结时刻\n\n这节课我们介绍了Chain of Thought（CoT，即“思维链”）和Tree of Thoughts（ToT，即“思维树”）这两个非常有趣的概念，并探讨了如何利用它们引导大型语言模型进行更深入的推理。\n\n- CoT的核心思想是通过生成一系列中间推理步骤来增强模型的推理能力。在Few-Shot CoT和Zero-Shot CoT两种应用方法中，前者通过提供链式思考示例传递给模型，后者则直接告诉模型进行要按部就班的推理。\n- ToT进一步扩展了CoT的思想，通过搜索由连贯的语言序列组成的思维树来解决复杂问题。我通过一个鲜花选择的实例，展示了如何在实际应用中使用ToT框架。\n\n\n  有朋友在GitHub上开了一个 [Repo](https://github.com/kyegomez/tree-of-thoughts)，专门给大家介绍ToT的应用方法和实例，他们还给出了几个非常简单的通用ToT提示语，就像下面这样。\n\n> 请你模拟三位出色、逻辑性强的专家合作回答一个问题。每个人都详细地解释他们的思考过程，考虑到其他人之前的解释，并公开承认错误。在每一步，只要可能，每位专家都会在其他人的思考基础上进行完善和建设，并承认他们的贡献。他们继续，直到对问题有一个明确的答案。为了清晰起见，您的整个回应应该是一个Markdown表格。\n>\n> 问题是…\n\n![图片](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/d719e10a2b045f5a70993b6135ef503c.png)\n\n如果你有兴趣，可以去这个Repo里面看一看。\n\n## 思考题\n\n1. 我们的CoT实战示例中使用的是Few-Shot CoT提示，请你把它换为Zero-Shot CoT，跑一下程序，看看结果。\n2. 请你设计一个你工作场景中的任务需求，然后用ToT让大语言模型帮你解决问题。\n\n期待在留言区看到你的分享，我们一起交流探讨，共创一个好的学习氛围。如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。\n\n## 延伸阅读\n\n1. 论文，自我一致性提升了语言模型中的思维链推理能力， [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/pdf/2205.11916.pdf)，Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A., & Zhou, D. (2023). Self-Consistency Improves Chain of Thought Reasoning in Language Models. Proceedings of the International Conference on Learning Representations (ICLR). arXiv preprint arXiv:2203.11171.\n2. 论文，大语言模型是零样本推理者， [Large Language Models are Zero-Shot Reasoners](https://proceedings.neurips.cc/paper_files/paper/2022/file/8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf)，Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. (2023). Large Language Models are Zero-Shot Reasoners. arXiv preprint arXiv:2205.11916v4.\n3. 论文，思维之树：使用大型语言模型进行深思熟虑的问题解决， [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601)，Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T. L., Cao, Y., & Narasimhan, K. (2023). Tree of Thoughts: Deliberate Problem Solving with Large Language Models. arXiv preprint arXiv:2305.10601.\n4. 论文，大型语言模型指导的思维之树， [Large Language Model Guided Tree-of-Thought](https://arxiv.org/abs/2305.08291)，Long, J. (2023). Large Language Model Guided Tree-of-Thought. arXiv preprint arXiv:2305.08291.\n5. GitHub链接， [tree-of-thoughts](https://github.com/kyegomez/tree-of-thoughts)，把ToT算法导入你的大模型应用，目前3.3K颗星"},{"url":"/posts/4.html","content":"# 06｜调用模型：使用OpenAI API还是微调开源Llama2/ChatGLM？\n你好，我是黄佳，欢迎来到LangChain实战课！\n\n之前，我们花了两节课的内容讲透了提示工程的原理以及LangChain中的具体使用方式。今天，我们来着重讨论Model I/O中的第二个子模块，LLM。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/cd7e1506af5b6a8e382c2c9eab4d7481.jpg)\n\n让我们带着下面的问题来开始这一节课的学习。大语言模型，不止ChatGPT一种。调用OpenAI的API，当然方便且高效，不过，如果我就是想用其他的模型（比如说开源的Llama2或者ChatGLM），该怎么做？再进一步，如果我就是想在本机上从头训练出来一个新模型，然后在LangChain中使用自己的模型，又该怎么做？\n\n关于大模型的微调（或称精调）、预训练、重新训练、乃至从头训练，这是一个相当大的话题，不仅仅需要足够的知识和经验，还需要大量的语料数据、GPU硬件和强大的工程能力。别说一节课了，我想两三个专栏也不一定能讲全讲透。不过，我可以提纲挈领地把大模型的训练流程和使用方法给你缕一缕。这样你就能体验到，在LangChain中使用自己微调的模型是完全没问题的。\n\n## 大语言模型发展史\n\n说到语言模型，我们不妨先从其发展史中去了解一些关键信息。\n\nGoogle 2018 年的论文名篇Attention is all you need，提出了Transformer架构，也给这一次AI的腾飞点了火。Transformer是几乎所有预训练模型的核心底层架构。基于Transformer预训练所得的大规模语言模型也被叫做“基础模型”（Foundation Model 或Base Model）。\n\n在这个过程中，模型学习了词汇、语法、句子结构以及上下文信息等丰富的语言知识。这种在大量数据上学到的知识，为后续的下游任务（如情感分析、文本分类、命名实体识别、问答系统等）提供了一个通用的、丰富的语言表示基础，为解决许多复杂的NLP问题提供了可能。\n\n在预训练模型出现的早期，BERT毫无疑问是最具代表性的，也是影响力最大的模型。BERT通过同时学习文本的前向和后向上下文信息，实现对句子结构的深入理解。BERT之后，各种大型预训练模型如雨后春笋般地涌现，自然语言处理（NLP）领域进入了一个新时代。这些模型推动了NLP技术的快速发展，解决了许多以前难以应对的问题，比如翻译、文本总结、聊天对话等等，提供了强大的工具。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/7f1108deceaa4b5281ed431598f1b0a6.jpg)\n\n当然，现今的预训练模型的趋势是参数越来越多，模型也越来越大，训练一次的费用可达几百万美元。这样大的开销和资源的耗费，只有世界顶级大厂才能够负担得起，普通的学术组织和高等院校很难在这个领域继续引领科技突破，这种现象开始被普通研究人员所诟病。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/95828d4e2234e7130bb2d500455092ef.jpg)\n\n## 预训练+微调的模式\n\n不过，话虽如此，大型预训练模型的确是工程师的福音。因为，经过预训练的大模型中所习得的语义信息和所蕴含的语言知识，能够非常容易地向下游任务迁移。NLP应用人员可以对模型的头部或者部分参数根据自己的需要进行适应性的调整，这通常涉及在相对较小的有标注数据集上进行有监督学习，让模型适应特定任务的需求。\n\n这就是对预训练模型的微调（Fine-tuning）。微调过程相比于从头训练一个模型要快得多，且需要的数据量也要少得多，这使得作为工程师的我们能够更高效地开发和部署各种NLP解决方案。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/75edd66d67ec8a20326b69514c9d9daf.jpg)\n\n图中的“具体任务”，其实也可以更换为“具体领域”。那么总结来说：\n\n- **预训练**：在大规模无标注文本数据上进行模型的训练，目标是让模型学习自然语言的基础表达、上下文信息和语义知识，为后续任务提供一个通用的、丰富的语言表示基础。\n- **微调**：在预训练模型的基础上，可以根据特定的下游任务对模型进行微调。现在你经常会听到各行各业的人说： _我们的优势就是领域知识嘛！我们比不过国内外大模型，我们可以拿开源模型做垂直领域嘛！做垂类模型！_—— 啥叫垂类？指的其实就是根据领域数据微调开源模型这件事儿。\n\n这种预训练+微调的大模型应用模式优势明显。首先，预训练模型能够将大量的通用语言知识迁移到各种下游任务上，作为应用人员，我们不需要自己寻找语料库，从头开始训练大模型，这减少了训练时间和数据需求；其次，微调过程可以快速地根据特定任务进行优化，简化了模型部署的难度；最后，预训练+微调的架构具有很强的可扩展性，可以方便地应用于各种自然语言处理任务，大大提高了NLP技术在实际应用中的可用性和普及程度，给我们带来了巨大的便利。\n\n好，下面咱们开始一步步地使用开源模型。今天我要带你玩的模型主要是Meta（Facebook）推出的Llama2。当然你可以去Llama的官网下载模型，然后通过Llama官方 [GitHub](https://github.com/facebookresearch/llama) 中提供的方法来调用它。但是，我还是会推荐你从HuggingFace下载并导入模型。因为啊，前天百川，昨天千问，今天流行Llama，明天不就流行别的了嘛。模型总在变，但是HuggingFace一直在那里，支持着各种开源模型。我们学东西，尽量选择学一次能够复用的知识。\n\n## 用 HuggingFace 跑开源模型\n\n### 注册并安装 HuggingFace\n\n第一步，还是要登录 [HuggingFace](https://huggingface.co/) 网站，并拿到专属于你的Token。（如果你做了前面几节课的实战案例，那么你应该已经有这个API Token了）\n\n第二步，用 `pip install transformers` 安装HuggingFace Library。详见 [这里](https://huggingface.co/docs/transformers/installation)。\n\n第三步，在命令行中运行 `huggingface-cli login`，设置你的API Token。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/5fa0c088652c8776f5ec50a059b1b1e6.png)\n\n当然，也可以在程序中设置你的API Token，但是这不如在命令行中设置来得安全。\n\n```plain\n# 导入HuggingFace API Token\nimport os\nos.environ['HUGGINGFACEHUB_API_TOKEN'] = '你的HuggingFace API Token'\n\n```\n\n### 申请使用 Meta 的 Llama2 模型\n\n在HuggingFace的Model中，找到 [meta-llama/Llama-2-7b](https://huggingface.co/meta-llama/Llama-2-7b)。注意，各种各样版本的Llama2模型多如牛毛，我们这里用的是最小的7B版。此外，还有13b\\\\70b\\\\chat版以及各种各样的非Meta官方版。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/88a4b8d60cc93e77c3573663aa096217.png)\n\n选择meta-llama/Llama-2-7b这个模型后，你能够看到这个模型的基本信息。如果你是第一次用Llama，你需要申请Access，因为我已经申请过了，所以屏幕中间有句话：“You have been granted access to this model”。从申请到批准，大概是几分钟的事儿。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/46c59c59545720ccff6d7c560792d4ce.png)\n\n### 通过 HuggingFace 调用 Llama\n\n好，万事俱备，现在我们可以使用HuggingFace的Transformers库来调用Llama啦！\n\n```plain\n# 导入必要的库\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n# 加载预训练模型的分词器\ntokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n\n# 加载预训练的模型\n# 使用 device_map 参数将模型自动加载到可用的硬件设备上，例如GPU\nmodel = AutoModelForCausalLM.from_pretrained(\n          \"meta-llama/Llama-2-7b-chat-hf\",\n          device_map = 'auto')\n\n# 定义一个提示，希望模型基于此提示生成故事\nprompt = \"请给我讲个玫瑰的爱情故事?\"\n\n# 使用分词器将提示转化为模型可以理解的格式，并将其移动到GPU上\ninputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n\n# 使用模型生成文本，设置最大生成令牌数为2000\noutputs = model.generate(inputs[\"input_ids\"], max_new_tokens=2000)\n\n# 将生成的令牌解码成文本，并跳过任何特殊的令牌，例如[CLS], [SEP]等\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n# 打印生成的响应\nprint(response)\n\n```\n\n这段程序是一个很典型的HuggingFace的Transformers库的用例，该库提供了大量预训练的模型和相关的工具。\n\n- 导入AutoTokenizer：这是一个用于自动加载预训练模型的相关分词器的工具。分词器负责将文本转化为模型可以理解的数字格式。\n- 导入AutoModelForCausalLM：这是用于加载因果语言模型（用于文本生成）的工具。\n- 使用from\\_pretrained方法来加载预训练的分词器和模型。其中， `device_map = 'auto'` 是为了自动地将模型加载到可用的设备上，例如GPU。\n- 然后，给定一个提示（prompt）： `\"请给我讲个玫瑰的爱情故事?\"`，并使用分词器将该提示转换为模型可以接受的格式， `return_tensors=\"pt\"` 表示返回PyTorch张量。语句中的 `.to(\"cuda\")` 是GPU设备格式转换，因为我在GPU上跑程序，不用这个的话会报错，如果你使用CPU，可以试一下删掉它。\n- 最后使用模型的 `.generate()` 方法生成响应。 `max_new_tokens=2000` 限制生成的文本的长度。使用分词器的 `.decode() ` 方法将输出的数字转化回文本，并且跳过任何特殊的标记。\n\n因为是在本地进行推理，耗时时间比较久。在我的机器上，大概需要30s～2min产生结果。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/933b7b11512bd06a977027cbbfd8d198.png)\n\n这样的回答肯定不能直接用做商业文案，而且，我的意思是玫瑰花相关的故事，它明显把玫瑰理解成一个女孩的名字了。所以，开源模型，尤其是7B的小模型和Open AI的ChatGPT还是有一定差距的。\n\n## LangChain 和 HuggingFace 的接口\n\n讲了半天，LangChain未出场。下面让我们看一看，如何把HuggingFace里面的模型接入LangChain。\n\n### 通过 HuggingFace Hub\n\n第一种集成方式，是通过HuggingFace Hub。HuggingFace Hub 是一个开源模型中心化存储库，主要用于分享、协作和存储预训练模型、数据集以及相关组件。\n\n我们给出一个HuggingFace Hub 和LangChain集成的代码示例。\n\n```plain\n# 导入HuggingFace API Token\nimport os\nos.environ['HUGGINGFACEHUB_API_TOKEN'] = '你的HuggingFace API Token'\n\n# 导入必要的库\nfrom langchain import PromptTemplate, HuggingFaceHub, LLMChain\n\n# 初始化HF LLM\nllm = HuggingFaceHub(\n    repo_id=\"google/flan-t5-small\",\n    #repo_id=\"meta-llama/Llama-2-7b-chat-hf\",\n)\n\n# 创建简单的question-answering提示模板\ntemplate = \"\"\"Question: {question}\n              Answer: \"\"\"\n\n# 创建Prompt\nprompt = PromptTemplate(template=template, input_variables=[\"question\"])\n\n# 调用LLM Chain --- 我们以后会详细讲LLM Chain\nllm_chain = LLMChain(\n    prompt=prompt,\n    llm=llm\n)\n\n# 准备问题\nquestion = \"Rose is which type of flower?\"\n\n# 调用模型并返回结果\nprint(llm_chain.run(question))\n\n```\n\n可以看出，这个集成过程非常简单，只需要在HuggingFaceHub类的repo\\_id中指定模型名称，就可以直接下载并使用模型，模型会自动下载到HuggingFace的Cache目录，并不需要手工下载。\n\n初始化LLM，创建提示模板，生成提示的过程，你已经很熟悉了。这段代码中有一个新内容是我通过llm\\_chain来调用了LLM。这段代码也不难理解，有关Chain的概念我们以后还会详述。\n\n不过，我尝试使用meta-llama/Llama-2-7b-chat-hf这个模型时，出现了错误，因此我只好用比较旧的模型做测试。我随便选择了google/flan-t5-small，问了它一个很简单的问题，想看看它是否知道玫瑰是哪一种花。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/5bfc31eacb422fcd1d148bb1a2b3bf71.png)\n\n模型告诉我，玫瑰是花。对，答案只有一个字，flower。这…不得不说，2023年之前的模型，和2023年之后的模型，水平没得比。以前的模型能说话就不错了。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/yyc2177bc3c06f1d738f26985b9fbd3e.png)\n\n### 通过 HuggingFace Pipeline\n\n既然HuggingFace Hub还不能完成Llama-2的测试，让我们来尝试另外一种方法，HuggingFace Pipeline。HuggingFace 的 Pipeline 是一种高级工具，它简化了多种常见自然语言处理（NLP）任务的使用流程，使得用户不需要深入了解模型细节，也能够很容易地利用预训练模型来做任务。\n\n让我来看看下面的示例：\n\n````plain\n# 指定预训练模型的名称\nmodel = \"meta-llama/Llama-2-7b-chat-hf\"\n\n# 从预训练模型中加载词汇器\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(model)\n\n# 创建一个文本生成的管道\nimport transformers\nimport torch\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    max_length = 1000\n)\n\n# 创建HuggingFacePipeline实例\nfrom langchain import HuggingFacePipeline\nllm = HuggingFacePipeline(pipeline = pipeline,\n                          model_kwargs = {'temperature':0})\n\n# 定义输入模板，该模板用于生成花束的描述\ntemplate = \"\"\"\n              为以下的花束生成一个详细且吸引人的描述：\n              花束的详细信息：\n              ```{flower_details}```\n           \"\"\"\n\n# 使用模板创建提示\nfrom langchain import PromptTemplate,  LLMChain\nprompt = PromptTemplate(template=template,\n                     input_variables=[\"flower_details\"])\n\n# 创建LLMChain实例\nfrom langchain import PromptTemplate\nllm_chain = LLMChain(prompt=prompt, llm=llm)\n\n# 需要生成描述的花束的详细信息\nflower_details = \"12支红玫瑰，搭配白色满天星和绿叶，包装在浪漫的红色纸中。\"\n\n# 打印生成的花束描述\nprint(llm_chain.run(flower_details))\n\n````\n\n这里简单介绍一下代码中使用到的transformers pipeline的配置参数。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/41yyb05408bd6a16e349f89279548f7e.jpg)\n\n生成的结果之一如下：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/1bb303ec8bd8150d23bebc79035af13c.jpg)\n\n此结果不敢恭维。但是，后续的测试告诉我，这很有可能是7B这个模型太小，尽管有形成中文的相应能力，但是能力不够强大，也就导致了这样的结果。\n\n至此，通过HuggingFace接口调用各种开源模型的尝试成功结束。下面，我们进行最后一个测试，看看LangChain到底能否直接调用本地模型。\n\n## 用 LangChain 调用自定义语言模型\n\n最后，我们来尝试回答这节课开头提出的问题，假设你就是想训练属于自己的模型。而且出于商业秘密的原因，不想开源它，不想上传到HuggingFace，就是要在本机运行模型。此时应该如何利用LangChain的功能？\n\n我们可以创建一个LLM的衍生类，自己定义模型。而LLM这个基类，则位于langchain.llms.base中，通过from langchain.llms.base import LLM语句导入。\n\n这个自定义的LLM类只需要实现一个方法：\n\n- \\_call方法：用于接收输入字符串并返回响应字符串。\n\n以及一个可选方法：\n\n- \\_identifying\\_params方法：用于帮助打印此类的属性。\n\n下面，让我们先从HuggingFace的 [这里](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/tree/main)，下载一个llama-2-7b-chat.ggmlv3.q4\\_K\\_S.bin模型，并保存在本地。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/54c0ec3cbe3c3cyy6988de10f619b51c.png)\n\n你可能会质疑我，不是说自己训练，自己微调，不再用HuggingFace了吗？\n\n不好意思，容许我解释一下。自己训练一个能用的模型没那么容易。这个模型，它并不是原始的Llama模型，而是TheBloke这位老兄用他的手段为我们量化过的新模型，你也可以理解成，他已经为我们压缩或者说微调了Llama模型。\n\n> 量化是AI模型大小和性能优化的常用技术，它将模型的权重简化到较少的位数，以减少模型的大小和计算需求，让大模型甚至能够在CPU上面运行。当你看到模型的后缀有GGML或者GPTQ，就说明模型已经被量化过，其中GPTQ 是一种仅适用于 GPU 的特定格式。GGML 专为 CPU 和 Apple M 系列设计，但也可以加速 GPU 上的某些层。llama-cpp-python这个包就是为了实现GGML而制作的。\n\n所以，这里你就假设，咱们下载下来的llama-2-7b-chat.ggmlv3.q4\\_K\\_S.bin这个模型，就是你自己微调过的。将来你真的微调了Llama2、ChatGLM、百川或者千问的开源版，甚至是自己从头训练了一个mini-ChatGPT，你也可以保存为you\\_own\\_model.bin的格式，就按照下面的方式加载到LangChain之中。\n\n然后，为了使用llama-2-7b-chat.ggmlv3.q4\\_K\\_S.bin这个模型，你需要安装 pip install llama-cpp-python 这个包。\n\n```plain\n# 导入需要的库\nfrom llama_cpp import Llama\nfrom typing import Optional, List, Mapping, Any\nfrom langchain.llms.base import LLM\n\n# 模型的名称和路径常量\nMODEL_NAME = 'llama-2-7b-chat.ggmlv3.q4_K_S.bin'\nMODEL_PATH = '/home/huangj/03_Llama/'\n\n# 自定义的LLM类，继承自基础LLM类\nclass CustomLLM(LLM):\n    model_name = MODEL_NAME\n\n    # 该方法使用Llama库调用模型生成回复\n    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n        prompt_length = len(prompt) + 5\n        # 初始化Llama模型，指定模型路径和线程数\n        llm = Llama(model_path=MODEL_PATH+MODEL_NAME, n_threads=4)\n        # 使用Llama模型生成回复\n        response = llm(f\"Q: {prompt} A: \", max_tokens=256)\n\n        # 从返回的回复中提取文本部分\n        output = response['choices'][0]['text'].replace('A: ', '').strip()\n\n        # 返回生成的回复，同时剔除了问题部分和额外字符\n        return output[prompt_length:]\n\n    # 返回模型的标识参数，这里只是返回模型的名称\n    @property\n    def _identifying_params(self) -> Mapping[str, Any]:\n        return {\"name_of_model\": self.model_name}\n\n    # 返回模型的类型，这里是\"custom\"\n    @property\n    def _llm_type(self) -> str:\n        return \"custom\"\n\n\n# 初始化自定义LLM类\nllm = CustomLLM()\n\n# 使用自定义LLM生成一个回复\nresult = llm(\"昨天有一个客户抱怨他买了花给女朋友之后，两天花就枯了，你说作为客服我应该怎么解释？\")\n\n# 打印生成的回复\nprint(result)\n\n```\n\n代码中需要解释的内容不多，基本上就是CustomLLM类的构建和使用，类内部通过Llama类来实现大模型的推理功能，然后直接返回模型的回答。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/0275183b3863e602c59afb94707aca59.jpg)\n\n似乎Llama经过量化之后，虽然仍读得懂中文，但是不会讲中文了。\n\n翻译成中文，他的回答是这样的。\n\n_当客户抱怨他们为女朋友买的花在两天内就枯萎了，我会以礼貌和专业的方式这样解释：_\n\n_“感谢您把这个问题告诉我们。对于给您带来的任何不便，我深感抱歉。有可能这些花没有被正确地存储或照料，这可能影响了它们的生命期。我们始终以提供高质量的产品为荣，但有时可能会出现意外的问题。请您知道，我们非常重视您的满意度并随时为您提供帮助。您希望我为您提供替换或退款吗？”_\n\n看上去，除了中文能力不大灵光之外，Llama2的英文表现真的非常完美，和GPT3.5差距不是很大，要知道：\n\n1. 这可是开源模型，而且是允许商业的免费模型。\n2. 这是在本机 CPU 的环境下运行的，模型的推理速度还是可以接受的。\n3. 这仅仅是Llama的最小版本，也就是7B的量化版，就达到了这么好的效果。\n\n基于上述三点原因，我给Llama2打98.5分。\n\n## 总结时刻\n\n今天的课程到此就结束了，相信你学到了很多新东西吧。的确，进入大模型开发这个领域，就好像打开了通往新世界的一扇门，有太多的新知识，等待着你去探索。\n\n现在，你已经知道大模型训练涉及在大量数据上使用深度学习算法，通常需要大量计算资源和时间。训练后，模型可能不完全适合特定任务，因此需要微调，即在特定数据集上继续训练，以使模型更适应该任务。为了减小部署模型的大小和加快推理速度，模型还会经过量化，即将模型参数从高精度格式减少到较低精度。\n\n如果你想继续深入学习大模型，那么有几个工具你不得不接着研究。\n\n- PyTorch是一个流行的深度学习框架，常用于模型的训练和微调。\n- HuggingFace是一个开源社区，提供了大量预训练模型和微调工具，尤其是NLP任务。\n- LangChain则擅长于利用大语言模型的推理功能，开发新的工具或应用，完成特定的任务。\n\n这些工具和库在AI模型的全生命周期中起到关键作用，使研究者和开发者更容易开发和部署高效的AI系统。\n\n## 思考题\n\n1. 现在请你再回答一下，什么时候应该使用OpenAI的API？什么时候应该使用开源模型？或者自己开发/微调的模型？\n\n   提示：的确，文中没有给出这个问题的答案。因为这个问题并没有标准答案。\n\n2. 请你使用HuggingFace的Transformers库，下载新的模型进行推理，比较它们的性能。\n\n3. 请你在LangChain中，使用HuggingFaceHub和HuggingFace Pipeline这两种接口，调用当前最流行的大语言模型。\n\n   提示：HuggingFace Model 页面，有模型下载量的当月排序，当月下载最多的模型就是最流行的模型。\n\n期待在留言区看到你的分享，我们一起交流探讨，共创一个良好的学习氛围。如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。\n\n## 延伸阅读\n\n1. Llama2，开源的可商用类ChatGPT模型， [Facebook链接](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/)、 [GitHub链接](https://github.com/facebookresearch/llama)\n2. HuggingFace [Transformer](https://huggingface.co/docs/transformers/index) 文档\n3. PyTorch 官方 [教程](https://pytorch.org/tutorials/)、 [文档](https://pytorch.org/docs/stable/index.html)\n4. [AutoGPTQ](https://github.com/PanQiWei/AutoGPTQ) 基于GPTQ算法的大模型量化工具包\n5. [Llama CPP](https://github.com/ggerganov/llama.cpp) 支持 [GGML](https://github.com/ggerganov/ggml)，目标是在MacBook（或类似的非GPU的普通家用硬件环境）上使用4位整数量化运行Llama模型"},{"url":"/posts/5.html","content":"# 08｜链（上）：写一篇完美鲜花推文？用SequencialChain链接不同的组件\n你好，我是黄佳。欢迎来到LangChain实战课！\n\n到这节课，我们已经学到了不少LangChain的应用，也体会到了LangChain功能的强大。但也许你心里开始出现了一个疑问：LangChain，其中的 **Chain** 肯定是关键组件，为什么我们还没有讲到呢？\n\n这的确是个好问题。对于简单的应用程序来说，直接调用LLM就已经足够了。因此，在前几节课的示例中，我们主要通过LangChain中提供的提示模板、模型接口以及输出解析器就实现了想要的功能。\n\n## 什么是 Chain\n\n但是，如果你想开发更复杂的应用程序，那么就需要通过 “Chain” 来链接LangChain的各个组件和功能——模型之间彼此链接，或模型与其他组件链接。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/e26993dd3957bfd2947424abb9de7cde.png)\n\n这种将多个组件相互链接，组合成一个链的想法简单但很强大。它简化了复杂应用程序的实现，并使之更加模块化，能够创建出单一的、连贯的应用程序，从而使调试、维护和改进应用程序变得容易。\n\n**说到链的实现和使用，也简单。**\n\n- 首先LangChain通过设计好的接口，实现一个具体的链的功能。例如，LLM链（LLMChain）能够接受用户输入，使用 PromptTemplate 对其进行格式化，然后将格式化的响应传递给 LLM。这就相当于把整个Model I/O的流程封装到链里面。\n- 实现了链的具体功能之后，我们可以通过将多个链组合在一起，或者将链与其他组件组合来构建更复杂的链。\n\n所以你看，链在内部把一系列的功能进行封装，而链的外部则又可以组合串联。 **链其实可以被视为LangChain中的一种基本功能单元。**\n\nLangChain中提供了很多种类型的预置链，目的是使各种各样的任务实现起来更加方便、规范。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/8b580b2b8e0fc8515d271165a46101c3.jpg)\n\n我们先使用一下最基础也是最常见的LLMChain。\n\n## LLMChain：最简单的链\n\nLLMChain围绕着语言模型推理功能又添加了一些功能，整合了PromptTemplate、语言模型（LLM或聊天模型）和 Output Parser，相当于把Model I/O放在一个链中整体操作。它使用提示模板格式化输入，将格式化的字符串传递给 LLM，并返回 LLM 输出。\n\n举例来说，如果我想让大模型告诉我某种花的花语，如果不使用链，代码如下：\n\n```plain\n#----第一步 创建提示\n# 导入LangChain中的提示模板\nfrom langchain import PromptTemplate\n# 原始字符串模板\ntemplate = \"{flower}的花语是?\"\n# 创建LangChain模板\nprompt_temp = PromptTemplate.from_template(template)\n# 根据模板创建提示\nprompt = prompt_temp.format(flower='玫瑰')\n# 打印提示的内容\nprint(prompt)\n\n#----第二步 创建并调用模型\n# 导入LangChain中的OpenAI模型接口\nfrom langchain import OpenAI\n# 创建模型实例\nmodel = OpenAI(temperature=0)\n# 传入提示，调用模型，返回结果\nresult = model(prompt)\nprint(result)\n\n```\n\n输出：\n\n```plain\n玫瑰的花语是?\n爱情、浪漫、美丽、永恒、誓言、坚贞不渝。\n\n```\n\n此时Model I/O的实现分为两个部分，提示模板的构建和模型的调用独立处理。\n\n如果使用链，代码结构则显得更简洁。\n\n```plain\n# 导入所需的库\nfrom langchain import PromptTemplate, OpenAI, LLMChain\n# 原始字符串模板\ntemplate = \"{flower}的花语是?\"\n# 创建模型实例\nllm = OpenAI(temperature=0)\n# 创建LLMChain\nllm_chain = LLMChain(\n    llm=llm,\n    prompt=PromptTemplate.from_template(template))\n# 调用LLMChain，返回结果\nresult = llm_chain(\"玫瑰\")\nprint(result)\n\n```\n\n输出：\n\n```plain\n{'flower': '玫瑰', 'text': '\\n\\n爱情、浪漫、美丽、永恒、誓言、坚贞不渝。'}\n\n```\n\n在这里，我们就把提示模板的构建和模型的调用封装在一起了。\n\n## 链的调用方式\n\n链有很多种调用方式。\n\n### 直接调用\n\n刚才我们是直接调用的链对象。当我们像函数一样调用一个对象时，它实际上会调用该对象内部实现的\\_\\_call\\_\\_方法。\n\n如果你的提示模板中包含多个变量，在调用链的时候，可以使用字典一次性输入它们。\n\n```plain\nprompt = PromptTemplate(\n    input_variables=[\"flower\", \"season\"],\n    template=\"{flower}在{season}的花语是?\",\n)\nllm_chain = LLMChain(llm=llm, prompt=prompt)\nprint(llm_chain({\n    'flower': \"玫瑰\",\n    'season': \"夏季\" }))\n\n```\n\n输出：\n\n```plain\n{'flower': '玫瑰', 'season': '夏季', 'text': '\\n\\n玫瑰在夏季的花语是爱的誓言，热情，美丽，坚定的爱情。'}\n\n```\n\n### 通过run方法\n\n通过run方法，也等价于直接调用\\_call\\_函数。\n\n语句：\n\n```plain\nllm_chain(\"玫瑰\")\n\n```\n\n等价于：\n\n```plain\nllm_chain.run(\"玫瑰\")\n\n```\n\n### 通过predict方法\n\npredict方法类似于run，只是输入键被指定为关键字参数而不是 Python 字典。\n\n```plain\nresult = llm_chain.predict(flower=\"玫瑰\")\nprint(result)\n\n```\n\n### 通过apply方法\n\napply方法允许我们针对输入列表运行链，一次处理多个输入。\n\n示例如下：\n\n```plain\n# apply允许您针对输入列表运行链\ninput_list = [\n    {\"flower\": \"玫瑰\",'season': \"夏季\"},\n    {\"flower\": \"百合\",'season': \"春季\"},\n    {\"flower\": \"郁金香\",'season': \"秋季\"}\n]\nresult = llm_chain.apply(input_list)\nprint(result)\n\n```\n\n输出：\n\n```plain\n'''[{'text': '\\n\\n玫瑰在夏季的花语是“恋爱”、“热情”和“浪漫”。'},\n{'text': '\\n\\n百合在春季的花语是“爱情”和“友谊”。'},\n {'text': '\\n\\n郁金香在秋季的花语表达的是“热情”、“思念”、“爱恋”、“回忆”和“持久的爱”。'}]'''\n\n```\n\n### 通过generate方法\n\ngenerate方法类似于apply，只不过它返回一个LLMResult对象，而不是字符串。LLMResult通常包含模型生成文本过程中的一些相关信息，例如令牌数量、模型名称等。\n\n```plain\nresult = llm_chain.generate(input_list)\nprint(result)\n\n```\n\n输出：\n\n```plain\ngenerations=[[Generation(text='\\n\\n玫瑰在夏季的花语是“热情”、“爱情”和“幸福”。',\ngeneration_info={'finish_reason': 'stop', 'logprobs': None})],\n[Generation(text='\\n\\n春季的花语是爱情、幸福、美满、坚贞不渝。',\ngeneration_info={'finish_reason': 'stop', 'logprobs': None})],\n[Generation(text='\\n\\n秋季的花语是“思念”。银色的百合象征着“真爱”，而淡紫色的郁金香则象征着“思念”，因为它们在秋天里绽放的时候，犹如在思念着夏天的温暖。',\ngeneration_info={'finish_reason': 'stop', 'logprobs': None})]]\nllm_output={'token_usage': {'completion_tokens': 243, 'total_tokens': 301, 'prompt_tokens': 58}, 'model_name': 'text-davinci-003'}\nrun=[RunInfo(run_id=UUID('13058cca-881d-4b76-b0cf-0f9c831af6c4')),\nRunInfo(run_id=UUID('7f38e33e-bab5-4d03-b77c-f50cd195affb')),\nRunInfo(run_id=UUID('7a1e45fd-77ee-4133-aab0-431147186db8'))]\n\n```\n\n## Sequential Chain：顺序链\n\n好，到这里，你已经掌握了最基本的LLMChain的用法。下面，我要带着你用Sequential Chain 把几个LLMChain串起来，形成一个顺序链。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/48f3f524ecf2d2yyeb11fd54yyf99f36.png)\n\n这个示例中，我们的目标是这样的：\n\n- 第一步，我们假设大模型是一个植物学家，让他给出某种特定鲜花的知识和介绍。\n- 第二步，我们假设大模型是一个鲜花评论者，让他参考上面植物学家的文字输出，对鲜花进行评论。\n- 第三步，我们假设大模型是易速鲜花的社交媒体运营经理，让他参考上面植物学家和鲜花评论者的文字输出，来写一篇鲜花运营文案。\n\n下面我们就来一步步地实现这个示例。\n\n首先，导入所有需要的库。\n\n```plain\n# 设置OpenAI API密钥\nimport os\nos.environ[\"OPENAI_API_KEY\"] = '你的OpenAI API Key'\n\nfrom langchain.llms import OpenAI\nfrom langchain.chains import LLMChain\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains import SequentialChain\n\n```\n\n然后，添加第一个LLMChain，生成鲜花的知识性说明。\n\n```plain\n# 这是第一个LLMChain，用于生成鲜花的介绍，输入为花的名称和种类\nllm = OpenAI(temperature=.7)\ntemplate = \"\"\"\n你是一个植物学家。给定花的名称和类型，你需要为这种花写一个200字左右的介绍。\n\n花名: {name}\n颜色: {color}\n植物学家: 这是关于上述花的介绍:\"\"\"\nprompt_template = PromptTemplate(input_variables=[\"name\", \"color\"], template=template)\nintroduction_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"introduction\")\n\n```\n\n接着，添加第二个LLMChain，根据鲜花的知识性说明生成评论。\n\n```plain\n# 这是第二个LLMChain，用于根据鲜花的介绍写出鲜花的评论\nllm = OpenAI(temperature=.7)\ntemplate = \"\"\"\n你是一位鲜花评论家。给定一种花的介绍，你需要为这种花写一篇200字左右的评论。\n\n鲜花介绍:\n{introduction}\n花评人对上述花的评论:\"\"\"\nprompt_template = PromptTemplate(input_variables=[\"introduction\"], template=template)\nreview_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"review\")\n\n```\n\n接着，添加第三个LLMChain，根据鲜花的介绍和评论写出一篇自媒体的文案。\n\n```plain\n# 这是第三个LLMChain，用于根据鲜花的介绍和评论写出一篇自媒体的文案\ntemplate = \"\"\"\n你是一家花店的社交媒体经理。给定一种花的介绍和评论，你需要为这种花写一篇社交媒体的帖子，300字左右。\n\n鲜花介绍:\n{introduction}\n花评人对上述花的评论:\n{review}\n\n社交媒体帖子:\n\"\"\"\nprompt_template = PromptTemplate(input_variables=[\"introduction\", \"review\"], template=template)\nsocial_post_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"social_post_text\")\n\n```\n\n最后，添加SequentialChain，把前面三个链串起来。\n\n```plain\n# 这是总的链，我们按顺序运行这三个链\noverall_chain = SequentialChain(\n    chains=[introduction_chain, review_chain, social_post_chain],\n    input_variables=[\"name\", \"color\"],\n    output_variables=[\"introduction\",\"review\",\"social_post_text\"],\n    verbose=True)\n\n# 运行链，并打印结果\nresult = overall_chain({\"name\":\"玫瑰\", \"color\": \"黑色\"})\nprint(result)\n\n```\n\n最终的输出如下：\n\n```plain\n> Entering new  chain...\n\n> Finished chain.\n{'name': '玫瑰', 'color': '黑色',\n'introduction': '\\n\\n黑色玫瑰，这是一种对传统玫瑰花的独特颠覆，它的出现挑战了我们对玫瑰颜色的固有认知。它的花瓣如煤炭般黑亮，反射出独特的微光，而花蕊则是金黄色的，宛如夜空中的一颗星，强烈的颜色对比营造出一种前所未有的视觉效果。在植物学中，黑色玫瑰的出现无疑提供了一种新的研究方向，对于我们理解花朵色彩形成的机制有着重要的科学价值。',\n'review': '\\n\\n黑色玫瑰，这不仅仅是一种花朵，更是一种完全颠覆传统的艺术表现形式。黑色的花瓣仿佛在诉说一种不可言喻的悲伤与神秘，而黄色的蕊瓣犹如漆黑夜空中的一抹亮色，给人带来无尽的想象。它将悲伤与欢乐，神秘与明亮完美地结合在一起，这是一种全新的视觉享受，也是一种对生活理解的深度表达。',\n'social_post_text': '\\n欢迎来到我们的自媒体平台，今天，我们要向您展示的是我们的全新产品——黑色玫瑰。这不仅仅是一种花，这是一种对传统观念的挑战，一种视觉艺术的革新，更是一种生活态度的象征。\n这种别样的玫瑰花，其黑色花瓣宛如漆黑夜空中闪烁的繁星，富有神秘的深度感，给人一种前所未有的视觉冲击力。这种黑色，它不是冷酷、不是绝望，而是充满着独特的魅力和力量。而位于黑色花瓣之中的金黄色花蕊，则犹如星星中的灵魂，默默闪烁，给人带来无尽的遐想，充满活力与生机。\n黑色玫瑰的存在，不仅挑战了我们对于玫瑰传统颜色的认知，它更是一种生动的生命象征，象征着那些坚韧、独特、勇敢面对生活的人们。黑色的花瓣中透露出一种坚韧的力量，而金黄的花蕊则是生活中的希望，二者的结合恰好象征了生活中的喜怒哀乐，体现了人生的百态。'}\n\n```\n\n至此，我们就通过两个LLM链和一个顺序链，生成了一篇完美的文案。\n\n## 总结时刻\n\nLangChain为我们提供了好用的“链”，帮助我们把多个组件像链条一样连接起来。这个“链条”其实就是一系列组件的调用顺序，这个顺序里还可以包括其他的“链条”。\n\n我们可以使用多种方法调用链，也可以根据开发时的需求选择各种不同的链。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/5fe2366c3e8294a61cb44d33b9d79638.png)\n\n除去最常见的LLMChain和SequenceChain之外，LangChain中还自带大量其他类型的链，封装了各种各样的功能。你可以看一看这些链的实现细节，并尝试着使用它们。\n\n下一节课，我们会继续介绍另外一种好用的链，RouterChain。\n\n## 思考题\n\n1. 在 [第3课](https://time.geekbang.org/column/article/699451) 中，我们曾经用提示模板生成过一段鲜花的描述，代码如下：\n\n```plain\nfor flower, price in zip(flowers, prices):\n    # 根据提示准备模型的输入\n    input = prompt.format(flower_name=flower, price=price)\n    # 获取模型的输出\n    output = model(input)\n    # 解析模型的输出\n    parsed_output = output_parser.parse(output)\n\n```\n\n请你使用LLMChain重构提示的format和获取模型输出部分，完成相同的功能。\n\n提示：\n\n```plain\n    llm_chain = LLMChain(\n        llm=model,\n        prompt=prompt)\n\n```\n\n1. 上一道题目中，我要求你把提示的format和获取模型输出部分整合到LLMChain中，其实你还可以更进一步，把output\\_parser也整合到LLMChain中，让程序结构进一步简化，请你尝试一下。\n\n提示：\n\n```plain\n    llm_chain = LLMChain(\n        llm=model,\n        prompt=prompt,\n        output_parser=output_parser)\n\n```\n\n1. 选择一个LangChain中的链（我们没用到的类型），尝试使用它解决一个问题，并分享你的用例和代码。\n\n题目较多，可以选择性思考，期待在留言区看到你的分享。如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。\n\n## 延伸阅读\n\n1. GitHub上各种各样的 [链](https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain/chains)\n2. 代码， [LLMChain](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/chains/llm.py) 的实现细节"},{"url":"/posts/6.html","content":"# 07｜输出解析：用OutputParser生成鲜花推荐列表\n你好，我是黄佳，欢迎来到LangChain实战课！\n\n首先请你回忆一下 [第4课](https://time.geekbang.org/column/article/700699) 中我们学了什么: 为一些花和价格生成吸引人的描述，并将这些描述和原因存储到一个CSV文件中。为了实现这个目标，程序调用了OpenAI模型，并利用了结构化输出解析器，以及一些数据处理和存储的工具。\n\n今天我要带着你深入研究一下LangChain中的输出解析器，并用一个新的解析器——Pydantic 解析器来重构第4课中的程序。这节课也是模型I/O框架的最后一讲。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/6215fdd31373523a46bb02f86283522d.jpg)\n\n下面先来看看LangChain中的输出解析器究竟是什么，有哪些种类。\n\n## LangChain 中的输出解析器\n\n语言模型输出的是文本，这是给人类阅读的。但很多时候，你可能想要获得的是程序能够处理的结构化信息。这就是输出解析器发挥作用的地方。\n\n输出解析器是 **一种专用于处理和构建语言模型响应的类**。一个基本的输出解析器类通常需要实现两个核心方法。\n\n- get\\_format\\_instructions：这个方法需要返回一个字符串，用于指导如何格式化语言模型的输出，告诉它应该如何组织并构建它的回答。\n- parse：这个方法接收一个字符串（也就是语言模型的输出）并将其解析为特定的数据结构或格式。这一步通常用于确保模型的输出符合我们的预期，并且能够以我们需要的形式进行后续处理。\n\n还有一个可选的方法。\n\n- parse\\_with\\_prompt：这个方法接收一个字符串（也就是语言模型的输出）和一个提示（用于生成这个输出的提示），并将其解析为特定的数据结构。这样，你可以根据原始提示来修正或重新解析模型的输出，确保输出的信息更加准确和贴合要求。\n\n下面是一个基于上述描述的简单伪代码示例：\n\n```plain\nclass OutputParser:\n    def __init__(self):\n        pass\n\n    def get_format_instructions(self):\n        # 返回一个字符串，指导如何格式化模型的输出\n        pass\n\n    def parse(self, model_output):\n        # 解析模型的输出，转换为某种数据结构或格式\n        pass\n\n    def parse_with_prompt(self, model_output, prompt):\n        # 基于原始提示解析模型的输出，转换为某种数据结构或格式\n        pass\n\n```\n\n在LangChain中，通过实现get\\_format\\_instructions、parse 和 parse\\_with\\_prompt 这些方法，针对不同的使用场景和目标，设计了各种输出解析器。让我们来逐一认识一下。\n\n1. 列表解析器（List Parser）：这个解析器用于处理模型生成的输出，当需要模型的输出是一个列表的时候使用。例如，如果你询问模型“列出所有鲜花的库存”，模型的回答应该是一个列表。\n2. 日期时间解析器（Datetime Parser）：这个解析器用于处理日期和时间相关的输出，确保模型的输出是正确的日期或时间格式。\n3. 枚举解析器（Enum Parser）：这个解析器用于处理预定义的一组值，当模型的输出应该是这组预定义值之一时使用。例如，如果你定义了一个问题的答案只能是“是”或“否”，那么枚举解析器可以确保模型的回答是这两个选项之一。\n4. 结构化输出解析器（Structured Output Parser）：这个解析器用于处理复杂的、结构化的输出。如果你的应用需要模型生成具有特定结构的复杂回答（例如一份报告、一篇文章等），那么可以使用结构化输出解析器来实现。\n5. Pydantic（JSON）解析器：这个解析器用于处理模型的输出，当模型的输出应该是一个符合特定格式的JSON对象时使用。它使用Pydantic库，这是一个数据验证库，可以用于构建复杂的数据模型，并确保模型的输出符合预期的数据模型。\n6. 自动修复解析器（Auto-Fixing Parser）：这个解析器可以自动修复某些常见的模型输出错误。例如，如果模型的输出应该是一段文本，但是模型返回了一段包含语法或拼写错误的文本，自动修复解析器可以自动纠正这些错误。\n7. 重试解析器（RetryWithErrorOutputParser）：这个解析器用于在模型的初次输出不符合预期时，尝试修复或重新生成新的输出。例如，如果模型的输出应该是一个日期，但是模型返回了一个字符串，那么重试解析器可以重新提示模型生成正确的日期格式。\n\n上面的各种解析器中，前三种很容易理解，而结构化输出解析器你已经用过了。所以接下来我们重点讲一讲Pydantic（JSON）解析器、自动修复解析器和重试解析器。\n\n## Pydantic（JSON）解析器实战\n\nPydantic (JSON) 解析器应该是最常用也是最重要的解析器，我带着你用它来重构鲜花文案生成程序。\n\n> Pydantic 是一个 Python 数据验证和设置管理库，主要基于 Python 类型提示。尽管它不是专为 JSON 设计的，但由于 JSON 是现代 Web 应用和 API 交互中的常见数据格式，Pydantic 在处理和验证 JSON 数据时特别有用。\n\n### 第一步：创建模型实例\n\n先通过环境变量设置OpenAI API密钥，然后使用LangChain库创建了一个OpenAI的模型实例。这里我们仍然选择了text-davinci-003作为大语言模型。\n\n```plain\n# ------Part 1\n# 设置OpenAI API密钥\nimport os\nos.environ[\"OPENAI_API_KEY\"] = '你的OpenAI API Key'\n\n# 创建模型实例\nfrom langchain import OpenAI\nmodel = OpenAI(model_name='text-davinci-003')\n\n```\n\n### 第二步：定义输出数据的格式\n\n先创建了一个空的DataFrame，用于存储从模型生成的描述。接下来，通过一个名为FlowerDescription的Pydantic BaseModel类，定义了期望的数据格式（也就是数据的结构）。\n\n```plain\n# ------Part 2\n# 创建一个空的DataFrame用于存储结果\nimport pandas as pd\ndf = pd.DataFrame(columns=[\"flower_type\", \"price\", \"description\", \"reason\"])\n\n# 数据准备\nflowers = [\"玫瑰\", \"百合\", \"康乃馨\"]\nprices = [\"50\", \"30\", \"20\"]\n\n# 定义我们想要接收的数据格式\nfrom pydantic import BaseModel, Field\nclass FlowerDescription(BaseModel):\n    flower_type: str = Field(description=\"鲜花的种类\")\n    price: int = Field(description=\"鲜花的价格\")\n    description: str = Field(description=\"鲜花的描述文案\")\n    reason: str = Field(description=\"为什么要这样写这个文案\")\n\n```\n\n在这里我们用到了负责数据格式验证的Pydantic库来创建带有类型注解的类FlowerDescription，它可以自动验证输入数据，确保输入数据符合你指定的类型和其他验证条件。\n\nPydantic有这样几个特点。\n\n1. 数据验证：当你向Pydantic类赋值时，它会自动进行数据验证。例如，如果你创建了一个字段需要是整数，但试图向它赋予一个字符串，Pydantic会引发异常。\n2. 数据转换：Pydantic不仅进行数据验证，还可以进行数据转换。例如，如果你有一个需要整数的字段，但你提供了一个可以转换为整数的字符串，如 `\"42\"`，Pydantic会自动将这个字符串转换为整数42。\n3. 易于使用：创建一个Pydantic类就像定义一个普通的Python类一样简单。只需要使用Python的类型注解功能，即可在类定义中指定每个字段的类型。\n4. JSON支持：Pydantic类可以很容易地从JSON数据创建，并可以将类的数据转换为JSON格式。\n\n下面，我们基于这个Pydantic数据格式类来创建LangChain的输出解析器。\n\n### 第三步：创建输出解析器\n\n在这一步中，我们创建输出解析器并获取输出格式指示。先使用LangChain库中的PydanticOutputParser创建了输出解析器，该解析器将用于解析模型的输出，以确保其符合FlowerDescription的格式。然后，使用解析器的get\\_format\\_instructions方法获取了输出格式的指示。\n\n```plain\n# ------Part 3\n# 创建输出解析器\nfrom langchain.output_parsers import PydanticOutputParser\noutput_parser = PydanticOutputParser(pydantic_object=FlowerDescription)\n\n# 获取输出格式指示\nformat_instructions = output_parser.get_format_instructions()\n# 打印提示\nprint(\"输出格式：\",format_instructions)\n\n```\n\n程序输出如下：\n\n```plain\n输出格式： The output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}}\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n\nHere is the output schema:\n\n{\"properties\": {\"flower_type\": {\"title\": \"Flower Type\", \"description\": \"\\u9c9c\\u82b1\\u7684\\u79cd\\u7c7b\", \"type\": \"string\"}, \"price\": {\"title\": \"Price\", \"description\": \"\\u9c9c\\u82b1\\u7684\\u4ef7\\u683c\", \"type\": \"integer\"}, \"description\": {\"title\": \"Description\", \"description\": \"\\u9c9c\\u82b1\\u7684\\u63cf\\u8ff0\\u6587\\u6848\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"\\u4e3a\\u4ec0\\u4e48\\u8981\\u8fd9\\u6837\\u5199\\u8fd9\\u4e2a\\u6587\\u6848\", \"type\": \"string\"}}, \"required\": [\"flower_type\", \"price\", \"description\", \"reason\"]}\n\n```\n\n上面这个输出，这部分是通过output\\_parser.get\\_format\\_instructions()方法生成的，这是Pydantic (JSON) 解析器的核心价值，值得你好好研究研究。同时它也算得上是一个很清晰的提示模板，能够为模型提供良好的指导，描述了模型输出应该符合的格式。（其中description中的中文被转成了UTF-8编码。）\n\n它指示模型输出JSON Schema的形式，定义了一个有效的输出应该包含哪些字段，以及这些字段的数据类型。例如，它指定了 `\"flower_type\"` 字段应该是字符串类型， `\"price\"` 字段应该是整数类型。这个指示中还提供了一个例子，说明了什么是一个格式良好的输出。\n\n下面，我们会把这个内容也传输到模型的提示中， **让输入模型的提示和输出解析器的要求相互吻合，前后就呼应得上**。\n\n### 第四步：创建提示模板\n\n我们定义了一个提示模板，该模板将用于为模型生成输入提示。模板中包含了你需要模型填充的变量（如价格和花的种类），以及之前获取的输出格式指示。\n\n```plain\n# ------Part 4\n# 创建提示模板\nfrom langchain import PromptTemplate\nprompt_template = \"\"\"您是一位专业的鲜花店文案撰写员。\n对于售价为 {price} 元的 {flower} ，您能提供一个吸引人的简短中文描述吗？\n{format_instructions}\"\"\"\n\n# 根据模板创建提示，同时在提示中加入输出解析器的说明\nprompt = PromptTemplate.from_template(prompt_template,\n       partial_variables={\"format_instructions\": format_instructions})\n\n# 打印提示\nprint(\"提示：\", prompt)\n\n```\n\n输出：\n\n````plain\n提示：\ninput_variables=['flower', 'price']\n\noutput_parser=None\n\npartial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\n\nAs an example, for the schema {\n\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}},\n\"required\": [\"foo\"]}}\\n\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema.\nThe object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\n\nHere is the output schema:\\n```\\n\n{\"properties\": {\n\"flower_type\": {\"title\": \"Flower Type\", \"description\": \"\\\\u9c9c\\\\u82b1\\\\u7684\\\\u79cd\\\\u7c7b\", \"type\": \"string\"},\n\"price\": {\"title\": \"Price\", \"description\": \"\\\\u9c9c\\\\u82b1\\\\u7684\\\\u4ef7\\\\u683c\", \"type\": \"integer\"},\n\"description\": {\"title\": \"Description\", \"description\": \"\\\\u9c9c\\\\u82b1\\\\u7684\\\\u63cf\\\\u8ff0\\\\u6587\\\\u6848\", \"type\": \"string\"},\n\"reason\": {\"title\": \"Reason\", \"description\": \"\\\\u4e3a\\\\u4ec0\\\\u4e48\\\\u8981\\\\u8fd9\\\\u6837\\\\u5199\\\\u8fd9\\\\u4e2a\\\\u6587\\\\u6848\", \"type\": \"string\"}},\n\"required\": [\"flower_type\", \"price\", \"description\", \"reason\"]}\\n```'}\n\ntemplate='您是一位专业的鲜花店文案撰写员。\n\\n对于售价为 {price} 元的 {flower} ，您能提供一个吸引人的简短中文描述吗？\\n\n{format_instructions}'\n\ntemplate_format='f-string'\n\nvalidate_template=True\n\n````\n\n这就是包含了format\\_instructions信息的提示模板。\n\n1. `input_variables=['flower', 'price']`：这是一个包含你想要在模板中使用的输入变量的列表。我们在模板中使用了 `'flower'` 和 `'price'` 两个变量，后面我们会用具体的值（如玫瑰、20元）来替换这两个变量。\n2. `output_parser=None`：这是你可以选择在模板中使用的一个输出解析器。在此例中，我们并没有选择在模板中使用输出解析器，而是在模型外部进行输出解析，所以这里是 `None`。\n3. `partial_variables`：包含了你想要在模板中使用，但在生成模板时无法立即提供的变量。在这里，我们通过 `'format_instructions'` 传入输出格式的详细说明。\n4. `template`：这是模板字符串本身。它包含了你想要模型生成的文本的结构。在此例中，模板字符串是你询问鲜花描述的问题，以及关于输出格式的说明。\n5. `template_format='f-string'`：这是一个表示模板字符串格式的选项。此处是f-string格式。\n6. `validate_template=True`：表示是否在创建模板时检查模板的有效性。这里选择了在创建模板时进行检查，以确保模板是有效的。\n\n总的来说，这个提示模板是一个用于生成模型输入的工具。你可以在模板中定义需要的输入变量，以及模板字符串的格式和结构，然后使用这个模板来为每种鲜花生成一个描述。\n\n后面，我们还要把实际的信息，循环传入提示模板，生成一个个的具体提示。下面让我们继续。\n\n### 第五步：生成提示，传入模型并解析输出\n\n这部分是程序的主体，我们循环来处理所有的花和它们的价格。对于每种花，都根据提示模板创建了输入，然后获取模型的输出。然后使用之前创建的解析器来解析这个输出，并将解析后的输出添加到DataFrame中。最后，你打印出了所有的结果，并且可以选择将其保存到CSV文件中。\n\n```plain\n# ------Part 5\nfor flower, price in zip(flowers, prices):\n    # 根据提示准备模型的输入\n    input = prompt.format(flower=flower, price=price)\n    # 打印提示\n    print(\"提示：\", input)\n\n    # 获取模型的输出\n    output = model(input)\n\n    # 解析模型的输出\n    parsed_output = output_parser.parse(output)\n    parsed_output_dict = parsed_output.dict()  # 将Pydantic格式转换为字典\n\n    # 将解析后的输出添加到DataFrame中\n    df.loc[len(df)] = parsed_output.dict()\n\n# 打印字典\nprint(\"输出的数据：\", df.to_dict(orient='records'))\n\n```\n\n这一步中，你使用你的模型和输入提示（由鲜花种类和价格组成）生成了一个具体鲜花的文案需求（同时带有格式描述），然后传递给大模型，也就是说，提示模板中的 flower 和 price，此时都被具体的花取代了，而且模板中的 {format\\_instructions}，也被替换成了 JSON Schema 中指明的格式信息。\n\n具体来说，输出的一个提示是这样的：\n\n> **提示**： 您是一位专业的鲜花店文案撰写员。\n>\n> 对于售价为 20 元的 康乃馨 ，您能提供一个吸引人的简短中文描述吗？\n>\n> The output should be formatted as a JSON instance that conforms to the JSON schema below.\n>\n> As an example, for the schema {“properties”: {“foo”: {“title”: “Foo”, “description”: “a list of strings”, “type”: “array”, “items”: {“type”: “string”}}}, “required”: \\[“foo”\\]}}\n>\n> the object {“foo”: \\[“bar”, “baz”\\]} is a well-formatted instance of the schema. The object {“properties”: {“foo”: \\[“bar”, “baz”\\]}} is not well-formatted.\n>\n> Here is the output schema:\n>\n> ```\n> {\"properties\": {\"flower_type\": {\"title\": \"Flower Type\", \"description\": \"\\u9c9c\\u82b1\\u7684\\u79cd\\u7c7b\", \"type\": \"string\"}, \"price\": {\"title\": \"Price\", \"description\": \"\\u9c9c\\u82b1\\u7684\\u4ef7\\u683c\", \"type\": \"integer\"}, \"description\": {\"title\": \"Description\", \"description\": \"\\u9c9c\\u82b1\\u7684\\u63cf\\u8ff0\\u6587\\u6848\", \"type\": \"string\"}, \"reason\": {\"title\": \"Reason\", \"description\": \"\\u4e3a\\u4ec0\\u4e48\\u8981\\u8fd9\\u6837\\u5199\\u8fd9\\u4e2a\\u6587\\u6848\", \"type\": \"string\"}}, \"required\": [\"flower_type\", \"price\", \"description\", \"reason\"]}\n>\n> ```\n\n下面，程序解析模型的输出。在这一步中，你使用你之前定义的输出解析器（output\\_parser）将模型的输出解析成了一个FlowerDescription的实例。FlowerDescription是你之前定义的一个Pydantic类，它包含了鲜花的类型、价格、描述以及描述的理由。\n\n然后，将解析后的输出添加到DataFrame中。在这一步中，你将解析后的输出（即FlowerDescription实例）转换为一个字典，并将这个字典添加到你的DataFrame中。这个DataFrame是你用来存储所有鲜花描述的。\n\n模型的最后输出如下：\n\n```plain\n输出的数据：\n[{'flower_type': 'Rose', 'price': 50, 'description': '玫瑰是最浪漫的花，它具有柔和的粉红色，有着浓浓的爱意，价格实惠，50元就可以拥有一束玫瑰。', 'reason': '玫瑰代表着爱情，是最浪漫的礼物，以实惠的价格，可以让您尽情体验爱的浪漫。'},\n{'flower_type': '百合', 'price': 30, 'description': '这支百合，柔美的花蕾，在你的手中摇曳，仿佛在与你深情的交谈', 'reason': '营造浪漫氛围'},\n{'flower_type': 'Carnation', 'price': 20, 'description': '艳丽缤纷的康乃馨，带给你温馨、浪漫的气氛，是最佳的礼物选择！', 'reason': '康乃馨是一种颜色鲜艳、芬芳淡雅、具有浪漫寓意的鲜花，非常适合作为礼物，而且20元的价格比较实惠。'}]\n\n```\n\n因此，Pydantic的优点就是容易解析，而解析之后的字典格式的列表在进行数据分析、处理和存储时非常方便。每个字典代表一条记录，它的键（ 即 `\"flower_type\"`、 `\"price\"`、 `\"description\"` 和 `\"reason\"`）是字段名称，对应的值是这个字段的内容。这样一来，每个字段都对应一列，每个字典就是一行，适合以DataFrame的形式来表示和处理。\n\n## 自动修复解析器（OutputFixingParser）实战\n\n下面咱们来看看如何使用自动修复解析器。\n\n首先，让我们来设计一个解析时出现的错误。\n\n```plain\n# 导入所需要的库和模块\nfrom langchain.output_parsers import PydanticOutputParser\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\n# 使用Pydantic创建一个数据格式，表示花\nclass Flower(BaseModel):\n    name: str = Field(description=\"name of a flower\")\n    colors: List[str] = Field(description=\"the colors of this flower\")\n# 定义一个用于获取某种花的颜色列表的查询\nflower_query = \"Generate the charaters for a random flower.\"\n\n# 定义一个格式不正确的输出\nmisformatted = \"{'name': '康乃馨', 'colors': ['粉红色','白色','红色','紫色','黄色']}\"\n\n# 创建一个用于解析输出的Pydantic解析器，此处希望解析为Flower格式\nparser = PydanticOutputParser(pydantic_object=Flower)\n# 使用Pydantic解析器解析不正确的输出\nparser.parse(misformatted)\n\n```\n\n这段代码如果运行，会出现错误。\n\n```plain\nlangchain.schema.output_parser.OutputParserException: Failed to parse Flower from completion {'name': '康乃馨', 'colors': ['粉红色','白色']}. Got: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n\n```\n\n这个错误消息来自Python的内建JSON解析器发现我们输入的JSON格式不正确。程序尝试用PydanticOutputParser来解析JSON字符串时，Python期望属性名称被双引号包围，但在给定的JSON字符串中是单引号。\n\n当这个错误被触发后，程序进一步引发了一个自定义异常：OutputParserException，它提供了更多关于错误的上下文。这个自定义异常的消息表示在尝试解析flower对象时遇到了问题。\n\n刚才说了，问题在于misformatted字符串的内容：\n\n`\"{'name': '康乃馨', 'colors': ['粉红色','白色','红色','紫色','黄色']}\"`\n\n应该改为：\n\n`'{\"name\": \"康乃馨\", \"colors\": [\"粉红色\",\"白色\",\"红色\",\"紫色\",\"黄色\"]}'`\n\n这样，你的JSON字符串就会使用正确的双引号格式，应该可以被正确地解析。\n\n不过，这里我并不想这样解决问题，而是尝试使用OutputFixingParser来帮助咱们自动解决类似的格式错误。\n\n```plain\n# 从langchain库导入所需的模块\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.output_parsers import OutputFixingParser\n\n# 设置OpenAI API密钥\nimport os\nos.environ[\"OPENAI_API_KEY\"] = '你的OpenAI API Key'\n\n# 使用OutputFixingParser创建一个新的解析器，该解析器能够纠正格式不正确的输出\nnew_parser = OutputFixingParser.from_llm(parser=parser, llm=ChatOpenAI())\n\n# 使用新的解析器解析不正确的输出\nresult = new_parser.parse(misformatted) # 错误被自动修正\nprint(result) # 打印解析后的输出结果\n\n```\n\n用上面的新的new\\_parser来代替Parser进行解析，你会发现，JSON格式的错误问题被解决了，程序不再出错。\n\n输出如下：\n\n```plain\nname='Rose' colors=['red', 'pink', 'white']\n\n```\n\n这里的秘密在于，在OutputFixingParser内部，调用了原有的PydanticOutputParser，如果成功，就返回；如果失败，它会将格式错误的输出以及格式化的指令传递给大模型，并要求LLM进行相关的修复。\n\n神奇吧，大模型不仅给我们提供知识，还随时帮助分析并解决程序出错的信息。\n\n## 重试解析器（RetryWithErrorOutputParser）实战\n\nOutputFixingParser不错，但它只能做简单的格式修复。如果出错的不只是格式，比如，输出根本不完整，有缺失内容，那么仅仅根据输出和格式本身，是无法修复它的。\n\n此时，通过实现输出解析器中parse\\_with\\_prompt方法，LangChain提供的重试解析器可以帮助我们利用大模型的推理能力根据原始提示找回相关信息。\n\n我们通过分析一个重试解析器的用例来理解上面的这段话。\n\n首先还是设计一个解析过程中的错误。\n\n```plain\n# 定义一个模板字符串，这个模板将用于生成提问\ntemplate = \"\"\"Based on the user question, provide an Action and Action Input for what step should be taken.\n{format_instructions}\nQuestion: {query}\nResponse:\"\"\"\n\n# 定义一个Pydantic数据格式，它描述了一个\"行动\"类及其属性\nfrom pydantic import BaseModel, Field\nclass Action(BaseModel):\n    action: str = Field(description=\"action to take\")\n    action_input: str = Field(description=\"input to the action\")\n\n# 使用Pydantic格式Action来初始化一个输出解析器\nfrom langchain.output_parsers import PydanticOutputParser\nparser = PydanticOutputParser(pydantic_object=Action)\n\n# 定义一个提示模板，它将用于向模型提问\nfrom langchain.prompts import PromptTemplate\nprompt = PromptTemplate(\n    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n    input_variables=[\"query\"],\n    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n)\nprompt_value = prompt.format_prompt(query=\"What are the colors of Orchid?\")\n\n# 定义一个错误格式的字符串\nbad_response = '{\"action\": \"search\"}'\nparser.parse(bad_response) # 如果直接解析，它会引发一个错误\n\n```\n\n由于bad\\_response只提供了action字段，而没有提供action\\_input字段，这与Action数据格式的预期不符，所以解析会失败。\n\n我们首先尝试用OutputFixingParser来解决这个错误。\n\n```plain\nfrom langchain.output_parsers import OutputFixingParser\nfrom langchain.chat_models import ChatOpenAI\nfix_parser = OutputFixingParser.from_llm(parser=parser, llm=ChatOpenAI())\nparse_result = fix_parser.parse(bad_response)\nprint('OutputFixingParser的parse结果:',parse_result)\n\n```\n\nOutputFixingParser的parse结果： `action='search' action_input='query'`\n\n我们来看看这个尝试解决了什么问题，没解决什么问题。\n\n**解决的问题有：**\n\n- 不完整的数据：原始的bad\\_response只提供了action字段而没有action\\_input字段。OutputFixingParser已经填补了这个缺失，为action\\_input字段提供了值 `'query'`。\n\n**没解决的问题有：**\n\n- 具体性：尽管OutputFixingParser为action\\_input字段提供了默认值 `'query'`，但这并不具有描述性。真正的查询是 “Orchid（兰花）的颜色是什么？”。所以，这个修复只是提供了一个通用的值，并没有真正地回答用户的问题。\n- 可能的误导： `'query'` 可能被误解为一个指示，要求进一步查询某些内容，而不是作为实际的查询输入。\n\n当然，还有更鲁棒的选择，我们最后尝试一下RetryWithErrorOutputParser这个解析器。\n\n```plain\n# 初始化RetryWithErrorOutputParser，它会尝试再次提问来得到一个正确的输出\nfrom langchain.output_parsers import RetryWithErrorOutputParser\nfrom langchain.llms import OpenAI\nretry_parser = RetryWithErrorOutputParser.from_llm(\n    parser=parser, llm=OpenAI(temperature=0)\n)\nparse_result = retry_parser.parse_with_prompt(bad_response, prompt_value)\nprint('RetryWithErrorOutputParser的parse结果:',parse_result)\n\n```\n\n这个解析器没有让我们失望，成功地还原了格式，甚至也根据传入的原始提示，还原了action\\_input字段的内容。\n\nRetryWithErrorOutputParser的parse结果： `action='search' action_input='colors of Orchid'`\n\n## 总结时刻\n\n结构化解析器和Pydantic解析器都旨在从大型语言模型中获取格式化的输出。结构化解析器更适合简单的文本响应，而Pydantic解析器则提供了对复杂数据结构和类型的支持。选择哪种解析器取决于应用的具体需求和输出的复杂性。\n\n自动修复解析器主要适用于纠正小的格式错误，它更加“被动”，仅在原始输出出现问题时进行修复。重试解析器则可以处理更复杂的问题，包括格式错误和内容缺失。它通过重新与模型交互，使得输出更加完整和符合预期。\n\n在选择哪种解析器时，需要考虑具体的应用场景。如果仅面临格式问题，自动修复解析器可能足够；但如果输出的完整性和准确性至关重要，那么重试解析器可能是更好的选择。\n\n## 思考题\n\n1. 到目前为止，我们已经使用了哪些LangChain输出解析器？请你说一说它们的用法和异同。同时也请你尝试使用其他类型的输出解析器，并把代码与大家分享。\n2. 为什么大模型能够返回JSON格式的数据，输出解析器用了什么魔法让大模型做到了这一点？\n3. 自动修复解析器的“修复”功能具体来说是怎样实现的？请做debug，研究一下LangChain在调用大模型之前如何设计“提示”。\n4. 重试解析器的原理是什么？它主要实现了解析器类的哪个可选方法？\n\n题目较多，可以选择性思考，期待在留言区看到你的分享。如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。\n\n## 延伸阅读\n\n1. 工具： [Pydantic](https://docs.pydantic.dev/latest/) 是一个Python库，用于数据验证，可以确保数据符合特定的格式\n2. 文档：LangChain中的各种 [Output Parsers](https://python.langchain.com/docs/modules/model_io/output_parsers/)"},{"url":"/posts/7.html","content":"# 09｜链（下）：想学“育花”还是“插花”？用RouterChain确定客户意图\n你好，我是黄佳。欢迎来到LangChain实战课！\n\n上一节课中，我带着你学习了Chain的基本概念，还使用了LLMChain和SequencialChain，这一节课，我们再来看看其他类型的一些Chain的用法。\n\n## 任务设定\n\n首先，还是先看一下今天要完成一个什么样的任务。\n\n这里假设咱们的鲜花运营智能客服ChatBot通常会接到两大类问题。\n\n1. **鲜花养护**（保持花的健康、如何浇水、施肥等）\n2. **鲜花装饰**（如何搭配花、如何装饰场地等）\n\n你的需求是， **如果接到的是第一类问题，你要给ChatBot A指示；如果接到第二类的问题，你要给ChatBot B指示**。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/d8491e696c03f49a331c94e31d20e559.jpg)\n\n我们可以根据这两个场景来构建两个不同的目标链。遇到不同类型的问题，LangChain会通过RouterChain来自动引导大语言模型选择不同的模板。\n\n当然我们的运营过程会遇到更多种类的问题，你只需要通过同样的方法扩充逻辑即可。\n\n## 整体框架\n\nRouterChain，也叫路由链，能动态选择用于给定输入的下一个链。我们会根据用户的问题内容，首先使用路由器链确定问题更适合哪个处理模板，然后将问题发送到该处理模板进行回答。如果问题不适合任何已定义的处理模板，它会被发送到默认链。\n\n在这里，我们会用LLMRouterChain和MultiPromptChain（也是一种路由链）组合实现路由功能，该MultiPromptChain会调用LLMRouterChain选择与给定问题最相关的提示，然后使用该提示回答问题。\n\n**具体步骤如下：**\n\n1. 构建处理模板：为鲜花护理和鲜花装饰分别定义两个字符串模板。\n2. 提示信息：使用一个列表来组织和存储这两个处理模板的关键信息，如模板的键、描述和实际内容。\n3. 初始化语言模型：导入并实例化语言模型。\n4. 构建目标链：根据提示信息中的每个模板构建了对应的LLMChain，并存储在一个字典中。\n5. 构建LLM路由链：这是决策的核心部分。首先，它根据提示信息构建了一个路由模板，然后使用这个模板创建了一个LLMRouterChain。\n6. 构建默认链：如果输入不适合任何已定义的处理模板，这个默认链会被触发。\n7. 构建多提示链：使用MultiPromptChain将LLM路由链、目标链和默认链组合在一起，形成一个完整的决策系统。\n\n## 具体实现\n\n下面，就是用路由链自动选择处理模板的具体代码实现。\n\n### 构建提示信息的模板\n\n首先，我们针对两种场景，构建两个提示信息的模板。\n\n```plain\n# 构建两个场景的模板\nflower_care_template = \"\"\"你是一个经验丰富的园丁，擅长解答关于养花育花的问题。\n                        下面是需要你来回答的问题:\n                        {input}\"\"\"\n\nflower_deco_template = \"\"\"你是一位网红插花大师，擅长解答关于鲜花装饰的问题。\n                        下面是需要你来回答的问题:\n                        {input}\"\"\"\n\n# 构建提示信息\nprompt_infos = [\n    {\n        \"key\": \"flower_care\",\n        \"description\": \"适合回答关于鲜花护理的问题\",\n        \"template\": flower_care_template,\n    },\n    {\n        \"key\": \"flower_decoration\",\n        \"description\": \"适合回答关于鲜花装饰的问题\",\n        \"template\": flower_deco_template,\n    }]\n\n```\n\n### 初始化语言模型\n\n接下来，我们初始化语言模型。\n\n```plain\n# 初始化语言模型\nfrom langchain.llms import OpenAI\nimport os\nos.environ[\"OPENAI_API_KEY\"] = '你的OpenAI Key'\nllm = OpenAI()\n\n```\n\n### 构建目标链\n\n下面，我们循环prompt\\_infos这个列表，构建出两个目标链，分别负责处理不同的问题。\n\n```plain\n# 构建目标链\nfrom langchain.chains.llm import LLMChain\nfrom langchain.prompts import PromptTemplate\nchain_map = {}\nfor info in prompt_infos:\n    prompt = PromptTemplate(template=info['template'],\n                            input_variables=[\"input\"])\n    print(\"目标提示:\\n\",prompt)\n    chain = LLMChain(llm=llm, prompt=prompt,verbose=True)\n    chain_map[info[\"key\"]] = chain\n\n```\n\n这里，目标链提示是这样的：\n\n```plain\n目标提示:\ninput_variables=['input']\noutput_parser=None partial_variables={}\ntemplate='你是一个经验丰富的园丁，擅长解答关于养花育花的问题。\\n                        下面是需要你来回答的问题:\\n\n{input}' template_format='f-string'\nvalidate_template=True\n\n目标提示:\ninput_variables=['input']\noutput_parser=None partial_variables={}\ntemplate='你是一位网红插花大师，擅长解答关于鲜花装饰的问题。\\n                        下面是需要你来回答的问题:\\n\n{input}' template_format='f-string'\nvalidate_template=True\n\n```\n\n对于每个场景，我们创建一个 LLMChain（语言模型链）。每个链会根据其场景模板生成对应的提示，然后将这个提示送入语言模型获取答案。\n\n### 构建路由链\n\n下面，我们构建路由链，负责查看用户输入的问题，确定问题的类型。\n\n```plain\n# 构建路由链\nfrom langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\nfrom langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE as RounterTemplate\ndestinations = [f\"{p['key']}: {p['description']}\" for p in prompt_infos]\nrouter_template = RounterTemplate.format(destinations=\"\\n\".join(destinations))\nprint(\"路由模板:\\n\",router_template)\nrouter_prompt = PromptTemplate(\n    template=router_template,\n    input_variables=[\"input\"],\n    output_parser=RouterOutputParser(),)\nprint(\"路由提示:\\n\",router_prompt)\nrouter_chain = LLMRouterChain.from_llm(llm,\n                                       router_prompt,\n                                       verbose=True)\n\n```\n\n输出：\n\n````\n路由模板:\n Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n\n<< FORMATTING >>\nReturn a markdown code snippet with a JSON object formatted to look like:\n```json\n{{\n    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n    \"next_inputs\": string \\ a potentially modified version of the original input\n}}\n```\n\nREMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\nREMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n\n<< CANDIDATE PROMPTS >>\nflower_care: 适合回答关于鲜花护理的问题\nflower_decoration: 适合回答关于鲜花装饰的问题\n\n<< INPUT >>\n{input}\n\n<< OUTPUT >>\n\n路由提示:\ninput_variables=['input'] output_parser=RouterOutputParser(default_destination='DEFAULT', next_inputs_type=<class 'str'>, next_inputs_inner_key='input')\npartial_variables={}\ntemplate='Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\\n\\n\n<< FORMATTING >>\\n\nReturn a markdown code snippet with a JSON object formatted to look like:\\n```json\\n{{\\n \"destination\": string \\\\ name of the prompt to use or \"DEFAULT\"\\n    \"next_inputs\": string \\\\ a potentially modified version of the original input\\n}}\\n```\\n\\n\nREMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\\n\nREMEMBER: \"next_inputs\" can just be the original input if you don\\'t think any modifications are needed.\\n\\n<< CANDIDATE PROMPTS >>\\n\nflower_care: 适合回答关于鲜花护理的问题\\n\nflower_decoration: 适合回答关于鲜花装饰的问题\\n\\n\n<< INPUT >>\\n{input}\\n\\n<< OUTPUT >>\\n'\ntemplate_format='f-string'\nvalidate_template=True\n\n````\n\n这里我说一下路由器链是如何构造提示信息，来引导大模型查看用户输入的问题并确定问题的类型的。\n\n先看路由模板部分，这段模板字符串是一个指导性的说明，目的是引导语言模型正确处理用户的输入，并将其定向到适当的模型提示。\n\n**1\\. 路由模板的解释**\n\n路由模板是路由功能得以实现的核心。我们来详细分解一下这个模板的每个部分。\n\n**引言**\n\n> Given a raw text input to a language model select the model prompt best suited for the input.\n\n这是一个简单的引导语句，告诉模型你将给它一个输入，它需要根据这个输入选择最适合的模型提示。\n\n> You will be given the names of the available prompts and a description of what the prompt is best suited for.\n\n这里进一步提醒模型，它将获得各种模型提示的名称和描述。\n\n> You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n\n这是一个可选的步骤，告诉模型它可以更改原始输入以获得更好的响应。\n\n**格式说明(<< FORMATTING >>)**\n\n指导模型如何格式化其输出，使其以特定的方式返回结果。\n\n> Return a markdown code snippet with a JSON object formatted to look like:\n\n表示模型的输出应该是一个 Markdown 代码片段，其中包含一个特定格式的 JSON 对象。\n\n下面的代码块显示了期望的 JSON 结构，其中 destination 是模型选择的提示名称（或“DEFAULT”），而 next\\_inputs 是可能被修订的原始输入。\n\n**额外的说明和要求**\n\n> REMEMBER: “destination” MUST be one of the candidate prompt names specified below OR it can be “DEFAULT”…\n\n这是一个重要的指导，提醒模型 “destination” 字段的值必须是下面列出的提示之一或是 “DEFAULT”。\n\n> REMEMBER: “next\\_inputs” can just be the original input if you don’t think any modifications are needed.\n\n这再次强调，除非模型认为有必要，否则原始输入不需要修改。\n\n**候选提示(<< CANDIDATE PROMPTS >>)**\n\n列出了两个示例模型提示及其描述：\n\n- “flower\\_care: 适合回答关于鲜花护理的问题”，适合处理与花卉护理相关的问题。\n- “flower\\_decoration: 适合回答关于鲜花装饰的问题”，适合处理与花卉装饰相关的问题。\n\n**输入/输出部分**\n\n> << INPUT >>\\\\n{input}\\\\n\\\\n<< OUTPUT >>\\\\n：\n\n这部分为模型提供了一个格式化的框架，其中它将接收一个名为 {input} 的输入，并在此后的部分输出结果。\n\n总的来说，这个模板的目的是让模型知道如何处理用户的输入，并根据提供的提示列表选择一个最佳的模型提示来回应。\n\n**2\\. 路由提示的解释**\n\n路由提示 (router\\_prompt）则根据路由模板，生成了具体传递给LLM的路由提示信息。\n\n- 其中input\\_variables 指定模板接收的输入变量名，这里只有 `\"input\"`。\n- output\\_parser 是一个用于解析模型输出的对象，它有一个默认的目的地和一个指向下一输入的键。\n- template 是实际的路由模板，用于给模型提供指示。这就是刚才详细解释的模板内容。\n- template\\_format 指定模板的格式，这里是 `\"f-string\"`。\n- validate\\_template 是一个布尔值，如果为 True，则会在使用模板前验证其有效性。\n\n简而言之，这个构造允许你将用户的原始输入送入路由器，然后路由器会决定将该输入发送到哪个具体的模型提示，或者是否需要对输入进行修订以获得最佳的响应。\n\n### 构建默认链\n\n除了处理目标链和路由链之外，我们还需要准备一个默认链。如果路由链没有找到适合的链，那么，就以默认链进行处理。\n\n```plain\n# 构建默认链\nfrom langchain.chains import ConversationChain\ndefault_chain = ConversationChain(llm=llm,\n                                  output_key=\"text\",\n                                  verbose=True)\n\n```\n\n### 构建多提示链\n\n最后，我们使用MultiPromptChain类把前几个链整合在一起，实现路由功能。这个MultiPromptChain类是一个多路选择链，它使用一个LLM路由器链在多个提示之间进行选择。\n\n**MultiPromptChain中有三个关键元素。**\n\n- router\\_chain（类型RouterChain）：这是用于决定目标链和其输入的链。当给定某个输入时，这个router\\_chain决定哪一个destination\\_chain应该被选中，以及传给它的具体输入是什么。\n- destination\\_chains（类型Mapping\\[str, LLMChain\\]）：这是一个映射，将名称映射到可以将输入路由到的候选链。例如，你可能有多种处理文本输入的方法（或“链”），每种方法针对特定类型的问题。destination\\_chains可以是这样一个字典： `{'weather': weather_chain, 'news': news_chain}`。在这里，weather\\_chain可能专门处理与天气相关的问题，而news\\_chain处理与新闻相关的问题。\n- default\\_chain（类型LLMChain）：当 router\\_chain 无法将输入映射到destination\\_chains中的任何一个链时，LLMChain 将使用此默认链。这是一个备选方案，确保即使路由器不能决定正确的链，也总有一个链可以处理输入。\n\n**它的工作流程如下：**\n\n1. 输入首先传递给router\\_chain。\n2. router\\_chain根据某些标准或逻辑决定应该使用哪一个destination\\_chain。\n3. 输入随后被路由到选定的destination\\_chain，该链进行处理并返回结果。\n4. 如果router\\_chain不能决定正确的destination\\_chain，则输入会被传递给default\\_chain。\n\n这样，MultiPromptChain就为我们提供了一个在多个处理链之间动态路由输入的机制，以得到最相关或最优的输出。\n\n实现代码如下：\n\n```plain\n# 构建多提示链\nfrom langchain.chains.router import MultiPromptChain\nchain = MultiPromptChain(\n    router_chain=router_chain,\n    destination_chains=chain_map,\n    default_chain=default_chain,\n    verbose=True)\n\n```\n\n## 运行路由链\n\n好了，至此我们的链路已经准备好了。现在开始提出各种问题，测试一下我们的链。\n\n**测试A：**\n\nprint(chain.run(“如何为玫瑰浇水？”))\n\n输出：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/89d0bfac97b259b93240a10cf777d9a2.png)\n\n**测试B：**\n\nprint(chain.run(“如何为婚礼场地装饰花朵？”))\n\n输出：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/4f848ca6592476358a25bf91996aa0ed.png)\n\n**测试C：**\n\nprint(chain.run(“如何考入哈佛大学？”))\n\n输出：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/acd4a69df2cef81b1f7bcf33f9b4bb12.png)\n\n这三个测试，分别被路由到了三个不同的目标链，其中两个是我们预设的“专家类型”目标链，而第三个问题：如何考入哈佛大学？被模型一眼看穿，并不属于任何鲜花运营业务场景，路由链把它抛入了一个 “default chain” —— ConversationChain 去解决。\n\n## 总结时刻\n\n在这个示例中，我们看到了LLMRouterChain以及MultiPromptChain。其中，LLMRouterChain继承自RouterChain；而MultiPromptChain则继承自MultiRouteChain。\n\n整体上，我们通过MultiPromptChain把其他链组织起来，完成了路由功能。\n\n```plain\nchain = MultiPromptChain(\n    router_chain=router_chain,\n    destination_chains=chain_map,\n    default_chain=default_chain,\n    verbose=True)\n\n```\n\n在LangChain的 chains -> router -> base.py 文件中，可以看到RouterChain和MultiRouteChain的代码实现。\n\n## 思考题\n\n1. 通过verbose=True这个选项的设定，在输出时显示了链的开始和结束日志，从而得到其相互调用流程。请你尝试把该选项设置为False，看一看输出结果有何不同。\n2. 在这个例子中，我们使用了ConversationChain作为default\\_chain，这个Chain是LLMChain的子类，你能否把这个Chain替换为LLMChain？\n\n期待在留言区看到你的分享。如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。\n\n## 延伸阅读\n\n1. 代码，RouterChain和MultiRouteChain的 [实现细节](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/chains/router/base.py)\n2. 代码，MultiPromptChain的 [实现细节](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/chains/router/multi_prompt.py)"},{"url":"/posts/8.html","content":"# 11｜代理（上）：ReAct框架，推理与行动的协同\n你好，我是黄佳，欢迎来到LangChain实战课！\n\n在之前介绍的思维链（CoT）中，我向你展示了 LLMs 执行推理轨迹的能力。在给出答案之前，大模型通过中间推理步骤（尤其是与少样本提示相结合）能够实现复杂的推理，获得更好的结果，以完成更具挑战的任务。\n\n然而，仅仅应用思维链推理并不能解决大模型的固有问题： **无法主动更新自己的知识，导致出现事实幻觉**。也就是说，因为缺乏和外部世界的接触，大模型只拥有训练时见过的知识，以及提示信息中作为上下文提供的附加知识。如果你问的问题超出它的知识范围，要么大模型向你坦白：“我的训练时间截至XXXX年XX月XX日”，要么它就会开始一本正经地胡说。\n\n下面这张图就属于第二种情况，我制作的一个Prompt骗过了大模型，它会误以为我引述的很多虚构的东西是事实，而且它还会顺着这个思路继续胡编乱造。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/50050ee434877dc4617a7cfe49386a45.png)\n\n这个问题如何解决呢？\n\n也不难。你可以让大模型先在本地知识库中进行搜索，检查一下提示中的信息的真实性，如果真实，再进行输出；如果不真实，则进行修正。如果本地知识库找不到相应的信息，可以调用工具进行外部搜索，来检查提示信息的真实性。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/7032d003ac36e858cbb53f90bb4f3a1b.jpg)\n\n上面所说的无论本地知识库还是搜索引擎，都不是封装在大模型内部的知识，我们把它们称为“外部工具”。\n\n## 代理的作用\n\n每当你遇到这种需要模型做自主判断、自行调用工具、自行决定下一步行动的时候，Agent（也就是代理）就出场了。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/e26993dd3957bfd2947424abb9de7cde.png)\n\n代理就像一个多功能的接口，它能够接触并使用一套工具。根据用户的输入，代理会决定调用哪些工具。它不仅可以同时使用多种工具，而且可以将一个工具的输出数据作为另一个工具的输入数据。\n\n在LangChain中使用代理，我们只需要理解下面三个元素。\n\n- **大模型**：提供逻辑的引擎，负责生成预测和处理输入。\n- 与之交互的 **外部工具**：可能包括数据清洗工具、搜索引擎、应用程序等。\n- 控制交互的 **代理**：调用适当的外部工具，并管理整个交互过程的流程。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/9a9550e7df156d15975dc027b3201d31.png)\n\n上面的思路看似简单，其实很值得我们仔细琢磨。\n\n这个过程有很多地方需要大模型自主判断下一步行为（也就是操作）要做什么，如果不加引导，那大模型本身是不具备这个能力的。比如下面这一系列的操作：\n\n- 什么时候开始在本地知识库中搜索（这个比较简单，毕竟是第一个步骤，可以预设）？\n- 怎么确定本地知识库的检索已经完成，可以开始下一步？\n- 调用哪一种外部搜索工具（比如Google引擎）？\n- 如何确定外部搜索工具返回了想要找的内容？\n- 如何确定信息真实性的检索已经全部完成，可以开始下一步？\n\n那么，LangChain中的代理是怎样自主计划、自行判断，并执行行动的呢？\n\n## ReAct框架\n\n这里我要请你思考一下：如果你接到一个新任务，你将如何做出决策并完成下一步的行动？\n\n比如说，你在运营花店的过程中，经常会经历天气变化而导致的鲜花售价变化，那么，每天早上你会如何为你的鲜花定价？\n\n也许你会告诉我，我会去Google上面查一查今天的鲜花成本价啊（ **行动**），也就是我预计的进货的价格，然后我会根据这个价格的高低（ **观察**），来确定我要加价多少（ **思考**），最后计算出一个售价（ **行动**）！\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/58bdbe17948a0ed2d52ceb3557194a12.png)\n\n你看，在这个简单的例子中，你有观察、有思考，然后才会具体行动。这里的观察和思考，我们统称为推理（Reasoning）过程，推理指导着你的行动（Acting）。\n\n我们今天要讲的 **ReAct 框架的灵感正是来自“行动”和“推理”之间的协同作用，这种协同作用使得咱们人类能够学习新任务并做出决策或推理**。这个框架，也是大模型能够作为“智能代理”，自主、连续、交错地生成推理轨迹和任务特定操作的理论基础。\n\n先和你说明一点，此 ReAct 并非指代流行的前端开发框架React，它在这里专指如何指导大语言模型推理和行动的一种思维框架。这个思维框架是Shunyu Yao等人在ICLR 2023会议论文《 [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/pdf/2210.03629.pdf)》（ReAct：在语言模型中协同推理和行动）中提出的。\n\n这篇文章的一个关键启发在于： **大语言模型可以通过生成推理痕迹和任务特定行动来实现更大的协同作用**。\n\n具体来说，就是引导模型生成一个任务解决轨迹：观察环境-进行思考-采取行动，也就是观察-思考-行动。那么，再进一步进行简化，就变成了推理-行动，也就是Reasoning-Acting框架。\n\n其中，Reasoning包括了对当前环境和状态的观察，并生成推理轨迹。这使模型能够诱导、跟踪和更新操作计划，甚至处理异常情况。Acting在于指导大模型采取下一步的行动，比如与外部源（如知识库或环境）进行交互并且收集信息，或者给出最终答案。\n\nReAct的每一个推理过程都会被详细记录在案，这也改善大模型解决问题时的可解释性和可信度，而且这个框架在各种语言和决策任务中都得到了很好的效果。\n\n下面让我们用一个具体的示例来说明这一点。比如我给出大模型这样一个任务：在一个虚拟环境中找到一个胡椒瓶并将其放在一个抽屉里。\n\n在这个任务中，没有推理能力的模型不能够在房间的各个角落中进行寻找，或者在找到胡椒瓶之后不能够判断下一步的行动，因而无法完成任务。如果使用ReAct，这一系列子目标将被具体地捕获在每一个思考过程中。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/638e1b0098211b1b622283e0f7100596.png)\n\n现在，让我们回到开始的时候我们所面临的问题。仅仅使用思维链（CoT）提示，LLMs能够执行推理轨迹，以完成算术和常识推理等问题，但这样的模型因为缺乏和外部世界的接触或无法更新自己的知识，会导致幻觉的出现。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/1189768e0ae5b6199fd6db301d2401c8.png)\n\n而将 ReAct框架和思维链（CoT）结合使用，则能够让大模型在推理过程同时使用内部知识和获取到的外部信息，从而给出更可靠和实际的回应，也提高了 LLMs 的可解释性和可信度。\n\nLangChain正是通过Agent类，将ReAct框架进行了完美封装和实现，这一下子就赋予了大模型极大的自主性（Autonomy）， **你的大模型现在从一个仅仅可以通过自己内部知识进行对话聊天的** **Bot** **，** **飞升为了一个有手有脚能使用工具的智能代理**。\n\nReAct框架会提示 LLMs 为任务生成推理轨迹和操作，这使得代理能系统地执行动态推理来创建、维护和调整操作计划，同时还支持与外部环境（例如Google搜索、Wikipedia）的交互，以将额外信息合并到推理中。\n\n## 通过代理实现ReAct框架\n\n下面，就让我们用LangChain中最为常用的 **ZERO\\_SHOT\\_REACT\\_DESCRIPTION** ——这种常用代理类型，来剖析一下LLM是如何在ReAct框架的指导之下进行推理的。\n\n此处，我们要给代理一个任务，这个任务是找到玫瑰的当前市场价格，然后计算出加价15%后的新价格。\n\n在开始之前，有一个准备工作，就是你需要在 [serpapi.com](https://serpapi.com/) 注册一个账号，并且拿到你的 SERPAPI\\_API\\_KEY，这个就是我们要为大模型提供的 Google 搜索工具。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/1841f5d709cd27f1000ee9a5b593325b.png)\n\n先安装SerpAPI的包。\n\n```\npip install google-search-results\n\n```\n\n设置好OpenAI和SerpAPI的API密钥。\n\n```\n# 设置OpenAI和SERPAPI的API密钥\nimport os\nos.environ[\"OPENAI_API_KEY\"] = 'Your OpenAI API Key'\nos.environ[\"SERPAPI_API_KEY\"] = 'Your SerpAPI API Key'\n\n```\n\n再导入所需的库。\n\n```plain\nfrom langchain.agents import load_tools\nfrom langchain.agents import initialize_agent\nfrom langchain.agents import AgentType\nfrom langchain.llms import OpenAI\n\n```\n\n然后加载将用于控制代理的语言模型。\n\n```plain\nllm = OpenAI(temperature=0)\n\n```\n\n接下来，加载一些要使用的工具，包括serpapi（这是调用Google搜索引擎的工具）以及llm-math（这是通过LLM进行数学计算的工具）。\n\n```plain\ntools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n\n```\n\n最后，让我们使用工具、语言模型和代理类型来初始化代理。\n\n```plain\nagent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n\n```\n\n好了，现在我们让代理来回答我刚才提出的问题了！目前市场上玫瑰花的平均价格是多少？如果我在此基础上加价15%卖出，应该如何定价？\n\n```plain\nagent.run(\"目前市场上玫瑰花的平均价格是多少？如果我在此基础上加价15%卖出，应该如何定价？\")\n\n```\n\n大模型成功遵循了ReAct框架，它输出的思考与行动轨迹如下：\n\n```plain\n> Entering new  chain...\n I need to find the current market price of roses and then calculate the new price with a 15% markup.\nAction: Search\nAction Input: \"Average price of roses\"\nObservation: According to the study, the average price for a dozen roses in the United States is $80.16. The Empire State hovers closer to that number than its neighbors, with a bouquet setting back your average New Yorker $78.33.\nThought: I need to calculate the new price with a 15% markup.\nAction: Calculator\nAction Input: 80.16 * 1.15\nObservation: Answer: 92.18399999999998\nThought: I now know the final answer.\nFinal Answer: The new price with a 15% markup would be $92.18.\n> Finished chain.\n\n```\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/c99893b6d8311d9ac95aeb8d818e1914.png)\n\n可以看到，ZERO\\_SHOT\\_REACT\\_DESCRIPTION类型的智能代理在LangChain中，自动形成了一个完善的思考与行动链条，而且给出了正确的答案。\n\n你可以对照下面这个表格，再巩固一下这个链条中的每一个环节。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/56fbe79e086052895f301383c27f4a0c.jpg)\n\n这个思维链条中，智能代理有思考、有观察、有行动，成功通过搜索和计算两个操作，完成了任务。在下一讲中，我们将继续深入剖析LangChain中的不同类型的代理，并利用它完成更为复杂的任务。\n\n## 总结时刻\n\n这节课我们介绍了什么是LangChain中的代理，更重要的是，我们介绍了代理自主行动的驱动力—— ReAct框架。\n\n通过ReAct框架，大模型将被引导生成一个任务解决轨迹，即观察环境-进行思考-采取行动。观察和思考阶段被统称为推理（Reasoning），而实施下一步行动的阶段被称为行动（Acting）。在每一步推理过程中，都会详细记录下来，这也改善了大模型解决问题时的可解释性和可信度。\n\n- 在推理阶段，模型对当前环境和状态进行观察，并生成推理轨迹，从而使模型能够诱导、跟踪和更新操作计划，甚至处理异常情况。\n- 在行动阶段，模型会采取下一步的行动，如与外部源（如知识库或环境）进行交互并收集信息，或给出最终答案。\n\nReAct框架的这些优点，使得它在未来的发展中具有巨大的潜力。随着技术的进步，我们可以期待ReAct框架将能够处理更多、更复杂的任务。特别是随着具身智能的发展，ReAct框架将能够使智能代理在虚拟或实际环境中进行更复杂的交互。例如，智能代理可能会在虚拟环境中进行导航，或者在实际环境中操作物理对象。这将大大扩展AI的应用范围，使得它们能够更好地服务于我们的生活和工作。\n\n## 思考题\n\n1. 在ReAct框架中，推理和行动各自代表什么？其相互之间的关系如何？\n2. 为什么说ReAct框架能改善大模型解决问题时的可解释性和可信度？\n3. 你能否说一说LangChain中的代理和链的核心差异？\n\n期待在留言区看到你的思考，如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面延伸阅读的两篇论文。\n\n## 延伸阅读\n\n1. 论文， [ReAct：在语言模型中协同推理和行动](https://arxiv.org/abs/2210.03629)，Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2023). ReAct: Synergizing Reasoning and Acting in Language Models. arXiv preprint arXiv:2210.03629\n2. 论文， [ART：大型语言模型的自动多步推理和工具使用](https://arxiv.org/abs/2303.09014)， Paranjape, B., Lundberg, S., Singh, S., Hajishirzi, H., Zettlemoyer, L., & Ribeiro, M. T. (2023). ART: Automatic multi-step reasoning and tool-use for large language models. arXiv preprint arXiv:2303.09014."},{"url":"/posts/9.html","content":"# 10｜记忆：通过Memory记住客户上次买花时的对话细节\n你好，我是黄佳，欢迎来到LangChain实战课！\n\n在默认情况下，无论是LLM还是代理都是无状态的，每次模型的调用都是独立于其他交互的。也就是说，我们每次通过API开始和大语言模型展开一次新的对话，它都不知道你其实昨天或者前天曾经和它聊过天了。\n\n你肯定会说，不可能啊，每次和ChatGPT聊天的时候，ChatGPT明明白白地记得我之前交待过的事情。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/c9907bc695521228cdfb5d3f75c13897.png)\n\n的确如此，ChatGPT之所以能够记得你之前说过的话，正是因为它使用了 **记忆（Memory）机制**，记录了之前的对话上下文，并且把这个上下文作为提示的一部分，在最新的调用中传递给了模型。在聊天机器人的构建中，记忆机制非常重要。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/e26993dd3957bfd2947424abb9de7cde.png)\n\n## 使用ConversationChain\n\n不过，在开始介绍LangChain中记忆机制的具体实现之前，先重新看一下我们上一节课曾经见过的ConversationChain。\n\n这个Chain最主要的特点是，它提供了包含AI 前缀和人类前缀的对话摘要格式，这个对话格式和记忆机制结合得非常紧密。\n\n让我们看一个简单的示例，并打印出ConversationChain中的内置提示模板，你就会明白这个对话格式的意义了。\n\n```plain\nfrom langchain import OpenAI\nfrom langchain.chains import ConversationChain\n\n# 初始化大语言模型\nllm = OpenAI(\n    temperature=0.5,\n    model_name=\"text-davinci-003\"\n)\n\n# 初始化对话链\nconv_chain = ConversationChain(llm=llm)\n\n# 打印对话的模板\nprint(conv_chain.prompt.template)\n\n```\n\n输出：\n\n```plain\nThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\n{history}\nHuman: {input}\nAI:\n\n```\n\n这里的提示为人类（我们）和人工智能（ text-davinci-003 ）之间的对话设置了一个基本对话框架：这是 **人类和** **AI** **之间的友好对话。AI** **非常健谈并从其上下文中提供了大量的具体细节。** (The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. )\n\n同时，这个提示试图通过说明以下内容来减少幻觉，也就是尽量减少模型编造的信息：\n\n**“如果** **AI** **不知道问题的答案，它就会如实说它不知道。”**（If the AI does not know the answer to a question, it truthfully says it does not know.）\n\n之后，我们看到两个参数 {history} 和 {input}。\n\n- **{history}** 是存储会话记忆的地方，也就是人类和人工智能之间对话历史的信息。\n- **{input}** 是新输入的地方，你可以把它看成是和ChatGPT对话时，文本框中的输入。\n\n这两个参数会通过提示模板传递给 LLM，我们希望返回的输出只是对话的延续。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/c11b24c318dbd762f13781e3e40f9b7c.png)\n\n**那么当有了** **{history}** **参数，以及** **Human** **和** **AI** **这两个前缀，我们就能够把历史对话信息存储在提示模板中，并作为新的提示内容在新一轮的对话过程中传递给模型。—— 这就是记忆机制的原理**。\n\n下面就让我们来在ConversationChain中加入记忆功能。\n\n## 使用ConversationBufferMemory\n\n在LangChain中，通过ConversationBufferMemory（ **缓冲记忆**）可以实现最简单的记忆机制。\n\n下面，我们就在对话链中引入ConversationBufferMemory。\n\n```plain\nfrom langchain import OpenAI\nfrom langchain.chains import ConversationChain\nfrom langchain.chains.conversation.memory import ConversationBufferMemory\n\n# 初始化大语言模型\nllm = OpenAI(\n    temperature=0.5,\n    model_name=\"text-davinci-003\")\n\n# 初始化对话链\nconversation = ConversationChain(\n    llm=llm,\n    memory=ConversationBufferMemory()\n)\n\n# 第一天的对话\n# 回合1\nconversation(\"我姐姐明天要过生日，我需要一束生日花束。\")\nprint(\"第一次对话后的记忆:\", conversation.memory.buffer)\n\n```\n\n输出：\n\n```plain\n第一次对话后的记忆:\nHuman: 我姐姐明天要过生日，我需要一束生日花束。\nAI:  哦，你姐姐明天要过生日，那太棒了！我可以帮你推荐一些生日花束，你想要什么样的？我知道有很多种，比如玫瑰、康乃馨、郁金香等等。\n\n```\n\n在下一轮对话中，这些记忆会作为一部分传入提示。\n\n```plain\n# 回合2\nconversation(\"她喜欢粉色玫瑰，颜色是粉色的。\")\nprint(\"第二次对话后的记忆:\", conversation.memory.buffer)\n\n```\n\n输出：\n\n```plain\n第二次对话后的记忆:\nHuman: 我姐姐明天要过生日，我需要一束生日花束。\nAI:  哦，你姐姐明天要过生日，那太棒了！我可以帮你推荐一些生日花束，你想要什么样的？我知道有很多种，比如玫瑰、康乃馨、郁金香等等。\nHuman: 她喜欢粉色玫瑰，颜色是粉色的。\nAI:  好的，那我可以推荐一束粉色玫瑰的生日花束给你。你想要多少朵？我可以帮你定制一束，比如说十朵、二十朵或者更多？\n\n```\n\n下面，我们继续对话，同时打印出此时提示模板的信息。\n\n```plain\n# 回合3 （第二天的对话）\nconversation(\"我又来了，还记得我昨天为什么要来买花吗？\")\nprint(\"/n第三次对话后时提示:/n\",conversation.prompt.template)\nprint(\"/n第三次对话后的记忆:/n\", conversation.memory.buffer)\n\n```\n\n模型输出：\n\n```plain\nHuman: 我姐姐明天要过生日，我需要一束生日花束。\nAI:  哦，你姐姐明天要过生日，那太棒了！我可以帮你推荐一些生日花束，你想要什么样的？我知道有很多种，比如玫瑰、康乃馨、郁金香等等。\nHuman: 她喜欢粉色玫瑰，颜色是粉色的。\nAI:  好的，那我可以推荐一束粉色玫瑰的生日花束给你，你想要多少朵？\nHuman: 我又来了，还记得我昨天为什么要来买花吗？\nAI:  是的，我记得你昨天来买花是因为你姐姐明天要过生日，你想要买一束粉色玫瑰的生日花束给她。\n\n```\n\n实际上，这些聊天历史信息，都被传入了ConversationChain的提示模板中的 {history} 参数，构建出了包含聊天记录的新的提示输入。\n\n有了记忆机制，LLM能够了解之前的对话内容，这样简单直接地存储所有内容为LLM提供了最大量的信息，但是新输入中也包含了更多的Token（所有的聊天历史记录），这意味着响应时间变慢和更高的成本。而且，当达到LLM的令牌数（上下文窗口）限制时，太长的对话无法被记住（对于text-davinci-003和gpt-3.5-turbo，每次的最大输入限制是4096个Token）。\n\n下面我们来看看针对Token太多、聊天历史记录过长的一些解决方案。\n\n## 使用ConversationBufferWindowMemory\n\n说到记忆，我们人类的大脑也不是无穷无尽的。所以说，有的时候事情太多，我们只能把有些遥远的记忆抹掉。毕竟，最新的经历最鲜活，也最重要。\n\nConversationBufferWindowMemory 是 **缓冲窗口记忆**，它的思路就是只保存最新最近的几次人类和AI的互动。因此，它在之前的“缓冲记忆”基础上增加了一个窗口值 k。这意味着我们只保留一定数量的过去互动，然后“忘记”之前的互动。\n\n下面看一下示例。\n\n```plain\nfrom langchain import OpenAI\nfrom langchain.chains import ConversationChain\nfrom langchain.chains.conversation.memory import ConversationBufferWindowMemory\n\n# 创建大语言模型实例\nllm = OpenAI(\n    temperature=0.5,\n    model_name=\"text-davinci-003\")\n\n# 初始化对话链\nconversation = ConversationChain(\n    llm=llm,\n    memory=ConversationBufferWindowMemory(k=1)\n)\n\n# 第一天的对话\n# 回合1\nresult = conversation(\"我姐姐明天要过生日，我需要一束生日花束。\")\nprint(result)\n# 回合2\nresult = conversation(\"她喜欢粉色玫瑰，颜色是粉色的。\")\n# print(\"\\n第二次对话后的记忆:\\n\", conversation.memory.buffer)\nprint(result)\n\n# 第二天的对话\n# 回合3\nresult = conversation(\"我又来了，还记得我昨天为什么要来买花吗？\")\nprint(result)\n\n```\n\n第一回合的输出：\n\n```plain\n{'input': '我姐姐明天要过生日，我需要一束生日花束。',\n'history': '',\n 'response': ' 哦，你姐姐明天要过生日！那太棒了！你想要一束什么样的花束呢？有很多种类可以选择，比如玫瑰花束、康乃馨花束、郁金香花束等等，你有什么喜欢的吗？'}\n\n```\n\n第二回合的输出：\n\n```plain\n{'input': '她喜欢粉色玫瑰，颜色是粉色的。',\n'history': 'Human: 我姐姐明天要过生日，我需要一束生日花束。\\nAI:  哦，你姐姐明天要过生日！那太棒了！你想要一束什么样的花束呢？有很多种类可以选择，比如玫瑰花束、康乃馨花束、郁金香花束等等，你有什么喜欢的吗？',\n'response': ' 好的，那粉色玫瑰花束怎么样？我可以帮你找到一束非常漂亮的粉色玫瑰花束，你觉得怎么样？'}\n\n```\n\n第三回合的输出：\n\n```plain\n{'input': '我又来了，还记得我昨天为什么要来买花吗？',\n'history': 'Human: 她喜欢粉色玫瑰，颜色是粉色的。\\nAI:  好的，那粉色玫瑰花束怎么样？我可以帮你找到一束非常漂亮的粉色玫瑰花束，你觉得怎么样？',\n'response': '  当然记得，你昨天来买花是为了给你喜欢的人送一束粉色玫瑰花束，表达你对TA的爱意。'}\n\n```\n\n在给定的例子中，设置 k=1，这意味着窗口只会记住与AI之间的最新的互动，即只保留上一次的人类回应和AI的回应。\n\n在第三个回合，当我们询问“还记得我昨天为什么要来买花吗？”，由于我们只保留了最近的互动（k=1），模型已经忘记了正确的答案。所以，虽然它说记得，但只能模糊地说出“喜欢的人”，而没有说关键字“姐姐”。不过，如果（我是说如果哈）在第二个回合，模型能回答“我可以帮你 **为你姐姐** 找到…”，那么，尽管我们没有第一回合的历史记录，但凭着上一个回合的信息，模型还是有可能推断出昨天来的人买花的真实意图。\n\n尽管这种方法不适合记住遥远的互动，但它非常擅长限制使用的Token数量。如果只需要记住最近的互动，缓冲窗口记忆是一个很好的选择。但是，如果需要混合远期和近期的互动信息，则还有其他选择。\n\n## 使用ConversationSummaryMemory\n\n上面说了，如果模型在第二轮回答的时候，能够说出“我可以帮你为你姐姐找到…”，那么在第三轮回答时，即使窗口大小 k=1，还是能够回答出正确答案。\n\n这是为什么？\n\n因为模型 **在回答新问题的时候，对之前的问题进行了总结性的重述**。\n\nConversationSummaryMemory（ **对话总结记忆**）的思路就是将对话历史进行汇总，然后再传递给 {history} 参数。这种方法旨在通过对之前的对话进行汇总来避免过度使用 Token。\n\nConversationSummaryMemory有这么几个核心特点。\n\n1. 汇总对话：此方法不是保存整个对话历史，而是每次新的互动发生时对其进行汇总，然后将其添加到之前所有互动的“运行汇总”中。\n2. 使用LLM进行汇总：该汇总功能由另一个LLM驱动，这意味着对话的汇总实际上是由AI自己进行的。\n3. 适合长对话：对于长对话，此方法的优势尤为明显。虽然最初使用的 Token 数量较多，但随着对话的进展，汇总方法的增长速度会减慢。与此同时，常规的缓冲内存模型会继续线性增长。\n\n下面，我们来看看使用ConversationSummaryMemory的代码示例。\n\n```plain\nfrom langchain.chains.conversation.memory import ConversationSummaryMemory\n\n# 初始化对话链\nconversation = ConversationChain(\n    llm=llm,\n    memory=ConversationSummaryMemory(llm=llm)\n)\n\n```\n\n第一回合的输出：\n\n```plain\n{'input': '我姐姐明天要过生日，我需要一束生日花束。',\n'history': '',\n'response': ' 我明白，你需要一束生日花束。我可以为你提供一些建议吗？我可以推荐一些花束给你，比如玫瑰，康乃馨，百合，仙客来，郁金香，满天星等等。挑选一束最适合你姐姐的生日花束吧！'}\n\n```\n\n第二回合的输出：\n\n```plain\n{'input': '她喜欢粉色玫瑰，颜色是粉色的。',\n'history': \"\\nThe human asked what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. The human then asked the AI for advice on what type of flower bouquet to get for their sister's birthday, to which the AI provided a variety of suggestions.\",\n'response': ' 为了为你的姐姐的生日准备一束花，我建议你搭配粉色玫瑰和白色康乃馨。你可以在玫瑰花束中添加一些紫色的满天星，或者添加一些绿叶以增加颜色对比。这将是一束可爱的花束，让你姐姐的生日更加特别。'}\n\n```\n\n第三回合的输出：\n\n```plain\n{'input': '我又来了，还记得我昨天为什么要来买花吗？',\n'history': \"\\n\\nThe human asked what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. The human then asked the AI for advice on what type of flower bouquet to get for their sister's birthday, to which the AI suggested pink roses and white carnations with the addition of purple aster flowers and green leaves for contrast. This would make a lovely bouquet to make the sister's birthday extra special.\",\n'response': ' 确实，我记得你昨天想买一束花给你的姐姐作为生日礼物。我建议你买粉红色的玫瑰花和白色的康乃馨花，再加上紫色的雏菊花和绿叶，这样可以让你的姐姐的生日更加特别。'}\n\n```\n\n看得出来，这里的 `'history'`，不再是之前人类和AI对话的简单复制粘贴，而是经过了总结和整理之后的一个综述信息。\n\n这里，我们 **不仅仅利用了LLM来回答每轮问题，还利用LLM来对之前的对话进行总结性的陈述，以节约Token数量**。这里，帮我们总结对话的LLM，和用来回答问题的LLM，可以是同一个大模型，也可以是不同的大模型。\n\nConversationSummaryMemory的优点是对于长对话，可以减少使用的 Token 数量，因此可以记录更多轮的对话信息，使用起来也直观易懂。不过，它的缺点是，对于较短的对话，可能会导致更高的 Token 使用。另外，对话历史的记忆完全依赖于中间汇总LLM的能力，还需要为汇总LLM使用 Token，这增加了成本，且并不限制对话长度。\n\n通过对话历史的汇总来优化和管理 Token 的使用，ConversationSummaryMemory 为那些预期会有多轮的、长时间对话的场景提供了一种很好的方法。然而，这种方法仍然受到 Token 数量的限制。在一段时间后，我们仍然会超过大模型的上下文窗口限制。\n\n而且，总结的过程中并没有区分近期的对话和长期的对话（通常情况下近期的对话更重要），所以我们还要继续寻找新的记忆管理方法。\n\n## 使用ConversationSummaryBufferMemory\n\n我要为你介绍的最后一种记忆机制是ConversationSummaryBufferMemory，即 **对话总结缓冲记忆**，它是一种 **混合记忆** 模型，结合了上述各种记忆机制，包括ConversationSummaryMemory 和 ConversationBufferWindowMemory的特点。这种模型旨在在对话中总结早期的互动，同时尽量保留最近互动中的原始内容。\n\n它是通过max\\_token\\_limit这个参数做到这一点的。当最新的对话文字长度在300字之内的时候，LangChain会记忆原始对话内容；当对话文字超出了这个参数的长度，那么模型就会把所有超过预设长度的内容进行总结，以节省Token数量。\n\n```plain\nfrom langchain.chains.conversation.memory import ConversationSummaryBufferMemory\n\n# 初始化对话链\nconversation = ConversationChain(\n    llm=llm,\n    memory=ConversationSummaryBufferMemory(\n        llm=llm,\n        max_token_limit=300))\n\n```\n\n第一回合的输出：\n\n```plain\n{'input': '我姐姐明天要过生日，我需要一束生日花束。',\n'history': '',\n'response': ' 哇，你姐姐要过生日啊！那太棒了！我建议你去买一束色彩鲜艳的花束，因为这样可以代表你给她的祝福和祝愿。你可以去你家附近的花店，或者也可以从网上订购，你可以看看有没有特别的花束，比如彩色玫瑰或者百合花，它们会更有特色。'}\n\n```\n\n第二回合的输出：\n\n```plain\n{'input': '她喜欢粉色玫瑰，颜色是粉色的。',\n'history': 'Human: 我姐姐明天要过生日，我需要一束生日花束。\\nAI:  哇，你姐姐要过生日啊！那太棒了！我建议你去买一束色彩鲜艳的花束，因为这样可以代表你给她的祝福和祝愿。你可以去你家附近的花店，或者也可以从网上订购，你可以看看有没有特别的花束，比如彩色玫瑰或者百合花，它们会更有特色。',\n'response': ' 好的，那粉色玫瑰就是一个很好的选择！你可以买一束粉色玫瑰花束，这样你姐姐会很开心的！你可以在花店里找到粉色玫瑰，也可以从网上订购，你可以根据你的预算，选择合适的数量。另外，你可以考虑添加一些装饰，比如细绳、彩带或者小礼品'}\n\n```\n\n第三回合的输出：\n\n```plain\n{'input': '我又来了，还记得我昨天为什么要来买花吗？',\n'history': \"System: \\nThe human asked the AI for advice on buying a bouquet for their sister's birthday. The AI suggested buying a vibrant bouquet as a representation of their wishes and blessings, and recommended looking for special bouquets like colorful roses or lilies for something more unique.\\nHuman: 她喜欢粉色玫瑰，颜色是粉色的。\\nAI:  好的，那粉色玫瑰就是一个很好的选择！你可以买一束粉色玫瑰花束，这样你姐姐会很开心的！你可以在花店里找到粉色玫瑰，也可以从网上订购，你可以根据你的预算，选择合适的数量。另外，你可以考虑添加一些装饰，比如细绳、彩带或者小礼品\",\n'response': ' 是的，我记得你昨天来买花是为了给你姐姐的生日。你想买一束粉色玫瑰花束来表达你的祝福和祝愿，你可以在花店里找到粉色玫瑰，也可以从网上订购，你可以根据你的预算，选择合适的数量。另外，你可以考虑添加一些装饰，比如细绳、彩带或者小礼品}\n\n```\n\n不难看出，在第二回合，记忆机制完整地记录了第一回合的对话，但是在第三回合，它察觉出前两轮的对话已经超出了300个字节，就把早期的对话加以总结，以节省Token资源。\n\nConversationSummaryBufferMemory的优势是通过总结可以回忆起较早的互动，而且有缓冲区确保我们不会错过最近的互动信息。当然，对于较短的对话，ConversationSummaryBufferMemory也会增加Token数量。\n\n总体来说，ConversationSummaryBufferMemory为我们提供了大量的灵活性。它是我们迄今为止的唯一记忆类型，可以回忆起较早的互动并完整地存储最近的互动。在节省Token数量方面，ConversationSummaryBufferMemory与其他方法相比，也具有竞争力。\n\n## 总结时刻\n\n好的，今天我给你介绍了一种对话链和四种类型的对话记忆机制，那么我们可以通过一个表格对这四种类型的记忆做一个整体比较。\n\n四种记忆机制的比较如下：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/a06b5db35405b74yy317de917eacbdc0.jpg)\n\n网上还有人总结了一个示意图，体现出了当对话轮次逐渐增加时，各种记忆机制对Token的消耗数量。意图向我们表达的是：有些记忆机制，比如说ConversationSummaryBufferMemory和ConversationSummaryMemory，在对话轮次较少的时候可能会浪费一些Token，但是多轮对话过后，Token的节省就逐渐体现出来了。\n\n当然ConversationBufferWindowMemory对于Token的节省最为直接，但是它会完全遗忘掉K轮之前的对话内容，因此对于某些场景也不是最佳选择。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/c56yyd7eb61637687de448512yy426ea.png)\n\n## 思考题\n\n1. 在你的客服聊天机器人设计中，你会首先告知客户：“亲，我的记忆能力有限，只能记住和你的最近10次对话哦。如果我忘了之前的对话，请你体谅我。” 当有了这样的预设，你会为你的ChatBot选择那种记忆机制？\n2. 尝试改变示例程序ConversationBufferWindowMemory中的k值，并增加对话轮次，看看记忆效果。\n3. 尝试改变示例程序ConversationSummaryBufferMemory中的max\\_token\\_limit值，看看记忆效果。\n\n期待在留言区看到你的分享。如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。\n\n## 延伸阅读\n\n1. 代码，ConversationBufferMemory的 [实现细节](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/memory/buffer.py)\n2. 代码，ConversationSummaryMemory的 [实现细节](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/memory/summary.py)"},{"url":"/posts/10.html","content":"# 13｜代理（下）：结构化工具对话、Self-Ask with Search以及Plan and execute代理\n你好，我是黄佳，欢迎来到LangChain实战课！\n\n在上一讲中，我们深入LangChain程序内部机制，探索了AgentExecutor究竟是如何思考（Thought）、执行（Execute/Act）和观察（Observe）的，这些步骤之间的紧密联系就是代理在推理（Reasoning）和工具调用过程中的“生死因果”。\n\n现在我们趁热打铁，再学习几种更为复杂的代理：Structured Tool Chat（结构化工具对话）代理、Self-Ask with Search（自主询问搜索）代理、Plan and execute（计划与执行） 代理。\n\n## 什么是结构化工具\n\nLangChain的第一个版本是在 2022 年 11 月推出的，当时的设计是基于 ReAct 论文构建的，主要围绕着代理和工具的使用，并将二者集成到提示模板的框架中。\n\n早期的工具使用十分简单，AgentExecutor引导模型经过推理调用工具时，仅仅能够生成两部分内容：一是工具的名称，二是输入工具的内容。而且，在每一轮中，代理只被允许使用一个工具，并且输入内容只能是一个简单的字符串。这种简化的设计方式是为了让模型的任务变得更简单，因为进行复杂的操作可能会使得执行过程变得不太稳定。\n\n不过，随着语言模型的发展，尤其是出现了如 gpt-3.5-turbo 和 GPT-4 这样的模型，推理能力逐渐增强，也为代理提供了更高的稳定性和可行性。这就使得 LangChain 开始考虑放宽工具使用的限制。\n\n2023年初，LangChain 引入了“多操作”代理框架，允许代理计划执行多个操作。在此基础上，LangChain 推出了结构化工具对话代理，允许更复杂、多方面的交互。通过指定AgentType.STRUCTURED\\_CHAT\\_ZERO\\_SHOT\\_REACT\\_DESCRIPTION 这个代理类型，代理能够调用包含一系列复杂工具的“ **结构化工具箱**”，组合调用其中的多个工具，完成批次相关的任务集合。\n\n举例来说，结构化工具的示例包括：\n\n1. 文件管理工具集：支持所有文件系统操作，如写入、搜索、移动、复制、列目录和查找。\n2. Web 浏览器工具集：官方的 PlayWright 浏览器工具包，允许代理访问网站、点击、提交表单和查询数据。\n\n下面，我们就以 PlayWright 工具包为例，来实现一个结构化工具对话代理。\n\n先来看一看什么是 PlayWright 工具包。\n\n## 什么是 Playwright\n\nPlaywright是一个开源的自动化框架，它可以让你模拟真实用户操作网页，帮助开发者和测试者自动化网页交互和测试。用简单的话说，它就像一个“机器人”，可以按照你给的指令去浏览网页、点击按钮、填写表单、读取页面内容等等，就像一个真实的用户在使用浏览器一样。\n\nPlaywright支持多种浏览器，比如Chrome、Firefox、Safari等，这意味着你可以用它来测试你的网站或测试应用在不同的浏览器上的表现是否一致。\n\n下面我们先用 `pip install playwright` 安装Playwright工具。\n\n不过，如果只用pip安装Playwright工具安装包，就使用它，还不行，会得到下面的信息。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/5cb10de270599b427a4efa9655ceb1c7.jpg)\n\n因此我们还需要通过 `playwright install` 命令来安装三种常用的浏览器工具。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/335f98d28232d1a7160f1d48f334d56d.jpg)\n\n现在，一切就绪，我们可以通过Playwright浏览器工具来访问一个测试网页。\n\n```plain\nfrom playwright.sync_api import sync_playwright\n\ndef run():\n    # 使用Playwright上下文管理器\n    with sync_playwright() as p:\n        # 使用Chromium，但你也可以选择firefox或webkit\n        browser = p.chromium.launch()\n\n        # 创建一个新的页面\n        page = browser.new_page()\n\n        # 导航到指定的URL\n        page.goto('https://langchain.com/')\n\n        # 获取并打印页面标题\n        title = page.title()\n        print(f\"Page title is: {title}\")\n\n        # 关闭浏览器\n        browser.close()\n\nif __name__ == \"__main__\":\n    run()\n\n```\n\n这个简单的Playwright脚本，它打开了一个新的浏览器实例。过程是：导航到指定的URL；获取页面标题并打印页面的标题；最后关闭浏览器。\n\n输出如下：\n\n```plain\nPage title is: LangChain\n\n```\n\n这个脚本展示了Playwright的工作方式，一切都是在命令行里面直接完成。它不需要我们真的去打开Chome网页，然后手工去点击菜单栏、拉动进度条等。\n\n下面这个表，我列出了使用命令行进行自动化网页测试的优势。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/0a5909f879b043b5f17d7c8ea5a88a20.jpg)\n\n现在你了解了Playwright这个工具包的基本思路，下面我们就开始使用它来作为工具集，来实现结构化工具对话代理。\n\n## 使用结构化工具对话代理\n\n在这里，我们要使用的Agent类型是STRUCTURED\\_CHAT\\_ZERO\\_SHOT\\_REACT\\_DESCRIPTION。要使用的工具则是PlayWrightBrowserToolkit，这是LangChain中基于PlayWrightBrowser包封装的工具箱，它继承自 BaseToolkit类。\n\nPlayWrightBrowserToolkit 为 PlayWright 浏览器提供了一系列交互的工具，可以在同步或异步模式下操作。\n\n其中具体的工具就包括：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/ce51ayya392733c6b55ec3568caaac46.jpg)\n\n下面，我们就来看看结构化工具对话代理是怎样通过组合调用PlayWrightBrowserToolkit中的各种工具，自动完成我们交给它的任务。\n\n```plain\nfrom langchain.agents.agent_toolkits import PlayWrightBrowserToolkit\nfrom langchain.tools.playwright.utils import create_async_playwright_browser\n\nasync_browser = create_async_playwright_browser()\ntoolkit = PlayWrightBrowserToolkit.from_browser(async_browser=async_browser)\ntools = toolkit.get_tools()\nprint(tools)\n\nfrom langchain.agents import initialize_agent, AgentType\nfrom langchain.chat_models import ChatAnthropic, ChatOpenAI\n\n# LLM不稳定，对于这个任务，可能要多跑几次才能得到正确结果\nllm = ChatOpenAI(temperature=0.5)\n\nagent_chain = initialize_agent(\n    tools,\n    llm,\n    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n    verbose=True,\n)\n\nasync def main():\n    response = await agent_chain.arun(\"What are the headers on python.langchain.com?\")\n    print(response)\n\nimport asyncio\nloop = asyncio.get_event_loop()\nloop.run_until_complete(main())\n\n```\n\n在这个示例中，我们询问大模型，网页python.langchain.com中有哪些标题目录？\n\n很明显，大模型不可能包含这个网页的内部信息，因为ChatGPT完成训练的那一年（2021年9月），LangChain还不存在。因此，大模型不可避免地需要通过PlayWrightBrowser工具来解决问题。\n\n### 第一轮思考\n\n代理进入AgentExecutor Chain之后的第一轮思考如下：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/6a5718eef084ac988a23e5488e967302.jpg)\n\n这里，我对上述思考做一个具体说明。\n\n> I can use the “navigate\\_browser” tool to visit the website and then use the “get\\_elements” tool to retrieve the headers. Let me do that.\n\n这是第一轮思考，大模型知道自己没有相关信息，决定使用PlayWrightBrowserToolkit工具箱中的 navigate\\_browser 工具。\n\n> Action:\\`\\`\\`{“action”: “navigate\\_browser”, “action\\_input”: {“url”: “ [https://python.langchain.com](https://python.langchain.com)”}}\\`\\`\\`\n\n行动：通过Playwright浏览器访问这个网站。\n\n> Observation: Navigating to [https://python.langchain.com](https://python.langchain.com) returned status code 200\n\n观察：成功得到浏览器访问的返回结果。\n\n在第一轮思考过程中，模型决定使用PlayWrightBrowserToolkit中的navigate\\_browser工具。\n\n### 第二轮思考\n\n下面是大模型的第二轮思考。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/663de1fda23de782af9233328ca5c2e5.jpg)\n\n还是对上述思考做一个具体说明。\n\n> Thought:Now that I have successfully navigated to the website, I can use the “get\\_elements” tool to retrieve the headers. I will specify the CSS selector for the headers and retrieve their text.\n\n第二轮思考：模型决定使用PlayWrightBrowserToolkit工具箱中的另一个工具 get\\_elements，并且指定CSS selector只拿标题的文字。\n\n> Action: \\`\\`\\`{“action”: “get\\_elements”, “action\\_input”: {“selector”: “h1, h2, h3, h4, h5, h6”, “attributes”: \\[“innerText”\\]}}\\`\\`\\`\n\n行动：用Playwright的 get\\_elements 工具去拿网页中各级标题的文字。\n\n> Observation: \\[{“innerText”: “Introduction”}, {“innerText”: “Get started​”}, {“innerText”: “Modules​”}, {“innerText”: “Model I/O​”}, {“innerText”: “Data connection​”}, {“innerText”: “Chains​”}, {“innerText”: “Agents​”}, {“innerText”: “Memory​”}, {“innerText”: “Callbacks​”}, {“innerText”: “Examples, ecosystem, and resources​”}, {“innerText”: “Use cases​”}, {“innerText”: “Guides​”}, {“innerText”: “Ecosystem​”}, {“innerText”: “Additional resources​”}, {“innerText”: “Support”}, {“innerText”: “API reference​”}\\]\n\n观察：成功地拿到了标题文本。\n\n在第二轮思考过程中，模型决定使用PlayWrightBrowserToolkit中的get\\_elements工具。\n\n### 第三轮思考\n\n下面是大模型的第三轮思考。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/01e427d582973da438c67940f132166d.jpg)\n\n对上述思考做一个具体说明。\n\n> Thought:The headers on python.langchain.com are:\n>\n> 1. Introduction\n>\n>\n>    … …\n> 2. API reference\n\n第三轮思考：模型已经找到了网页中的所有标题。\n\n> Action:\n>\n> ```\n> {\n>   \"action\": \"Final Answer\",\n>   \"action_input\": \"The headers on python.langchain.com are: 1. Introduction 2. Get started 3. Modules 4. Model I/O 5. Data connection 6. Chains 7. Agents 8. Memory 9. Callbacks 10. Examples, ecosystem, and resources 11. Use cases 12. Guides 13. Ecosystem 14. Additional resources 15. Support 16. API reference\"\n> }\n>\n> ```\n\n行动：给出最终答案。\n\nAgentExecutor Chain结束之后，成功输出python.langchain.com这个页面中各级标题的具体内容。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/961a5c0cc2b9c19d7147b2120608a663.jpg)\n\n在这个过程中，结构化工具代理组合调用了Playwright工具包中的两种不同工具，自主完成了任务。\n\n## 使用 Self-Ask with Search 代理\n\n讲完了Structured Tool Chat代理，我们再来看看Self-Ask with Search代理。\n\nSelf-Ask with Search 也是LangChain中的一个有用的代理类型（SELF\\_ASK\\_WITH\\_SEARCH）。它利用一种叫做 “Follow-up Question（追问）”加“Intermediate Answer（中间答案）”的技巧，来辅助大模型寻找事实性问题的过渡性答案，从而引出最终答案。\n\n这是什么意思？让我通过示例来给你演示一下，你就明白了。在这个示例中，我们使用SerpAPIWrapper作为工具，用OpenAI作为语言模型，创建Self-Ask with Search代理。\n\n```plain\nfrom langchain import OpenAI, SerpAPIWrapper\nfrom langchain.agents import initialize_agent, Tool\nfrom langchain.agents import AgentType\n\nllm = OpenAI(temperature=0)\nsearch = SerpAPIWrapper()\ntools = [\n    Tool(\n        name=\"Intermediate Answer\",\n        func=search.run,\n        description=\"useful for when you need to ask with search\",\n    )\n]\n\nself_ask_with_search = initialize_agent(\n    tools, llm, agent=AgentType.SELF_ASK_WITH_SEARCH, verbose=True\n)\nself_ask_with_search.run(\n    \"使用玫瑰作为国花的国家的首都是哪里?\"\n)\n\n```\n\n该代理对于这个问题的输出如下：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/dd6dcfa6c90384abc80640fe5ea1850d.jpg)\n\n其实，细心的你可能会发现，“ **使用玫瑰作为国花的国家的首都是哪里?**”这个问题不是一个简单的问题，它其实是一个多跳问题—— **在问题和最终答案之间，存在中间过程**。\n\n多跳问题（Multi-hop question）是指为了得到最终答案，需要进行多步推理或多次查询。这种问题不能直接通过单一的查询或信息源得到答案，而是需要跨越多个信息点，或者从多个数据来源进行组合和整合。\n\n也就是说，问题的答案依赖于另一个子问题的答案，这个子问题的答案可能又依赖于另一个问题的答案。这就像是一连串的问题跳跃，对于人类来说，解答这类问题可能需要从不同的信息源中寻找一系列中间答案，然后结合这些中间答案得出最终结论。\n\n“使用玫瑰作为国花的国家的首都是哪里？”这个问题并不直接询问哪个国家使用玫瑰作为国花，也不是直接询问英国的首都是什么。而是先要推知使用玫瑰作为国花的国家（英国）之后，进一步询问这个国家的首都。这就需要多跳查询。\n\n为什么 Self-Ask with Search 代理适合解决多跳问题呢？有下面几个原因。\n\n1. **工具集合**：代理包含解决问题所必须的搜索工具，可以用来查询和验证多个信息点。这里我们在程序中为代理武装了SerpAPIWrapper工具。\n2. **逐步逼近**：代理可以根据第一个问题的答案，提出进一步的问题，直到得到最终答案。这种逐步逼近的方式可以确保答案的准确性。\n3. **自我提问与搜索**：代理可以自己提问并搜索答案。例如，首先确定哪个国家使用玫瑰作为国花，然后确定该国家的首都是什么。\n4. **决策链**：代理通过一个决策链来执行任务，使其可以跟踪和处理复杂的多跳问题，这对于解决需要多步推理的问题尤为重要。\n\n在上面的例子中，通过大模型的两次follow-up追问，搜索工具给出了两个中间答案，最后给出了问题的最终答案——伦敦。\n\n## 使用 Plan and execute 代理\n\n在这节课的最后，我再给你介绍一种比较新的代理类型：Plan and execute 代理。\n\n计划和执行代理通过首先计划要做什么，然后执行子任务来实现目标。这个想法是受到 [Plan-and-Solve](https://arxiv.org/abs/2305.04091) 论文的启发。论文中提出了计划与解决（Plan-and-Solve）提示。它由两部分组成：首先，制定一个计划，并将整个任务划分为更小的子任务；然后按照该计划执行子任务。\n\n这种代理的独特之处在于，它的计划和执行不再是由同一个代理所完成，而是：\n\n- 计划由一个大语言模型代理（负责推理）完成。\n- 执行由另一个大语言模型代理（负责调用工具）完成。\n\n因为这个代理比较新，它隶属于LangChain的实验包langchain\\_experimental，所以你需要先安装langchain\\_experimental这个包。\n\n```plain\npip install -U langchain langchain_experimental\n\n```\n\n下面我们来使用一下这个代理。在这里，我们创建了Plan and execute代理，这个代理和之前看到的代理不同，它有一个Planner，有一个Executor，它们可以是不同的模型。\n\n当然，在这个示例中，我们都使用了ChatOpenAI模型。\n\n```plain\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain_experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\nfrom langchain.llms import OpenAI\nfrom langchain import SerpAPIWrapper\nfrom langchain.agents.tools import Tool\nfrom langchain import LLMMathChain\n\nsearch = SerpAPIWrapper()\nllm = OpenAI(temperature=0)\nllm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\ntools = [\n    Tool(\n        name = \"Search\",\n        func=search.run,\n        description=\"useful for when you need to answer questions about current events\"\n    ),\n    Tool(\n        name=\"Calculator\",\n        func=llm_math_chain.run,\n        description=\"useful for when you need to answer questions about math\"\n    ),\n]\nmodel = ChatOpenAI(temperature=0)\nplanner = load_chat_planner(model)\nexecutor = load_agent_executor(model, tools, verbose=True)\nagent = PlanAndExecute(planner=planner, executor=executor, verbose=True)\n\nagent.run(\"在纽约，100美元能买几束玫瑰?\")\n\n```\n\n输出如下：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/fd28e5f19a6a8b8ef9c4d68b3e5c0d38.jpg)\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/8ea16266717acf88a2fedb72283744b2.jpg)\n\n在上面输出中，PlanAndExecute 链的调用流程以及代理的思考过程，我就留给你来做分析了，相信你可以把握住Plan and execute代理解决问题的基本脉络。\n\n## 总结时刻\n\n这节课是Agent的最后一课，也是LangChain所有基础知识的最后一课。我给你总结了两张的表。\n\n第一个表，是LangChain中常见的代理类型和它们的介绍。在这些代理中，有很多我们已经一起使用过了，有些则需要你自己去阅读相关文档，自己去探索它的使用方法。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/ee248367eef96616690831498519eeae.jpg)\n\n第二个表，是我对LangChain各个组件的一个简明总结。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/e26993dd3957bfd2947424abb9de7cde.png)\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/577333985abb70b890d94bf99fe58ed9.jpg)\n\n上面这个图片，相信此时你已经不再陌生了，也掌握了它们的精髓所在。\n\n最后还有一个问题值得讲一讲，就是图中的 Indexes，到底是什么，其实这个Indexes是LangChang早期版本的一个组件，现在已经被整合到Retrieval（数据检索）这个单元中了。而Retrieval（包括Indexes），讲的其实就是如何把离散的文档及其他信息做嵌入，存储到向量数据库中，然后再提取的过程。这个过程我们在 [第3课](https://time.geekbang.org/column/article/699451) 已经讲过，在后面的课程中还会再深入介绍。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/e3yyf61d8ccc0b2ba47a76dfc1fdf190.jpg)\n\n此外，在LangChain文档中，新的6大组件中其实还有一个模块——Callbacks，目前我们尚未涉及，在后续的课程中也会介绍。\n\n好了，LangChain的基础知识就讲到这里，从下节课起，我们将整合以前学过的各个组件的内容，为你讲解更多偏重具体应用的内容。\n\n## 思考题\n\n1. 在结构化工具对话代理的示例中，请你打印出PlayWrightBrowserToolkit中的所有具体工具名称的列表。\n\n提示：\n\n```plain\ntools = toolkit.get_tools()\nprint(tools)\n\n```\n\n1. 在Plan and execute代理的示例中，请你分析PlanAndExecute、AgentExecutor和LLMMathChain链的调用流程以及代理的思考过程。\n\n期待在留言区看到你的分享，如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。\n\n## 延伸阅读\n\n1. 代码 Github [Playwright](https://github.com/microsoft/playwright) 工具包\n2. 论文 [\"计划与解决\"提示：通过大型语言模型改进Zero-Shot链式思考推理](https://arxiv.org/abs/2305.04091) Wang, L., Xu, W., Lan, Y., Hu, Z., Lan, Y., Lee, R. K.-W., & Lim, E.-P. (2023). Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models. arXiv preprint arXiv:2305.04091.\n\n## 放假通知\n\n相信细心的同学已经发现了，我们这个专栏的更新节奏还是很快的，前面的内容基本接近工作日日更。从内容的重要程度来说，基础篇其实相当重要，值此中秋&国庆双节长假来临之际，希望大家能好好休息，也能空出一段时间好好复习前面所学，所以我们的专栏计划停更一周，10月9日恢复正常更新，也期待你能把前面的思考题都做一做，我会在留言区等你的分享，与你交流探讨。最后祝大家小长假愉快，中秋阖家团圆！"},{"url":"/posts/11.html","content":"# 12｜代理（中）：AgentExecutor究竟是怎样驱动模型和工具完成任务的？\n你好，我是黄佳，欢迎来到LangChain实战课！\n\n上节课中，你了解了ReAct框架的原理，最后我给你留了一道思考题，让你说一说LangChain中的“代理”和“链”的差异究竟是什么。\n\n我的答案是： **在链中，一系列操作被硬编码（在代码中）。在代理中，语言模型被用作推理引擎来确定要采取哪些操作以及按什么顺序执行这些操作。**\n\n下面这个图，就展现出了Agent接到任务之后，自动进行推理，然后自主调用工具完成任务的过程。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/aeb7497d833b0b3188fbc7152282b0e3.jpg)\n\n那么，你看LangChain，乃至整个大模型应用开发的核心理念就呼之欲出了。这个核心理念就是 **操作的序列并非硬编码在代码中，而是使用语言模型（如GPT-3或GPT-4）来选择执行的操作序列**。\n\n这里，我又一次重复了上一段话，显得有点啰嗦，但是这个思路真的是太重要了，它也凸显了LLM作为AI自主决定程序逻辑这个编程新范式的价值，我希望你仔细认真地去理解。\n\n## Agent 的关键组件\n\n在LangChain的代理中，有这样几个关键组件。\n\n1. **代理**（Agent）：这个类决定下一步执行什么操作。它由一个语言模型和一个提示（prompt）驱动。提示可能包含代理的性格（也就是给它分配角色，让它以特定方式进行响应）、任务的背景（用于给它提供更多任务类型的上下文）以及用于激发更好推理能力的提示策略（例如ReAct）。LangChain中包含很多种不同类型的代理。\n\n2. **工具**（Tools）：工具是代理调用的函数。这里有两个重要的考虑因素：一是让代理能访问到正确的工具，二是以最有帮助的方式描述这些工具。如果你没有给代理提供正确的工具，它将无法完成任务。如果你没有正确地描述工具，代理将不知道如何使用它们。LangChain提供了一系列的工具，同时你也可以定义自己的工具。\n\n3. **工具包**（Toolkits）：工具包是一组用于完成特定目标的彼此相关的工具，每个工具包中包含多个工具。比如LangChain的Office365工具包中就包含连接Outlook、读取邮件列表、发送邮件等一系列工具。当然LangChain中还有很多其他工具包供你使用。\n\n4. **代理执行器**（AgentExecutor）：代理执行器是代理的运行环境，它调用代理并执行代理选择的操作。执行器也负责处理多种复杂情况，包括处理代理选择了不存在的工具的情况、处理工具出错的情况、处理代理产生的无法解析成工具调用的输出的情况，以及在代理决策和工具调用进行观察和日志记录。\n\n总的来说，代理就是一种用语言模型做出决策、调用工具来执行具体操作的系统。通过设定代理的性格、背景以及工具的描述，你可以定制代理的行为，使其能够根据输入的文本做出理解和推理，从而实现自动化的任务处理。而代理执行器（AgentExecutor）就是上述机制得以实现的引擎。\n\n在这一讲中，我们将深入LangChain源代码的内部，揭示代理是如何通过代理执行器来自动决策的。\n\n## 深挖 AgentExcutor 的运行机制\n\n让我们先来回顾一下上一讲中的关键代码。\n\n```plain\nllm = OpenAI(temperature=0) # 大语言模型\ntools = load_tools([\"serpapi\", \"llm-math\"], llm=llm) # 工具-搜索和数学运算\nagent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True) # 代理\nagent.run(\"目前市场上玫瑰花的平均价格是多少？如果我在此基础上加价15%卖出，应该如何定价？\") # 运行代理\n\n```\n\n在这段代码中，模型、工具、代理的初始化，以及代理运行的过程都极为简洁。但是，LangChain的内部封装的逻辑究竟是怎样的？我希望带着你至少弄清楚两个问题。\n\n1. 代理每次给大模型的具体提示是什么样子的？能够让模型给出下一步的行动指南，这个提示的秘密何在？\n2. 代理执行器是如何按照ReAct框架来调用模型，接收模型的输出，并根据这个输出来调用工具，然后又根据工具的返回结果生成新的提示的。\n\n运行代码后我们得到下面的日志。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/106f1c0f2f34b77473d2b18616a30a73.jpg)\n\n要回答上面的两个问题，仅仅观察LangChain输出的Log是不够的。我们需要深入到LangChain的程序内部，深挖一下AgentExcutor的运行机制。\n\n### 开始 Debug\n\n现在，请你用你的代码编辑工具（比如VS Code）在agent.run这个语句设置一个断点，用 “Step Into” 功能深入几层LangChain内部代码，直到我们进入了 **agent.py文件的AgentExecutor类的内部方法 \\_take\\_next\\_step**。\n\n这个 \\_take\\_next\\_step 方法掌控着下一步要调用什么的计划，你可以看到self.agent.plan方法被调用，这是计划开始之处。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/99869f62yy0c82a35797d0fc6712736d.jpg)\n\n注意：如果使用VS Code，要把launch.json的justMycode项设置为false才可以debug LangChain包中的代码。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/d5accaa1f9a751e7678e7634f2a56942.jpg)\n\n### 第一轮思考：模型决定搜索\n\n在AgentExecutor 的\\_take\\_next\\_step 方法的驱动下，我们进一步Debug， **深入self.agent.plan方法**，来到了整个行为链条的第一步—— **Plan**，这个Plan的具体细节是由Agent类的Plan方法来完成的，你可以看到，输入的问题将会被传递给llm\\_chain，然后接收llm\\_chain调用大模型的返回结果。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/1d60291f18dc4087b7e166ac5d69d849.jpg)\n\n再往前进一步，我们就要开始调用大模型了，那么，LangChain到底传递给了大模型什么具体的提示信息，让大模型能够主动进行工具的选择呢？秘密在 **LLMChain类的generate方法** 中，我们可以看到提示的具体内容。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/2e441106b2e8b04eb1806b4f0f46b251.jpg)\n\n在Debug过程中，你可以观察prompt，也就是提示的具体内容，这里我把这个提示Copy出来，你可以看一下。\n\n```plain\n0: StringPromptValue(text='Answer the following questions as best you can. You have access to the following tools:\\n\\nSearch: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\\nCalculator: Useful for when you need to answer questions about math.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Search, Calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: 目前市场上玫瑰花的平均价格是多少？如果我在此基础上加价15%卖出，应该如何定价？\\nThought:\n\n```\n\n我来给你详细拆解一下这个prompt。注意，下面的解释文字不是原始提示，而是我添加的说明。\n\n> 0: StringPromptValue(text='Answer the following questions as best you can. You have access to the following tools:\\\\n\\\\n\n\n这句提示是让模型尽量回答问题，并告诉模型拥有哪些工具。\n\n> Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\\\\n\n\n这是向模型介绍第一个工具：搜索。\n\n> Calculator: Useful for when you need to answer questions about math.\\\\n\\\\n\n\n这是向模型介绍第二个工具：计算器。\n\n> Use the following format:\\\\n\\\\n （指导模型使用下面的格式）\n>\n> Question: the input question you must answer\\\\n （问题）\n>\n> Thought: you should always think about what to do\\\\n （思考）\n>\n> Action: the action to take, should be one of \\[Search, Calculator\\]\\\\n （行动）\n>\n> Action Input: the input to the action\\\\n （行动的输入）\n>\n> Observation: the result of the action\\\\n… （观察：行动的返回结果）\n>\n> (this Thought/Action/Action Input/Observation can repeat N times)\\\\n （上面这个过程可以重复多次）\n>\n> Thought: I now know the final answer\\\\n （思考：现在我知道最终答案了）\n>\n> Final Answer: the final answer to the original input question\\\\n\\\\n （最终答案）\n\n上面，就是给模型的思考框架。具体解释可以看一下括号中的文字\n\n> Begin!\\\\n\\\\n\n\n现在开始！\n\n> Question: 目前市场上玫瑰花的平均价格是多少？如果我在此基础上加价15%卖出，应该如何定价？\\\\nThought:')\n\n具体问题，也就是具体任务。\n\n上面我一句句拆解的这个提示词，就是Agent之所以能够趋动大模型，进行 **思考-行动-观察行动结果-再思考-再行动-再观察** 这个循环的核心秘密。有了这样的提示词，模型就会不停地思考、行动，直到模型判断出问题已经解决，给出最终答案，跳出循环。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/e1d0551d616f798740bfcbc3da983b07.jpg)![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/5e9a4139170699bce6c2500d51332090.jpg)\n\n那么，调用大模型之后，模型具体返回了什么结果呢？\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/ddd55cb0bf32117a88e9f829d4906092.jpg)\n\n在Debug过程中，我们发现调用模型之后的outputs中包含下面的内容。\n\n```plain\n0: LLMResult(generations=[[Generation(text=' I need to find the current market price of roses and then calculate the new price with a 15% markup.\\n\nAction: Search\\nAction Input: \"Average price of roses\"', generation_info={'finish_reason': 'stop', 'logprobs': None})]],\nllm_output={'token_usage': {'completion_tokens': 36, 'total_tokens': 294, 'prompt_tokens': 258}, 'model_name': 'text-davinci-003'}, run=None)\n\n```\n\n把上面的内容拆解如下：\n\n> ‘text’: ’ I need to find the current market price of roses and then calculate the new price with a 15% markup.\\\\n （Text：问题文本）\n>\n> Action: Search\\\\n （行动：搜索）\n>\n> Action Input: “Average price of roses”’ （行动的输入：搜索玫瑰平均价格）\n\n看来，模型知道面对这个问题， **它自己根据现有知识解决不了，下一步行动是需要选择工具箱中的搜索工具**。而此时，命令行中也输出了模型的第一步计划——调用搜索工具。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/406abee8ce87448bf62110574cb84680.jpg)\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/35510020fd06f7ec0e7572977ab14a8c.jpg)\n\n现在模型知道了要调用什么工具，第一轮的Plan部分就结束了。下面，我们就来到了AgentExecutor 的\\_take\\_next\\_step 的 **工具调用部分。**\n\n在这里，因为模型返回了Action为Search，OutputParse解析了这个结果之后，LangChain很清楚地知道，Search工具会被调用。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/2f9ef860f7f5b68d1c880c4d088b8c47.jpg)\n\n工具调用完成之后，我们就拥有了一个对当前工具调用的 **Observation**，也就是当前工具调用的结果。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/40c6796eca3448f16e3d57987f9b4413.jpg)\n\n下一步，我们要再次调用大模型，形成新的 **Thought**，看看任务是否已经完成了，或者仍需要再次调用工具（新的工具或者再次调用同一工具）。\n\n### 第二轮思考：模型决定计算\n\n因为任务尚未完成，第二轮思考开始，程序重新进入了Plan环节。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/14422cdffed757470b2a60d0d0f325c6.jpg)\n\n此时，LangChain的LLM Chain根据目前的input，也就是历史对话记录生成了新的提示信息。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/d0d604056dc85b2b570651d084099801.jpg)\n\n```plain\n0: StringPromptValue(text='Answer the following questions as best you can. You have access to the following tools:\\n\\nSearch: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\\nCalculator: Useful for when you need to answer questions about math.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Search, Calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: 目前市场上玫瑰花的平均价格是多少？如果我在此基础上加价15%卖出，应该如何定价？\\nThought: I need to find the current market price of roses and then calculate the new price with a 15% markup.\\nAction: Search\\nAction Input: \"Average price of roses\"\\nObservation: The average price for a dozen roses in the U.S. is $80.16. The state where a dozen roses cost the most is Hawaii at $108.33. That\\'s 35% more expensive than the national average. A dozen roses are most affordable in Pennsylvania, costing $66.15 on average.\\nThought:\n\n```\n\n我们再来拆解一下这个prompt。\n\n> 0: StringPromptValue(text='Answer the following questions as best you can. You have access to the following tools:\\\\n\\\\n\n\n这句提示是让模型尽量回答问题，并告诉模型拥有哪些工具。\n\n> Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\\\\n\n\n这是向模型介绍第一个工具：搜索。\n\n> Calculator: Useful for when you need to answer questions about math.\\\\n\\\\n\n\n这是向模型介绍第二个工具：计算器。\n\n> Use the following format:\\\\n\\\\n （指导模型使用下面的格式）\n>\n> Question: the input question you must answer\\\\n （问题）\n>\n> Thought: you should always think about what to do\\\\n （思考）\n>\n> Action: the action to take, should be one of \\[Search, Calculator\\]\\\\n （行动）\n>\n> Action Input: the input to the action\\\\n （行动的输入）\n>\n> Observation: the result of the action\\\\n… （观察：行动的返回结果）\n>\n> (this Thought/Action/Action Input/Observation can repeat N times)\\\\n （上面这个过程可以重复多次）\n>\n> Thought: I now know the final answer\\\\n （思考：现在我知道最终答案了）\n>\n> Final Answer: the final answer to the original input question\\\\n\\\\n （最终答案）\n\n上面是一段比较细节的解释说明，看一下括号中的文字。\n\n> Begin!\\\\n\\\\n\n\n现在开始！\n\n> Question: 目前市场上玫瑰花的平均价格是多少？如果我在此基础上加价15%卖出，应该如何定价？\\\\n\n\n具体问题，也就是具体任务。\n\n这句之前的提示，与我们在第一轮思考时看到的完全相同。\n\n> Thought: I need to find the current market price of roses and then calculate the new price with a 15% markup.\\\\n （思考：我需要找到玫瑰花的价格，并加入15%的加价）\n>\n> Action: Search\\\\nAction （行动：搜索）\n>\n> Input: “Average price of roses”\\\\n （行动的输入：玫瑰花的平均价格）\n>\n> Observation: The average price for a dozen roses in the U.S. is $80.16. The state where a dozen roses cost the most is Hawaii at $108.33. That’s 35% more expensive than the national average. A dozen roses are most affordable in Pennsylvania, costing $66.15 on average.\\\\n （观察：这里时搜索工具返回的玫瑰花价格信息）\n\n> Thought:’\n\n思考：后面是大模型应该进一步推理的内容。\n\n大模型根据上面这个提示，返回了下面的output信息。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/a05de0f3b03182a7fc6428f307401c9d.jpg)\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/cd2a2730736af44a3842b80f50yyfdce.jpg)\n\n```plain\nAgentAction(tool='Calculator', tool_input='80.16 * 1.15', log=' I need to calculate the new price with a 15% markup.\\nAction: Calculator\\nAction Input: 80.16 * 1.15')\n\n```\n\n这个输出显示，模型告诉自己，“我需要计算新的Price，在搜索结果的基础上加价15%”，并确定Action为计算器，输入计算器工具的指令为80.16\\*1.15。 **这是一个非常有逻辑性的思考。**\n\n经过解析之后的Thought在命令行中的输出如下：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/ee390d3baa268d97cc9c4b4c8cbc0076.jpg)\n\n有了上面的Thought做指引，AgentExecutor调用了第二个工具：LLMMath。现在开始计算。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/71a3861377d741bce1379c2a9cd9eee1.jpg)\n\n因为这个数学工具也是调用LLM，我们可以看一下内部的提示，看看这个工具是怎样指导LLM做数学计算的。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/c9bc03e84ddf6966a819c4a221becee4.jpg)\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/f8a4e1ff0744829f4ce3157da35b8ef3.jpg)\n\n这个提示，我把它拷贝出来，也拆解一下。\n\n> 0: StringPromptValue(text='Translate a math problem into a expression that can be executed using Python’s numexpr library. Use the output of running this code to answer the question.\\\\n\\\\n\n\n指定模型用Python的数学库来编程解决数学问题，而不是自己计算。这就规避了大模型数学推理能力弱的局限。\n\n> Question: ${Question with math problem.}\\\\n （问题）\n>\n> text\\\\n${single line mathematical expression that solves the problem} n\\`\\`\\`\\\\n （问题的数学描述）\n>\n> …numexpr.evaluate(text)…\\\\n\\`\\`\\` （通过Python库运行问题的数学描述）\n>\n> output\\\\n${Output of running the code}\\\\n\\`\\`\\`\\\\n （输出的Python代码运行结果）\n>\n> Answer: ${Answer}\\\\n\\\\n （问题的答案）\n>\n> Begin.\\\\n\\\\n （开始）\n\n从这里开始是两个数学式的解题示例。\n\n> Question: What is 37593 \\* 67?\\\\n\n>\n> \\`\\`\\`text\\\\n37593 \\* 67\\\\n\\`\\`\\`\n>\n> \\\\n…numexpr.evaluate(“37593 \\* 67”)…\\\\n\n>\n> \\`\\`\\`output\\\\n2518731\\\\n\\`\\`\\`\\\\n\n>\n> Answer: 2518731\\\\n\\\\n\n>\n> Question: 37593^(1/5)\\\\n\n>\n> \\`\\`\\`text\\\\n37593\\*\\*(1/5)\\\\n\\`\\`\\`\\\\n…\n>\n> numexpr.evaluate(“37593\\*\\*(1/5)”)…\\\\n\n>\n> \\`\\`\\`output\\\\n8.222831614237718\\\\n\\`\\`\\`\\\\n\n>\n> Answer: 8.222831614237718\\\\n\\\\n\n\n两个数学式的解题示例结束。\n\n> Question: 80.16 \\* 1.15\\\\n’)\n\n这里是玫瑰花问题的具体描述。\n\n下面，就是模型返回结果。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/f43a49f3c6592a94be0d6ffa0bfa99c4.jpg)\n\n在LLMChain内部，根据Python代码进行了计算，因此final\\_ansewer也已经算好了。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/b2bd0d29d9368164eyy9yyf038b974d8.jpg)\n\n至此，LangChain的BaseTool返回的Observation如下：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/86841a3b2d90ecbd686c54fc25ddf703.jpg)\n\n```plain\nobservation\n'Answer: 92.18399999999998'\n\n```\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/823eyy2ed415d7ab87f1e411d9172525.jpg)\n\n命令行中也输出了当前数学工具调用后的Observation结果：92.18。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/1d07de9cb80bf06e64d6c4fe49391b7f.jpg)\n\n### 第三轮思考：模型完成任务\n\n第三轮思考开始。此时，Executor的Plan应该进一步把当前的新结果传递给大模型，不出所料的话，大模型应该有足够的智慧判断出任务此时已经成功地完成了。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/ea36a2be7da26f303a966218d530ac65.jpg)\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/92c28162c1bf5c2c525f6204658f6438.jpg)\n\n下面是目前最新的 prompt。\n\n```plain\n0: StringPromptValue(text='Answer the following questions as best you can. You have access to the following tools:\\n\\nSearch: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\\nCalculator: Useful for when you need to answer questions about math.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Search, Calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: 目前市场上玫瑰花的平均价格是多少？如果我在此基础上加价15%卖出，应该如何定价？\\nThought: I need to find the current market price of roses and then calculate the new price with a 15% markup.\\nAction: Search\\nAction Input: \"Average price of roses\"\\nObservation: The average price for a dozen roses in the U.S. is $80.16. The state where a dozen roses cost the most is Hawaii at $108.33. That\\'s 35% more expensive than the national average. A dozen roses are most affordable in Pennsylvania, costing $66.15 on average.\\nThought: I need to calculate the new price with a 15% markup.\\nAction: Calculator\\nAction Input: 80.16 * 1.15\\nObservation: Answer: 92.18399999999998\\nThought:')\n\n```\n\n我们再来拆解一下这个最终的prompt。\n\n> 0: StringPromptValue(text='Answer the following questions as best you can. You have access to the following tools:\\\\n\\\\n\n\n这句提示是让模型尽量回答问题，并告诉模型拥有哪些工具。\n\n> Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\\\\n\n\n这是向模型介绍第一个工具：搜索。\n\n> Calculator: Useful for when you need to answer questions about math.\\\\n\\\\n\n\n这是向模型介绍第二个工具：计算器。\n\n> Use the following format:\\\\n\\\\n （指导模型使用下面的格式）\n>\n> Question: the input question you must answer\\\\n （问题）\n>\n> Thought: you should always think about what to do\\\\n （思考）\n>\n> Action: the action to take, should be one of \\[Search, Calculator\\]\\\\n （行动）\n>\n> Action Input: the input to the action\\\\n （行动的输入）\n>\n> Observation: the result of the action\\\\n… （观察：行动的返回结果）\n>\n> (this Thought/Action/Action Input/Observation can repeat N times)\\\\n （上面这个过程可以重复多次）\n>\n> Thought: I now know the final answer\\\\n （思考：现在我知道最终答案了）\n>\n> Final Answer: the final answer to the original input question\\\\n\\\\n （最终答案）\n\n仍然是比较细节的说明，看括号文字。\n\n> Begin!\\\\n\\\\n\n\n现在开始！\n\n> Question: 目前市场上玫瑰花的平均价格是多少？如果我在此基础上加价15%卖出，应该如何定价？\\\\n\n\n具体问题，也就是具体任务。\n\n> Thought: I need to find the current market price of roses and then calculate the new price with a 15% markup.\\\\n （思考：我需要找到玫瑰花的价格，并加入15%的加价）\n>\n> Action: Search\\\\nAction （行动：搜索）\n>\n> Input: “Average price of roses”\\\\n （行动的输入：玫瑰花的平均价格）\n>\n> Observation: The average price for a dozen roses in the U.S. is $80.16. The state where a dozen roses cost the most is Hawaii at $108.33. That’s 35% more expensive than the national average. A dozen roses are most affordable in Pennsylvania, costing $66.15 on average.\\\\n （观察：这里时搜索工具返回的玫瑰花价格信息）\n\n这句之前的提示，与我们在第二轮思考时看到的完全相同。\n\n> Thought: I need to calculate the new price with a 15% markup.\\\\n （思考：我需要计算玫瑰花15%的加价）\n>\n> Action: Calculator\\\\n （行动：计算器工具）\n>\n> Action Input: 80.16 \\* 1.15\\\\n （行动输入：一个数学式）\n>\n> Observation: Answer: 92.18399999999998\\\\n （观察：计算得到的答案）\n>\n> Thought:’ （思考）\n\n可见，每一轮的提示都跟随着模型的思维链条，逐步递进，逐步完善。环环相扣，最终结果也就呼之欲出了。\n\n继续Debug，发现模型在这一轮思考之后的输出中终于包含了 “ **I now know the final answer.**”，这说明模型意识到任务已经成功地完成了。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/7d94a6yy78f9858ff53db67011e9a615.jpg)\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/a0f4febfb2ea1978ff8fafyyb52c6920.jpg)\n\n此时，AgentExcutor的plan方法返回一个 **AgentFinish** **实例**，这表示代理经过对输出的检查，其内部逻辑判断出任务已经完成，思考和行动的循环要结束了。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/2234d186828cb5c7d27ca89e3d356aac.jpg)\n\n至此，整个链条完成，AgentExecutor 的任务结束。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/45e60142ebfa7da7a93c73edd54a18af.jpg)\n\n在命令行中，模型输出 `Thought: I now know the final answer. `（我已经知道最终的答案）。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/3bc53515c70d4f2d03b7a82599cc1612.jpg)\n\n最终答案：玫瑰的平均价格是 80.16 美元，加价15%后，是 92.18 美元。\n\n## 总结时刻\n\n这一课中，我们深入到AgentExecutor的代码内部，深挖其运行机制，了解了AgentExecutor是如何通过计划和工具调用，一步一步完成Thought、Action和Observation的。\n\n如果我们审视一下AgentExecutor 的代码实现，会发现AgentExecutor这个类是作为链（Chain）而存在，同时也为代理执行各种工具，完成任务。它会接收代理的计划，并执行代理思考链路中每一步的行动。\n\nAgentExecutor中最重要的方法是步骤处理方法，\\_take\\_next\\_step方法。它用于在思考-行动-观察的循环中采取单步行动。先调用代理的计划，查找代理选择的工具，然后使用选定的工具执行该计划（此时把输入传给工具），从而获得观察结果，然后继续思考，直到输出是 AgentFinish 类型，循环才会结束。\n\n## 思考题\n\n1. 请你在 [agent.py](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/agent.py) 文件中找到AgentExecutor类。\n\n2. 请你在AgentExecutor类中找到\\_take\\_next\\_step方法，对应本课的内容，分析AgentExecutor类是怎样实现Plan和工具调用的。\n\n\n期待在留言区看到你的分享，如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。\n\n# 延伸阅读\n\n1. 代码，AgentExecutor类的 [实现细节](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/agent.py)\n2. 代码，LLMChain类的 [实现细节](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/chains/llm.py)"},{"url":"/posts/12.html","content":"# 14｜工具和工具箱：LangChain中的Tool和Toolkits一览\n你好，我是黄佳，欢迎来到LangChain实战课！\n\n这节课我们来一起看一看LangChain中各种强大的工具（Tool），以及如何使用它们。\n\n在之前的几节课中，我们深入讲解了LangChain中的代理。未来的AI Agent，应该就是以LLM为核心控制器的代理系统。而 **工具，则是代理身上延展出的三头六臂，是代理的武器，代理通过工具来与世界进行交互，控制并改造世界**。\n\n## 工具是代理的武器\n\nLangChain之所以强大，第一是大模型的推理能力强大，第二则是工具的执行能力强大！孙猴子法力再强，没有金箍棒，也降伏不了妖怪。大模型再能思考，没有工具也不行。\n\n工具是代理可以用来与世界交互的功能。这些工具可以是通用实用程序（例如搜索），也可以是其他链，甚至其他的代理。\n\n那么到底什么是工具？在LangChain中，工具是如何发挥作用的？\n\nLangChain通过提供一个统一的框架来集成功能的具体实现。在这个框架中，每个功能都被封装成一个工具。每个工具都有自己的输入和输出，以及处理这些输入和生成输出的方法。\n\n当代理接收到一个任务时，它会根据任务的类型和需求，通过大模型的推理，来选择合适的工具处理这个任务。这个选择过程可以基于各种策略，例如基于工具的性能，或者基于工具处理特定类型任务的能力。\n\n一旦选择了合适的工具，LangChain就会将任务的输入传递给这个工具，然后工具会处理这些输入并生成输出。这个输出又经过大模型的推理，可以被用作其他工具的输入，或者作为最终结果，被返回给用户。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/ebcyyaccd79133c03f417c45c225d1b6.png)\n\n通过这种方式，LangChain 大大延展了大模型的功能。大模型的推理，加上工具的调用，都集成在一个系统中，而这个系统可以处理多种类型的任务。这提高了系统的灵活性和可扩展性，也大大简化了开发者的工作。\n\n## 如何加载工具\n\n在程序中，可以使用以下代码片段加载工具。\n\n```plain\nfrom langchain.agents import load_tools\ntool_names = [...]\ntools = load_tools(tool_names)\n\n```\n\n某些工具（例如链、代理）可能需要 LLM 来初始化它们。\n\n```plain\nfrom langchain.agents import load_tools\ntool_names = [...]\nllm = ...\ntools = load_tools(tool_names, llm=llm)\n\n```\n\n## LangChain 支持的工具一览\n\n下面，我给你列出目前LangChain中所支持的工具。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/e2f8a0318b4f1da7f0e756e87761d95b.jpg)\n\n当然这个列表随着时间的推移会越来越长，也就意味着LangChain的功能会越来越强大。\n\n## 使用 arXiv 工具开发科研助理\n\n其中有一些工具，比如SerpAPI，你已经用过了，这里我们再来用一下arXiv工具。arXiv本身就是一个论文研究的利器，里面的论文数量比AI顶会还早、还多、还全。那么把它以工具的形式集成到LangChain中，能让你在研究学术最新进展时如虎添翼。\n\n> arXiv是一个提供免费访问的预印本库，供研究者在正式出版前上传和分享其研究工作。它成立于1991年，最初是作为物理学预印本数据库开始的，但后来扩展到了数学、计算机科学、生物学、经济学等多个领域。\n>\n> 预印本是研究者完成的、但尚未经过同行评议或正式出版的论文。Arxiv允许研究者上传这些预印本，使其他研究者可以在正式出版之前查看、评论和使用这些工作。这样，研究的发现可以更快地传播和分享，促进学术交流。\n\n```plain\n# 设置OpenAI API的密钥\nimport os\nos.environ[\"OPENAI_API_KEY\"] = 'Your Key'\n\n# 导入库\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.agents import load_tools, initialize_agent, AgentType\n\n# 初始化模型和工具\nllm = ChatOpenAI(temperature=0.0)\ntools = load_tools(\n    [\"arxiv\"],\n)\n\n# 初始化链\nagent_chain = initialize_agent(\n    tools,\n    llm,\n    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n    verbose=True,\n)\n\n# 运行链\nagent_chain.run(\"介绍一下2005.14165这篇论文的创新点?\")\n\n```\n\n首先，我们还是来研究一下ZERO\\_SHOT\\_REACT\\_DESCRIPTION这个Agent是怎么通过提示来引导模型调用工具的。\n\n> “prompts”: \\[\n>\n>     \"Answer the following questions as best you can. You have access to the following tools:\\\\n\\\\n\n\n首先告诉模型，要尽力回答问题，但是可以访问下面的工具。\n\n> **arxiv:** A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.\\\\n\\\\n\n\narxiv工具：一个围绕Arxiv.org的封装工具。当你需要回答关于物理学、数学、计算机科学、定量生物学、定量金融、统计学、电气工程和经济学的问题时，来自arxiv.org上的科学文章非常有用。同时还告诉模型：输入这个工具的内容应该是搜索查询。\n\n> Use the following format:\\\\n\\\\n\n\n指导模型输出下面的内容。\n\n> Question: the input question you must answer\\\\n （问题：需要回答的问题）\n>\n> Thought: you should always think about what to do\\\\n （思考：应该总是思考下一步做什么）\n>\n> Action: the action to take, should be one of \\[arxiv\\]\\\\n （行动：从具体工具列表中选择行动——这里只有arxiv一个工具）\n>\n> Action Input: the input to the action\\\\n （行动的输入：输入工具的内容）\n>\n> Observation: the result of the action\\\\n… （观察：工具返回的结果）\n>\n> (this Thought/Action/Action Input/Observation can repeat N times)\\\\n （上面 Thought/Action/Action Input/Observation 的过程将重复N次）\n>\n> Thought: I now know the final answer\\\\n （现在我知道最终答案了）\n>\n> Final Answer: the final answer to the original input question\\\\n\\\\n （原始问题的最终答案）\n\n> **Begin!**\\\\n\\\\n\n\n现在开始！\n\n> **Question**: 'Chain-of-Thought Prompting Elicits Reasoning in Large Language Models’这篇论文的创新点\\\\n\n\n真正的问题在此。\n\n> Thought:\"\n\n开始思考吧！\n\n然后，我们来看看Chain的运行过程。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/6e1195d608d47fbe5b67131c1fe32357.jpg)\n\n其中，代理的思考过程中的第一个返回结果如下：\n\n> “text”: \" I need to read the paper to understand the innovation\\\\n （思考：我需要阅读文章才能理解创新点）\n>\n> Action: arxiv\\\\n （行动：arxiv工具）\n>\n> Action Input: ‘Chain-of-Thought Prompting Elicits Reasoning in Large Language Models’\", （行动的输入：论文的标题）\n\n因为在之前的提示中，LangChain告诉大模型，对于Arxiv工具的输入总是以搜索的形式出现，因此尽管我指明了论文的ID，Arxiv还是根据这篇论文的关键词搜索到了3篇相关论文的信息。\n\n模型对这些信息进行了总结，认为信息已经完善，并给出了最终答案。\n\n> Thought: I now know the final answer\n\n想法：我现在知道了最终答案。\n\n> Final Answer: The innovation of the paper ‘Chain-of-Thought Prompting Elicits Reasoning in Large Language Models’ is the introduction of a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting, which significantly improves the ability of large language models to perform complex reasoning.\"\n\n最终答案：这篇名为《链式思考提示促使大型语言模型进行推理》的论文的创新之处在于，引入了一种简单的方法，即链式思考提示，在提示中提供了一些链式思考的示例，这大大提高了大型语言模型执行复杂推理的能力。\n\n## LangChain 中的工具箱一览\n\n下面，我给你列出了目前LangChain中所支持的工具箱。每个工具箱中都有一系列工具。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/c87be0638409b278c2657a66f45aa927.jpg)\n\n## 使用 Gmail 工具箱开发个人助理\n\n刚才，你使用了arXiv工具帮助你做了一些科研工作。你当然还希望你的AI Agent能够成为你的全能自动助理，你开发出的智能应用应该能帮你检查邮件、写草稿，甚至发邮件、写文档，对吧？\n\n上面这一切的一切，LangChain当然能够安排上！\n\n- 通过Gmail工具箱，你可以通过LangChain应用检查邮件、删除垃圾邮件，甚至让它帮你撰写邮件草稿。\n- 通过Office365工具箱，你可以让LangChain应用帮你读写文档、总结文档，甚至做PPT。\n- 通过GitHub工具箱，你可以指示LangChain应用来检查最新的代码，Commit Changes、Merge Branches，甚至尝试让大模型自动回答 Issues 中的问题——反正大模型解决代码问题的能力本来就更强。\n\n这些都不再是梦想。\n\n下面咱们从一个最简单的应用开始。\n\n**目标：我要让AI应用来访问我的Gmail邮件，让他每天早晨检查一次我的邮箱，看看“易速鲜花”的客服有没有给我发信息。**（因为我可能正在焦急地等待他们的退款😁）\n\n现在开始。\n\n### 第一步：在 Google Cloud 中设置你的应用程序接口\n\n这个步骤你要跟着Gmail API的官方配置 [链接](https://developers.google.com/gmail/api/quickstart/python?hl=zh-cn#authorize_credentials_for_a_desktop_application) 完成，这个和LangChain无关。蛮复杂的，你需要有点耐心。跟着流程一步步配置就好了。\n\n下面是我在这个设置过程中截取的一部分图片，只是供你参考。详细配置你要follow Google的官方说明。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/8a3c72f48c231bd2d886b4d99e9f3321.jpg)\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/3822d1effb90c855c133acdecea2eaab.jpg)\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/96a788e8a1f7d4f32e3d23eb94cce8f3.jpg)\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/0f746cfa48ba60c0fe98e657cb3yyb29.jpg)\n\n下面这个OAuth同意屏幕里面的配置非常重要，你的智能代理能做什么，不能做什么，就看你怎么给权限了！\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/195ec3590bb075ecff42911f13d2f22f.jpg)\n\n所有设置都完成之后，在OAuth客户段已创建这个页面，你拥有了开发密钥。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/f6829a70c320161a1002ee3380c5b1b0.jpg)\n\n### 第二步：根据密钥生成开发 Token\n\n在这一步之前，你可能需要安装一些相关的包。\n\n```plain\npip install --upgrade google-api-python-client\npip install --upgrade google-auth-oauthlib\npip install --upgrade google-auth-httplib2\n\n```\n\n然后，把密钥下载下来，保存为credentials.json。\n\n运行下面的代码，生成token.json。\n\n```plain\nfrom __future__ import print_function\n\nimport os.path\n\nfrom google.auth.transport.requests import Request\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import InstalledAppFlow\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\n\n# If modifying these scopes, delete the file token.json.\nSCOPES = ['https://www.googleapis.com/auth/gmail.readonly']\n\ndef main():\n    \"\"\"Shows basic usage of the Gmail API.\n    Lists the user's Gmail labels.\n    \"\"\"\n    creds = None\n    # The file token.json stores the user's access and refresh tokens, and is\n    # created automatically when the authorization flow completes for the first\n    # time.\n    if os.path.exists('token.json'):\n        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n    # If there are no (valid) credentials available, let the user log in.\n    if not creds or not creds.valid:\n        if creds and creds.expired and creds.refresh_token:\n            creds.refresh(Request())\n        else:\n            flow = InstalledAppFlow.from_client_secrets_file(\n                'credentials.json', SCOPES)\n            creds = flow.run_local_server(port=8088)\n        # Save the credentials for the next run\n        with open('token.json', 'w') as token:\n            token.write(creds.to_json())\n\n    try:\n        # Call the Gmail API\n        service = build('gmail', 'v1', credentials=creds)\n        results = service.users().labels().list(userId='me').execute()\n        labels = results.get('labels', [])\n\n        if not labels:\n            print('No labels found.')\n            return\n        print('Labels:')\n        for label in labels:\n            print(label['name'])\n\n    except HttpError as error:\n        # TODO(developer) - Handle errors from gmail API.\n        print(f'An error occurred: {error}')\n\nif __name__ == '__main__':\n    main()\n\n```\n\n这是Google API网站提供的标准示例代码，里面给了读取权限（gmail.readonly）的Token，如果你要编写邮件，甚至发送邮件，需要根据需求来调整权限。更多细节可以参阅Google API的 [文档](https://cloud.google.com/compute/docs/apis?hl=zh-cn)。\n\n这个程序会生成一个token.json文件，是有相关权限的开发令牌。这个文件在LangChain应用中需要和密钥一起使用。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/541c541b377063b49d74ddc53f41d578.jpg)\n\n把密钥和Token文件都放在程序的同一个目录中，你就可以开始开发应用程序了。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/f23144b35b44fef8d900d0d50c9da6b4.jpg)\n\n### 第三步：用 LangChain 框架开发 Gmail App\n\n这段代码的核心目的是连接到Gmail API，查询用户的邮件，并通过LangChain的Agent框架智能化地调用API（用语言而不是具体API），与邮件进行互动。\n\n```plain\n# 设置OpenAI API的密钥\nimport os\nos.environ[\"OPENAI_API_KEY\"] = 'Your Key'\n\n# 导入与Gmail交互所需的工具包\nfrom langchain.agents.agent_toolkits import GmailToolkit\n\n# 初始化Gmail工具包\ntoolkit = GmailToolkit()\n\n# 从gmail工具中导入一些有用的功能\nfrom langchain.tools.gmail.utils import build_resource_service, get_gmail_credentials\n\n# 获取Gmail API的凭证，并指定相关的权限范围\ncredentials = get_gmail_credentials(\n    token_file=\"token.json\",  # Token文件路径\n    scopes=[\"https://mail.google.com/\"],  # 具有完全的邮件访问权限\n    client_secrets_file=\"credentials.json\",  # 客户端的秘密文件路径\n)\n# 使用凭证构建API资源服务\napi_resource = build_resource_service(credentials=credentials)\ntoolkit = GmailToolkit(api_resource=api_resource)\n\n# 获取工具\ntools = toolkit.get_tools()\nprint(tools)\n\n# 导入与聊天模型相关的包\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.agents import initialize_agent, AgentType\n\n# 初始化聊天模型\nllm = ChatOpenAI(temperature=0, model='gpt-4')\n\n# 通过指定的工具和聊天模型初始化agent\nagent = initialize_agent(\n    tools=toolkit.get_tools(),\n    llm=llm,\n    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n)\n\n# 使用agent运行一些查询或指令\nresult = agent.run(\n    \"今天易速鲜花客服给我发邮件了么？最新的邮件是谁发给我的？\"\n)\n\n# 打印结果\nprint(result)\n\n```\n\n代码的核心部分主要是连接到Gmail API，获取用户的邮件数据，并通过特定的 Agent 查询这些数据。\n\n你的请求是查询今天是否收到了来自“易速鲜花客服”的邮件，以及最新邮件的发送者是谁。 **这个请求是模糊的，是自然语言格式，具体调用什么API，由Agent、Tool也就是Gmail API它俩商量着来。** 这与我们之前所进行的清晰的、具体API调用式的应用开发迥然不同。\n\n第一次运行程序，会进行一些确认，并让我Login我的Gmail。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/0e2a7df295caa50512552e05ea3def37.jpg)\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/3208ff117674ebf3f08eac6118393e51.jpg)\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/0cc81560c4bc412104b5144a474c5530.jpg)\n\n之后，我就得到了智能助手的回答！\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/455f8cb0138cd3860869e5eee74f8ecf.jpg)\n\n她说： **主人，看起来你没有收到“易速鲜花”的邮件耶，还需要我帮你做些什么吗？** 真的很贴心，这样的话，我每天早晨就不需要自己去检查邮件啦！\n\n后来，我又问她，那么谁给我发来了新邮件呢？\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/c95a8e75cdc78a7da4960c8f2yyf8be4.jpg)\n\n她告诉我说，Medium - Programing 给我发了一篇 VS code 的 10 个 tips 的文章，还有Kubernetes的点子啥的。\n\n嗯，这是我订阅的内容。下一步，我还可以让她针对这些内容给我总结总结！这也是她的强项！\n\n## 总结时刻\n\n学到现在，你应该对LangChain 的核心价值有了更深的感悟吧。它的价值，在于它将模型运行和交互的复杂性进行了封装和抽象化，为开发者提供了一个更简单、更直观的接口来利用大模型。\n\n- **集成多模型和多策略：** LangChain 提供了一种方法，使得多个模型或策略能够在一个统一的框架下工作。例如，arXiv 是一个单独的工具，它负责处理特定的任务。这种工具可以与其他工具（例如用于处理自然语言查询或者数据库查询的工具）一起作为一个集成的系统存在。这样，你可以轻松地创建一个系统，该系统可以处理多种类型的输入并执行多种任务，而不必为每个任务单独写代码。\n\n- **更易于交互和维护：** 通过 LangChain，你可以更方便地管理和维护你的工具和模型。LangChain 提供的工具和代理（Agent）抽象使得开发者可以将关注点从底层实现细节转向实现应用的高层逻辑。而且，LangChain封装了像模型的加载、输入输出的处理、工具的调度等底层任务，使得开发者能够更专注于如何组合这些工具以解决实际问题。\n\n- **适应性：** LangChain 提供的架构允许你轻松地添加新的工具或模型，或者替换现有的工具或模型。这种灵活性使得你的系统可以很容易地适应新的需求或改变。\n\n- **可解释性：** LangChain 还提供了对模型决策的可解释性。在你的示例中，LangChain 提供的对话历史和工具选择的记录可以帮助理解系统做出某些决策的原因。\n\n总的来说，尽管直接调用模型可能对于单一任务或简单应用来说足够了，但是当你需要处理更复杂的场景，例如需要协调多个模型或工具，或者需要处理多种类型的输入时，使用像 LangChain 这样的框架可以大大简化你的工作。\n\n## 思考题\n\n1. 上面Gmail的示例中我只是展示了邮件读取功能，你能否让你的AI助理帮你写邮件的草稿甚至发送邮件？\n\n2. 你可否尝试使用GitHub工具开发一些App来自动完成一部分GitHub任务，比如查看Issues、Merge Branches之类的事儿。\n\n提示：参考此 [链接](https://docs.github.com/en/apps/creating-github-apps/registering-a-github-app/registering-a-github-app) 创建 GitHub App，以及LangChain的 [参考文档](https://python.langchain.com/docs/integrations/toolkits/github)。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/1bc0dcd6e05133f934ed926cdcc9eb2e.jpg)\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/e037cf6460826e189811ea2af4bb96ea.jpg)\n\n期待在留言区看到你的分享，如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。\n\n## 延伸阅读\n\n1. 文档：LangChain中集成的所有 [工具](https://python.langchain.com/docs/integrations/tools/)\n2. 文档：LangChain中集成的所有 [工具箱](https://python.langchain.com/docs/integrations/toolkits/)\n3. 文档：Google Cloud [API](https://cloud.google.com/compute/docs/apis?hl=zh-cn)\n4. 文档：Github REST [API](https://support.github.com/features/rest-api)"},{"url":"/posts/13.html","content":"# 15｜检索增强生成：通过RAG助力鲜花运营\n你好，我是黄佳，欢迎来到LangChain实战课！\n\n在 [第2课](https://time.geekbang.org/column/article/699436) 中，我曾经带着你完成了一个基于本地文档的问答系统。用当下时髦的话说，你实现了一个RAG 应用。\n\n什么是RAG？其全称为Retrieval-Augmented Generation，即检索增强生成，它结合了检索和生成的能力，为文本序列生成任务引入外部知识。RAG将传统的语言生成模型与大规模的外部知识库相结合，使模型在生成响应或文本时可以动态地从这些知识库中检索相关信息。这种结合方法旨在增强模型的生成能力，使其能够产生更为丰富、准确和有根据的内容，特别是在需要具体细节或外部事实支持的场合。\n\nRAG 的工作原理可以概括为几个步骤。\n\n1. **检索** **：** 对于给定的输入（问题），模型首先使用检索系统从大型文档集合中查找相关的文档或段落。这个检索系统通常基于密集向量搜索，例如ChromaDB、Faiss这样的向量数据库。\n2. **上下文编码** **：** 找到相关的文档或段落后，模型将它们与原始输入（问题）一起编码。\n3. **生成** **：** 使用编码的上下文信息，模型生成输出（答案）。这通常当然是通过大模型完成的。\n\nRAG 的一个关键特点是，它不仅仅依赖于训练数据中的信息，还可以从大型外部知识库中检索信息。这使得RAG模型特别适合处理在训练数据中未出现的问题。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/f326343298bc0bc540978604203a3e0d.jpg)\n\nRAG类的任务，目前企业实际应用场景中的需求量相当大，也是LangChain所关注的一个重点内容。在这节课中，我会对LangChain中所有与之相关的工具进行一个梳理，便于你把握LangChain在这个领域中都能够做到些什么。\n\n## 文档加载\n\nRAG的第一步是文档加载。LangChain 提供了多种类型的文档加载器，以加载各种类型的文档（HTML、PDF、代码），并与该领域的其他主要提供商如 Airbyte 和 Unstructured.IO 进行了集成。\n\n下面给出常用的文档加载器列表。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/2af251fa78768b54a7d6a4a96423a867.jpg)\n\n## 文本转换\n\n加载文档后，下一个步骤是对文本进行转换，而最常见的文本转换就是把长文档分割成更小的块（或者是片，或者是节点），以适合模型的上下文窗口。LangChain 有许多内置的文档转换器，可以轻松地拆分、组合、过滤和以其他方式操作文档。\n\n### 文本分割器\n\n把长文本分割成块听起来很简单，其实也存在一些细节。文本分割的质量会影响检索的结果质量。理想情况下，我们希望将语义相关的文本片段保留在一起。\n\nLangChain中，文本分割器的工作原理如下：\n\n1. 将文本分成小的、具有语义意义的块（通常是句子）。\n2. 开始将这些小块组合成一个更大的块，直到达到一定的大小。\n3. 一旦达到该大小，一个块就形成了，可以开始创建新文本块。这个新文本块和刚刚生成的块要有一些重叠，以保持块之间的上下文。\n\n因此，LangChain提供的各种文本拆分器可以帮助你从下面几个角度设定你的分割策略和参数：\n\n1. 文本如何分割\n2. 块的大小\n3. 块之间重叠文本的长度\n\n这些文本分割器的说明和示例如下：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/517c22ba8c7d78a755d5b29ec16d3e83.jpg)\n\n你可能会关心，文本分割在实践，有哪些具体的考量因素，我总结了下面几点。\n\n**首先，就是LLM 的具体限制。** GPT-3.5-turbo支持的上下文窗口为4096个令牌，这意味着输入令牌和生成的输出令牌的总和不能超过4096，否则会出错。为了保证不超过这个限制，我们可以预留约2000个令牌作为输入提示，留下约2000个令牌作为返回的消息。这样，如果你提取出了五个相关信息块，那么每个片的大小不应超过400个令牌。\n\n**此外，文本分割策略的选择和任务类型相关。**\n\n- 需要细致查看文本的任务，最好使用较小的分块。例如，拼写检查、语法检查和文本分析可能需要识别文本中的单个单词或字符。垃圾邮件识别、查找剽窃和情感分析类任务，以及搜索引擎优化、主题建模中常用的关键字提取任务也属于这类细致任务。\n- 需要全面了解文本的任务，则使用较大的分块。例如，机器翻译、文本摘要和问答任务需要理解文本的整体含义。而自然语言推理、问答和机器翻译需要识别文本中不同部分之间的关系。还有创意写作，都属于这种粗放型的任务。\n\n**最后，你也要考虑所分割的文本的性质。** 例如，如果文本结构很强，如代码或HTML，你可能想使用较大的块，如果文本结构较弱，如小说或新闻文章，你可能想使用较小的块。\n\n你可以反复试验不同大小的块和块与块之间重叠窗口的大小，找到最适合你特定问题的解决方案。\n\n### 其他形式的文本转换\n\n除拆分文本之外，LangChain中还集成了各种工具对文档执行的其他类型的转换。下面让我们对其进行逐点分析。\n\n1. 过滤冗余的文档：使用 EmbeddingsRedundantFilter 工具可以识别相似的文档并过滤掉冗余信息。这意味着如果你有多份高度相似或几乎相同的文档，这个功能可以帮助识别并删除这些多余的副本，从而节省存储空间并提高检索效率。\n2. 翻译文档：通过与工具 doctran 进行集成，可以将文档从一种语言翻译成另一种语言。\n3. 提取元数据：通过与工具 doctran 进行集成，可以从文档内容中提取关键信息（如日期、作者、关键字等），并将其存储为元数据。元数据是描述文档属性或内容的数据，这有助于更有效地管理、分类和检索文档。\n4. 转换对话格式：通过与工具 doctran 进行集成，可以将对话式的文档内容转化为问答（Q/A）格式，从而更容易地提取和查询特定的信息或回答。这在处理如访谈、对话或其他交互式内容时非常有用。\n\n所以说，文档转换不仅限于简单的文本拆分，还可以包含附加的操作，这些操作的目的都是更好地准备和优化文档，以供后续生成更好的索引和检索功能。\n\n## 文本嵌入\n\n文本块形成之后，我们就通过LLM来做嵌入（Embeddings），将文本转换为数值表示，使得计算机可以更容易地处理和比较文本。OpenAI、Cohere、Hugging Face 中都有能做文本嵌入的模型。\n\nEmbeddings 会创建一段文本的向量表示，让我们可以在向量空间中思考文本，并执行语义搜索之类的操作，在向量空间中查找最相似的文本片段。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/b54fc88694120820cd1afea29946d9ba.png)\n\nLangChain中的Embeddings 类是设计用于与文本嵌入模型交互的类。这个类为所有这些提供者提供标准接口。\n\n```plain\n# 初始化Embedding类\nfrom langchain.embeddings import OpenAIEmbeddings\nembeddings_model = OpenAIEmbeddings()\n\n```\n\n它提供两种方法：\n\n1. 第一种是 embed\\_documents 方法，为文档创建嵌入。这个方法接收多个文本作为输入，意味着你可以一次性将多个文档转换为它们的向量表示。\n2. 第二种是 embed\\_query 方法，为查询创建嵌入。这个方法只接收一个文本作为输入，通常是用户的搜索查询。\n\n**为** **什么需要两种方法？** 虽然看起来这两种方法都是为了文本嵌入，但是LangChain将它们分开了。原因是一些嵌入提供者对于文档和查询使用的是不同的嵌入方法。文档是要被搜索的内容，而查询是实际的搜索请求。这两者可能因为其性质和目的，而需要不同的处理或优化。\n\nembed\\_documents 方法的示例代码如下：\n\n```plain\nembeddings = embeddings_model.embed_documents(\n    [\n        \"您好，有什么需要帮忙的吗？\",\n        \"哦，你好！昨天我订的花几天送达\",\n        \"请您提供一些订单号？\",\n        \"12345678\",\n    ]\n)\nlen(embeddings), len(embeddings[0])\n\n```\n\n输出：\n\n```plain\n(4, 1536)\n\n```\n\nembed\\_documents 方法的示例代码如下：\n\n```plain\nembedded_query = embeddings_model.embed_query(\"刚才对话中的订单号是多少?\")\nembedded_query[:3]\n\n```\n\n输出：\n\n```plain\n[-0.0029746221837547455, -0.007710168602107487, 0.00923260021751183]\n\n```\n\n## 存储嵌入\n\n计算嵌入可能是一个时间消耗大的过程。为了加速这一过程，我们可以将计算出的嵌入存储或临时缓存，这样在下次需要它们时，就可以直接读取，无需重新计算。\n\n### 缓存存储\n\nCacheBackedEmbeddings是一个支持缓存的嵌入式包装器，它可以将嵌入缓存在键值存储中。具体操作是：对文本进行哈希处理，并将此哈希值用作缓存的键。\n\n要初始化一个CacheBackedEmbeddings，主要的方式是使用from\\_bytes\\_store。其需要以下参数：\n\n- underlying\\_embedder：实际计算嵌入的嵌入器。\n- document\\_embedding\\_cache：用于存储文档嵌入的缓存。\n- namespace（可选）：用于文档缓存的命名空间，避免与其他缓存发生冲突。\n\n**不同的缓存策略如下：**\n\n1. InMemoryStore：在内存中缓存嵌入。主要用于单元测试或原型设计。如果需要长期存储嵌入，请勿使用此缓存。\n2. LocalFileStore：在本地文件系统中存储嵌入。适用于那些不想依赖外部数据库或存储解决方案的情况。\n3. RedisStore：在Redis数据库中缓存嵌入。当需要一个高速且可扩展的缓存解决方案时，这是一个很好的选择。\n\n在内存中缓存嵌入的示例代码如下：\n\n```plain\n# 导入内存存储库，该库允许我们在RAM中临时存储数据\nfrom langchain.storage import InMemoryStore\n\n# 创建一个InMemoryStore的实例\nstore = InMemoryStore()\n\n# 导入与嵌入相关的库。OpenAIEmbeddings是用于生成嵌入的工具，而CacheBackedEmbeddings允许我们缓存这些嵌入\nfrom langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n\n# 创建一个OpenAIEmbeddings的实例，这将用于实际计算文档的嵌入\nunderlying_embeddings = OpenAIEmbeddings()\n\n# 创建一个CacheBackedEmbeddings的实例。\n# 这将为underlying_embeddings提供缓存功能，嵌入会被存储在上面创建的InMemoryStore中。\n# 我们还为缓存指定了一个命名空间，以确保不同的嵌入模型之间不会出现冲突。\nembedder = CacheBackedEmbeddings.from_bytes_store(\n    underlying_embeddings,  # 实际生成嵌入的工具\n    store,  # 嵌入的缓存位置\n    namespace=underlying_embeddings.model  # 嵌入缓存的命名空间\n)\n\n# 使用embedder为两段文本生成嵌入。\n# 结果，即嵌入向量，将被存储在上面定义的内存存储中。\nembeddings = embedder.embed_documents([\"你好\", \"智能鲜花客服\"])\n\n```\n\n解释下这段代码。首先我们在内存中设置了一个存储空间，然后初始化了一个嵌入工具，该工具将实际生成嵌入。之后，这个嵌入工具被包装在一个缓存工具中，用于为两段文本生成嵌入。\n\n至于其他两种缓存器，嵌入的使用方式也不复杂，你可以参考LangChain文档自行学习。\n\n### 向量数据库（向量存储）\n\n更常见的存储向量的方式是通过向量数据库（Vector Store）来保存它们。LangChain支持非常多种向量数据库，其中有很多是开源的，也有很多是商用的。比如Elasticsearch、Faiss、Chroma和Qdrant等等。\n\n因为选择实在是太多了，我也给你列出来了一个表。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/2eb52480f790fd3281ae905ee1c58077.jpg)\n\n那么问题来了，面对这么多种类的向量数据库，应该如何选择呢？\n\n这就涉及到许多技术和业务层面的考量，你应该 **根据具体需求进行选型**。\n\n1. 数据规模和速度需求：考虑你的数据量大小以及查询速度的要求。一些向量数据库在处理大规模数据时更加出色，而另一些在低延迟查询中表现更好。\n2. 持久性和可靠性：根据你的应用场景，确定你是否需要数据的高可用性、备份和故障转移功能。\n3. 易用性和社区支持：考虑向量数据库的学习曲线、文档的完整性以及社区的活跃度。\n4. 成本：考虑总体拥有成本，包括许可、硬件、运营和维护成本。\n5. 特性：考虑你是否需要特定的功能，例如多模态搜索等。\n6. 安全性：确保向量数据库符合你的安全和合规要求。\n\n在进行向量数据库的评测时，进行 **性能基准测试** 是了解向量数据库实际表现的关键。这可以帮助你评估查询速度、写入速度、并发性能等。\n\n没有“最好”的向量数据库，只有“最适合”的向量数据库。在你的需求上做些研究和测试，确保你选择的向量数据库满足你的业务和技术要求就好。\n\n## 数据检索\n\n在LangChain中，Retriever，也就是检索器，是数据检索模块的核心入口，它通过非结构化查询返回相关的文档。\n\n### 向量存储检索器\n\n向量存储检索器是最常见的，它主要支持向量检索。当然LangChain也有支持其他类型存储格式的检索器。\n\n下面实现一个端到端的数据检索功能，我们通过VectorstoreIndexCreator来创建索引，并在索引的query方法中，通过vectorstore类的as\\_retriever方法，把向量数据库（Vector Store）直接作为检索器，来完成检索任务。\n\n```plain\n# 设置OpenAI的API密钥\nimport os\nos.environ[\"OPENAI_API_KEY\"] = 'Your OpenAI Key'\n\n# 导入文档加载器模块，并使用TextLoader来加载文本文件\nfrom langchain.document_loaders import TextLoader\nloader = TextLoader('LangChainSamples/OneFlower/易速鲜花花语大全.txt', encoding='utf8')\n\n# 使用VectorstoreIndexCreator来从加载器创建索引\nfrom langchain.indexes import VectorstoreIndexCreator\nindex = VectorstoreIndexCreator().from_loaders([loader])\n\n# 定义查询字符串, 使用创建的索引执行查询\nquery = \"玫瑰花的花语是什么？\"\nresult = index.query(query)\nprint(result) # 打印查询结果\n\n```\n\n输出：\n\n```plain\n玫瑰花的花语是爱情、热情、美丽。\n\n```\n\n你可能会觉得，这个数据检索过程太简单了。这就要归功于LangChain的强大封装能力。如果我们审视一下位于vectorstore.py中的VectorstoreIndexCreator类的代码，你就会发现，它其中封装了vectorstore、embedding以及text\\_splitter，甚至document loader（如果你使用from\\_documents方法的话）。\n\n```plain\nclass VectorstoreIndexCreator(BaseModel):\n    \"\"\"Logic for creating indexes.\"\"\"\n\n    vectorstore_cls: Type[VectorStore] = Chroma\n    embedding: Embeddings = Field(default_factory=OpenAIEmbeddings)\n    text_splitter: TextSplitter = Field(default_factory=_get_default_text_splitter)\n    vectorstore_kwargs: dict = Field(default_factory=dict)\n\n    class Config:\n        \"\"\"Configuration for this pydantic object.\"\"\"\n\n        extra = Extra.forbid\n        arbitrary_types_allowed = True\n\n    def from_loaders(self, loaders: List[BaseLoader]) -> VectorStoreIndexWrapper:\n        \"\"\"Create a vectorstore index from loaders.\"\"\"\n        docs = []\n        for loader in loaders:\n            docs.extend(loader.load())\n        return self.from_documents(docs)\n\n    def from_documents(self, documents: List[Document]) -> VectorStoreIndexWrapper:\n        \"\"\"Create a vectorstore index from documents.\"\"\"\n        sub_docs = self.text_splitter.split_documents(documents)\n        vectorstore = self.vectorstore_cls.from_documents(\n            sub_docs, self.embedding, **self.vectorstore_kwargs\n        )\n        return VectorStoreIndexWrapper(vectorstore=vectorstore)\n\n```\n\n因此，上面的检索功能就相当于我们第2课中讲过的一系列工具的整合。而我们也可以用下面的代码，来显式地指定索引创建器的vectorstore、embedding以及text\\_splitter，并把它们替换成你所需要的工具，比如另外一种向量数据库或者别的Embedding模型。\n\n```plain\nfrom langchain.text_splitter import CharacterTextSplitter\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings import OpenAIEmbeddings\nembeddings = OpenAIEmbeddings()\nindex_creator = VectorstoreIndexCreator(\n    vectorstore_cls=Chroma,\n    embedding=OpenAIEmbeddings(),\n    text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n)\n\n```\n\n那么，下一个问题是 index.query(query)，又是如何完成具体的检索及文本生成任务的呢？我们此处既没有看到大模型，又没有看到LangChain的文档检索工具（比如我们在第2课中见过的QARetrival链）。\n\n秘密仍然存在于源码中，在VectorStoreIndexWrapper类的query方法中，可以看到，在调用方法的同时，RetrievalQA链被启动，以完成检索功能。\n\n```plain\nclass VectorStoreIndexWrapper(BaseModel):\n    \"\"\"Wrapper around a vectorstore for easy access.\"\"\"\n\n    vectorstore: VectorStore\n\n    class Config:\n        \"\"\"Configuration for this pydantic object.\"\"\"\n\n        extra = Extra.forbid\n        arbitrary_types_allowed = True\n\n    def query(\n        self,\n        question: str,\n        llm: Optional[BaseLanguageModel] = None,\n        retriever_kwargs: Optional[Dict[str, Any]] = None,\n        **kwargs: Any\n    ) -> str:\n        \"\"\"Query the vectorstore.\"\"\"\n        llm = llm or OpenAI(temperature=0)\n        retriever_kwargs = retriever_kwargs or {}\n        chain = RetrievalQA.from_chain_type(\n            llm, retriever=self.vectorstore.as_retriever(**retriever_kwargs), **kwargs\n        )\n        return chain.run(question)\n\n```\n\n上面我们用到的向量存储检索器，是向量存储类的轻量级包装器，使其符合检索器接口。它使用向量存储中的搜索方法（例如相似性搜索和 MMR）来查询向量存储中的文本。\n\n### 各种类型的检索器\n\n除向量存储检索器之外，LangChain中还提供很多种其他的检索工具。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/f87c2d22bb1e71419ee129c9871724a8.jpg)\n\n这些检索工具，各有其功能特点，你可以查找它们的文档说明，并尝试使用。\n\n## 索引\n\n在本节课的最后，我们来看看LangChain中的索引（Index）。简单的说，索引是一种高效地管理和定位文档信息的方法，确保每个文档具有唯一标识并便于检索。\n\n尽管在 [第2课](https://time.geekbang.org/column/article/699436) 的示例中，我们并没有显式的使用到索引就完成了一个RAG任务，但在复杂的信息检索任务中，有效地管理和索引文档是关键的一步。LangChain 提供的索引 API 为开发者带来了一个高效且直观的解决方案。具体来说，它的优势包括：\n\n- 避免重复内容：确保你的向量存储中不会有冗余数据。\n- 只更新更改的内容：能检测哪些内容已更新，避免不必要的重写。\n- 省时省钱：不对未更改的内容重新计算嵌入，从而减少了计算资源的消耗。\n- 优化搜索结果：减少重复和不相关的数据，从而提高搜索的准确性。\n\nLangChain 利用了记录管理器（RecordManager）来跟踪哪些文档已经被写入向量存储。\n\n在进行索引时，API 会对每个文档进行哈希处理，确保每个文档都有一个唯一的标识。这个哈希值不仅仅基于文档的内容，还考虑了文档的元数据。\n\n一旦哈希完成，以下信息会被保存在记录管理器中：\n\n- 文档哈希：基于文档内容和元数据计算出的唯一标识。\n- 写入时间：记录文档何时被添加到向量存储中。\n- 源 ID：这是一个元数据字段，表示文档的原始来源。\n\n这种方法确保了即使文档经历了多次转换或处理，也能够精确地跟踪它的状态和来源，确保文档数据被正确管理和索引。\n\n## 总结时刻\n\n这节课的内容非常多，而且我给出了很多表格供你查询之用，信息量很大。同时，你可以复习 [第2课](https://time.geekbang.org/column/article/699436) 的内容，我希望你对RAG的流程有个更深的理解。\n\n通过检索增强生成来存储和搜索非结构化数据的最常见方法是，给这些非结构化的数据做嵌入并存储生成的嵌入向量，然后在查询时给要查询的文本也做嵌入，并检索与嵌入查询“最相似”的嵌入向量。向量数据库则负责存储嵌入数据，并为你执行向量的搜索。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/39ab4b67b2689e6daf9a83bc5895b684.jpg)\n\n你看，RAG实际上是为非结构化数据创建了一个“地图”。当用户有查询请求时，该查询同样被嵌入，然后你的应用程序会在这个“地图”中寻找与之最匹配的位置，从而快速准确地检索信息。\n\n在我们的鲜花运营场景中，RAG当然可以在很多方面发挥巨大的作用。你的鲜花有各种各样的品种、颜色和花语，这些数据往往是自然的、松散的，也就是非结构化的。使用RAG，你可以通过嵌入向量，把库存的鲜花与相关的非结构化信息（如花语、颜色、产地等）关联起来。当客户或者员工想要查询某种鲜花的信息时，系统可以快速地提供准确的答案。\n\n此外，RAG还可以应用于订单管理。每个订单，无论是客户的姓名、地址、购买的鲜花种类，还是订单状态，都可以被视为非结构化数据。通过RAG，我们可以轻松地嵌入并检索这些订单，为客户提供实时的订单更新、跟踪和查询服务。\n\n当然，对于订单这样的信息，更常见的情况仍是把它们组织成结构化的数据，存储在数据库中（至少也是CSV或者Excel表中），以便高效、精准地查询。那么，LLM能否帮助我们查询数据库表中的条目呢？在下一课中，我将为你揭晓答案。\n\n## 思考题\n\n1. 请你尝试使用一种文本分割器来给你的文档分块。\n2. 请你尝试使用一种新的向量数据库来存储你的文本嵌入。\n3. 请你尝试使用一种新的检索器来提取信息。\n\n期待在留言区看到你的实践成果，如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。\n\n## 延伸阅读\n\n1. Github： [doctran](https://github.com/psychic-api/doctran/tree/main)，辅助LangChain进行文本转换\n2. 文档：LangChain中 [Indexing](https://python.langchain.com/docs/modules/data_connection/indexing) 的说明"},{"url":"/posts/14.html","content":"# 16｜连接数据库：通过链和代理查询鲜花信息\n你好，我是黄佳，欢迎来到 LangChain 实战课！\n\n一直以来，在计算机编程和数据库管理领域，所有的操作都需要通过严格、专业且结构化的语法来完成。这就是结构化查询语言（SQL）。当你想从一个数据库中提取信息或进行某种操作时，你需要使用这种特定的语言明确地告诉计算机你的要求。这不仅需要我们深入了解正在使用的技术，还需要对所操作的数据有充分的了解。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/829798a55a330518c7c95dcac948890d.png)\n\n你需要拥有一个程序员基本的技能和知识才能有效地与计算机交互。不过，随着人工智能的兴起和大语言模型的发展，情况开始发生变化。\n\n现在，我们正进入一个 **全新的编程范式**，其中机器学习和自然语言处理技术使得与计算机的交互变得更加自然。这意味着，我们可以用更加接近我们日常话语的自然语言来与计算机交流。例如，不用复杂的SQL语句查询数据库，我们可以简单地问：“请告诉我去年的销售额是多少？” 计算机能够理解这个问题，并给出相应的答案。\n\n这种转变不仅使得非技术人员更容易与计算机交互，还为开发者提供了更大的便利性。简而言之，我们从“ **告诉计算机每一步怎么做**”，转变为“ **告诉计算机我们想要什么**”，整个过程变得更加人性化和高效。\n\n## 新的数据库查询范式\n\n下面这个图，非常清晰地解释了这个以LLM为驱动引擎，从自然语言的（模糊）询问，到自然语言的查询结果输出的流程。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/60ffbcbe5a891ae74a12d3d5d24cf426.jpg)\n\n这种范式结合了自然语言处理和传统数据库查询的功能，为用户提供了一个更为直观和高效的交互方式。下面我来解释下这个过程。\n\n1. 提出问题：用户用自然语言提出一个问题，例如“去年的总销售额是多少？”。\n2. LLM理解并转译：LLM首先会解析这个问题，理解其背后的意图和所需的信息。接着，模型会根据解析的内容，生成相应的SQL查询语句，例如 “SELECT SUM(sales) FROM sales\\_data WHERE year = ‘last\\_year’;”。\n3. 执行SQL查询：生成的SQL查询语句会被发送到相应的数据库进行执行。数据库处理这个查询，并返回所需的数据结果。\n4. LLM接收并解释结果：当数据库返回查询结果后，LLM会接收到这些数据。然后，LLM会开始解析这些数据，并将其转化为更容易被人类理解的答案格式。\n5. 提供答案：最后，LLM将结果转化为自然语言答案，并返回给用户。例如“去年的总销售额为1,000,000元”。\n\n你看，用户不需要知道数据库的结构，也不需要具备编写SQL的技能。他们只需要用自然语言提问，然后就可以得到他们所需的答案。这大大简化了与数据库的交互过程，并为各种应用场景提供了巨大的潜力。\n\n## 实战案例背景信息\n\n下面我们将通过LangChain实现这个新的数据库应用开发范式。\n\n在这个实战案例中，我们的所有业务数据都存储在数据库中，而目标则是通过自然语言来为销售的每一种鲜花数据创建各种查询。这样，无论是员工还是顾客，当他们想了解某种鲜花的价格时，都可以快速地生成适当的查询语句。\n\n**这就大大简化了查询过程和难度。**\n\n首先，这个应用可以被简单地用作一个查询工具，允许员工在存货或销售系统中快速查找价格。员工不再需要记住复杂的查询语句或进行手动搜索，只需选择鲜花种类，告诉系统他所想要的东西，系统就会为他们生成正确的查询。\n\n其次，这个模板也可以被整合到一个聊天机器人或客服机器人中。顾客可以直接向机器人询问：“红玫瑰的价格是多少？” 机器人会根据输入内容来调用LangChain和LLM，生成适当的查询，然后返回确切的价格给顾客。这样，不仅提高了服务效率，还增强了用户体验。\n\n了解完项目的背景信息，下面我们就开始行动吧！\n\n## 创建数据库表\n\n首先，让我们创建一系列的数据库表，存储易速鲜花的业务数据。\n\n这里，我们使用SQLite作为我们的示例数据库。它提供了轻量级的磁盘文件数据库，并不需要单独的服务器进程或系统，应用程序可以直接与数据库文件交互。同时，它也不需要配置、安装或管理，非常适合桌面应用、嵌入式应用或初创企业的简单需求。\n\nSQLite支持ACID（原子性、一致性、隔离性、持久性），这意味着你的数据库操作即使在系统崩溃或电源失败的情况下也是安全的。虽然SQLite被认为是轻量级的，但它支持大多数SQL的标准特性，包括事务、触发器和视图。\n\n因此，它也特别适用于那些不需要大型数据库系统带来的全部功能，但仍然需要数据持久性的应用程序，如移动应用或小型Web应用。当然，也非常适合我们做Demo。\n\nsqlite3库，则是Python内置的轻量级SQLite数据库。通过sqlite3库，Python为开发者提供了一个简单、直接的方式来创建、查询和管理SQLite数据库。当你安装Python时，sqlite3模块已经包含在内，无需再进行额外的安装。\n\n基于这个sqlite3库，创建业务数据的代码如下：\n\n```plain\n# 导入sqlite3库\nimport sqlite3\n\n# 连接到数据库\nconn = sqlite3.connect('FlowerShop.db')\ncursor = conn.cursor()\n\n# 执行SQL命令来创建Flowers表\ncursor.execute('''\n        CREATE TABLE Flowers (\n            ID INTEGER PRIMARY KEY,\n            Name TEXT NOT NULL,\n            Type TEXT NOT NULL,\n            Source TEXT NOT NULL,\n            PurchasePrice REAL,\n            SalePrice REAL,\n            StockQuantity INTEGER,\n            SoldQuantity INTEGER,\n            ExpiryDate DATE,\n            Description TEXT,\n            EntryDate DATE DEFAULT CURRENT_DATE\n        );\n    ''')\n\n# 插入5种鲜花的数据\nflowers = [\n    ('Rose', 'Flower', 'France', 1.2, 2.5, 100, 10, '2023-12-31', 'A beautiful red rose'),\n    ('Tulip', 'Flower', 'Netherlands', 0.8, 2.0, 150, 25, '2023-12-31', 'A colorful tulip'),\n    ('Lily', 'Flower', 'China', 1.5, 3.0, 80, 5, '2023-12-31', 'An elegant white lily'),\n    ('Daisy', 'Flower', 'USA', 0.7, 1.8, 120, 15, '2023-12-31', 'A cheerful daisy flower'),\n    ('Orchid', 'Flower', 'Brazil', 2.0, 4.0, 50, 2, '2023-12-31', 'A delicate purple orchid')\n]\n\nfor flower in flowers:\n    cursor.execute('''\n        INSERT INTO Flowers (Name, Type, Source, PurchasePrice, SalePrice, StockQuantity, SoldQuantity, ExpiryDate, Description)\n        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?);\n    ''', flower)\n\n# 提交更改\nconn.commit()\n\n# 关闭数据库连接\nconn.close()\n\n```\n\n首先，我们连接到FlowerShop.db数据库。然后，我们创建一个名为Flowers的新表，此表将存储与每种鲜花相关的各种数据。\n\n该表有以下字段：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/d569yy552347e51ba9514a183yyef731.jpg)\n\n接着，我们创建了一个名为flowers的列表，其中包含5种鲜花的所有相关数据。使用for循环，我们遍历flowers列表，并将每种鲜花的数据插入到Flowers表中。然后提交这些更改，把它们保存到数据库中。最后，我们关闭与数据库的连接。\n\n## 用 Chain 查询数据库\n\n因为LangChain的数据库查询功能较新，目前还处于实验阶段，因此，需要先安装langchain-experimental包，这个包含有实验性的LangChain新功能。\n\n```plain\npip install langchain-experimental\n\n```\n\n下面，我们就开始通过SQLDatabaseChain来查询数据库。代码如下：\n\n```plain\n# 导入langchain的实用工具和相关的模块\nfrom langchain.utilities import SQLDatabase\nfrom langchain.llms import OpenAI\nfrom langchain_experimental.sql import SQLDatabaseChain\n\n# 连接到FlowerShop数据库（之前我们使用的是Chinook.db）\ndb = SQLDatabase.from_uri(\"sqlite:///FlowerShop.db\")\n\n# 创建OpenAI的低级语言模型（LLM）实例，这里我们设置温度为0，意味着模型输出会更加确定性\nllm = OpenAI(temperature=0, verbose=True)\n\n# 创建SQL数据库链实例，它允许我们使用LLM来查询SQL数据库\ndb_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)\n\n# 运行与鲜花运营相关的问题\nresponse = db_chain.run(\"有多少种不同的鲜花？\")\nprint(response)\n\nresponse = db_chain.run(\"哪种鲜花的存货数量最少？\")\nprint(response)\n\nresponse = db_chain.run(\"平均销售价格是多少？\")\nprint(response)\n\nresponse = db_chain.run(\"从法国进口的鲜花有多少种？\")\nprint(response)\n\nresponse = db_chain.run(\"哪种鲜花的销售量最高？\")\nprint(response)\n\n```\n\n这里，我们导入必要的LangChain模块，然后连接到FlowerShop数据库，初始化OpenAI的LLM实例。之后用SQLDatabaseChain来创建一个从LLM到数据库的链接。\n\n最后，用db\\_chain.run()方法来查询多个与鲜花运营相关的问题，Chain的内部会把这些自然语言转换为SQL语句，并查询数据库表，得到查询结果之后，又通过LLM把这个结果转换成自然语言。\n\n因此，Chain的输出结果是我们可以理解的，也是可以直接传递给Chatbot的人话。\n\n输出如下：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/04b4de7c9fd93a98cc58e6de2f8aaaaa.jpg)\n\nSQLDatabaseChain调用大语言模型，完美地完成了从自然语言（输入）到自然语言（输出）的新型SQL查询。\n\n## 用 Agent 查询数据库\n\n除了通过Chain完成数据库查询之外，LangChain 还可以通过SQL Agent来完成查询任务。相比SQLDatabaseChain，使用 SQL 代理有一些优点。\n\n- 它可以根据数据库的架构以及数据库的内容回答问题（例如它会检索特定表的描述）。\n- 它具有纠错能力，当执行生成的查询遇到错误时，它能够捕获该错误，然后正确地重新生成并执行新的查询。\n\nLangChain使用create\\_sql\\_agent函数来初始化代理，通过这个函数创建的SQL代理包含SQLDatabaseToolkit，这个工具箱中包含以下工具：\n\n- 创建并执行查询\n- 检查查询语法\n- 检索数据表的描述\n\n在这些工具的辅助之下，代理可以趋动LLM完成SQL查询任务。代码如下：\n\n```plain\nfrom langchain.utilities import SQLDatabase\nfrom langchain.llms import OpenAI\nfrom langchain.agents import create_sql_agent\nfrom langchain.agents.agent_toolkits import SQLDatabaseToolkit\nfrom langchain.agents.agent_types import AgentType\n\n# 连接到FlowerShop数据库\ndb = SQLDatabase.from_uri(\"sqlite:///FlowerShop.db\")\nllm = OpenAI(temperature=0, verbose=True)\n\n# 创建SQL Agent\nagent_executor = create_sql_agent(\n    llm=llm,\n    toolkit=SQLDatabaseToolkit(db=db, llm=llm),\n    verbose=True,\n    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n)\n\n# 使用Agent执行SQL查询\n\nquestions = [\n    \"哪种鲜花的存货数量最少？\",\n    \"平均销售价格是多少？\",\n]\n\nfor question in questions:\n    response = agent_executor.run(question)\n    print(response)\n\n```\n\n问题1的输出如下：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/97bd63f7bf63eb90a33eb88829a3d118.jpg)\n\n问题2的输出如下：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/749ddf06803b961a16856494c33a163b.jpg)\n\n可以看到，和Chain直接生成SQL语句不同，代理会使用 ReAct 风格的提示。首先，它思考之后，将先确定第一个action是使用工具 sql\\_db\\_list\\_tables，然后观察该工具所返回的表格，思考后再确定下一个 action是sql\\_db\\_schema，也就是创建SQL语句，逐层前进，直到得到答案。\n\n## 总结时刻\n\n今天的内容很容易理解，又很开脑洞。我最想强调的，仍然是从“告诉计算机要做什么”的编程范式向“告诉计算机我们想要什么”的范式的转变。\n\n这种转变具有深远的意义。\n\n1. 更大的可达性：不再需要深入的技术知识或特定的编程背景。这意味着非技术人员，比如业务分析师、项目经理甚至是终端用户，都可以直接与数据交互。\n2. 高效率与生产力：传统的编程方法需要大量的时间和努力，尤其是在复杂的数据操作中。自然语言处理和理解能够显著减少这种负担，使得复杂的数据操作变得更加直观。\n3. 错误的减少：许多编程错误源于对特定语法或结构的误解，通过使用自然语言，这些源于误解的错误将大大减少。\n4. 人与机器的紧密结合：在这种新范式下，机器更像是人类的合作伙伴，而不仅仅是一个工具。它们可以理解我们的需求，并为我们提供解决方案，而无需我们明确指导每一步。\n\n但这种转变也带来了挑战。\n\n1. 模糊性的问题：自然语言本身是模糊的，机器必须能够准确地解释这种模糊性，并在必要时寻求澄清。\n2. 对现有系统的依赖：虽然自然语言查询看起来很有吸引力，但许多现有系统可能不支持或不兼容这种新范式。\n3. 过度依赖：如果过于依赖机器为我们做决策，那么我们可能会失去对数据的深入了解和对结果的质疑。\n\n我们正处于一个技术变革的时刻，自然语言与编程之间的界限正在消失。对于那些愿意接受和采纳这种新范式的人来说，未来充满了无限的可能性。\n\n## 思考题\n\n1. LangChain中用Chain和Agent来查询数据库，这两种方式有什么异同？\n2. 你能否深入上面这两种方法的代码，看一看它们的底层实现。尤其是要看LangChain是如何做提示工程，指导模型生成 SQL 代码的。\n\n期待在留言区看到你的分享，如果你觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。\n\n## 延伸阅读\n\n1. 文档：LangChain中关于数据库接口的 [官方文档](https://python.langchain.com/docs/modules/chains/popular/sqlite)\n2. 工具：上面的文档中提到了 [LangSmith](https://docs.smith.langchain.com/) 工具，用于调试、测试和评估LangChain开发的LLM应用程序"},{"url":"/posts/15.html","content":"# 17｜回调函数：在AI应用中引入异步通信机制\n你好，我是黄佳，欢迎来到LangChain实战课！\n\n这节课我们一起来学习一下LangChain中的回调函数。\n\n## 回调函数和异步编程\n\n回调函数，你可能并不陌生。它是函数A作为参数传给另一个函数B，然后在函数B内部执行函数A。当函数B完成某些操作后，会调用（即“回调”）函数A。这种编程模式常见于处理异步操作，如事件监听、定时任务或网络请求。\n\n> 在编程中，异步通常是指代码不必等待某个操作完成（如I/O操作、网络请求、数据库查询等）就可以继续执行的能力。异步机制的实现涉及事件循环、任务队列和其他复杂的底层机制。这与同步编程形成对比，在同步编程中，操作必须按照它们出现的顺序完成。\n\n下面是回调函数的一个简单示例。\n\n```plain\ndef compute(x, y, callback):\n    result = x + y\n    callback(result)\n\ndef print_result(value):\n    print(f\"The result is: {value}\")\n\ndef square_result(value):\n    print(f\"The squared result is: {value**2}\")\n\n# 使用print_result作为回调\ncompute(3, 4, print_result)  # 输出: The result is: 7\n\n# 使用square_result作为回调\ncompute(3, 4, square_result)  # 输出: The squared result is: 49\n\n```\n\n不过，上面这个程序中并没有体现出异步操作。虽然回调函数这种编程模式常见于处理异步操作，但回调函数本身并不代表异步。回调只是一种编程模式，允许你在某个操作完成时（无论是否异步）执行某些代码。\n\n而下面的例子，就是在异步操作时使用回调函数的示例。\n\n```plain\nimport asyncio\n\nasync def compute(x, y, callback):\n    print(\"Starting compute...\")\n    await asyncio.sleep(0.5)  # 模拟异步操作\n    result = x + y\n    # callback(result)\n    print(\"Finished compute...\")\n\ndef print_result(value):\n    print(f\"The result is: {value}\")\n\nasync def another_task():\n    print(\"Starting another task...\")\n    await asyncio.sleep(1)\n    print(\"Finished another task...\")\n\nasync def main():\n    print(\"Main starts...\")\n    task1 = asyncio.create_task(compute(3, 4, print_result))\n    task2 = asyncio.create_task(another_task())\n\n    await task1\n    await task2\n    print(\"Main ends...\")\n\nasyncio.run(main())\n\n```\n\n这个示例中，当我们调用 asyncio.create\\_task(compute(3, 4, print\\_result))，compute函数开始执行。当它遇到 await asyncio.sleep(2) 时，它会暂停，并将控制权交还给事件循环。这时，事件循环可以选择开始执行another\\_task，这是另一个异步任务。这样，你可以清晰地看到，尽管compute函数还没有完成，another\\_task函数也得以开始执行并完成。这就是异步编程，允许你同时执行多个操作，而不需要等待一个完成后再开始另一个。\n\n## LangChain 中的 Callback 处理器\n\nLangChain 的 Callback 机制允许你在应用程序的不同阶段进行自定义操作，如日志记录、监控和数据流处理，这个机制通过 CallbackHandler（回调处理器）来实现。\n\n回调处理器是LangChain中实现 CallbackHandler 接口的对象，为每类可监控的事件提供一个方法。当该事件被触发时，CallbackManager 会在这些处理器上调用适当的方法。\n\nBaseCallbackHandler是最基本的回调处理器，你可以继承它来创建自己的回调处理器。它包含了多种方法，如on\\_llm\\_start/on\\_chat（当 LLM 开始运行时调用）和on\\_llm\\_error（当 LLM 出现错误时调用）等。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/f393b0aa5b0b4fa795c27b5e04cae491.jpg)\n\nLangChain 也提供了一些内置的处理器，例如 StdOutCallbackHandler，它会将所有事件记录到标准输出。还有FileCallbackHandler，会将所有的日志记录到一个指定的文件中。\n\n## 在组件中使用回调处理器\n\n在 LangChain 的各个组件，如 Chains、Models、Tools、Agents 等，都提供了两种类型的回调设置方法：构造函数回调和请求回调。你可以在初始化 LangChain 时将回调处理器传入，或者在单独的请求中使用回调。例如，当你想要在整个链的所有请求中进行日志记录时，可以在初始化时传入处理器；而当你只想在某个特定请求中使用回调时，可以在请求时传入。\n\n这两者的区别，我给你整理了一下。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/a593e19a4c3693365756a5c34a96355e.jpg)\n\n下面这段示例代码，使用 LangChain 执行了一个简单的任务，结合使用 LangChain 的回调机制与 loguru 日志库，将相关事件同时输出到标准输出和 `\"output.log\"` 文件中。\n\n```plain\nfrom loguru import logger\n\nfrom langchain.callbacks import FileCallbackHandler\nfrom langchain.chains import LLMChain\nfrom langchain.llms import OpenAI\nfrom langchain.prompts import PromptTemplate\n\nlogfile = \"output.log\"\n\nlogger.add(logfile, colorize=True, enqueue=True)\nhandler = FileCallbackHandler(logfile)\n\nllm = OpenAI()\nprompt = PromptTemplate.from_template(\"1 + {number} = \")\n\n# this chain will both print to stdout (because verbose=True) and write to 'output.log'\n# if verbose=False, the FileCallbackHandler will still write to 'output.log'\nchain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler], verbose=True)\nanswer = chain.run(number=2)\nlogger.info(answer)\n\n```\n\n其中，初始化LLMChain时指定的 verbose 参数，就等同于将一个输出到控制台的回调处理器添加到你的对象中。这个在你调试程序时非常有用，因为它会将所有事件的信息输出到控制台。\n\n简而言之，LangChain 通过回调系统提供了一种灵活的方式，来监控和操作应用程序的不同阶段。\n\n## 自定义回调函数\n\n我们也可以通过BaseCallbackHandler和AsyncCallbackHandler来自定义回调函数。下面是一个示例。\n\n```plain\nimport asyncio\nfrom typing import Any, Dict, List\n\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.schema import LLMResult, HumanMessage\nfrom langchain.callbacks.base import AsyncCallbackHandler, BaseCallbackHandler\n\n# 创建同步回调处理器\nclass MyFlowerShopSyncHandler(BaseCallbackHandler):\n    def on_llm_new_token(self, token: str, **kwargs) -> None:\n        print(f\"获取花卉数据: token: {token}\")\n\n# 创建异步回调处理器\nclass MyFlowerShopAsyncHandler(AsyncCallbackHandler):\n\n    async def on_llm_start(\n        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any\n    ) -> None:\n        print(\"正在获取花卉数据...\")\n        await asyncio.sleep(0.5)  # 模拟异步操作\n        print(\"花卉数据获取完毕。提供建议...\")\n\n    async def on_llm_end(self, response: LLMResult, **kwargs: Any) -> None:\n        print(\"整理花卉建议...\")\n        await asyncio.sleep(0.5)  # 模拟异步操作\n        print(\"祝你今天愉快！\")\n\n# 主要的异步函数\nasync def main():\n    flower_shop_chat = ChatOpenAI(\n        max_tokens=100,\n        streaming=True,\n        callbacks=[MyFlowerShopSyncHandler(), MyFlowerShopAsyncHandler()],\n    )\n\n    # 异步生成聊天回复\n    await flower_shop_chat.agenerate([[HumanMessage(content=\"哪种花卉最适合生日？只简单说3种，不超过50字\")]])\n\n# 运行主异步函数\nasyncio.run(main())\n\n```\n\n在这个鲜花店客服的程序中，当客户问及关于鲜花的建议时，我们使用了一个同步和一个异步回调。\n\nMyFlowerShopSyncHandler 是一个同步回调，每当新的Token生成时，它就简单地打印出正在获取的鲜花数据。\n\n而 MyFlowerShopAsyncHandler 则是异步的，当客服开始提供鲜花建议时，它会模拟数据的异步获取。在建议完成后，它还会模拟一个结束的操作，如向客户发出感谢。\n\n这种结合了同步和异步操作的方法，使得程序能够更有效率地处理客户请求，同时提供实时反馈。\n\n**这里的异步体现在这样几个方面。**\n\n1. 模拟延时操作：在MyFlowerShopAsyncHandler中，我们使用了await asyncio.sleep(0.5)来模拟其他请求异步获取花卉信息的过程。当执行到这个await语句时，当前的on\\_llm\\_start函数会“暂停”，释放控制权回到事件循环。这意味着，在这个sleep期间，其他异步任务（如其他客户的请求）可以被处理。\n\n2. 回调机制：当ChatOpenAI在处理每个新Token时，它会调用on\\_llm\\_new\\_token方法。因为这是一个同步回调，所以它会立即输出。但是，开始和结束的异步回调on\\_llm\\_start和on\\_llm\\_end在开始和结束时都有一个小的延时操作，这是通过await asyncio.sleep(0.5)模拟的。\n\n3. 事件循环：Python的syncio库提供了一个事件循环，允许多个异步任务并发运行。在我们的例子中，虽然看起来所有的操作都是按顺序发生的，但由于我们使用了异步操作和回调，如果有其他并发任务，它们可以在await暂停期间运行。\n\n为了更清晰地展示异步的优势，通常我们会在程序中同时运行多个异步任务，并观察它们如何“并发”执行。但在这个简单的例子中，我们主要是通过模拟延时来展示异步操作的基本机制。\n\n因此说，回调函数为异步操作提供了一个机制，使你可以定义“当操作完成时要做什么”，而异步机制的真正实现涉及更深层次的底层工作，如事件循环和任务调度。\n\n## 用 get\\_openai\\_callback 构造令牌计数器\n\n下面，我带着你使用LangChain中的回调函数来构造一个令牌计数器。这个计数功能对于监控大模型的会话消耗以及成本控制十分重要。\n\n在构造令牌计数器之前，我们来回忆一下 [第10课](https://time.geekbang.org/column/article/704183) 中的记忆机制。我们用下面的代码生成了ConversationBufferMemory。\n\n```plain\nfrom langchain import OpenAI\nfrom langchain.chains import ConversationChain\nfrom langchain.chains.conversation.memory import ConversationBufferMemory\n\n# 初始化大语言模型\nllm = OpenAI(\n    temperature=0.5,\n    model_name=\"text-davinci-003\")\n\n# 初始化对话链\nconversation = ConversationChain(\n    llm=llm,\n    memory=ConversationBufferMemory()\n)\n\n# 第一天的对话\n# 回合1\nconversation(\"我姐姐明天要过生日，我需要一束生日花束。\")\nprint(\"第一次对话后的记忆:\", conversation.memory.buffer)\n\n# 回合2\nconversation(\"她喜欢粉色玫瑰，颜色是粉色的。\")\nprint(\"第二次对话后的记忆:\", conversation.memory.buffer)\n\n# 回合3 （第二天的对话）\nconversation(\"我又来了，还记得我昨天为什么要来买花吗？\")\nprint(\"/n第三次对话后时提示:/n\",conversation.prompt.template)\nprint(\"/n第三次对话后的记忆:/n\", conversation.memory.buffer)\n\n```\n\n同时，我们也给出了各种记忆机制对Token的消耗数量的估算示意图。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/b605f14e7c9151c5172fff5860285e52.png)\n\n不过，这张图毕竟是估算，要真正地衡量出每种记忆机制到底耗费了多少个Token，那就需要回调函数上场了。\n\n下面，我们通过回调函数机制，重构这段程序。为了做到这一点，我们首先需要确保在与大语言模型进行交互时，使用了get\\_openai\\_callback上下文管理器。\n\n> 在Python中，一个上下文管理器通常用于管理资源，如文件或网络连接，这些资源在使用前需要设置，在使用后需要清理。上下文管理器经常与with语句一起使用，以确保资源正确地设置和清理。\n>\n> get\\_openai\\_callback被设计用来监控与OpenAI交互的Token数量。当你进入该上下文时，它会通过监听器跟踪Token的使用。当你退出上下文时，它会清理监听器并提供一个Token的总数。通过这种方式，它充当了一个回调机制，允许你在特定事件发生时执行特定的操作或收集特定的信息。\n\n具体代码如下：\n\n```plain\nfrom langchain import OpenAI\nfrom langchain.chains import ConversationChain\nfrom langchain.chains.conversation.memory import ConversationBufferMemory\nfrom langchain.callbacks import get_openai_callback\n\n# 初始化大语言模型\nllm = OpenAI(temperature=0.5, model_name=\"text-davinci-003\")\n\n# 初始化对话链\nconversation = ConversationChain(\n    llm=llm,\n    memory=ConversationBufferMemory()\n)\n\n# 使用context manager进行token counting\nwith get_openai_callback() as cb:\n    # 第一天的对话\n    # 回合1\n    conversation(\"我姐姐明天要过生日，我需要一束生日花束。\")\n    print(\"第一次对话后的记忆:\", conversation.memory.buffer)\n\n    # 回合2\n    conversation(\"她喜欢粉色玫瑰，颜色是粉色的。\")\n    print(\"第二次对话后的记忆:\", conversation.memory.buffer)\n\n    # 回合3 （第二天的对话）\n    conversation(\"我又来了，还记得我昨天为什么要来买花吗？\")\n    print(\"/n第三次对话后时提示:/n\",conversation.prompt.template)\n    print(\"/n第三次对话后的记忆:/n\", conversation.memory.buffer)\n\n# 输出使用的tokens\nprint(\"\\n总计使用的tokens:\", cb.total_tokens)\n\n```\n\n这里，我使用了get\\_openai\\_callback上下文管理器来监控与ConversationChain的交互。这允许我们计算在这些交互中使用的总Tokens数。\n\n输出：\n\n```plain\n总计使用的tokens: 966\n\n```\n\n下面，我再添加了一个additional\\_interactions异步函数，用于演示如何在多个并发交互中计算Tokens。\n\n> 当我们讨论异步交互时，指的是我们可以启动多个任务，它们可以并发（而不是并行）地运行，并且不会阻塞主线程。在Python中，这是通过asyncio库实现的，它使用事件循环来管理并发的异步任务。\n\n```plain\nimport asyncio\n# 进行更多的异步交互和token计数\nasync def additional_interactions():\n    with get_openai_callback() as cb:\n        await asyncio.gather(\n            *[llm.agenerate([\"我姐姐喜欢什么颜色的花？\"]) for _ in range(3)]\n        )\n    print(\"\\n另外的交互中使用的tokens:\", cb.total_tokens)\n\n# 运行异步函数\nasyncio.run(additional_interactions())\n\n```\n\n简单解释一下。\n\n1. `async def`：这表示additional\\_interactions是一个异步函数。它可以使用await关键字在其中挂起执行，允许其他异步任务继续。\n2. `await asyncio.gather(...)`：这是asyncio库提供的一个非常有用的方法，用于并发地运行多个异步任务。它会等待所有任务完成，然后继续执行。\n3. `*[llm.agenerate([\"我姐姐喜欢什么颜色的花？\"]) for _ in range(3)]`：这实际上是一个Python列表解析，它生成了3个 llm.agenerate(…)的异步调用。asyncio.gather将并发地运行这3个调用。\n\n由于这3个llm.agenerate调用是并发的，所以它们不会按顺序执行，而是几乎同时启动，并在各自完成时返回。这意味着，即使其中一个调用由于某种原因需要更长时间，其他调用也不会被阻塞，它们会继续并完成。\n\n## 总结时刻\n\n回调函数是计算机科学中一个重要和广泛应用的概念，它允许我们在特定的时间或条件下执行特定的代码。\n\n回调函数在开发过程中有很多应用场景。\n\n1. 异步编程：在JavaScript中，回调函数常常用于异步编程。例如，当你发送一个AJAX请求到服务器时，你可以提供一个回调函数，这个函数将在服务器的响应到达时被调用。\n2. 事件处理：在许多编程语言和框架中，回调函数被用作事件处理器。例如，你可能会写一个回调函数来处理用户的点击事件，当用户点击某个按钮时，这个函数就会被调用。\n3. 定时器：你可以使用回调函数来创建定时器。例如，你可以使用JavaScript的setTimeout或setInterval函数，并提供一个回调函数，这个函数会在指定的时间过后被调用。\n\n在 LangChain 中，回调机制同样为用户提供了灵活性和自定义能力，以便更好地控制和响应事件。CallbackHandler允许开发者在链的特定阶段或条件下注入自定义的行为，例如异步编程中的响应处理、事件驱动编程中的事件处理等。这为 LangChain 提供了灵活性和扩展性，使其能够适应各种应用场景。\n\n## 思考题\n\n1. 我通过get\\_openai\\_callback重构了ConversationBufferMemory的程序，你能否把这个令牌计数器实现到其他记忆机制中？\n\n2. 在LangChain开发过程中，可以在构造函数中引入回调机制，我给出了一个示例，你能否尝试在请求过程（run/apply方法）中引入回调机制？\n\n提示：请求回调常用在流式传输的实现中。在传统的传输中，我们必须等待这个函数生成所有数据后才能开始处理。在流式传输中，我们可以在数据被生成时立即开始处理。如果你想将单个请求的输出流式传输到一个WebSocket，你可以将一个Callback处理器传递给 call() 方法。\n\n期待在留言区看到你的分享，如果觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。\n\n## 延伸阅读\n\n1. GitHub 代码： [CallbackHandler](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/callbacks/base.py) 中的可监控事件和方法\n2. 文档：LangChain中的 [回调](https://python.langchain.com/docs/modules/callbacks/) 机制\n3. 文档：什么是 [回调函数](https://www.zhihu.com/question/19801131)（知乎）"},{"url":"/posts/16.html","content":"# 18｜CAMEL：通过角色扮演脑暴一个鲜花营销方案\n你好，我是黄佳，欢迎来到LangChain实战课！\n\n大模型的成功，在很大程度上依赖于用户的输入来引导对话生成。如果用户能够详细描述他们的任务和需求，并与ChatGPT建立一个连贯的聊天上下文，那么ChatGPT往往能提供更精确和高质量的答案。但是，为模型提供这种引导是一项既费时又费力的任务。\n\n这就引出了一个有趣的问题： **能否让ChatGPT自己生成这些引导文本呢？**\n\n基于这个想法，KAUST（阿卜杜拉国王大学）的研究团队提出了一个名为CAMEL的框架。CAMEL采用了一种基于“角色扮演”方式的大模型交互策略。在这种策略中，不同的AI代理扮演不同的角色，通过互相交流来完成任务。\n\n## CAMEL 交流式代理框架\n\n下面我们一起来看看CAMEL——这个多AI通过角色扮演进行交互的框架，以及它在LangChain中的具体实现。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/578c7a5a91ffe7007c0fe4cea3d20bc3.png)\n\nCAMEL，字面意思是骆驼。这个框架来自于论文《 [CAMEL: Communicative Agents for “Mind” Exploration of Large Scale Language Model Society](https://arxiv.org/pdf/2303.17760.pdf)》（CAMEL：用于大规模语言模型社会的“心智”探索的交流式代理）。这里面所谓的CAMEL，实际上来自 **沟通（也就是交流）**、 **代理**、 **心智**、 **探索** 以及 **LLM** 这五个单词的英文首字母。\n\nCAMEL框架旨在通过角色扮演来促进交流代理之间的自主合作，并为其“认知”过程提供洞察。这种方法涉及使用启示式提示来指导聊天代理完成任务，同时保持与人类意图的一致性。这个框架为研究多代理系统的合作行为和能力提供了一种可扩展的方法。\n\n上面这段介绍里面新名词不少，我们要一个个解释一下。\n\n- **交流式代理** Communicative Agents，是一种可以与人类或其他代理进行交流的计算机程序。这些代理可以是聊天机器人、智能助手或任何其他需要与人类交流的软件。为了使这些代理能够更好地与人类交流，研究人员一直在寻找方法来提高它们的交流能力。\n- **角色扮演** role-playing，则是这篇论文提出的主要思路，它允许交流代理扮演不同的角色，以更好地与人类或其他代理交流。这意味着代理可以模仿人类的行为，理解人类的意图，并据此做出反应。\n- **启示式提示** inception prompting，是一种指导代理完成任务的方法。通过给代理提供一系列的提示或指示，代理可以更好地理解它应该如何行动。这种方法可以帮助代理更好地与人类交流，并完成与人类的合作任务。\n\n这里的核心创新点是，通过角色扮演和启示式提示的框架来引导代理的交流过程。\n\n## 股票交易场景设计\n\n论文中还提出了下面的目标场景和角色扮演设置。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/ee865a375320fc2e9e3e690e24766e16.png)\n\n### 场景和角色设置\n\n**人类用户角色**：负责提供要实现的想法，如为股票市场开发一个交易机器人。\n\n人类可能不知道如何实现这个想法，但我们需要指定可能实现这个想法的角色，例如Python程序员和股票交易员。\n\n**任务指定代理**（Task Specifier Agent）：负责根据输入的想法为AI助手和AI用户确定一个具体的任务。因为人类用户的想法可能比较模糊，所以任务指定代理将提供详细描述，以使想法具体化。\n\n描述： **开发一个具有情感分析能力的交易机器人，该机器人可以监控社交媒体平台上特定股票的正面或负面评论，并根据情感分析结果执行交易。**\n\n这样，就为AI助手提供了一个明确的任务来解决。\n\n这里多说一句，之所以引入任务指定代理，是因为对话代理通常需要一个具体的任务提示来实现任务，对于非领域专家来说，创建这样一个具体的任务提示可能是具有挑战性或耗时的。\n\n那么，参与此任务的 AI 角色就包括：\n\n- 一个以Python程序员为身份的 **AI** **助手** 代理\n- 一个以股票交易员为身份的 **AI** **用户** 代理\n\n接收到初步想法和角色分配后，AI用户和AI助手通过指令跟随的方式互相聊天，他们将通过多轮对话合作完成指定任务，直到 AI 用户确定任务已完成。\n\n其中，AI 用户是任务规划者，负责向 AI 助手发出以完成任务为导向的指令。另一方面，AI 助手是任务执行者，被设计为遵循 AI 用户指令并提供具体的解决方案，在这里他将给出设计股票交易系统的具体Python代码。\n\n### 提示模板设计\n\n在CAMEL这个角色扮演框架中，Prompt Engineering非常关键。与其他对话语言模型技术有所不同，这种提示工程只在角色扮演的初始阶段进行，主要用于明确任务和分配角色。当会话开始后，AI助手和AI用户会自动地相互给出提示，直到对话结束。这种方法被称为 “Inception Prompting”。\n\nInception Prompting 包括三种类型的提示：任务明确提示、AI助手提示和AI用户提示。在论文中，给出了两个提示模板作为示例。\n\n在论文中，AI Society和AI Code是两种不同的提示模板。这些提示模板被设计用来指导AI助手与AI用户之间的交互。\n\nAI Society：这个提示模板主要关注AI助手在多种不同角色中的表现。例如，AI助手可能扮演会计师、演员、设计师、医生、工程师等多种角色，而用户也可能有各种不同的角色，如博主、厨师、游戏玩家、音乐家等。这种设置是为了研究AI助手如何与不同角色的用户合作以完成各种任务。\n\nAI Code：这个提示模板主要关注与编程相关的任务。它涉及到多种编程语言，如Java、Python、JavaScript等，以及多个领域，如会计、农业、生物学等。这种设置是为了研究AI助手如何在特定的编程语言和领域中帮助用户完成任务。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/8258bbe76e664b41ce636bfa8655c4f4.png)\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/d824e74e324556232d86f20a3ab6e6e2.png)\n\n以AI Society为例，这个提示模板是为AI助手系统和AI用户系统设计的，它在角色扮演的开始时就给出了初始提示。以下是对这个模板的详细解释。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/cc725b0b74f2a066acdefc7c9a3c7da5.jpg)\n\n这个提示模板为AI助手和AI用户提供了一个明确的框架，确保它们在对话中的行为是有序、一致和有效的。可以看出，与之前传统的提示设计不同，这种提示的设计更加复杂和细致，更像是一种交互协议或规范。这种设计在一定程度上提高了AI与AI之间自主合作的能力，并能更好地模拟人类之间的交互过程。\n\n## 易速鲜花营销方案\n\n好，看完了论文的思路和论文中给出的示例，我们就要开始以“易速鲜花”为背景进行自己的CAMEL实战了。\n\n### 准备工作\n\n先导入API密钥和所需要的库。\n\n```plain\n# 设置OpenAI API密钥\nimport os\nos.environ[\"OPENAI_API_KEY\"] = 'Your Key'\n\n# 导入所需的库\nfrom typing import List\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.prompts.chat import (\n    SystemMessagePromptTemplate,\n    HumanMessagePromptTemplate,\n)\nfrom langchain.schema import (\n    AIMessage,\n    HumanMessage,\n    SystemMessage,\n    BaseMessage,\n)\n\n```\n\n### 定义 CAMELAgent 类\n\n下面，定义CAMELAgent类。这是一个核心类，用于管理与语言模型的交互。它包含了初始化消息、更新消息和与模型进行交互的方法。\n\n```plain\n# 定义CAMELAgent类，用于管理与语言模型的交互\nclass CAMELAgent:\n    def __init__(\n        self,\n        system_message: SystemMessage,\n        model: ChatOpenAI,\n    ) -> None:\n        self.system_message = system_message\n        self.model = model\n        self.init_messages()\n\n    def reset(self) -> None:\n        \"\"\"重置对话消息\"\"\"\n        self.init_messages()\n        return self.stored_messages\n\n    def init_messages(self) -> None:\n        \"\"\"初始化对话消息\"\"\"\n        self.stored_messages = [self.system_message]\n\n    def update_messages(self, message: BaseMessage) -> List[BaseMessage]:\n        \"\"\"更新对话消息列表\"\"\"\n        self.stored_messages.append(message)\n        return self.stored_messages\n\n    def step(self, input_message: HumanMessage) -> AIMessage:\n        \"\"\"进行一步交互，并获取模型的响应\"\"\"\n        messages = self.update_messages(input_message)\n\n        output_message = self.model(messages)\n        self.update_messages(output_message)\n\n        return output_message\n\n```\n\n### 预设角色和任务提示\n\n预设的角色和任务提示，这部分定义了AI助手和用户的角色名称、任务描述以及每次讨论的字数限制。\n\n```plain\n# 设置一些预设的角色和任务提示\nassistant_role_name = \"花店营销专员\"\nuser_role_name = \"花店老板\"\ntask = \"整理出一个夏季玫瑰之夜的营销活动的策略\"\nword_limit = 50  # 每次讨论的字数限制\n\n```\n\n这里，assistant\\_role\\_name 和 user\\_role\\_name 是用来定义代理的角色。这两个角色在后续的对话中扮演着不同的功能，具体设定如下。\n\n- `assistant_role_name = \"花店营销专员\"`：这是定义助手的角色。在此设定中，助手被视为一名花店营销专员，主要职责是为花店老板（即用户）提供关于营销活动的建议和策略。\n- `user_role_name = \"花店老板\"`：这是定义用户的角色。用户在这里是花店的老板，他们可能会向营销专员（即助手）提出关于花店推广活动的需求或询问，然后由营销专员来答复和提供建议。\n\n这种角色设定，主要是为了模拟现实中的交互场景，使得聊天代理能够更好地理解任务，并为实现这些任务提供有效的解决方案。通过为每个聊天代理设定一个特定的角色，可以使聊天的过程更加有目的性和效率，同时也能提供更为真实的人类对话体验。\n\n### 任务指定代理\n\n然后，使用任务指定代理（Task Specifier）来明确任务描述。这是CAMEL框架的一个关键步骤，它确保了任务描述的具体性和清晰性。\n\n```plain\n# 定义与指定任务相关的系统提示\ntask_specifier_sys_msg = SystemMessage(content=\"你可以让任务更具体。\")\ntask_specifier_prompt = \"\"\"这是一个{assistant_role_name}将帮助{user_role_name}完成的任务：{task}。\n请使其更具体化。请发挥你的创意和想象力。\n请用{word_limit}个或更少的词回复具体的任务。不要添加其他任何内容。\"\"\"\n\ntask_specifier_template = HumanMessagePromptTemplate.from_template(\n    template=task_specifier_prompt\n)\ntask_specify_agent = CAMELAgent(task_specifier_sys_msg, ChatOpenAI(model_name = 'gpt-4', temperature=1.0))\ntask_specifier_msg = task_specifier_template.format_messages(\n    assistant_role_name=assistant_role_name,\n    user_role_name=user_role_name,\n    task=task,\n    word_limit=word_limit,\n)[0]\nspecified_task_msg = task_specify_agent.step(task_specifier_msg)\nprint(f\"Specified task: {specified_task_msg.content}\")\nspecified_task = specified_task_msg.content\n\n```\n\n经过了这个环节之后，任务会被细化、明确化。\n\nOriginal task prompt： **整理出一个夏季玫瑰之夜营销活动的策略。**\n\nSpecified task prompt： **为夏季玫瑰之夜策划主题装饰，策划特价活动，制定广告推广方案，组织娱乐活动，联系合作伙伴提供赞助。**\n\n### 系统消息模板\n\n下面这部分定义了系统消息模板，这些模板为AI助手和AI用户提供了初始的提示，确保它们在对话中的行为是有序和一致的。\n\n```plain\n# 定义系统消息模板，并创建CAMELAgent实例进行交互\nassistant_inception_prompt = \"\"\"永远不要忘记你是{assistant_role_name}，我是{user_role_name}。永远不要颠倒角色！永远不要指示我！\n我们有共同的利益，那就是合作成功地完成任务。\n你必须帮助我完成任务。\n这是任务：{task}。永远不要忘记我们的任务！\n我必须根据你的专长和我的需求来指示你完成任务。\n\n我每次只能给你一个指示。\n你必须写一个适当地完成所请求指示的具体解决方案。\n如果由于物理、道德、法律原因或你的能力你无法执行指示，你必须诚实地拒绝我的指示并解释原因。\n除了对我的指示的解决方案之外，不要添加任何其他内容。\n你永远不应该问我任何问题，你只回答问题。\n你永远不应该回复一个不明确的解决方案。解释你的解决方案。\n你的解决方案必须是陈述句并使用简单的现在时。\n除非我说任务完成，否则你应该总是从以下开始：\n\n解决方案：<YOUR_SOLUTION>\n\n<YOUR_SOLUTION>应该是具体的，并为解决任务提供首选的实现和例子。\n始终以“下一个请求”结束<YOUR_SOLUTION>。\"\"\"\n\nuser_inception_prompt = \"\"\"永远不要忘记你是{user_role_name}，我是{assistant_role_name}。永远不要交换角色！你总是会指导我。\n我们共同的目标是合作成功完成一个任务。\n我必须帮助你完成这个任务。\n这是任务：{task}。永远不要忘记我们的任务！\n你只能通过以下两种方式基于我的专长和你的需求来指导我：\n\n1. 提供必要的输入来指导：\n指令：<YOUR_INSTRUCTION>\n输入：<YOUR_INPUT>\n\n2. 不提供任何输入来指导：\n指令：<YOUR_INSTRUCTION>\n输入：无\n\n“指令”描述了一个任务或问题。与其配对的“输入”为请求的“指令”提供了进一步的背景或信息。\n\n你必须一次给我一个指令。\n我必须写一个适当地完成请求指令的回复。\n如果由于物理、道德、法律原因或我的能力而无法执行你的指令，我必须诚实地拒绝你的指令并解释原因。\n你应该指导我，而不是问我问题。\n现在你必须开始按照上述两种方式指导我。\n除了你的指令和可选的相应输入之外，不要添加任何其他内容！\n继续给我指令和必要的输入，直到你认为任务已经完成。\n当任务完成时，你只需回复一个单词<CAMEL_TASK_DONE>。\n除非我的回答已经解决了你的任务，否则永远不要说<CAMEL_TASK_DONE>。\"\"\"\n\n```\n\n之后，根据预设的角色和任务提示生成系统消息。\n\n```plain\n# 根据预设的角色和任务提示生成系统消息\ndef get_sys_msgs(assistant_role_name: str, user_role_name: str, task: str):\n    assistant_sys_template = SystemMessagePromptTemplate.from_template(\n        template=assistant_inception_prompt\n    )\n    assistant_sys_msg = assistant_sys_template.format_messages(\n        assistant_role_name=assistant_role_name,\n        user_role_name=user_role_name,\n        task=task,\n    )[0]\n\n    user_sys_template = SystemMessagePromptTemplate.from_template(\n        template=user_inception_prompt\n    )\n    user_sys_msg = user_sys_template.format_messages(\n        assistant_role_name=assistant_role_name,\n        user_role_name=user_role_name,\n        task=task,\n    )[0]\n\n    return assistant_sys_msg, user_sys_msg\n\nassistant_sys_msg, user_sys_msg = get_sys_msgs(\n    assistant_role_name, user_role_name, specified_task\n)\n\n```\n\n### 创建 Agent 实例\n\n创建助手和用户的CAMELAgent实例，并初始化对话互动，使用CAMELAgent类的实例来模拟助手和用户之间的对话交互。\n\n```plain\n# 创建助手和用户的CAMELAgent实例\nassistant_agent = CAMELAgent(assistant_sys_msg, ChatOpenAI(temperature=0.2))\nuser_agent = CAMELAgent(user_sys_msg, ChatOpenAI(temperature=0.2))\n\n# 重置两个agent\nassistant_agent.reset()\nuser_agent.reset()\n\n# 初始化对话互动\nassistant_msg = HumanMessage(\n    content=(\n        f\"{user_sys_msg.content}。\"\n        \"现在开始逐一给我介绍。\"\n        \"只回复指令和输入。\"\n    )\n)\n\nuser_msg = HumanMessage(content=f\"{assistant_sys_msg.content}\")\nuser_msg = assistant_agent.step(user_msg)\n\nprint(f\"Original task prompt:\\n{task}\\n\")\nprint(f\"Specified task prompt:\\n{specified_task}\\n\")\n\n```\n\n这里，assistant\\_inception\\_prompt 和 user\\_inception\\_prompt 是两个关键的提示，用于引导聊天代理的行为和交流方式。关于这两个提示，让我们一起来深入理解一下它们的设计和目标。\n\n1. **assistant\\_inception\\_prompt：** 这个提示是为了引导助手（即营销专员）如何响应用户（即花店老板）的指示。它明确指出助手的角色和职责，强调了在完成任务的过程中需要遵循的一些基本规则和原则。例如，助手需要针对用户的每一个指示提供一个明确的解决方案，而且这个解决方案必须是具体、易于理解的，并且只有在遇到物理、道德、法律的限制或自身能力的限制时，才能拒绝用户的指示。这个提示的设计目标是引导助手在一次有目标的对话中，有效地对用户的指示做出响应。\n2. **user\\_inception\\_prompt：** 这个提示是为了引导用户（即花店老板）如何给助手（即营销专员）下达指示。它明确指出了用户的角色和职责，强调了在提出任务指示时需要遵循的一些基本规则和原则。例如，用户需要一次只给出一个指示，并且必须清楚地提供相关的输入（如果有的话）。而且用户在给出指示的同时，不能向助手提问。这个提示的设计目标是引导用户在一次有目标的对话中，有效地给出指示，以便助手能够更好地理解和完成任务。\n\n这两个提示的设计都体现了一种“角色扮演”的机制，即通过赋予聊天代理具体的角色和职责，以帮助它们更好地理解和完成任务。这种机制可以有效地引导聊天代理的交流行为，使得对话更加有目的性和效率，同时也能提供更为真实的人类对话体验。\n\n### 头脑风暴开始\n\n接下来，模拟助手和用户之间的多轮对话，直到达到对话轮次上限或任务完成。\n\n```plain\n# 模拟对话交互，直到达到对话轮次上限或任务完成\nchat_turn_limit, n = 30, 0\nwhile n < chat_turn_limit:\n    n += 1\n    user_ai_msg = user_agent.step(assistant_msg)\n    user_msg = HumanMessage(content=user_ai_msg.content)\n    print(f\"AI User ({user_role_name}):\\n\\n{user_msg.content}\\n\\n\")\n\n    assistant_ai_msg = assistant_agent.step(user_msg)\n    assistant_msg = HumanMessage(content=assistant_ai_msg.content)\n    print(f\"AI Assistant ({assistant_role_name}):\\n\\n{assistant_msg.content}\\n\\n\")\n    if \"<CAMEL_TASK_DONE>\" in user_msg.content:\n        break\n\n```\n\n运行程序，营销策划头脑风暴开始！\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/453054aabe9d816ff88e05bb6ca03390.jpg)\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/dff9cdf1f992756a3a02e48f63e96d01.jpg)\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/219851d4806bd8fa01f7ee09ac0f715c.jpg)\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/dc6fb40781a2e53017e7d48d18f96a6f.jpg)\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/7c01866d547f9517787cf25cd4a65587.jpg)\n\n怎么样，看到这样的策划水准，是否觉得CAMEL框架趋动的AI助理完全不输给一个专业的营销策划专员呢？\n\n讲到这里，我冒出了两个想法。是不是只有我们想不到，没有AI做不到的？一大批人可能真的要失业了。所以，赶快学习吧！继续卷起来。\n\n## 总结时刻\n\n智能代理在未来世界中将扮演越来越重要的角色。为了使这些代理能够更好地为人类服务，我们需要找到方法来提高它们的交流能力。CAMEL这篇论文提供了一个全新的视角来看待交流代理的发展。通过使用“角色扮演”框架，可以开发出更加智能和人性化的交流代理，这将为我们的日常生活带来更多的便利。\n\n同时，我们也回顾一下CAMEL框架的实现，以及在这个实现中提示设计的特别之处。\n\n1. 角色扮演：每个代理都被赋予了一个角色，且每个角色都有清晰的责任和行为准则。比如，Python程序员（助手）的角色是根据股票交易员（用户）的指示提供具体的解决方案，而股票交易员的角色是提供详细的任务指示。这种角色扮演机制有助于模拟人类之间的交互过程，更加真实地完成任务。\n2. 任务的具体化：为了使AI更好地理解和执行任务，提出了将抽象任务具体化的步骤。这可以帮助AI更清晰地理解任务需求，更准确地给出解决方案。\n3. 初始提示的设定：为了启动会话并提供合适的引导，系统初始化时会提供两个初始提示，一条是助手角色的提示，另一条是用户角色的提示。这两条提示分别描述了各自角色的行为准则和任务细节，为整个对话过程提供了框架和指引。\n4. 交互规范：该代码实现中有明确的交互规范，如一次只能给出一个指令，解决方案必须具有详细的解释，使用 “Solution: ” 开始输出解决方案，等等。这些规范有助于保持对话的清晰性和高效性。\n\n与传统的提示设计不同，CAMEL中提示的设计更加复杂和细致，更像是一种交互协议或规范。这种设计在一定程度上提高了AI与AI之间自主合作的能力，并能更好地模拟人类之间的交互过程。\n\n## 思考题\n\n1. 在你的业务需求中，有什么需要细化、具体化的业务场景吗？不妨套用这里的CAMEL代码模板，做一次头脑风暴。\n2. 对于这个AI交流代理指导框架和提示模板的设计，你能否说说其优劣之处？有没有能进一步改进的地方？\n\n期待在留言区看到你的思考，如果觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。\n\n## 延伸阅读\n\n1. CAMEL 项目 [官网](https://www.camel-ai.org/) [GitHub](https://github.com/camel-ai/camel) 论文\n2. 新闻 [「零人工含量」的「游戏公司」](https://mp.weixin.qq.com/s/GKHD6M74rqC42u2w8EFjJw)\\- Chen, Q., Cong, X., Yang, C., Chen, W., Su, Y., Xu, J., Liu, Z., & Sun, M. (2023). [Communicative Agents for Software Development.](https://arxiv.org/abs/2307.07924) arXiv preprint arXiv:2307.07924 \\[cs.SE\\]."},{"url":"/posts/17.html","content":"# 19｜BabyAGI：根据气候变化自动制定鲜花存储策略\n你好，我是黄佳，欢迎来到LangChain实战课！\n\n在上节课中，我们深入探讨了如何利用CAMEL框架制定出一个高效的鲜花营销方案。然而，LangChain目前是将基于CAMEL框架的代理定义为Simulation Agents（模拟代理）。这种代理在模拟环境中进行角色扮演，试图模拟特定场景或行为，而不是在真实世界中完成具体的任务。\n\n随着ChatGPT的崭露头角，我们迎来了一种新型的代理——Autonomous Agents（自治代理或自主代理）。这些代理的设计初衷就是能够独立地执行任务，并持续地追求长期目标。在LangChain的代理、工具和记忆这些组件的支持下， **它们能够在无需外部干预的情况下自主运行，这在真实世界的应用中具有巨大的价值。**\n\n目前，GitHub上已有好几个备受关注的“网红”项目，如AutoGPT、BabyAGI和HuggingGPT，它们都代表了自治代理的初步尝试。尽管这些代理仍处于实验阶段，但潜力十分巨大。它们都是基于LangChain框架构建的。通过LangChain，你可以在这些开源项目中轻松地切换和测试多种LLM、使用多种向量存储作为记忆，以及充分利用LangChain的丰富工具集。\n\n今天的这节课，我就带着你看一看这些项目，同时也通过LangChain完成一个 BabyAGI 的实现。\n\n## AutoGPT\n\nAuto-GPT 是由Toran Bruce Richards创建的一个开源的自主AI代理，基于OpenAI的GPT-4语言模型。它的主要功能是 **自动链接多个任务**，以实现用户设定的大目标。与传统的聊天机器人（如ChatGPT）不同，用户只需提供一个提示或一组自然语言指令，Auto-GPT 就会通过自动化多步提示过程，将目标分解为子任务，以达到其目标。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/8527f131880785688eac48b10f7e5bbc.png)\n\nAuto-GPT一出世，就受到了广泛的宣传和追捧，Star数量半年飙升到了150K。\n\n**为什么Auto-GPT吸引了这么多眼球？**\n\n因为与ChatGPT相比，它能够与互联网集成，提供实时数据访问。Auto-GPT 将活动分解为子任务，自我提示（而不是像ChatGPT 那样需要用户多次提示才能把复杂任务完善地完成），并重复该过程，直到达到所提供的目标。\n\n技术上，Auto-GPT 使用短期记忆管理来保存上下文；同时Auto-GPT 是多模态的，可以处理文本和图像作为输入。\n\n从具体应用上说，Auto-GPT可以用于各种任务，例如生成文本、执行特定操作和进行网络搜索等。它还可以作为研究助手，帮助用户进行科学研究、市场研究、内容创建、销售线索生成、业务计划创建、产品评论、播客大纲制定等。\n\n当然，Auto-GPT并不完善，作为一个实验性质的项目，它还存在诸多挑战，比如它的运行成本可能很高，而且它可能会分心或陷入循环。技术上，它的缺陷是没有长期记忆。\n\n但是，作为一个开源项目，它的优势在于，它展示出了AI的边界和自主行动能力，凸显出了自主代理的潜力，也从实践上验证了人类正朝向人工普通智能（AGI）迈进。 **理论上说，更成熟的** **Auto-GPT** **版本可以启动与其他自主代理进行交互过程，实现AI代理之间的对话。**\n\nAuto-GPT 在GitHub上的社区非常活跃，开发者可以分享他们使用Auto-GPT的进展和想法。Auto-GPT 还有一个Hackathon活动，鼓励开发者提交他们的代理进行基准测试和比较。\n\n## Baby AGI\n\nBabyAGI是由中岛洋平（Yohei Nakajima）于2023年3月28日开发的自主任务驱动AI系统。核心在于，它可以根据设定的目标生成、组织、确定优先级以及执行任务。它也使用OpenAI的GPT-4语言模型来理解和创建任务，利用Pinecone向量搜索来存储和检索特定任务的结果，提供执行任务的上下文，并采用LangChain框架进行决策。\n\nBabyAGI尝试使用预定义的目标进行自我驱动，自动化个人任务管理。它不仅可以自动生成和执行任务，而且还可以根据完成的任务结果生成新任务，并且可以实时确定任务的优先级。\n\n与传统的AI工具（如ChatGPT）不同，BabyAGI不仅仅是解释查询和提供响应，而且能够根据目标生成任务列表，连续执行它们，并根据先前任务的输出适应性地创建更多任务。\n\n和Auto-GPT一样，该系统发布后广受关注，也被某些人誉为 **完全自主人工智能的起点**。\n\n在BabyAGI中，你向系统提出一个目标之后，它将不断优先考虑需要实现或完成的任务，以实现该目标。具体来说，系统将形成任务列表，从任务列表中拉出优先级最高的第一个任务，使用 OpenAI API 根据上下文将任务发送到执行代理并完成任务，一旦这些任务完成，它们就会被存储在内存（或者Pinecone这类向量数据库）中，然后，根据目标和上一个任务的结果创建新任务并确定优先级。\n\n整个过程如下图所示：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/07cbca8cfff33ffa231830eff145556c.png)\n\n在这个过程中，驱动任务的是三个不同作用的代理。分别是执行代理execution\\_agent，任务创建代理task\\_creation\\_agent，以及优先级设置代理prioritization\\_agent。\n\n- **执行代理**，是系统的核心，利用OpenAI的API来处理任务。这个代理的实现函数有两个参数，目标和任务，用于向 OpenAI 的 API 发送提示，并以字符串形式返回任务结果。\n- **任务创建代理**，通过OpenAI的API根据当前对象和先前任务的结果创建新任务。这个代理的实现函数有四个参数，目标、上一个任务的结果、任务描述和当前任务列表。这个代理会向 OpenAI 的 API 发送一条提示，该 API 将以字符串形式返回新任务列表。然后，该函数将以字典列表的形式返回这些新任务，其中每个字典都包含任务的名称。\n- **优先级设置代理**，负责任务列表的排序和优先级，仍然是通过调用OpenAI 的 API 来重新确定任务列表的优先级。这个代理的实现函数有一个参数，即当前任务的 ID。这个代理会向 OpenAI 的 API 发送提示，并返回已重新优先排序为编号列表的新任务列表。\n\n等一下，我就用这个BabyAGI的框架来带着你开发一个能够根据气候变化自动制定鲜花存储策略的AI智能代理。\n\n## HuggingGPT\n\n在Yongliang Shen的论文《HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face》中，介绍了HuggingGPT的系统。HuggingGPT的工作流程包括四个阶段。\n\n1. 任务规划：LLM（例如ChatGPT）解析用户请求，生成任务列表，并确定任务之间的执行顺序和资源依赖关系。\n2. 模型选择：LLM根据Hugging Face上的专家模型描述，为任务分配适当的模型。\n3. 任务执行：整合各个任务端点上的专家模型，执行分配的任务。\n4. 响应生成：LLM整合专家的推断结果，生成工作流摘要，并给用户提供最终的响应。\n\nHuggingGPT的设计，使其能够根据用户请求自动生成计划，并使用外部模型，从而整合多模态感知能力，并处理多个复杂的AI任务。此外，这种流程还允许HuggingGPT持续从任务特定的专家模型中吸收能力，从而实现可增长和可扩展的AI能力。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/7ec5769743e7ddf58883ca74385cbd36.png)\n\n文章还提到，HuggingGPT的优势在于， **它能够使用不同的模型来执行特定的任务**，如图像分类、对象检测、图像描述等。例如，它使用 OpenCV 的 OpenPose 模型来分析图像中小朋友的姿势，并使用其他模型生成新图像和描述。\n\n不难看出，尽管实现过程各有特点，但这些自主类的AI代理应用的基本思想和流程还是很类似的。关键是利用LLM的推理能力生成任务，确定任务优先级，然后执行任务，实现目标。\n\n## 根据气候变化自动制定鲜花存储策略\n\n下面，我们就解析一下 LangChain 中 BabyAGI 的具体实现。这里的 “BabyAGI” 是一个简化版的实现，其核心功能是自动创建、优先级排序和执行任务。\n\n首先，我们导入相关的库。\n\n```plain\n# 设置API Key\nimport os\nos.environ[\"OPENAI_API_KEY\"] = 'Your OpenAI API Key\n\n# 导入所需的库和模块\nfrom collections import deque\nfrom typing import Dict, List, Optional, Any\nfrom langchain.chains import LLMChain\nfrom langchain.prompts import PromptTemplate\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.llms import BaseLLM, OpenAI\nfrom langchain.vectorstores.base import VectorStore\nfrom pydantic import BaseModel, Field\nfrom langchain.chains.base import Chain\nfrom langchain.vectorstores import FAISS\nimport faiss\nfrom langchain.docstore import InMemoryDocstore\n\n```\n\n然后，我们初始化OpenAIEmbedding作为嵌入模型，并使用Faiss作为向量数据库存储任务信息。\n\n```plain\n# 定义嵌入模型\nembeddings_model = OpenAIEmbeddings()\n# 初始化向量存储\nembedding_size = 1536\nindex = faiss.IndexFlatL2(embedding_size)\nvectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})\n\n```\n\n下面是定义任务生成链，基于给定的条件，这个链可以创建新任务。例如，它可以根据最后一个完成的任务的结果来生成新任务。\n\n```plain\n# 任务生成链\nclass TaskCreationChain(LLMChain):\n    \"\"\"负责生成任务的链\"\"\"\n    @classmethod\n    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n        \"\"\"从LLM获取响应解析器\"\"\"\n        task_creation_template = (\n            \"You are a task creation AI that uses the result of an execution agent\"\n            \" to create new tasks with the following objective: {objective},\"\n            \" The last completed task has the result: {result}.\"\n            \" This result was based on this task description: {task_description}.\"\n            \" These are incomplete tasks: {incomplete_tasks}.\"\n            \" Based on the result, create new tasks to be completed\"\n            \" by the AI system that do not overlap with incomplete tasks.\"\n            \" Return the tasks as an array.\"\n        )\n        prompt = PromptTemplate(\n            template=task_creation_template,\n            input_variables=[\n                \"result\",\n                \"task_description\",\n                \"incomplete_tasks\",\n                \"objective\",\n            ],\n        )\n        return cls(prompt=prompt, llm=llm, verbose=verbose)\n\n```\n\n下面是定义任务优先级链，这个链负责重新排序任务的优先级。给定一个任务列表，它会返回一个新的按优先级排序的任务列表。\n\n```plain\n# 任务优先级链\nclass TaskPrioritizationChain(LLMChain):\n    \"\"\"负责任务优先级排序的链\"\"\"\n    @classmethod\n    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n        \"\"\"从LLM获取响应解析器\"\"\"\n        task_prioritization_template = (\n            \"You are a task prioritization AI tasked with cleaning the formatting of and reprioritizing\"\n            \" the following tasks: {task_names}.\"\n            \" Consider the ultimate objective of your team: {objective}.\"\n            \" Do not remove any tasks. Return the result as a numbered list, like:\"\n            \" #. First task\"\n            \" #. Second task\"\n            \" Start the task list with number {next_task_id}.\"\n        )\n        prompt = PromptTemplate(\n            template=task_prioritization_template,\n            input_variables=[\"task_names\", \"next_task_id\", \"objective\"],\n        )\n        return cls(prompt=prompt, llm=llm, verbose=verbose)\n\n```\n\n下面是定义任务执行链，这个链负责执行具体的任务，并返回结果。\n\n```plain\n# 任务执行链\nclass ExecutionChain(LLMChain):\n    \"\"\"负责执行任务的链\"\"\"\n\n    @classmethod\n    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n        \"\"\"从LLM获取响应解析器\"\"\"\n        execution_template = (\n            \"You are an AI who performs one task based on the following objective: {objective}.\"\n            \" Take into account these previously completed tasks: {context}.\"\n            \" Your task: {task}.\"\n            \" Response:\"\n        )\n        prompt = PromptTemplate(\n            template=execution_template,\n            input_variables=[\"objective\", \"context\", \"task\"],\n        )\n        return cls(prompt=prompt, llm=llm, verbose=verbose)\n\n```\n\n之后，我们定义一系列功能函数，实现 get\\_next\\_task、prioritize\\_tasks、\\_get\\_top\\_tasks 以及 execute\\_task 等具体功能。\n\n```plain\ndef get_next_task(\n    task_creation_chain: LLMChain,\n    result: Dict,\n    task_description: str,\n    task_list: List[str],\n    objective: str,\n) -> List[Dict]:\n    \"\"\"Get the next task.\"\"\"\n    incomplete_tasks = \", \".join(task_list)\n    response = task_creation_chain.run(\n        result=result,\n        task_description=task_description,\n        incomplete_tasks=incomplete_tasks,\n        objective=objective,\n    )\n    new_tasks = response.split(\"\\n\")\n    return [{\"task_name\": task_name} for task_name in new_tasks if task_name.strip()]\n\ndef prioritize_tasks(\n    task_prioritization_chain: LLMChain,\n    this_task_id: int,\n    task_list: List[Dict],\n    objective: str,\n) -> List[Dict]:\n    \"\"\"Prioritize tasks.\"\"\"\n    task_names = [t[\"task_name\"] for t in task_list]\n    next_task_id = int(this_task_id) + 1\n    response = task_prioritization_chain.run(\n        task_names=task_names, next_task_id=next_task_id, objective=objective\n    )\n    new_tasks = response.split(\"\\n\")\n    prioritized_task_list = []\n    for task_string in new_tasks:\n        if not task_string.strip():\n            continue\n        task_parts = task_string.strip().split(\".\", 1)\n        if len(task_parts) == 2:\n            task_id = task_parts[0].strip()\n            task_name = task_parts[1].strip()\n            prioritized_task_list.append({\"task_id\": task_id, \"task_name\": task_name})\n    return prioritized_task_list\n\ndef _get_top_tasks(vectorstore, query: str, k: int) -> List[str]:\n    \"\"\"Get the top k tasks based on the query.\"\"\"\n    results = vectorstore.similarity_search_with_score(query, k=k)\n    if not results:\n        return []\n    sorted_results, _ = zip(*sorted(results, key=lambda x: x[1], reverse=True))\n    return [str(item.metadata[\"task\"]) for item in sorted_results]\n\ndef execute_task(\n    vectorstore, execution_chain: LLMChain, objective: str, task: str, k: int = 5\n) -> str:\n    \"\"\"Execute a task.\"\"\"\n    context = _get_top_tasks(vectorstore, query=objective, k=k)\n    return execution_chain.run(objective=objective, context=context, task=task)\n\n```\n\n然后，我们定义BabyAGI，这是主类，它控制整个系统的运行流程，包括添加任务、输出任务列表、执行任务等。\n\n```plain\n# BabyAGI 主类\nclass BabyAGI(Chain, BaseModel):\n    \"\"\"BabyAGI代理的控制器模型\"\"\"\n\n    task_list: deque = Field(default_factory=deque)\n    task_creation_chain: TaskCreationChain = Field(...)\n    task_prioritization_chain: TaskPrioritizationChain = Field(...)\n    execution_chain: ExecutionChain = Field(...)\n    task_id_counter: int = Field(1)\n    vectorstore: VectorStore = Field(init=False)\n    max_iterations: Optional[int] = None\n\n    class Config:\n        \"\"\"Configuration for this pydantic object.\"\"\"\n\n        arbitrary_types_allowed = True\n\n    def add_task(self, task: Dict):\n        self.task_list.append(task)\n\n    def print_task_list(self):\n        print(\"\\033[95m\\033[1m\" + \"\\n*****TASK LIST*****\\n\" + \"\\033[0m\\033[0m\")\n        for t in self.task_list:\n            print(str(t[\"task_id\"]) + \": \" + t[\"task_name\"])\n\n    def print_next_task(self, task: Dict):\n        print(\"\\033[92m\\033[1m\" + \"\\n*****NEXT TASK*****\\n\" + \"\\033[0m\\033[0m\")\n        print(str(task[\"task_id\"]) + \": \" + task[\"task_name\"])\n\n    def print_task_result(self, result: str):\n        print(\"\\033[93m\\033[1m\" + \"\\n*****TASK RESULT*****\\n\" + \"\\033[0m\\033[0m\")\n        print(result)\n\n    @property\n    def input_keys(self) -> List[str]:\n        return [\"objective\"]\n\n    @property\n    def output_keys(self) -> List[str]:\n        return []\n\n    def _call(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Run the agent.\"\"\"\n        objective = inputs[\"objective\"]\n        first_task = inputs.get(\"first_task\", \"Make a todo list\")\n        self.add_task({\"task_id\": 1, \"task_name\": first_task})\n        num_iters = 0\n        while True:\n            if self.task_list:\n                self.print_task_list()\n\n                # Step 1: Pull the first task\n                task = self.task_list.popleft()\n                self.print_next_task(task)\n\n                # Step 2: Execute the task\n                result = execute_task(\n                    self.vectorstore, self.execution_chain, objective, task[\"task_name\"]\n                )\n                this_task_id = int(task[\"task_id\"])\n                self.print_task_result(result)\n\n                # Step 3: Store the result in Pinecone\n                result_id = f\"result_{task['task_id']}_{num_iters}\"\n                self.vectorstore.add_texts(\n                    texts=[result],\n                    metadatas=[{\"task\": task[\"task_name\"]}],\n                    ids=[result_id],\n                )\n\n                # Step 4: Create new tasks and reprioritize task list\n                new_tasks = get_next_task(\n                    self.task_creation_chain,\n                    result,\n                    task[\"task_name\"],\n                    [t[\"task_name\"] for t in self.task_list],\n                    objective,\n                )\n                for new_task in new_tasks:\n                    self.task_id_counter += 1\n                    new_task.update({\"task_id\": self.task_id_counter})\n                    self.add_task(new_task)\n                self.task_list = deque(\n                    prioritize_tasks(\n                        self.task_prioritization_chain,\n                        this_task_id,\n                        list(self.task_list),\n                        objective,\n                    )\n                )\n            num_iters += 1\n            if self.max_iterations is not None and num_iters == self.max_iterations:\n                print(\n                    \"\\033[91m\\033[1m\" + \"\\n*****TASK ENDING*****\\n\" + \"\\033[0m\\033[0m\"\n                )\n                break\n        return {}\n\n    @classmethod\n    def from_llm(\n        cls, llm: BaseLLM, vectorstore: VectorStore, verbose: bool = False, **kwargs\n    ) -> \"BabyAGI\":\n        \"\"\"Initialize the BabyAGI Controller.\"\"\"\n        task_creation_chain = TaskCreationChain.from_llm(llm, verbose=verbose)\n        task_prioritization_chain = TaskPrioritizationChain.from_llm(\n            llm, verbose=verbose\n        )\n        execution_chain = ExecutionChain.from_llm(llm, verbose=verbose)\n        return cls(\n            task_creation_chain=task_creation_chain,\n            task_prioritization_chain=task_prioritization_chain,\n            execution_chain=execution_chain,\n            vectorstore=vectorstore,\n            **kwargs,\n        )\n\n```\n\n主执行部分，这是代码的入口点，定义了一个目标（分析北京市今天的气候情况，并提出鲜花储存策略），然后初始化并运行BabyAGI。\n\n```plain\n# 主执行部分\nif __name__ == \"__main__\":\n    OBJECTIVE = \"分析一下北京市今天的气候情况，写出鲜花储存策略。\"\n    llm = OpenAI(temperature=0)\n    verbose = False\n    max_iterations: Optional[int] = 6\n    baby_agi = BabyAGI.from_llm(llm=llm, vectorstore=vectorstore,\n                                verbose=verbose,\n                                max_iterations=max_iterations)\n    baby_agi({\"objective\": OBJECTIVE})\n\n```\n\n运行这个程序之后，产生了下面的结果。\n\n```plain\n'''*****TASK LIST*****\n\n1: Make a todo list\n\n*****NEXT TASK*****\n\n1: Make a todo list\n\n*****TASK RESULT*****\n\n1. Gather data on current weather conditions in Beijing, including temperature, humidity, wind speed, and precipitation.\n\n2. Analyze the data to determine the best storage strategy for flowers.\n\n3. Research the optimal temperature, humidity, and other environmental conditions for flower storage.\n\n4. Develop a plan for storing flowers in Beijing based on the data and research.\n\n5. Implement the plan and monitor the flowers for any changes in condition.\n\n6. Make adjustments to the plan as needed.\n\n*****TASK LIST*****\n\n2: Identify the most suitable materials for flower storage in Beijing.\n3: Investigate the effects of temperature, humidity, and other environmental factors on flower storage.\n4: Research the best methods for preserving flowers in Beijing.\n5: Develop a plan for storing flowers in Beijing that takes into account the data and research.\n6: Monitor the flowers for any changes in condition and make adjustments to the plan as needed.\n7: Analyze the current climate conditions in Beijing and write out a strategy for flower storage.\n8: Create a report summarizing the findings and recommendations for flower storage in Beijing.\n\n*****NEXT TASK*****\n\n2: Identify the most suitable materials for flower storage in Beijing.\n\n*****TASK RESULT*****\n\nIn order to store flowers in Beijing, it is important to consider the current weather conditions. Today, the temperature in Beijing is around 18°C with a humidity of around 70%. This means that the air is relatively dry and cool, making it suitable for storing flowers.\n\nThe best materials for flower storage in Beijing would be materials that are breathable and moisture-resistant. Examples of suitable materials include paper, cardboard, and fabric. These materials will help to keep the flowers fresh and prevent them from wilting. Additionally, it is important to keep the flowers away from direct sunlight and heat sources, as this can cause them to dry out quickly.\n\n*****TASK LIST*****\n\n3: Analyze the current climate conditions in Beijing and write out a strategy for flower storage.\n4: Investigate the effects of temperature, humidity, and other environmental factors on flower storage in Beijing.\n5: Research the best methods for preserving flowers in Beijing.\n6: Develop a plan for storing flowers in Beijing that takes into account the data and research.\n7: Monitor the flowers for any changes in condition and make adjustments to the plan as needed.\n8: Create a report summarizing the findings and recommendations for flower storage in Beijing, and provide suggestions for improvement.\n\n*****NEXT TASK*****\n\n3: Analyze the current climate conditions in Beijing and write out a strategy for flower storage.\n\n*****TASK RESULT*****\n\nBased on the current climate conditions in Beijing, the best strategy for flower storage is to keep the flowers in a cool, dry place. This means avoiding direct sunlight and keeping the flowers away from any sources of heat. Additionally, it is important to keep the flowers away from any sources of moisture, such as humidifiers or air conditioners. The flowers should also be kept away from any sources of strong odors, such as perfumes or cleaning products. Finally, it is important to keep the flowers away from any sources of pests, such as insects or rodents. To ensure the flowers remain in optimal condition, it is important to regularly check the temperature and humidity levels in the storage area.\n\n*****TASK LIST*****\n\n4: Monitor the flowers for any changes in condition and make adjustments to the plan as needed.\n1: Analyze the impact of different types of flowers on flower storage in Beijing.\n2: Compare the effectiveness of different flower storage strategies in Beijing.\n3: Investigate the effects of temperature, humidity, and other environmental factors on flower storage in Beijing.\n5: Research the best methods for preserving flowers in Beijing.\n6: Develop a plan for storing flowers in Beijing that takes into account the data and research.\n7: Investigate the effects of different storage materials on flower preservation in Beijing.\n8: Develop a system for monitoring the condition of flowers in storage in Beijing.\n9: Create a checklist for flower storage in Beijing that can be used to ensure optimal conditions.\n10: Identify potential risks associated with flower storage in Beijing and develop strategies to mitigate them.\n11: Create a report summarizing the findings and recommendations for flower storage in Beijing, and provide suggestions for improvement.\n\n*****NEXT TASK*****\n\n4: Monitor the flowers for any changes in condition and make adjustments to the plan as needed.\n\n*****TASK RESULT*****\n\nI will monitor the flowers for any changes in condition and make adjustments to the plan as needed. This includes checking for signs of wilting, discoloration, or other signs of deterioration. I will also monitor the temperature and humidity levels in the storage area to ensure that the flowers are kept in optimal conditions. If necessary, I will adjust the storage plan to ensure that the flowers remain in good condition. Additionally, I will keep track of the expiration date of the flowers and adjust the storage plan accordingly.\n\n*****TASK LIST*****\n\n5: Analyze the current climate conditions in Beijing and how they affect flower storage.\n6: Investigate the effects of different storage containers on flower preservation in Beijing.\n7: Develop a system for tracking the condition of flowers in storage in Beijing.\n8: Identify potential pests and diseases that could affect flower storage in Beijing and develop strategies to prevent them.\n9: Create a report summarizing the findings and recommendations for flower storage in Beijing, and provide suggestions for improvement.\n10: Develop a plan for storing flowers in Beijing that takes into account the data and research.\n11: Compare the cost-effectiveness of different flower storage strategies in Beijing.\n12: Research the best methods for preserving flowers in Beijing in different seasons.\n13: Investigate the effects of temperature, humidity, and other environmental factors on flower storage in Beijing.\n14: Investigate the effects of different storage materials on flower preservation in Beijing.\n15: Analyze the impact of different types of flowers on flower storage in Beijing.\n16: Compare the effectiveness of different flower storage strategies in Beijing.\n17: Create a checklist for flower storage in Beijing that can be used to ensure optimal conditions.\n18: Identify potential risks associated with flower storage in\n\n*****NEXT TASK*****\n\n5: Analyze the current climate conditions in Beijing and how they affect flower storage.\n\n*****TASK RESULT*****\n\nBased on the current climate conditions in Beijing, the most suitable materials for flower storage would be materials that are breathable and moisture-resistant. This would include materials such as burlap, cotton, and linen. Additionally, it is important to ensure that the flowers are stored in a cool, dry place, away from direct sunlight. Furthermore, it is important to monitor the flowers for any changes in condition and make adjustments to the plan as needed. Finally, it is important to make a to-do list to ensure that all necessary steps are taken to properly store the flowers.\n\n*****TASK LIST*****\n\n6: Develop a plan for storing flowers in Beijing that takes into account the local climate conditions.\n1: Investigate the effects of different storage containers on flower preservation in Beijing.\n2: Investigate the effects of different storage materials on flower preservation in Beijing in different seasons.\n3: Analyze the impact of different types of flowers on flower storage in Beijing.\n4: Compare the cost-effectiveness of different flower storage strategies in Beijing.\n5: Research the best methods for preserving flowers in Beijing in different weather conditions.\n7: Develop a system for tracking the condition of flowers in storage in Beijing.\n8: Identify potential pests and diseases that could affect flower storage in Beijing and develop strategies to prevent them.\n9: Create a report summarizing the findings and recommendations for flower storage in Beijing, and provide suggestions for improvement.\n10: Create a checklist for flower storage in Beijing that can be used to ensure optimal conditions.\n11: Identify potential risks associated with flower storage in Beijing.\n\n*****NEXT TASK*****\n\n6: Develop a plan for storing flowers in Beijing that takes into account the local climate conditions.\n\n*****TASK RESULT*****\nBased on the previously completed tasks, I have developed a plan for storing flowers in Beijing that takes into account the local climate conditions.\n\nFirst, I will analyze the current climate conditions in Beijing, including temperature, humidity, and air quality. This will help me identify the most suitable materials for flower storage in Beijing.\n\nSecond, I will create a to-do list of tasks that need to be completed in order to properly store the flowers. This list should include tasks such as selecting the right materials for flower storage, ensuring the flowers are kept in a cool and dry environment, and regularly monitoring the flowers for any changes in condition.\n\nThird, I will develop a strategy for flower storage that takes into account the local climate conditions. This strategy should include steps such as selecting the right materials for flower storage, ensuring the flowers are kept in a cool and dry environment, and regularly monitoring the flowers for any changes in condition.\n\nFinally, I will monitor the flowers for any changes in condition and make adjustments to the plan as needed. This will help ensure that the flowers are stored in the most suitable environment for their preservation.\n\n*****TASK ENDING*****'''\n\n```\n\n从结构上看，内容以循环方式进行组织，首先是 TASK LIST（任务列表），接着是 NEXT TASK（下一个任务），然后是 TASK RESULT（任务结果）。\n\n每个任务结果似乎都是基于前一个任务的输出。随着自主代理思考的逐步深入，子任务的重点从获取当前的天气数据，到确定最佳的花朵储存策略，再到对策略的实际执行和调整。\n\n6 轮循环之后，在任务的最终结果部分提供了具体的步骤和策略，以确保花朵在最佳的条件下储存。至于这个策略有多大用途，就仁者见仁智者见智了吧。\n\n## 总结时刻\n\n模拟代理主要关注模拟特定环境中的行为，而自主代理则更加关注独立性、自适应性和长期的任务执行。\n\n本节课中我们介绍的 Auto-GPT、BabyAGI 以及 HuggingGPT，它们作为自主代理（Autonomous Agents）的代表，旨在创建更加普适和强大的算法，这些算法能够处理各种任务，并在没有明确编程指令的情况下自我改进。\n\n这些自主代理的特点，我列表总结如下，供你参考。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/56d4bdbcaec0deba243a4d7cf6eb71d1.jpg)\n\n未来，这种自主代理将在企业运营的任务分配、项目管理和资源调度等环节中起到至关重要的作用。想象一下，随着人工智能技术的飞速发展，会有众多的自主趋动型的应用程序被开发出来，优化任务管理，AI 将涵盖从项目开始到结束的整个过程，确保每个任务都得到有效的监控和组织。\n\n## 思考题\n\n1. 请你阅读 [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT) 的细节，并构造自己的AI代理。\n2. 请你阅读 [HuggingGPT](https://arxiv.org/pdf/2303.17580.pdf) 的细节，并构造自己的AI代理。\n\n期待在留言区看到你的分享，如果觉得内容对你有帮助，也欢迎分享给有需要的朋友！最后如果你学有余力，可以进一步学习下面的延伸阅读。\n\n## 延伸阅读\n\n1. GitHub 项目 [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT) [官网](https://autogpt.net/)\n2. GitHub 项目 [BabyAGI](https://github.com/yoheinakajima/babyagi) [官网](https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/)\n3. 论文 [HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face](https://arxiv.org/pdf/2303.17580.pdf) [官网](https://huggingface.co/spaces/microsoft/HuggingGPT)"},{"url":"/posts/18.html","content":"# 20｜部署一个鲜花网络电商的人脉工具（上）\n你好，我是黄佳，欢迎来到LangChain实战课！\n\n从今天开始，我要用4节课的篇幅，带着你设计两个有趣而又实用的应用程序。设计这两个应用程序的目的，是为了让你能够把LangChain中的各个组件灵活地组合起来，融会贯通，并以此作为启发，在你熟悉的业务场景中，利用LangChain和LLM的能力，开发出更多、更强大的效率工具。\n\n第一个应用程序，是用LangChain创建出一个专属于“易速鲜花”的网络人脉工具。光这么说，有些模糊，这个人脉工具长啥样？有些啥具体功能？\n\n动手之前，让我先给你把这个所谓“人脉”工具的能力和细节说清楚。\n\n## “人脉工具”项目说明\n\n**项目背景**：易速鲜花电商网络自从创建以来，通过微信、抖音、小红书等自媒体宣传推广，短期内获得了广泛流量展示。目前，营销部门希望以此为契机，再接再厉，继续扩大品牌影响力。经过调研，发现很多用户会通过微博热搜推荐的新闻来购买鲜花赠送给明星、达人等，因此各部门一致认为应该联络相关微博大V，共同推广，带动品牌成长。\n\n然而，发掘并选择适合于“鲜花推广”的微博大V有一定难度。营销部门员工表示，这个任务比找微信、抖音和小红书达人要难得多。他们都希望技术部门能够给出一个“人脉搜索工具”来协助完成这一目标。\n\n**项目目标：** 帮助市场营销部门的员工找到微博上适合做鲜花推广的大V，并给出具体的联络方案。\n\n## 项目的技术实现细节\n\n这个项目的具体技术实现细节，这里简述如下。\n\n**第一步：** 通过LangChain的搜索工具，以模糊搜索的方式，帮助运营人员找到微博中有可能对相关鲜花推广感兴趣的大V（比如喜欢玫瑰花的大V），并返回UID。\n\n**第二步：** 根据微博UID，通过爬虫工具拿到相关大V的微博公开信息，并以JSON格式返回大V的数据。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/0049810d3cfe1aee633d29722ded8e5f.png)\n\n**第三步：** 通过LangChain调用LLM，通过LLM的总结整理以及生成功能，根据大V的个人信息，写一篇热情洋溢的介绍型文章，谋求与该大V的合作。\n\n**第四步：** 把LangChain输出解析功能加入进来，让LLM生成可以嵌入提示模板的格式化数据结构。\n\n**第五步：** 添加HTML、CSS，并用Flask创建一个App，在网络上部署及发布这个鲜花电商人脉工具，供市场营销部门的人员使用。\n\n在上面的5个步骤中，我们使用到很多LangChain技术，包括 **提示工程、模型、链、代理、输出解析** 等。\n\n这节课我们先来实现项目的前两个部分。\n\n## 第一步：找到大 V\n\n因为咱们的项目需要用到很多工具，所以我创建了一个项目目录，叫做socializer\\_v0（项目每完成一步，我就创建一个新目录，并把版本号加1）。当第一个步骤“找到大 V”实现之后，项目中的文档结构如下。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/5dab492f802d34086975616d06708e0c.jpg)\n\n这里，主程序是findbigV.py。意思就是派程序来作为智能代理，找到喜欢鲜花的微博大V。\n\n## 主程序 findbigV.py\n\n主程序findbigV.py在第一步完成之后，是这样的。\n\n```plain\n# 设置OpenAI API密钥\nimport os\nos.environ[\"OPENAI_API_KEY\"] = ''\nos.environ[\"SERPAPI_API_KEY\"] = ''\n\n# 导入所取的库\nimport re\nfrom agents.weibo_agent import lookup_V\n\nif __name__ == \"__main__\":\n\n    # 拿到UID\n    response_UID = lookup_V(flower_type = \"牡丹\" )\n    print(response_UID)\n\n    # 抽取UID里面的数字\n    UID = re.findall(r'\\d+', response_UID)[0]\n    print(\"这位鲜花大V的微博ID是\", UID)\n\n```\n\n这里，我们要搜到的，是一个热爱鲜花的大V的微博UID，而不是URL。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/520688ef98a70c3d3651420bcc26bef1.jpg)\n\n比如，上面这位喜欢牡丹花的大V，他的UID是6053338099。这些都是公开的信息。\n\n为什么我们希望得到UID呢？因为我们可以通过这个ID，爬取他个人主页里的更多介绍信息，有利于进一步了解他。\n\n### 微博 Agent：查找大 V 的 ID\n\n下面，我们就来看看，文件agents\\\\weibo\\_agent.py中的lookup\\_V函数是如何实现这个搜寻UID的功能的。\n\n```plain\n# 导入一个搜索UID的工具\nfrom tools.search_tool import get_UID\n\n# 导入所需的库\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.agents import initialize_agent, Tool\nfrom langchain.agents import AgentType\n\n# 通过LangChain代理找到UID的函数\ndef lookup_V(flower_type: str) :\n    # 初始化大模型\n    llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n\n    # 寻找UID的模板\n    template = \"\"\"given the {flower} I want you to get a related 微博 UID.\n                  Your answer should contain only a UID.\n                  The URL always starts with https://weibo.com/u/\n                  for example, if https://weibo.com/u/1669879400 is her 微博, then 1669879400 is her UID\n                  This is only the example don't give me this, but the actual UID\"\"\"\n    # 完整的提示模板\n    prompt_template = PromptTemplate(\n        input_variables=[\"flower\"], template=template\n    )\n\n    # 代理的工具\n    tools = [\n        Tool(\n            name=\"Crawl Google for 微博 page\",\n            func=get_UID,\n            description=\"useful for when you need get the 微博 UID\",\n        )\n    ]\n\n    # 初始化代理\n    agent = initialize_agent(\n        tools,\n        llm,\n        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n        verbose=True\n    )\n\n    # 返回找到的UID\n    ID = agent.run(prompt_template.format_prompt(flower=flower_type))\n\n    return ID\n\n```\n\n这段代码的目的，是为了通过提供的花的类型（flower type）来查找与之相关的微博UID。其中使用了LangChain中的代理和工具。\n\n这里有两点需要特别说明：\n\n1. 搜索UID的工具通过from tools.search\\_tool import get\\_UID导入，这个内容后面还会介绍。\n2. 下面的提示模板说明，强调了需要的是UID，而不是URL。刚才说了，这是因为后续的爬虫工具需要一个特定的UID，来获取该微博大V的个人信息（公开）。然后我们会继续利用这些信息让LLM为我们写“勾搭”文案。\n\n```plain\n    # 寻找UID的模板\n    template = \"\"\"given the {flower} I want you to get a related 微博 UID.\n                  Your answer should contain only a UID.\n                  The URL always starts with https://weibo.com/u/\n                  for example, if https://weibo.com/u/1669879400 is her 微博, then 1669879400 is her UID\n                  This is only the example don't give me this, but the actual UID\"\"\"\n\n```\n\n### 定制的 SerpAPI：getUID\n\n上面的程序只是调用了代理，但是没有给出具体的工具实现。现在我们来继续实现搜索大V的UID的功能。\n\n```plain\n# 导入一个搜索UID的工具\nfrom tools.search_tool import get_UID\n\n```\n\n这个具体的实现，在代码 \\\\tools\\\\search\\_tool.py 中。\n\n说到通过LangChain来搜索微博，相信你会马上想到已经多次使用过的SerpAPI。我们先来试一试标准的SerpAPI，看看它能否满足我们的需求。\n\n```plain\nfrom langchain.utilities import SerpAPIWrapper\n\ndef get_UID(flower: str):\n    \"\"\"Searches for Linkedin or twitter Profile Page.\"\"\"\n    search = SerpAPIWrapper()\n    res = search.run(f\"{flower}\")\n    return res\n\n```\n\n写好了这段代码，第一步就可以说是完成了。下面我们跑一遍findbigV.py，看看程序会给出我们什么样的结果。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/a22043515a4b9686c58ccedcda2075d8.jpg)\n\n结果还好，不算太失望，SerpAPI找到了一个貌似喜欢牡丹花的大V，名叫戏精牡丹，搜到的信息也都是真实的。看起来他蛮适合为我们的牡丹花代言。然而，这个大V的微博ID肯定不是6。\n\n中间哪里或许是出了点小问题。\n\n像这样的错误，明显发生在LangChain内部，那你的 trouble\\_shooting 也只能通过Debug来解决。这里，我就忽略掉一长串的错误排查过程，直接指出问题的根本原因所在。\n\n让我们把断点设置在SerpAPIWrapper类的\\_process\\_response中。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/86238bae7452cde52f23e4d6ea3a1688.jpg)\n\n当程序进入 ` if \"organic_results\" in res.keys()` 这段逻辑之后，我发现，它返回的总是一个snippet（摘要文字），而不是link（URL）。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/38643a041b2f24ed9e8405a485580cbe.jpg)\n\n无论这背后的逻辑何在，这并不是我们所想要的。在Debug过程中，我们发现，新浪微博的UID，实际上包含在URL中，也就是 [https://weibo.com/u/6053338099](https://weibo.com/u/6053338099)。因此，如果我们不返回微博的简短说明（戏精牡丹，搞笑视频自媒体……），而是返回URL，会更有利于大模型提炼出UID。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/2a78e4b1cc0734f1c5ce171a05f153c0.jpg)\n\n如何做呢？直接修改LangChain的SerpAPIWrapper类的\\_process\\_response源代码肯定不是一个好办法。\n\n因此，这里我们可以继承SerpAPIWrapper类，并构造一个CustomSerpAPIWrapper类，在这个类中，我们重构\\_process\\_response这个静态方法。\n\n新的search\\_tool.py完整代码如下：\n\n```plain\n# 导入SerpAPIWrapper\nfrom langchain.utilities import SerpAPIWrapper\n\n# 重新定制SerpAPIWrapper，重构_process_response，返回URL\nclass CustomSerpAPIWrapper(SerpAPIWrapper):\n    def __init__(self):\n        super(CustomSerpAPIWrapper, self).__init__()\n\n    @staticmethod\n    def _process_response(res: dict) -> str:\n        \"\"\"Process response from SerpAPI.\"\"\"\n        if \"error\" in res.keys():\n            raise ValueError(f\"Got error from SerpAPI: {res['error']}\")\n        if \"answer_box_list\" in res.keys():\n            res[\"answer_box\"] = res[\"answer_box_list\"]\n        '''删去很多无关代码'''\n        snippets = []\n        if \"knowledge_graph\" in res.keys():\n            knowledge_graph = res[\"knowledge_graph\"]\n            title = knowledge_graph[\"title\"] if \"title\" in knowledge_graph else \"\"\n            if \"description\" in knowledge_graph.keys():\n                snippets.append(knowledge_graph[\"description\"])\n            for key, value in knowledge_graph.items():\n                if (\n                    isinstance(key, str)\n                    and isinstance(value, str)\n                    and key not in [\"title\", \"description\"]\n                    and not key.endswith(\"_stick\")\n                    and not key.endswith(\"_link\")\n                    and not value.startswith(\"http\")\n                ):\n                    snippets.append(f\"{title} {key}: {value}.\")\n        if \"organic_results\" in res.keys():\n            first_organic_result = res[\"organic_results\"][0]\n            if \"snippet\" in first_organic_result.keys():\n                # 此处是关键修改\n                # snippets.append(first_organic_result[\"snippet\"])\n                snippets.append(first_organic_result[\"link\"])\n            elif \"snippet_highlighted_words\" in first_organic_result.keys():\n                snippets.append(first_organic_result[\"snippet_highlighted_words\"])\n            elif \"rich_snippet\" in first_organic_result.keys():\n                snippets.append(first_organic_result[\"rich_snippet\"])\n            elif \"rich_snippet_table\" in first_organic_result.keys():\n                snippets.append(first_organic_result[\"rich_snippet_table\"])\n            elif \"link\" in first_organic_result.keys():\n                snippets.append(first_organic_result[\"link\"])\n        if \"buying_guide\" in res.keys():\n            snippets.append(res[\"buying_guide\"])\n        if \"local_results\" in res.keys() and \"places\" in res[\"local_results\"].keys():\n            snippets.append(res[\"local_results\"][\"places\"])\n\n        if len(snippets) > 0:\n            return str(snippets)\n        else:\n            return \"No good search result found\"\n\n# 获取与某种鲜花相关的微博UID的函数\ndef get_UID(flower: str):\n    \"\"\"Searches for Linkedin or twitter Profile Page.\"\"\"\n    # search = SerpAPIWrapper()\n    search = CustomSerpAPIWrapper()\n    res = search.run(f\"{flower}\")\n    return res\n\n```\n\n唯一的区别就是，我们在下面的逻辑中返回了link，而不是snippet。\n\n```plain\n        if \"organic_results\" in res.keys():\n            first_organic_result = res[\"organic_results\"][0]\n            if \"snippet\" in first_organic_result.keys():\n                # snippets.append(first_organic_result[\"snippet\"])\n                snippets.append(first_organic_result[\"link\"])\n\n```\n\n再次Debug，我们发现返回的snippets里面包含了URL信息，其中UID信息包含在URL中了。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/06da407d1f6d93eeaefa6e9f450cdf5e.jpg)\n\n此时运行主程序findbigV.py，会发现代理中返回了URL信息，并且经过进一步思考，提炼出了UID。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/ab67de9be2b4f26be53c0e8af713f16f.jpg)\n\n## 第二步：爬取大 V 资料\n\n好的，第一步虽然是有磕有绊，但是经过了调整的CustomSerpAPIWrapper工具和代理，在LLM的帮助之下，总算是不辱使命，完成了找到UID的任务。\n\n这位大V，看起来又喜欢牡丹，又喜欢搞笑。我们很想和他联络一下，也许他很适合为我们的牡丹花品牌代言。（到底是否适合，不必特别认真哈，总之搜索“牡丹”，Agent给了这个ID，就可以了。咱学的是LangChain，不是真的要找他代言）\n\n不过，知己知彼，百战不殆。想要和他沟通，就得了解他更多。下面，我们将使用爬虫程序，通过UID来爬取他的更多信息。\n\n### 主程序 findbigV.py\n\n第二步完成之后，主程序代码如下：\n\n```plain\n# 设置OpenAI API密钥\nimport os\nos.environ[\"OPENAI_API_KEY\"] = 'Your OpenAI API Key'\nos.environ[\"SERPAPI_API_KEY\"] = 'Your SerpAPI Key'\n\n# 导入所取的库\nimport re\nfrom agents.weibo_agent import lookup_V\nfrom tools.general_tool import remove_non_chinese_fields\nfrom tools.scraping_tool import get_data\n\nif __name__ == \"__main__\":\n\n    # 拿到UID\n    response_UID = lookup_V(flower_type = \"牡丹\" )\n\n    # 抽取UID里面的数字\n    UID = re.findall(r'\\d+', response_UID)[0]\n    print(\"这位鲜花大V的微博ID是\", UID)\n\n    # 根据UID爬取大V信息\n    person_info = get_data(UID)\n    print(person_info)\n\n```\n\n从第一步到第二步，我们主要是完成了一次微博信息的爬取。\n\n### scraping\\_tool.py 中的 scrape\\_weibo 方法\n\n第二步中的关键逻辑是scraping\\_tool.py中的scrape\\_weibo方法，具体代码如下：\n\n```plain\n# 导入所需的库\nimport json\nimport requests\nimport time\n\n# 定义爬取微博用户信息的函数\ndef scrape_weibo(url: str):\n    '''爬取相关鲜花服务商的资料'''\n    headers = {\n        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36\",\n        \"Referer\": \"https://weibo.com\"\n    }\n    cookies = {\n        \"cookie\": '''SINAGLOBAL=3762226753815.13.1696496172299; ALF=1699182321; SCF=AiOo8xtPwGonZcAbYyHXZbz9ixm97mWi0vHt_VvuOKB-u4-rcvlGtWCrE6MfMucpxiOy5bYpkIFNWTj7nYGcyp4.; _sc_token=v2%3A2qyeqD3cTZFNTl0sn3KAYe4fNqzMUEP-C7nxNsd_Q1r-vpYMlF2K3xc4vWNuLNBbp3RsohghkJdlSVN09cymVo5AKAm0V92004V8cSRe9O5v9B65jd4yiG_sATDeB06GnjiJulXUrEF_6XsHh1ozK6jvbTKEUIkF7v0_BlbX6IcWrPkwh6xL_WM_0YUV2v7CtNPwyxfbAjaWnG32TsxG_ftN3s5m7qfaRftU6iTOSnE%3D; XSRF-TOKEN=4o0E6jaUQ0BlN77az0sURTg3; PC_TOKEN=dcf0e7607f; login_sid_t=36ebf31f1b3694fb71e77e35d30f052f; cross_origin_proto=SSL; WBStorage=4d96c54e|undefined; _s_tentry=passport.weibo.com; UOR=www.google.com,weibo.com,login.sina.com.cn; Apache=7563213131783.361.1696667509205; ULV=1696667509207:2:2:2:7563213131783.361.1696667509205:1696496172302; wb_view_log=3440*14401; WBtopGlobal_register_version=2023100716; crossidccode=CODE-gz-1QP2Jh-13l47h-79FGqrAQgQbR8ccb7b504; SSOLoginState=1696667553; SUB=_2A25IJWfwDeThGeFJ6lsQ-SbNzjuIHXVr5gm4rDV8PUJbkNAbLUWtkW1NfJd_XHamKIzj5RlT_-RGMma6z3YQZUK3; SUBP=0033WrSXqPxfM725Ws9jqgMF55529P9D9WFDKvBlvg14YuHk_4c6MEH_5NHD95QNS024eK.ReK-NWs4DqcjZCJ8oIN.pSKzceBtt; WBPSESS=gyY2mn77F4p5VxWF2IB_yFR0phHVTNfaJAHAMprnW7MeUr-NHPZNyeeyKae3tHELlc_RbcI1XPSz-TjSJqWrIXs-yh1fwhxL4mSDrnpPZEogFt8ScF5NEwSqPGn7x2KMAgTHtWde-3MBm6orQ98PDA=='''\n    }\n    response = requests.get(url, headers=headers, cookies=cookies)\n    time.sleep(3)   # 加上3s 的延时防止被反爬\n    return response.text\n\n# 根据UID构建URL爬取信息\ndef get_data(id):\n    url = \"https://weibo.com/ajax/profile/detail?uid={}\".format(id)\n    html = scrape_weibo(url)\n    response = json.loads(html)\n\n    return response\n\n```\n\n我这段爬虫代码特别简洁，不需要过多的解释，唯一需要说明的部分是怎么找到你自己的Cookies。\n\n> Cookie 是由服务器发送到用户浏览器的一小段数据，并可能在随后的请求中被回传。它的主要目的是让服务器知道用户的上下文信息或状态。在Web爬虫中，使用正确的Cookie可以模拟登录状态，从而获取到需要权限的网页内容。\n\n首先，我是用QQ ID登录的微博，我发现通过这样的方式找到的Cookie能用得比较久。\n\n然后，从我的浏览器中获取 Cookie，以下是简单步骤：\n\n1. 使用浏览器（如 Chrome、Firefox）访问微博并登录。\n2. 登录后，右键单击页面并选择“检查”（Inspect）。\n3. 打开开发者工具，点击 Network 选项卡。\n4. 在页面上进行一些操作（如刷新页面），然后在 Network 选项卡下查看请求列表。\n5. 选择任一请求项，然后在右侧的 Headers 选项卡中查找 Request Headers 部分。\n6. 在这部分中，你应该可以看到一个名为 Cookie 的字段，这就是你需要的 Cookie 值。\n\n将获取到的完整Cookie值复制（挺长的），并替换上述代码中的 `\"你的Cookie\"` 部分。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/92ea6832ea69c8a1342a62180b7da538.jpg)\n\n> 但请注意，微博的Cookie可能有过期时间，所以如果你发现一段时间后你的爬虫无法正常工作，你可能需要再次获取新的Cookie。同时，频繁地爬取或大量请求可能会导致你的账号被封禁，所以请谨慎使用爬虫。\n\n此时，运行 findbigV.py，就得到了下面的输出。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/e696b6dae6332a486763e29e9f310594.jpg)\n\n### 精简爬取输出\n\n最后一个步骤，是精简上面的输出，因为类似 `'word_color': '#FFEA8011', 'background_color': '#FF181818'` 这样的内容会占据很多Token空间，而且对于LLM总结整理信息，也没啥作用。\n\n因此，我创建了一个额外的步骤，就是\\\\tools\\\\general\\_tool.py中的remove\\_non\\_chinese\\_fields函数。\n\n```plain\nimport re\n\ndef contains_chinese(s):\n    return bool(re.search('[\\u4e00-\\u9fa5]', s))\n\ndef remove_non_chinese_fields(d):\n    if isinstance(d, dict):\n        to_remove = [key for key, value in d.items() if isinstance(value, (str, int, float, bool)) and (not contains_chinese(str(value)))]\n        for key in to_remove:\n            del d[key]\n\n        for key, value in d.items():\n            if isinstance(value, (dict, list)):\n                remove_non_chinese_fields(value)\n    elif isinstance(d, list):\n        to_remove_indices = []\n        for i, item in enumerate(d):\n            if isinstance(item, (str, int, float, bool)) and (not contains_chinese(str(item))):\n                to_remove_indices.append(i)\n            else:\n                remove_non_chinese_fields(item)\n\n        for index in reversed(to_remove_indices):\n            d.pop(index)\n\n```\n\n在findbigV.py中，调用这个函数，对爬虫的输出结果进行了精简。\n\n```plain\n    # 移除无用的信息\n    remove_non_chinese_fields(person_info)\n    print(person_info)\n\n```\n\n重新运行findbigV.py，结果如下：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/16aaa4d952428bb1960ecfee9df6df10.jpg)\n\n此时，爬取的内容就只剩下了干货。\n\n## 总结时刻\n\n这节课我们完成了前两步的工作。分别是，找到适合推广某种鲜花的大V的微博UID，并且爬取了大V的资料。这为我们后续生成文本、进一步链接大V打下了良好的基础。\n\n其中，我们用到了大量之前学习过的LangChain组件，具体包括：\n\n1. 用提示模板告诉大模型我们要找到内容（UID）。\n2. 调用LLM。\n3. 使用Chain。\n4. 使用Agent。\n5. 在Agent中，我们使用了一个Customized Tool，因为LangChain内置的SerpAPI Tool不能完全满足我们的需要。这给了我们一个好机会创建自己的“私人定制” Tool。\n\n在下节课中，我们还要继续利用大模型的总结文本、生成文本的功能，来为我们撰写能够打动大V和咱易速鲜花合作的文案，我们还将利用Output Parser把文案解析成需要的格式，部署到网络服务器端。敬请期待！\n\n## 思考题\n\n1. 如果Agent不返回UID，而是返回URL，是不是也能够完成这个任务？你可以尝试重构提示模板以及后续逻辑，返回URL，然后手动从URL中解析出UID。\n2. 研究一下SerpAPIWrapper类的\\_process\\_response中的代码，看看这个方法具体是怎么设计的，用来实现了什么功能？\n\n期待在留言区看到你的分享，如果觉得内容对你有帮助，也欢迎分享给有需要的朋友！"},{"url":"/posts/19.html","content":"# 21｜部署一个鲜花网络电商的人脉工具（下）\n你好，我是黄佳，欢迎来到LangChain实战课！\n\n在上节课中，我们通过LangChain，找到了适合为某一类鲜花做推广的微博大V，并且爬取了他的信息。下面，我带着你继续完成易速鲜花电商人脉工具的后续部分。\n\n## 项目步骤复习\n\n先复习一下项目实现过程的五个具体步骤。\n\n**第一步：** 通过LangChain的搜索工具，以模糊搜索的方式，帮助运营人员找到微博中有可能对相关鲜花推广感兴趣的大V（比如喜欢牡丹花的大V），并返回UID。\n\n**第二步：** 根据微博UID，通过爬虫工具拿到相关大V的微博公开信息，并以JSON格式返回大V的数据。\n\n**第三步：** 通过LangChain调用LLM，通过信息整合以及文本生成功能，根据大V的个人信息，写一篇热情洋溢的介绍型文章，谋求与该大V的合作。\n\n**第四步：** 把LangChain输出解析功能加入进来，让LLM生成可以嵌入提示模板的格式化数据结构。\n\n**第五步：** 添加HTML、CSS，并用Flask创建一个App，在网络上部署及发布这个鲜花电商人脉工具，供市场营销部门的人员使用。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/27d8byyfcacec4e4d584ba5f55b70a23.jpg)\n\n## **第三步** **：** **生成介绍文章**\n\n下面我们开始第三个步骤，把步骤二中返回的JSON数据（大V的个人简介）传递给LLM，发挥大模型超强的总结整理和文本生成能力，帮助运营人员创建文案。\n\n这个文案可以有很多种形式，比如说可以总结一下大V的特点，根据他的自我介绍猜测一下他的兴趣爱好，还可以让LLM帮助运营人员撰写一篇联络信件的草稿。\n\n这就看我们如何设计提示模板了。\n\n重构之后的 findbigV.py 代码如下：\n\n```plain\n# 设置OpenAI API密钥\nimport os\nos.environ[\"OPENAI_API_KEY\"] = 'Your OpenAI Key'\nos.environ[\"SERPAPI_API_KEY\"] = 'Your SerpAPI Key'\n\n# 导入所取的库\nimport re\nfrom agents.weibo_agent import lookup_V\nfrom tools.general_tool import remove_non_chinese_fields\nfrom tools.scraping_tool import get_data\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.chains import LLMChain\n\nif __name__ == \"__main__\":\n\n    # 拿到UID\n    response_UID = lookup_V(flower_type = \"牡丹\" )\n\n    # 抽取UID里面的数字\n    UID = re.findall(r'\\d+', response_UID)[0]\n    print(\"这位鲜花大V的微博ID是\", UID)\n\n    # 根据UID爬取大V信息\n    person_info = get_data(UID)\n    print(person_info)\n\n    # 移除无用的信息\n    remove_non_chinese_fields(person_info)\n    print(person_info)\n\n    # 设计提示模板\n    letter_template = \"\"\"\n         下面是这个人的微博信息 {information}\n         请你帮我:\n         1. 写一个简单的总结\n         2. 挑两件有趣的事情说一说\n         3. 找一些他比较感兴趣的事情\n         4. 写一篇热情洋溢的介绍信\n     \"\"\"\n    prompt_template = PromptTemplate(\n        input_variables=[\"information\"],\n        template=letter_template\n    )\n\n    # 初始化大模型\n    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n\n    # 初始化链\n    chain = LLMChain(llm=llm, prompt=prompt_template)\n\n    # 生成文案\n    result = chain.run(information = person_info)\n    print(result)\n\n```\n\n运行程序之后，LLM没有让我们失望，给出了相当专业的文案。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/20469bcbe91f6803fdb3c7da8cbe9af9.jpg)\n\n下面我整理一下程序，把生成文案的功能放在 \\\\tools\\\\textgen\\_tool.py 中，定义为 generate\\_letter 函数。这样主程序显得比较清爽。\n\n新的 findbigV.py 代码如下：\n\n```plain\n# 导入所取的库\nimport re\nfrom agents.weibo_agent import lookup_V\nfrom tools.general_tool import remove_non_chinese_fields\nfrom tools.scraping_tool import get_data\nfrom tools.textgen_tool import generate_letter\n\nif __name__ == \"__main__\":\n\n    # 拿到UID\n    response_UID = lookup_V(flower_type = \"牡丹\" )\n\n    # 抽取UID里面的数字\n    UID = re.findall(r'\\d+', response_UID)[0]\n    print(\"这位鲜花大V的微博ID是\", UID)\n\n    # 根据UID爬取大V信息\n    person_info = get_data(UID)\n    print(person_info)\n\n    # 移除无用的信息\n    remove_non_chinese_fields(person_info)\n    print(person_info)\n\n    # 调用函数根据大V信息生成文本\n    result = generate_letter(information = person_info)\n    print(result)\n\n```\n\n## **第四步** **：** **加入输出解析**\n\n上面的文案已经非常到位，但是你需要把文字Copy Paste出来才能够使用。下面，我们要通过LangChain的输出解析器一步到位，让LLM给我们生成有良好结构的JSON文档，便于下一步集成到 HTML 中进行展示。\n\n在 tools 文件夹中，新建一个 tools\\\\ParsingTool.py 文件。\n\n```plain\n# 导入所需的类\nfrom langchain.output_parsers import PydanticOutputParser\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\n# 定义一个名为TextParsing的模型，描述了如何解析大V信息\nclass TextParsing(BaseModel):\n    summary: str = Field(description=\"大V个人简介\")  # 大V的简介或背景信息\n    facts: List[str] = Field(description=\"大V的特点\")  # 大V的一些显著特点或者事实\n    interest: List[str] = Field(description=\"这个大V可能感兴趣的事情\")  # 大V可能感兴趣的主题或活动\n    letter: List[str] = Field(description=\"一篇联络这个大V的邮件\")  # 联络大V的建议邮件内容\n\n    # 将模型对象转换为字典\n    def to_dict(self):\n        return {\n            \"summary\": self.summary,\n            \"facts\": self.facts,\n            \"interest\": self.interest,\n            \"letter\": self.letter,\n        }\n\n# 创建一个基于Pydantic模型的解析器，用于将文本输出解析为特定的结构\nletter_parser: PydanticOutputParser = PydanticOutputParser(\n    pydantic_object=TextParsing\n)\n\n```\n\n此处，TextParsing 是一个用 Pydantic 定义的数据模型，描述了一个大V的个人信息如何被解析和组织。该模型包含四个字段：summary（简介）、facts（事实）、interest（兴趣）、letter（信件）。而to\\_dict是一个实例方法，它可以将该模型的实例转换为一个字典。最后，我们创建了一个PydanticOutputParser对象，该对象基于TextParsing模型，可以被用来解析一段文本并填充到这个数据模型中。\n\n然后，我们更新 \\\\tools\\\\textgen\\_tool.py 文件。\n\n```plain\n# 导入所需要的库\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.chains import LLMChain\nfrom tools.parsing_tool import letter_parser\n\n# 生成文案的函数\ndef generate_letter(information):\n\n    # 设计提示模板\n    letter_template = \"\"\"\n         下面是这个人的微博信息 {information}\n         请你帮我:\n         1. 写一个简单的总结\n         2. 挑两件有趣的特点说一说\n         3. 找一些他比较感兴趣的事情\n         4. 写一篇热情洋溢的介绍信\n         \\n{format_instructions}\"\"\"\n\n    prompt_template = PromptTemplate(\n        input_variables=[\"information\"],\n        template=letter_template,\n        partial_variables={\n            \"format_instructions\": letter_parser.get_format_instructions()\n        },\n    )\n\n    # 初始化大模型\n    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n\n    # 初始化链\n    chain = LLMChain(llm=llm, prompt=prompt_template)\n\n    # 生成文案\n    result = chain.run(information = information)\n    return result\n\n```\n\n通过 {format\\_instructions} 和 partial\\_variables 参数，我们利用输出解析器增强了这个提示模板，让 LLM 直接返回我们所需要的格式。\n\n重新运行 findbigV.py，可以看到，输出已经被解析为标准的JSON格式。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/c2e1ceb17f44133195d6da9eb4b93ba2.jpg)\n\n不过，此时的文案似乎和鲜花运营缺少了一些关联，你可以尝试着调整提示模板中的内容，让这封信写得更加贴合我们鲜花运营的具体意图。\n\n## 第五步：部署人脉工具\n\n好啦，到目前为止，这个人脉工具的所有功能都已经完善。我们利用LangChain自动做了好多事。\n\n下面，我们就制作一个前端页面，同时把这个工具部署到服务器上面去，让我们的运营人员能够随时访问它。\n\n### HTML 文件\n\n首先，创建一个 HTML 文件，用于交互展示，这个文件放在 templates 目录下。\n\n```plain\n<!-- templates/index.html -->\n\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='css/style.css') }}\">\n    <script src=\"https://code.jquery.com/jquery-3.6.0.min.js\"></script>\n    <title>Ice Breaker</title>\n    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.0/css/all.min.css\" />\n    <div class=\"spinner-container\" id=\"spinner-container\" style=\"display: none;\">\n        <i id=\"loading-spinner\" class=\"fas fa-spinner fa-spin\"></i>\n    </div>\n</head>\n<body>\n    <div class=\"container\">\n        <h1>易速鲜花人脉工具</h1>\n        <form id=\"name-form\">\n            <input type=\"text\" id=\"flower\" name=\"flower\" placeholder=\"输入一种花（或者其它东西也行）\">\n            <button id=\"magic-button\" type=\"submit\">找到大V</button>\n        </form>\n        <div id=\"result\">\n            <img id=\"profile-pic\" src=\"\" alt=\"Profile Picture\" style=\"display: none; max-width: 100%; height: auto; border-radius: 50%; margin-bottom: 20px;\">\n            <h2>基本情况</h2>\n            <p id=\"summary\"></p>\n            <h2>特色内容</h2>\n            <div id=\"facts\"></div>\n            <h2>可能感兴趣的事儿</h2>\n            <div id=\"interest\"></div>\n            <h2>联络邮件</h2>\n            <div id=\"letter\"></div>\n        </div>\n    </div>\n    <script>\n        $(document).ready(function () {\n            $('#name-form').on('submit', function (e) {\n                e.preventDefault();\n                $('#spinner-container').show();\n                $.ajax({\n                    url: '/process',\n                    data: $('#name-form').serialize(),\n                    type: 'POST',\n                    success: function (response) {\n                        $('#profile-pic').attr('src', '你的URL');\n                        $('#profile-pic').show();\n                        $('#summary').text(response.summary);\n                        $('#facts').html('<ul>' + response.facts.map(fact => '<li>' + fact + '</li>').join('') + '</ul>');\n                        $('#interest').html('<ul>' + response.interest.map(interest => '<li>' + interest + '</li>').join('') + '</ul>');\n                        $('#letter').text(response.letter);\n                    },\n                    error: function (error) {\n                        console.log(error);\n                    },\n                    complete: function () {\n                        $('#spinner-container').hide();\n                    }\n                });\n            });\n        });\n    </script>\n</body>\n</html>\n\n```\n\n### CSS 文件\n\n为了让 HTML 美一点，我们还制作了一个 CSS 文件 style.css，放在 \\\\static\\\\css\\ 目录下。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/4e067ac76ab579f3f8029a1631f336e0.jpg)\n\n这个文件就请你去咱们的 [GitHub Repo](https://github.com/huangjia2019/langchain) 下载，我就不在这儿展示了。\n\n### 重构 findbigV.py\n\n下一步是重构 findbigV.py，把功能封装到一个函数中。\n\n```plain\ndef find_bigV(flower: str) :\n    # 拿到UID\n    response_UID = lookup_V(flower_type = flower )\n\n    # 抽取UID里面的数字\n    UID = re.findall(r'\\d+', response_UID)[0]\n    print(\"这位鲜花大V的微博ID是\", UID)\n\n    # 根据UID爬取大V信息\n    person_info = get_data(UID)\n    print(person_info)\n\n    # 移除无用的信息\n    remove_non_chinese_fields(person_info)\n    print(person_info)\n\n    # 调用函数根据大V信息生成文本\n    result = generate_letter(information = person_info)\n    print(result)\n\n    return result\n\n```\n\n### 创建 app.py\n\n下面，我们创建一个基于 Flask 的 Web应用，主要用于显示一个输入表单，供大家提交花的名称，并返回市场营销人员所需要的内容，在网页中展示。\n\n```plain\n# 导入所需的库和模块\nfrom flask import Flask, render_template, request, jsonify\nfrom findbigV import find_bigV\nimport json\n\n# 实例化Flask应用\napp = Flask(__name__)\n\n# 主页路由，返回index.html模板\n@app.route(\"/\")\ndef index():\n    return render_template(\"index.html\")\n\n# 处理请求的路由，仅允许POST请求\n@app.route(\"/process\", methods=[\"POST\"])\ndef process():\n    # 获取提交的花的名称\n    flower = request.form[\"flower\"]\n    # 使用find_bigV函数获取相关数据\n    response_str = find_bigV(flower=flower)\n    # 使用json.loads将字符串解析为字典\n    response = json.loads(response_str)\n\n    # 返回数据的json响应\n    return jsonify(\n        {\n            \"summary\": response[\"summary\"],\n            \"facts\": response[\"facts\"],\n            \"interest\": response[\"interest\"],\n            \"letter\": response[\"letter\"],\n        }\n    )\n\n# 判断是否是主程序运行，并设置Flask应用的host和debug模式\nif __name__ == \"__main__\":\n    app.run(host=\"0.0.0.0\", debug=True)\n\n```\n\n程序非常简单，简单介绍下。\n\n1. 导入库和模块：这部分导入了Flask框架的相关模块，以及find\\_bigV函数和JSON库。\n\n2. 创建了一个Flask应用实例。\n\n3. 定义主页路由：当用户访问这个路由时，它将返回一个叫 index.html 的模板。\n\n4. 定义处理请求的路由：这是一个专门处理 POST 请求的路由。其流程如下：\n\n\n   - 从表单数据中获取名为 `\"flower\"` 的字段\n   - 使用 find\\_bigV 函数查询与该花名相关的数据\n   - 解析返回的数据（字符串格式）为 Python 字典\n   - 将这些数据整理并返回为 JSON 格式的响应\n5. 启动 Flask 应用，监听所有公开的 IP 地址，并在调试模式中运行。\n\n这样，我们就真正大功告成了，系统上线，运营人员可以在网页中调用我们的产品了。\n\n运行App程序，就看到了这个人脉工具。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/262yyb04ccde1a3f49b4e9173527df4d.jpg)\n\n刚才我一直用牡丹花进行测试，下面使用月季花进行测试，看看能否找出月季花的爱好者。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/a01632933a6ee20af3646d9008a1249f.jpg)\n\n不辱使命，天狼月季和天狼园艺旗舰店老板，华冠园创园艺科技有限公司的董事长，被我们的大V搜索器发现。我相信，和他联络并且建立合作关系，能够大大拓展易速鲜花的花卉事业。\n\n有了人脉搜索工具，我对自己的事业充满了进一步的期待！你呢？\n\n## 总结时刻\n\n项目完成了！整体程序结构如下：\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/7cdd3207cea4d75ebc3f6c2658a1e0cc.jpg)\n\n说老实话，这是一个创意和创造力兼备的Project，没有LangChain，很难想象用这么简单的方式，在这么短的时间内，就可以构建出这么有特色的项目。\n\n此处，我们一块复习了LangChain中的链、代理、工具（特别是标准工具不灵光时，自定义了新工具）、LLM的文本摘要和生成功能、提示模板、输出解析。可以说，这个项目把前面讲的几乎所有最重要的LangChain模块都贯串起来了。\n\n在这里，我要感谢Eden Marco先生，这个人脉项目的设计（ **注意：只是这个项目，可不是整个专栏的课程设计**），受到了他的启发（Udemy 课程《Learn LangChain by building FAST a real world generative ai LLM powered application LLM (Python)，Section 3》），并在他的程序架构上进行了大刀阔斧的扩充优化。创意部分，不敢掠美，特此说明。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/271f4b899703yy033324828f862d93a2.jpg)\n\n你可以把这个项目当作一次复习，也可以把它当作一个启发，开发出属于你的、更有创意的程序。\n\n## 思考题\n\n1. 修改提示模板，让LLM为你生成更多更有创意、业务上更实用的文案。\n2. 试试爬取其他网站（比如豆瓣）上的公开数据，制作更全面的人脉工具。\n3. 你或许已经发现，我的这个程序不够鲁棒。这里，我用了牡丹、月季进行了测试，程序都找到了相关的UID，但是当我使用其他一些花的时候，比如玫瑰、野菊花，会出现各种各样的错误。你能否修改程序（比如提示模板、输出解析、整体结构），让程序更健壮？\n\n期待在留言区看到你的成果分享，如果觉得内容对你有帮助，也欢迎分享给有需要的朋友！"},{"url":"/posts/20.html","content":"# 22｜易速鲜花聊天客服机器人的开发（上）\n你好，我是黄佳，欢迎来到LangChain实战课！\n\n上节课，咱们的易速鲜花人脉工具成功上线。市场部的朋友们用了都说好。\n\n这节课，我们继续为易速鲜花市场部、销售部和客服部门的员工，以及易速鲜花的广大用户来开发一个聊天机器人。\n\n## “聊天机器人”项目说明\n\n聊天机器人（Chatbot）是LLM和LangChain的核心用例之一，很多人学习大语言模型，学习LangChain，就是为了开发出更好的、更能理解用户意图的聊天机器人。聊天机器人的核心特征是，它们可以进行长时间的对话并访问用户想要了解的信息。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/0dbb30e1ac6d6dd22eaf0e7bf3b5e4b1.jpg)\n\n如图所示，聊天机器人设计过程中的核心组件包括：\n\n- 聊天模型：这是对话的基础，它更偏向于自然的对话风格。你可以参考LangChain相关文档中所支持的聊天模型的列表。尽管大模型（LLM）也可以应用于聊天机器人，但专用的聊天模型（Chat Model）更适合对话场景。\n- 提示模板：帮助你整合默认消息、用户输入、历史交互以及检索时需要的上下文。\n- 记忆：它允许机器人记住与用户之间的先前互动，增强对话连贯性。\n- 检索器：这是一个可选组件，特别适合那些需要提供特定领域知识的机器人。\n\n整体来说，聊天机器人的关键在于其记忆和检索能力，记忆使聊天机器人能够记住过去的交互，而检索则为聊天机器人提供最新的、特定于领域的信息。\n\n## 项目的技术实现细节\n\n在这个聊天机器人的实现过程中，我们将遵循敏捷开发的原则。先集中精力开发一个基础版本的机器人，实现最核心的功能，比如说能够聊天就可以了。然后，再逐步加入更多的功能，例如，能够基于易速鲜花的企业知识库进行检索，比如，用户可以输入订单号来查询订单状态，或询问如何退货等常见问题。\n\n这个项目的具体技术实现步骤，这里简述一下。\n\n**第一步：** 通过LangChain的ConversationChain，实现一个最基本的聊天对话工具。\n\n**第二步：** 通过LangChain中的记忆功能，让这个聊天机器人能够记住用户之前所说的话。\n\n**第三步：** 通过LangChain中的检索功能，整合易速鲜花的内部文档资料，让聊天机器人不仅能够基于自己的知识，还可以基于易速鲜花的业务流程，给出专业的回答。\n\n**第四步（可选）：** 通过LangChain中的数据库查询功能，让用户可以输入订单号来查询订单状态，或者看看有没有存货等等。\n\n**第五步** **：** 在网络上部署及发布这个聊天机器人，供企业内部员工和易速鲜花用户使用。\n\n在上面的 5 个步骤中，我们使用到了很多LangChain技术，包括提示工程、模型、链、代理、RAG、数据库检索等。\n\n这节课我们先来实现项目的前三个步骤，第四个步骤我会留给你作为思考题，你可以复习并参考 [第16讲](https://time.geekbang.org/column/article/713462) 中的内容来实现它。在下节课中，我将为你介绍两个 AI 网络 UI 框架， **Streamlit** 和 **Gradio**，利用这两个框架，你可以轻松地把你的 AI 应用部署到网络中。\n\n## 第一步：开发最基本的聊天机器人\n\n让我们先来用LangChain打造出一个最简单的聊天机器人。\n\n```plain\n# 设置OpenAI API密钥\nimport os\nos.environ[\"OPENAI_API_KEY\"] = 'Your OpenAI Key'\n\n# 导入所需的库和模块\nfrom langchain.schema import (\n    HumanMessage,\n    SystemMessage\n)\nfrom langchain.chat_models import ChatOpenAI\n\n# 创建一个聊天模型的实例\nchat = ChatOpenAI()\n\n# 创建一个消息列表\nmessages = [\n    SystemMessage(content=\"你是一个花卉行家。\"),\n    HumanMessage(content=\"朋友喜欢淡雅的颜色，她的婚礼我选择什么花？\")\n]\n\n# 使用聊天模型获取响应\nresponse = chat(messages)\nprint(response)\n\n```\n\n运行程序，输出如下：\n\n```plain\ncontent='对于喜欢淡雅的颜色的婚礼，你可以选择以下花卉：\\n\\n1. 白色玫瑰：白色玫瑰象征纯洁和爱情，它们能为婚礼带来一种优雅和浪漫的氛围。\\n\\n2. 紫色满天星：紫色满天星是十分优雅的小花，它们可以作为装饰花束或餐桌中心点使用，为婚礼增添一丝神秘感。\\n\\n3. 淡粉色康乃馨：淡粉色康乃馨是一种温馨而浪漫的花卉，能为婚礼带来一种柔和的氛围。\\n\\n4.  白色郁金香：白色郁金香代表纯洁和完美，它们可以为婚礼带来一种高贵和典雅的感觉。\\n\\n5. 淡紫色蓝雏菊：淡紫色蓝雏菊是一种可爱的小花，它们可以作为装饰花束或花冠使用，为婚礼增添一丝童真和浪漫。\\n\\n这些花卉都能营造出淡雅的氛围，并与婚礼的整体风格相得益彰。当然，你也可以根据你朋友的喜好和主题来选择适合的花卉。'\n\n```\n\n下面，我把它重构一下，让Chatbot能够和我们循环地进行对话。\n\n```plain\n# 设置OpenAI API密钥\nimport os\nos.environ[\"OPENAI_API_KEY\"] = 'Your OpenAI Key'\n\n# 导入所需的库和模块\nfrom langchain.schema import HumanMessage, SystemMessage\nfrom langchain.chat_models import ChatOpenAI\n\n# 定义一个命令行聊天机器人的类\nclass CommandlineChatbot:\n    # 在初始化时，设置花卉行家的角色并初始化聊天模型\n    def __init__(self):\n        self.chat = ChatOpenAI()\n        self.messages = [SystemMessage(content=\"你是一个花卉行家。\")]\n\n    # 定义一个循环来持续与用户交互\n    def chat_loop(self):\n        print(\"Chatbot 已启动! 输入'exit'来退出程序。\")\n        while True:\n            user_input = input(\"你: \")\n            # 如果用户输入“exit”，则退出循环\n            if user_input.lower() == 'exit':\n                print(\"再见!\")\n                break\n            # 将用户的输入添加到消息列表中，并获取机器人的响应\n            self.messages.append(HumanMessage(content=user_input))\n            response = self.chat(self.messages)\n            print(f\"Chatbot: {response.content}\")\n\n# 如果直接运行这个脚本，启动聊天机器人\nif __name__ == \"__main__\":\n    bot = CommandlineChatbot()\n    bot.chat_loop()\n\n```\n\n运行程序后，你可以一直和这个Bot聊天，直到你聊够了，输入exit，它会和你说再见。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/7a7700e70928a051f38cb82b5f7b5931.jpg)\n\n好的，一个简单的聊天机器人已经搭建好了，不过，这个聊天机器人没有记忆功能，它不会记得你之前说过的话。\n\n下面，我们要通过记忆机制，把它改造成一个能记住话的Chatbot。\n\n## 第二步：增加记忆机制\n\n下面，我们来通过ConversationBufferMemory给Chatbot增加记忆。具体代码如下：\n\n```plain\n# 设置OpenAI API密钥\nimport os\nos.environ[\"OPENAI_API_KEY\"] = 'Your OpenAI Key'\n\n# 导入所需的库和模块\nfrom langchain.schema import HumanMessage, SystemMessage\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.prompts import (\n    ChatPromptTemplate,\n    MessagesPlaceholder,\n    SystemMessagePromptTemplate,\n    HumanMessagePromptTemplate,\n)\nfrom langchain.chains import LLMChain\nfrom langchain.chat_models import ChatOpenAI\n\n# 设置OpenAI API密钥\nos.environ[\"OPENAI_API_KEY\"] = 'Your OpenAI Key'\n\n# 带记忆的聊天机器人类\nclass ChatbotWithMemory:\n    def __init__(self):\n\n        # 初始化LLM\n        self.llm = ChatOpenAI()\n\n        # 初始化Prompt\n        self.prompt = ChatPromptTemplate(\n            messages=[\n                SystemMessagePromptTemplate.from_template(\n                    \"你是一个花卉行家。你通常的回答不超过30字。\"\n                ),\n                MessagesPlaceholder(variable_name=\"chat_history\"),\n                HumanMessagePromptTemplate.from_template(\"{question}\")\n            ]\n        )\n\n        # 初始化Memory\n        self.memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n\n        # 初始化LLMChain with LLM, prompt and memory\n        self.conversation = LLMChain(\n            llm=self.llm,\n            prompt=self.prompt,\n            verbose=True,\n            memory=self.memory\n        )\n\n    # 与机器人交互的函数\n    def chat_loop(self):\n        print(\"Chatbot 已启动! 输入'exit'来退出程序。\")\n        while True:\n            user_input = input(\"你: \")\n            if user_input.lower() == 'exit':\n                print(\"再见!\")\n                break\n\n            response = self.conversation({\"question\": user_input})\n            print(f\"Chatbot: {response['text']}\")\n\nif __name__ == \"__main__\":\n    # 启动Chatbot\n    bot = ChatbotWithMemory()\n    bot.chat_loop()\n\n```\n\n程序的核心是ChatbotWithMemory类，这是一个带有记忆功能的聊天机器人类。在这个类的初始化函数中，定义了一个对话缓冲区记忆，它会跟踪对话历史。在LLMChain被创建时，就整合了LLM、提示和记忆，形成完整的对话链。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/6d1eb1ea673807f16046d10754a640f4.jpg)\n\n你看，我们的 Chatbot 成功地复述出了我好几轮之前传递给它的关键信息，也就是我的姐姐已经44岁了。她的推荐是基于这个原则来进行的。\n\n## 第三步：增加检索机制\n\n下面，继续增强 Chatbot 的功能，我们要把易速鲜花的内部文档信息嵌入到大模型的知识库中。让它成为一个拥有“易速鲜花”价值观的Super客服。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/0ac1830644bac89bb552db5c64d83441.jpg)\n\n上图中的易速鲜花内部价值观，如果你感到陌生的话，可以复习一下 [第2讲](https://time.geekbang.org/column/article/699436) 的内容。\n\n```plain\n# 导入所需的库\nimport os\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.vectorstores import Qdrant\nfrom langchain.memory import ConversationSummaryMemory\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.chains import ConversationalRetrievalChain\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.document_loaders import Docx2txtLoader\nfrom langchain.document_loaders import TextLoader\n\n# 设置OpenAI API密钥\nos.environ[\"OPENAI_API_KEY\"] = 'Your OpenAI Key'\n\n# ChatBot类的实现-带检索功能\nclass ChatbotWithRetrieval:\n\n    def __init__(self, dir):\n\n        # 加载Documents\n        base_dir = dir # 文档的存放目录\n        documents = []\n        for file in os.listdir(base_dir):\n            file_path = os.path.join(base_dir, file)\n            if file.endswith('.pdf'):\n                loader = PyPDFLoader(file_path)\n                documents.extend(loader.load())\n            elif file.endswith('.docx') or file.endswith('.doc'):\n                loader = Docx2txtLoader(file_path)\n                documents.extend(loader.load())\n            elif file.endswith('.txt'):\n                loader = TextLoader(file_path)\n                documents.extend(loader.load())\n\n        # 文本的分割\n        text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n        all_splits = text_splitter.split_documents(documents)\n\n        # 向量数据库\n        self.vectorstore = Qdrant.from_documents(\n            documents=all_splits, # 以分块的文档\n            embedding=OpenAIEmbeddings(), # 用OpenAI的Embedding Model做嵌入\n            location=\":memory:\",  # in-memory 存储\n            collection_name=\"my_documents\",) # 指定collection_name\n\n        # 初始化LLM\n        self.llm = ChatOpenAI()\n\n        # 初始化Memory\n        self.memory = ConversationSummaryMemory(\n            llm=self.llm,\n            memory_key=\"chat_history\",\n            return_messages=True\n            )\n\n        # 设置Retrieval Chain\n        retriever = self.vectorstore.as_retriever()\n        self.qa = ConversationalRetrievalChain.from_llm(\n            self.llm,\n            retriever=retriever,\n            memory=self.memory\n            )\n\n    # 交互对话的函数\n    def chat_loop(self):\n        print(\"Chatbot 已启动! 输入'exit'来退出程序。\")\n        while True:\n            user_input = input(\"你: \")\n            if user_input.lower() == 'exit':\n                print(\"再见!\")\n                break\n            # 调用 Retrieval Chain\n            response = self.qa(user_input)\n            print(f\"Chatbot: {response['answer']}\")\n\nif __name__ == \"__main__\":\n    # 启动Chatbot\n    folder = \"OneFlower\"\n    bot = ChatbotWithRetrieval(folder)\n    bot.chat_loop()\n\n```\n\n通过文档加载、文本分割、文档向量化以及检索功能，这个新的机器人除了常规的聊天功能，还能够检索存储在指定目录中的文档，并基于这些文档提供答案。\n\n当用户输入一个问题时，机器人首先在向量数据库中查找与问题最相关的文本块。这是通过将用户问题转化为向量，并在数据库中查找最接近的文本块向量来实现的。然后，机器人使用 LLM（大模型）在这些相关的文本块上进一步寻找答案，并生成回答。\n\n现在，新的Chatbot既能够回答一般性的问题，又能够回答易速鲜花内部问题，成了一个多面手！\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/da7ecbf3b39e72be9f774380yy4624db.jpg)\n\n## 总结时刻\n\n咱们的聊天机器人基本完成。它拥有了很多能力，有些能力来自于模型本身，比如World Knowledge（世界知识）、总结、对话等等。除此之外，我们还为它武装了记忆功能以及检索易速鲜花内部文档的功能。\n\n除了基本的提示和LLM之外，记忆和检索是聊天机器人的核心组件。这两者使其不仅可以回忆起过去的交互，还可以提供最新的、特定领域的信息。\n\n在这个聊天机器人的构建过程中，我们进一步复习了LangChain中的对话模型、提示模板、记忆的实现，以及检索功能和 RAG 功能的实现。\n\n下节课我将借着这个聊天机器人的部署过程，给你介绍两个实用的 Web UI 工具。敬请期待！\n\n## 思考题\n\n1. 如果你回忆 [第10讲](https://time.geekbang.org/column/article/704183)，会发现我当时是在ConversationChain中实现了记忆机制。在这节课的示例中，我直接把Memory应用到了LLMChain中，你能否用ConversationChain中的Memory来重构并简化代码？\n\n\n\n\n   提示：ConversationChain实际上是对Memory和LLMChain进行了封装，简化了初始化Memory的步骤。\n\n2. 我希望在聊天机器人中增加对数据库的查询能力，让用户或者业务人员知道某种鲜花的库存情况、销售情况等等。你能否参考 [第16讲](https://time.geekbang.org/column/article/713462) 的内容，把这个功能整合到这个Chatbot中呢？\n\n期待在留言区看到你的成果分享，如果觉得内容对你有帮助，也欢迎分享给有需要的朋友！"},{"url":"/posts/21.html","content":"# 23｜易速鲜花聊天客服机器人的开发（下）\n你好，我是黄佳，欢迎来到LangChain实战课！\n\n上节课，咱们的聊天机器人已经基本完成，这节课，我们要看一看如何把它部署到网络上。\n\n## “聊天机器人”项目说明\n\n简单回顾一下这个项目的设计。\n\n**第一步：** 通过LangChain的ConversationChain，实现一个最基本的聊天对话工具。\n\n**第二步：** 通过LangChain中的记忆功能，让这个聊天机器人能够记住用户之前所说的话。\n\n**第三步：** 通过LangChain中的检索功能，整合易速鲜花的内部文档资料，让聊天机器人不仅能够基于自己的知识，还可以基于易速鲜花的业务流程，给出专业的回答。\n\n**第四步（可选）：** 通过LangChain中的数据库查询功能，用户可以输入订单号来查询订单状态，或者看看有没有存货等等。\n\n**第五步：** 在网络上部署及发布这个聊天机器人，供企业内部员工和易速鲜花用户使用。\n\n在上一个项目中，我们是通过 Flask 部署的人脉工具。Flask是一个通用的、微型的Web应用框架，非常适合创建各种Web应用程序，不仅仅局限于机器学习或数据科学项目。Flask为开发者提供了很高的灵活性，你可以自定义路由、模板、前端和后端的交互等等。对于初学者，Flask可能需要更长时间来学习，尤其是需要结合其他前端技术或数据库技术时。\n\n不过，对于机器学习项目来说，我们还有其他部署方案。比如 Streamlit 和 Gradio，就为机器学习和数据科学应用提供了快速、专门化的解决方案。如果你的项目目标是快速展示和验证模型效果，那么 Streamlit 和 Gradio 是优秀的选择。这些框架提供了简单易用的 API 和丰富的可视化组件，让你可以用少量代码快速构建交互式应用程序，提高你的开发效率，也可以更好地展示工作成果。\n\n下面，我就带着你用这两种机器学习部署框架来展示我们的聊天机器人。\n\n## 方案 1 ：通过 Streamlit 部署聊天机器人\n\n首先来看看Streamlit。这是一个挺有名的专门为数据科学家和机器学习工程师设计的开源Python库，它可以迅速地将Python脚本转化为交互式Web应用。\n\n**Streamlit** **的一些主要特点和亮点包括：**\n\n- 简易性：Streamlit 的真正魅力在于它的简单性，只需几行代码，你就可以为其数据或模型创建交互式应用。\n- 无需前端经验：与传统的Web开发框架相比，使用 Streamlit，你不需要深入了解HTML、CSS或JavaScript，所有交互都是通过Python代码来管理的。\n- 实时交互：当你更改代码或数据时，Streamlit 应用会实时更新，这为迭代和实验提供了极大的便利。\n- 内置组件：Streamlit 附带了许多内置的可视化和交互组件，如滑块、按钮、表格等，可以无缝集成到你的应用中。\n- 数据集可视化：除了基本的图形和图表，Streamlit 还支持其他数据可视化库，如 Plotly、Matplotlib 和 Altair，使你能够轻松地展示数据。\n- 设计简洁：Streamlit 的界面设计简洁而优雅，使得应用程序看起来既专业又时尚。\n- 部署和共享：尽管 Streamlit 专注于创建应用，但它也有与部署和分享相关的工具和整合，如 Streamlit Sharing，允许你免费托管其应用。\n- 社区与生态系统：Streamlit 拥有一个积极的开源社区，定期提供新的功能更新、组件和扩展。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/718fbd049acdf8681185805384028f6a.jpg)\n\n我们用下面的语句，安装Streamlit。\n\n```plain\npip install streamlit\n\n```\n\n然后，简单的几行代码，就可以做出一个网页版的小程序。\n\n```plain\nimport streamlit as st\n\n# 设置标题\nst.title('平方计算器')\n\n# 创建一个滑块\nnumber = st.slider(\"Select a number:\", min_value=0, max_value=100)\n\n# 显示选中数字的平方\nst.write(f\"Square of {number} is {number ** 2}\")\n\n```\n\n用 `streamlit run <your_script_name>.py`（注意，必须是streamlit run命令，而不是通过python命令来跑程序）来运行程序，就可以在浏览器中看到它。\n\n```plain\nstreamlit run 01_SimpleStreamlit.py\n\n```\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/22e0fcf90978160e1f50d75fe9a33dee.jpg)\n\n此时，在 localhost 的 8501 端口，程序开始启动。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/ef4e3a09a3df9776330b343e721fbe87.jpg)\n\n下面就通过 Streamlit 来重构聊天机器人。\n\n```plain\n# 导入所需的库\nimport os\nimport streamlit as st\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.vectorstores import Qdrant\nfrom langchain.memory import ConversationSummaryMemory\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.chains import ConversationalRetrievalChain\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.document_loaders import Docx2txtLoader\nfrom langchain.document_loaders import TextLoader\n\n# 设置OpenAI API密钥\nos.environ[\"OPENAI_API_KEY\"] = 'Your OpenAI Key'\n\n# ChatBot类的实现\nclass ChatbotWithRetrieval:\n\n    def __init__(self, dir):\n\n        # 加载Documents\n        base_dir = dir # 文档的存放目录\n        documents = []\n        for file in os.listdir(base_dir):\n            file_path = os.path.join(base_dir, file)\n            if file.endswith('.pdf'):\n                loader = PyPDFLoader(file_path)\n                documents.extend(loader.load())\n            elif file.endswith('.docx') or file.endswith('.doc'):\n                loader = Docx2txtLoader(file_path)\n                documents.extend(loader.load())\n            elif file.endswith('.txt'):\n                loader = TextLoader(file_path)\n                documents.extend(loader.load())\n\n        # 文本的分割\n        text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n        all_splits = text_splitter.split_documents(documents)\n\n        # 向量数据库\n        self.vectorstore = Qdrant.from_documents(\n            documents=all_splits, # 以分块的文档\n            embedding=OpenAIEmbeddings(), # 用OpenAI的Embedding Model做嵌入\n            location=\":memory:\",  # in-memory 存储\n            collection_name=\"my_documents\",) # 指定collection_name\n\n        # 初始化LLM\n        self.llm = ChatOpenAI()\n\n        # 初始化Memory\n        self.memory = ConversationSummaryMemory(\n            llm=self.llm,\n            memory_key=\"chat_history\",\n            return_messages=True\n            )\n\n        # 设置Retrieval Chain\n        retriever = self.vectorstore.as_retriever()\n        self.qa = ConversationalRetrievalChain.from_llm(\n            self.llm,\n            retriever=retriever,\n            memory=self.memory\n            )\n\n    def chat_loop(self):\n        print(\"Chatbot 已启动! 输入'exit'来退出程序。\")\n        while True:\n            user_input = input(\"你: \")\n            if user_input.lower() == 'exit':\n                print(\"再见!\")\n                break\n            # 调用 Retrieval Chain\n            response = self.qa(user_input)\n            print(f\"Chatbot: {response['answer']}\")\n\n# Streamlit界面的创建\ndef main():\n    st.title(\"易速鲜花聊天客服\")\n\n    # Check if the 'bot' attribute exists in the session state\n    if \"bot\" not in st.session_state:\n        st.session_state.bot = ChatbotWithRetrieval(\"OneFlower\")\n\n    user_input = st.text_input(\"请输入你的问题：\")\n\n    if user_input:\n        response = st.session_state.bot.qa(user_input)\n        st.write(f\"Chatbot: {response['answer']}\")\n\nif __name__ == \"__main__\":\n    main()\n\n```\n\n以下是使用 Streamlit 进行的更改和添加功能的简要说明。\n\n1. 界面创建：\n\n\n   a. `st.title(\"易速鲜花聊天客服\")`：设置 Web 应用程序的标题为“易速鲜花聊天客服”。\n\n2. 会话状态：\n\n\n   a. 使用 `st.session_state` 来存储用户会话状态。这是 Streamlit 的一个特性，允许你在用户与应用程序交互时保存变量。\n\n\n   b. `if \"bot\" not in st.session_state`：检查是否已经有一个 bot 实例存在于 session state 中。如果没有，就创建一个新的 ChatbotWithRetrieval 实例，并将其保存到 session state。这样做的好处是可以避免在每次用户与应用程序交互时重新初始化机器人。\n\n3. 用户交互：\n\n\n   a. `user_input = st.text_input(\"请输入你的问题：\")`：创建一个文本输入框供用户输入问题。当用户输入内容并提交后，代码会获取用户的输入，并使用聊天机器人的 qa 方法来获取响应。\n\n\n   b. `st.write(f\"Chatbot: {response['answer']}\")`：在应用程序界面上显示机器人的响应。\n\n4. 主函数中，当脚本被执行时，它将启动 Streamlit 服务器，并显示创建的 Web 应用程序。\n\n\n用 `streamlit run` 运行程序，就可以开始聊天了！\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/1f380b60c8cdec362c9c8070c919d849.jpg)\n\n## 方案2 ：通过 Gradio 部署聊天机器人\n\n与 Streamlit 不同，Gradio 界面更侧重于模型的交互，据说上手也更简单。这使得 Gradio 非常适合展示和测试机器学习模型。我在GitHub上看到很多新的开源LLM都是提供一个Gradio UI界面来进行测试的。相比之下， Streamlit 则提供了更丰富的 Web 应用开发功能。\n\n到底有多简单，等会你看到 Gradio UI的界面，你就明白我的意思了。\n\n下面，我们先安装这个包。\n\n```plain\npip install gradio\n\n```\n\n通过 Gradio 框架重构聊天机器人的程序代码如下：\n\n```plain\n# 导入所需的库\nimport os\nimport gradio as gr\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.vectorstores import Qdrant\nfrom langchain.memory import ConversationSummaryMemory\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.chains import ConversationalRetrievalChain\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.document_loaders import Docx2txtLoader\nfrom langchain.document_loaders import TextLoader\n\n# 设置OpenAI API密钥\nos.environ[\"OPENAI_API_KEY\"] = 'Your OpenAI Key'\n\nclass ChatbotWithRetrieval:\n    def __init__(self, dir):\n\n        # 加载Documents\n        base_dir = dir # 文档的存放目录\n        documents = []\n        for file in os.listdir(base_dir):\n            file_path = os.path.join(base_dir, file)\n            if file.endswith('.pdf'):\n                loader = PyPDFLoader(file_path)\n                documents.extend(loader.load())\n            elif file.endswith('.docx') or file.endswith('.doc'):\n                loader = Docx2txtLoader(file_path)\n                documents.extend(loader.load())\n            elif file.endswith('.txt'):\n                loader = TextLoader(file_path)\n                documents.extend(loader.load())\n\n        # 文本的分割\n        text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n        all_splits = text_splitter.split_documents(documents)\n\n        # 向量数据库\n        self.vectorstore = Qdrant.from_documents(\n            documents=all_splits, # 以分块的文档\n            embedding=OpenAIEmbeddings(), # 用OpenAI的Embedding Model做嵌入\n            location=\":memory:\",  # in-memory 存储\n            collection_name=\"my_documents\",) # 指定collection_name\n\n        # 初始化LLM\n        self.llm = ChatOpenAI()\n\n        # 初始化Memory\n        self.memory = ConversationSummaryMemory(\n            llm=self.llm,\n            memory_key=\"chat_history\",\n            return_messages=True\n            )\n        # 初始化对话历史\n        self.conversation_history = \"\"\n\n        # 设置Retrieval Chain\n        retriever = self.vectorstore.as_retriever()\n        self.qa = ConversationalRetrievalChain.from_llm(\n            self.llm,\n            retriever=retriever,\n            memory=self.memory\n            )\n\n    def get_response(self, user_input):  # 这是为 Gradio 创建的新函数\n        response = self.qa(user_input)\n        # 更新对话历史\n        self.conversation_history += f\"你: {user_input}\\nChatbot: {response['answer']}\\n\"\n        return self.conversation_history\n\nif __name__ == \"__main__\":\n    folder = \"OneFlower\"\n    bot = ChatbotWithRetrieval(folder)\n\n    # 定义 Gradio 界面\n    interface = gr.Interface(\n        fn=bot.get_response,  # 使用我们刚刚创建的函数\n        inputs=\"text\",  # 输入是文本\n        outputs=\"text\",  # 输出也是文本\n        live=False,  # 实时更新，这样用户可以连续与模型交互\n        title=\"易速鲜花智能客服\",  # 界面标题\n        description=\"请输入问题，然后点击提交。\"  # 描述\n    )\n    interface.launch()  # 启动 Gradio 界面\n\n```\n\n以下是 Gradio 部分代码的详细解释。\n\n1. `get_response(self, user_input)`：这个新函数是为 Gradio 创建的，它接收用户输入作为参数，并返回机器人的响应。为了保持聊天历史连续性，此函数将每次的用户输入和机器人的响应添加到 conversation\\_history，并返回整个聊天历史。\n\n2. 使用 `gr.Interface()` 来定义 Gradio 界面。 `fn=bot.get_response`：设置界面的主函数为刚刚创建的 get\\_response 函数。 `live=False`：确保实时更新是关闭的，这意味着用户需要点击提交按钮来发送他们的问题，而不是一边打字，一边生成回答的流模式（比较适合展示生成式模型）。\n\n3. 启动 Gradio 界面。 `interface.launch()`：调用这个方法会启动 Gradio 的 Web 服务器，并在默认的 Web 浏览器中打开一个新窗口，显示刚刚定义的界面，用户可以通过这个界面与机器人交互。\n\n运行程序，聊天机器人在本地端口 7860 上启动。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/28d3c772116bf4733ed55e937e476d26.jpg)\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/460fa6854ffa68ef4bfa54056cb034d8.jpg)\n\n这里，输入输出窗口的配置更加清晰，而且相对于原来的只记录一轮对话的机器人，这里我们增加了历史对话信息记录功能。\n\n## 总结时刻\n\nStreamlit 和 Gradio 都是让数据科学家和开发者能够快速为机器学习模型创建 Web UI 的框架。\n\n- Streamlit 是为数据应用、仪表板和可视化设计的。它提供了多种小部件，使得用户可以与数据和模型进行交互。它非常 Pythonic，意味着它的使用方式非常自然，对于熟悉Python的人来说非常直观。\n- Gradio 更多是为了展示和演示机器学习模型。它提供了一种快速的方法，使非技术用户也能与机器学习模型进行交互，无需编写复杂的代码。\n\n以下是对它们特点进行的对比总结。\n\n![](https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202312/654d95bdb96e627c2464b4cedd964e87.jpg)\n\n无论选择哪个框架，你都可以在非常短的时间内为你的应用创建一个Web UI。至于选择哪个，更多取决于你的具体需求和个人喜好。\n\n如果你用这些框架，在你熟悉的业务场景中，利用LangChain和LLM的能力开发出了更为酷炫的LangChain应用，不要忘记在留言区中和大家分享！说说思路就行，有具体代码实现更好。\n\n## 思考题\n\n1. 我的易速鲜花Chatbot有很多不完美的地方，比如，检索功能的设计不够细致，UI不够美观，等等。请你在这个Repo的基础上，大刀阔斧地进行改进。\n2. 请你用Flask框架设计自己的Chatbot UI，重构聊天机器人，实现更多、更完善的功能。\n3. 请你回过头去看看 [第01讲](https://time.geekbang.org/column/article/699400) 我给你留的3道思考题。那时候，你不了解LangChain，现在你已经基本掌握了它的精髓，能否把第01讲的思考题重新回答一遍呢？应该很有趣吧！\n\n期待在留言区看到你的成果分享，如果觉得内容对你有帮助，也欢迎分享给有需要的朋友！"},{"url":"/posts/22.html","content":"# 结束语｜人生的价值就在于创造\n你好，我是黄佳。\n\n时间过得真快，转眼间就到了本专栏的最后一节课，我想为坚持学到最后的你大声鼓掌，也很开心能将我的阶段性沉淀传递出去，相信此刻的你已经体验到了 LangChain 的魅力。\n\n技术上的进步，还需要你不断去练习，因为我深知： **动手实践，比千言万语更有力量**。所以在结束语中，我们不再谈技术细节，只分享一点我近期的感悟吧！如果我们恰好有共鸣，那就太棒了。\n\n某一个深夜，SpaceX 研发的最新一代运载火箭系统“星舰”升空，但在发射仅3分钟后，“超重型推进器”未能与“星舰”分离，在高空解体。\n\n不过，SpaceX CEO 马斯克没有太多的情绪，他在推特写道：“恭喜 SpaceX 团队令人兴奋的星舰试射，这为几个月后的下一次试射积累了许多经验。”马斯克希望在10年内建造1000艘“星舰”登陆火星，使人类成为跨行星物种的愿景不变。\n\n![](images/719508/d22a491c640ca39f8125f0b9fac21806.png)\n\n仰望苍穹，宇宙浩瀚。每每想起人类已在月球上留下脚印，而今又要再度出发，就不由在心中感慨：如此有幸，能生活在这个时代。如此有幸，能见证通用人工智能时代的到来！\n\n是的，人类见证过一次次的历史时刻，现在，我们又站在另一个历史的节点上——通用人工智能的诞生。这并不仅仅是一个技术的进步，更是对未来世界的重新塑造。让我深感幸运的是，即便 AI 如此发达，有些东西仍是不可替代的，那就是人的创造力和情感。\n\n也许， **人生的真正价值并不仅仅是在于我们拥有了什么，计划了什么，更是在于我们创造了什么**。创造意味着超越了现有的限制，突破了旧的境界，向着未知前行。而在这个愈发高速的时代，我们正在共同见证各种壮观的创造。\n\nLangChain，这一新型的开发范式，也是一个绝佳的例证。 **LangChain，或者说基于** **LLM** **的智能开发框架，最吸引我的地方，就是凸显了代理的自主性**。与传统固定逻辑的开发方式相比，有了大模型的推理能力和ReAct等框架，就带给了它更高的灵活性、更强的自适应能力、更好的可扩展性和更高效的开发。这是一个创新的设计，能够充分释放人的创造力，应对未知的挑战。\n\nAI，把计算机程序从人类的工具进化成了智能的代理。\n\n相信学完了LangChain课程的你，能够非常了解我想强调的这一点，也是我们这个专栏的核心价值。\n\n前几天，在极客时间的 [部落](https://horde.geekbang.org/usercenter/8EC41D2EAB0E3C) 里面，我贴了几张女儿的画作，同时抛出了一个问题： **AIGC** **来了，人类画师还有价值吗？**\n\n> 一位朋友回答：当然有价值，抛开现在大部分 AI 绘画都是在拼图，还有一个就是人在画中注入的情感、寄托，比如图2，如果 AI 作图，只能画出“母亲”的形象，您女儿画出的才是“妈妈”。\n\n![](images/719508/152e3d7e34d131d3c21bfa99775b630c.jpg)\n\n![](images/719508/3e2a32320c85904b5fd3c508303d3307.jpg)\n\n的确是这样的，她在纸上展现的不仅仅是线条和颜色，更是她的情感、她的视界、她的梦想。当 AI 能够绘画时，它可能会画出“母亲”的形象，但只有人能够画出“妈妈”。这是我们的情感、记忆和经历给予的，是无法复制的。\n\n我们的《LangChain实战课》也是一样，无论是我的课程设计，还是编辑老师的心力注入、耐心打磨，乃至你的刻苦学习、留言讨论，无不汇聚了我们彼此的情感和信心、认可和期盼。这就是专属于我们人类的创造。\n\n因此，不论是探索外太空，还是深挖技术的内涵，或是简简单单的一笔一划，都证明了一个事实： **人生的价值就在于创造**。只有创造，我们才能真正感知到生命的深度，感受到存在的意义。让我们一起，以学习者的心态，拥抱这个充满无限可能的未来，创造更多的美好！\n\n最后，这里有一份 [结课问卷](https://jinshuju.net/f/HdGqeg)，期待你谈谈对这门课程的学习体验，建议或意见都欢迎指出。我们会根据你的反馈持续迭代课程，让知识长久传递，常看常新。\n\n[![](images/719508/7bd45d90193ab7e716a478629996f0c0.jpg)](https://jinshuju.net/f/HdGqeg)"}]