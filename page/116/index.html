<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>geekbang</title><meta name="author" content="码农张三"><meta name="copyright" content="码农张三"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="geekbang">
<meta property="og:url" content="https://zhuansun.github.io/geekbang/page/116/index.html">
<meta property="og:site_name" content="geekbang">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pic.imgdb.cn/item/653470a0c458853aef5813f1.png">
<meta property="article:author" content="码农张三">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic.imgdb.cn/item/653470a0c458853aef5813f1.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://zhuansun.github.io/geekbang/page/116/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":false,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'geekbang',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2024-03-21 07:45:10'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="geekbang" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://pic.imgdb.cn/item/653470a0c458853aef5813f1.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">1345</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">23</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('https://s2.loli.net/2023/10/21/zfMGZnL6qB9S3Ue.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">geekbang</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">geekbang</h1><div id="site-subtitle"><span id="subtitle"></span></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/2776413479.html" title="16 人工神经网络 | 道法自然，久藏玄冥：神经网络的生理学背景">16 人工神经网络 | 道法自然，久藏玄冥：神经网络的生理学背景</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-02-29T12:17:18.000Z" title="发表于 2024-02-29 12:17:18">2024-02-29</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E8%AF%BE/">人工智能基础课</a></span></div><div class="content">16 人工神经网络 | 道法自然，久藏玄冥：神经网络的生理学背景当下，人工智能主流的研究方法是连接主义。连接主义学派并不认为人工智能源于数理逻辑，也不认为智能的关键在于思维方式。这一学派把智能建立在神经生理学和认知科学的基础上，强调智能活动是将大量简单的单元通过复杂方式相互连接后并行运行的结果。
基于以上的思路，连接主义学派通过人工构建神经网络的方式来模拟人类智能。 它以工程技术手段模拟人脑神经系统的结构和功能，通过大量的非线性并行处理器模拟人脑中众多的神经元，用处理器复杂的连接关系模拟人脑中众多神经元之间的突触行为。相较符号主义学派，连接主义学派显然更看重是智能赖以实现的“硬件”。
人类智能的本质是什么？这是认知科学的基本问题。根据自底向上的分析方法，人类智能的本质很大程度上取决于“什么是认知的基本单元”。目前的理论和实验结果表明，要分析认知基本单元，合理的方法既不是物理推理也不是数学分析，而是设计科学实验加以验证。大量的实验结果显示，从被认知的客体角度来看，认知基本单元是知觉组织形成的“知觉物体”。
知觉物体概念的形成具备其特殊的物理基础。 脑神经科学研究表明，人脑由大约千亿个神经细胞及亿亿个神经突触组成，这些神经细胞及其突触共同构成了一个庞大的生物神经网络。每个神经细胞通过突触与其他神经细胞进行连接与通信。当通过突触所接收到的信号强度超过某个阈值时，神经细胞便会进入激活状态， ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/2407228687.html" title="17 人工神经网络 | 一个青年才俊的意外死亡：神经元与感知器">17 人工神经网络 | 一个青年才俊的意外死亡：神经元与感知器</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-02-29T12:17:18.000Z" title="发表于 2024-02-29 12:17:18">2024-02-29</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E8%AF%BE/">人工智能基础课</a></span></div><div class="content">17 人工神经网络 | 一个青年才俊的意外死亡：神经元与感知器1943年，美国芝加哥大学的神经科学家沃伦·麦卡洛克和他的助手沃尔特·皮茨发表了论文《神经活动中思想内在性的逻辑演算》（A Logical Calculus of Ideas Immanent in Nervous Activity），系统阐释了他们的想法： 一个极度简化的机械大脑。麦卡洛克和皮茨首先将神经元的状态二值化，再通过复杂的方式衔接不同的神经元，从而实现对抽象信息的逻辑运算。正是这篇论文宣告了人工神经网络的呱呱坠地，它传奇的故事自此徐徐展开。
与生理学上的神经网络类似，麦卡洛克和皮茨的人工神经网络也由类似神经元的基本单元构成，这一基本单元以两位发明者的名字命名为“ MP神经元（MP neuron）”。大脑中的神经元接受神经树突的兴奋性突触后电位和抑制性突触后电位，产生出沿其轴突传递的神经元的动作电位；MP神经元则接受一个或多个输入，并对输入的线性加权进行非线性处理以产生输出。假定MP神经元的输入信号是个$N + 1$维向量$(x_0, x_1, \cdots, x_N)$，第i个分量的权重为$w_i$，则其输出可以写成
$$ y &#x3D; \phi (\sum\limits_{i &#x3D; 0}^N w_i x_i)$$
上式中的$x_0$通常被赋值为+1，也就使$w_0$变成固定的偏置输入$b$。
M ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/2224831516.html" title="18 人工神经网络 | 左手信号，右手误差：多层感知器">18 人工神经网络 | 左手信号，右手误差：多层感知器</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-02-29T12:17:18.000Z" title="发表于 2024-02-29 12:17:18">2024-02-29</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E8%AF%BE/">人工智能基础课</a></span></div><div class="content">18 人工神经网络 | 左手信号，右手误差：多层感知器虽然异或问题成为感知器和早期神经网络的阿喀琉斯之踵，但它并非无解的问题。 恰恰相反，解决它的思路相当简单，就是将单层感知器变成多层感知器。下图就是一个多层感知器的实例，这个包含单个隐藏层的神经网络能够完美地解决异或问题。
（图片来自 Machine Learning: An Algorithmic Perspective, 2nd Edition, Figure 4.2）
假定两个输入节点A和B的二进制输入分别为1和0，则根据图中的权重系数可以计算出神经元C的输入为0.5，而神经元D的输入为0。在由C和D构成的隐藏层中，由于C的输入大于0，因而符号函数使其输出为1；由于D的输入等于0，符号函数则使其输出为0。在输出节点的神经元E上，各路输入线性组合的结果为0.5，因而E的输出，也是神经网络整体的输出，为1，与两个输入的异或相等。在此基础上可以进一步证明，这个神经网络的运算规则就是异或操作的运算规则。
多层感知器（multilayer perceptron）包含一个或多个在输入节点和输出节点之间的隐藏层（hidden layer），除了输入节点外，每个节点都是使用非线性激活函数的神经元。而在不同层之间，多层感知器具有全连接性，即任意层中的每个神经元都与它前一层中的所有神经元或者节点相连接，连接的强度由网络中的权重系数决定。 多层感 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/3574383629.html" title="22 深度学习 | 空山鸣响，静水流深：深度学习概述">22 深度学习 | 空山鸣响，静水流深：深度学习概述</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-02-29T12:17:18.000Z" title="发表于 2024-02-29 12:17:18">2024-02-29</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E8%AF%BE/">人工智能基础课</a></span></div><div class="content">22 深度学习 | 空山鸣响，静水流深：深度学习概述多年以后，面对李世石与AlphaGo的厮杀，加里·卡斯帕罗夫将会回想起，与深蓝对弈的那个遥远的下午。彼时的对手是一个庞大的超级计算机，记下变化多端的开局，以固定的逻辑决策应对中局，穷极所有可能性筛选残局。人工智能蹒跚学步之时，许多概念尚且是空中楼阁，计算机能够战胜优秀的人类围棋选手，这样的想法不啻于天方夜谭。
棋类游戏的核心在于根据棋局判断下一手的最优下法，深蓝通过穷举的方法在国际象棋的棋局中解决了这个问题。在64格的国际象棋棋盘上，深蓝的运算能力决定了它能算出12手棋之后的局面下的最优解，而身为人类棋手执牛耳者的卡斯帕罗夫最多只能算出10手棋，多出来的两手棋就会成为左右战局的关键因素。
深蓝的核心在于“算”：利用强大的计算资源来优化目标函数。深蓝本身就是一套专用于国际象棋的硬件，大部分逻辑规则是以特定的象棋芯片电路实现，辅以较少量负责调度与实现高阶功能的软件代码。其算法的核心是暴力穷举：生成所有可能的下法，然后执行尽可能深的搜索，并不断对局面进行评估，尝试找出最佳的一手。
可在围棋棋盘上，可以落子的点数达到了361个。别说12手棋，就是6手棋的运算量都已经接近于天文数字！这使得计算机相对于人脑的运算优势变得微不足道，走出优于人类棋手的妙手的概率也微乎其微，这也是为什么计算机会在围棋领域被看衰的原因。
围棋的棋盘状态远比国际象棋复 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/3777316228.html" title="23 深度学习 | 前方有路，未来可期：深度前馈网络">23 深度学习 | 前方有路，未来可期：深度前馈网络</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-02-29T12:17:18.000Z" title="发表于 2024-02-29 12:17:18">2024-02-29</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E8%AF%BE/">人工智能基础课</a></span></div><div class="content">23 深度学习 | 前方有路，未来可期：深度前馈网络深度前馈网络（Deep Feedforward Network）是具有深度结构的前馈神经网络，可以看成是进化版的多层感知器。与只有一个或两个隐藏层的浅层网络相比，深度前馈网络具有更多的隐藏层数目，从而具备了更强的特征提取能力。
深度前馈网络不考虑输入数据可能具备的任何特定结构，也就是不使用关于数据的先验信息。但特征提取能力增强的代价是运算复杂度的提升。因而， 网络架构的建立、损失函数的选择、输出单元和隐藏单元的设计、训练误差的处理等问题就成为深度前馈网络设计中的一系列核心问题。
在深度前馈网络的设计中，确定架构是首要考虑的关键问题。架构决定着网络中包含多少基本单元，以及这些基本单元之间如何相互连接。几乎所有前馈网络采用的都是链式架构，即前一层的输出是后一层的输入。在这样的链式架构中，层的数目和每一层中神经元的数目就是网络的主要变量。
介绍多层感知器时我曾提到了通用逼近的性质，这个性质的严格形式是通用逼近定理。 通用逼近定理的内容是如果一个前馈网络具有单个隐藏层，这个隐藏层又有足够但是有限数目的神经元，这个神经网络就可以以任意精度逼近任意连续函数。虽然在这个定理的初始证明中，隐藏神经元的传递函数是具有“挤压”性质的非线性函数，但定理的成立性实际上并不取决于传递函数的性质，而是由网络的前馈架构所决定的。
通用逼近定理是一个存在性定理， ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/1875178351.html" title="25 深度学习 | 玉不琢不成器：深度学习中的优化">25 深度学习 | 玉不琢不成器：深度学习中的优化</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-02-29T12:17:18.000Z" title="发表于 2024-02-29 12:17:18">2024-02-29</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E8%AF%BE/">人工智能基础课</a></span></div><div class="content">25 深度学习 | 玉不琢不成器：深度学习中的优化除了正则化之外，优化也是深度学习需要解决的一个核心问题。由于深度神经网络中的隐藏层数目较多，因而将整个网络作为一个整体进行优化是非常困难的事情，需要花费大量的时间和计算力。出于效率和精确性的考虑，在深度学习的优化上需要使用专门的技术。
出于可解性的考虑，传统机器学习算法往往会小心翼翼地选择代价函数和优化条件，将待优化问题转化为容易求解的 凸优化问题。但在神经网络，尤其是在深度神经网络中，更一般的非凸情况是不可避免的，这就给深度学习中的优化带来很多额外的挑战。
当待优化的代价函数的输入是$n$维向量时，其二阶导数就包含针对不同变量分别求偏导所得到的很多分量，将这些分量按顺序排列可以得到 Hessian矩阵。而在神经网络的训练中，Hessian矩阵的病态问题非常常见，甚至无论优化问题是否具有凸优化的形式，病态的Hessian矩阵都会出现。
在线性方程$\mathbf{A} \mathbf{x} &#x3D; \mathbf{b}$中，当系数矩阵$\mathbf{A}$的微小扰动会给解集$\mathbf{x}$带来较大幅度的波动时，这样的矩阵就被称为 病态矩阵（ill-conditioned matrix）。
病态矩阵是科学计算不愿打交道的对象，因为数值精度导致的不可避免的舍入误差可能会给输出带来巨大的偏离，正所谓“差之毫厘，谬以千里”。 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/3564829922.html" title="24 深度学习 | 小树不修不直溜：深度学习中的正则化">24 深度学习 | 小树不修不直溜：深度学习中的正则化</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-02-29T12:17:18.000Z" title="发表于 2024-02-29 12:17:18">2024-02-29</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E8%AF%BE/">人工智能基础课</a></span></div><div class="content">24 深度学习 | 小树不修不直溜：深度学习中的正则化正则化（Regularization）作为抑制过拟合的手段，是机器学习和深度学习之中必不可少的环节，具有举足轻重的地位。好的机器学习算法不仅要在训练集上表现出色，当推广到未知的测试数据时，其优良的性能依然能够得以保持。 正则化就是一类通过显式设计降低泛化误差，以提升算法通用性的策略的统称。由于深度学习中涉及的参数众多，正则化就变得尤为重要。
正则化被定义为对学习算法的修改，这些修改的目的在于减少泛化误差。通常说来，泛化误差的下降是以训练误差的上升为代价的，但有些算法也能兼顾泛化误差和训练误差的良好性能。
正则化处理可以看成是奥卡姆剃刀原则（Occam’s razor）在学习算法上的应用。奥卡姆剃刀原则的表述是：“当两个假说具有完全相同的解释力和预测力时，以那个较为简单的假说作为讨论依据。”在机器学习中，正则化处理得到的正是更加简单的模型。
从概率论角度看，许多正则化技术对应的是在模型参数上施加一定的先验分布，其作用是改变泛化误差的结构。正则化是对欠拟合和过拟合的折中，在不过度增加偏差的情况下显著减少方差。正则化能够改变数据分布，让通过模型得到的数据分布尽可能和真实的数据生成过程相匹配。
虽然目前在深度学习中应用的正则化方式称得上“八仙过海，各显神通”，却并不存在能够系统描述这些方法、并进一步指导设计的通用主线。因此，要从通观全局 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/4001607788.html" title="26 深度学习 | 空竹里的秘密：自编码器">26 深度学习 | 空竹里的秘密：自编码器</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-02-29T12:17:18.000Z" title="发表于 2024-02-29 12:17:18">2024-02-29</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E8%AF%BE/">人工智能基础课</a></span></div><div class="content">26 深度学习 | 空竹里的秘密：自编码器自编码器（auto-encoder）是一类执行无监督学习任务的神经网络结构，它的目的是学习一组数据的重新表达，也就是编码。
在结构上，自编码器是包含若干隐藏层的深度前馈神经网络，其独特之处是输入层和输出层的单元数目相等；在功能上，自编码器的目的不是根据输入来预测输出，而是重建网络的输入，正是这样的功能将自编码器和其他神经网络区分开来。由于自编码器的图形表示像极了杂技中使用的道具空竹，因而也得了个“空竹网络”的雅号。
自编码器结构由编码映射和解码映射两部分组成。如果将编码映射记作$\phi$，解码映射记作$\psi$，自编码器的作用就是将输入$\mathbf{X}$改写为$(\psi \circ \phi) (\mathbf{X})$，这相当于将输入从一个表象下转换到另一个表象下来表示，就像量子力学中粒子不同表象之间的变化一样。 如果以均方误差作为网络训练中的损失函数，自编码器的目的就是找到使均方误差最小的编解码映射的组合，即
$$ \phi, \psi &#x3D; \arg \min_{\phi, \psi} || \mathbf{X} - (\phi \circ \psi) (\mathbf{X}) || ^ 2$$
在最简单的情形，也就是只有一个隐藏层的情形下，自编码器隐藏层的输出就是编码映射。当隐藏层的维度小于输入数据的维度时，这就 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/1450191275.html" title="27 深度学习 | 困知勉行者勇：深度强化学习">27 深度学习 | 困知勉行者勇：深度强化学习</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-02-29T12:17:18.000Z" title="发表于 2024-02-29 12:17:18">2024-02-29</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E8%AF%BE/">人工智能基础课</a></span></div><div class="content">27 深度学习 | 困知勉行者勇：深度强化学习在2017年新鲜出炉的《麻省理工科技评论》十大突破性技术中，“强化学习”榜上有名。如果把时钟调回到一年多之前的围棋人机大战，彼时的深度强化学习在AlphaGo对李世乭的横扫中就已经初露峥嵘。而在进化版AlphaGo Zero中，深度强化学习更是大放异彩，AlphaGo Zero之所以能够摆脱对人类棋谱的依赖，其原因就在于使用纯粹的深度强化学习进行端到端的自我对弈，从而超越了人类的围棋水平。
要介绍深度强化学习就不得不先说一说强化学习的故事。相比于纯人造的监督学习和无监督学习，强化学习的思想根源来自于认知科学。20世纪初，美国心理学家爱德华·桑代克在对教育过程的研究中提出了强化学习的原始理论，而作为人工智能方法的强化学习则力图使计算机在没有明确指导的情况下实现自主学习，完成从数据到决策的转变。
强化学习（reinforcement learning）实质上是智能系统从环境到行为的学习过程，智能体通过与环境的互动来改善自身的行为，改善准则是使某个累积奖励函数最大化。具体来说，强化学习是基于环境反馈实现决策制定的通用框架，根据不断试错得到来自环境的奖励或者惩罚，从而实现对趋利决策信念的不断增强。它强调在与环境的交互过程中实现学习，产生能获得最大利益的习惯性行为。
强化学习的特点在于由环境提供的强化信号只是对智能体所产生动作的好坏作一种评价，和 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/posts/2164221631.html" title="28 深度学习框架下的神经网络 | 枯木逢春：深度信念网络">28 深度学习框架下的神经网络 | 枯木逢春：深度信念网络</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-02-29T12:17:18.000Z" title="发表于 2024-02-29 12:17:18">2024-02-29</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E8%AF%BE/">人工智能基础课</a></span></div><div class="content">28 深度学习框架下的神经网络 | 枯木逢春：深度信念网络2006年，深度学习的祖师爷乔弗里·辛顿提出了深度信念网络模型，它吹响了连接主义学派复兴的号角，也打开了通向人工智能新世界的大门。
深度信念网络是一种概率生成模型，能够建立输入数据和输出类别的联合概率分布。网络中包含多个隐藏层，隐藏层中的隐藏变量通常是二进制数，用来对输入信号进行特征提取。输入信号从深度信念网络的最底层输入，并自下而上有向地传递给隐藏层。而在网络最上面的两层中，神经元之间的连接是没有方向并且对称的，这两个层次共同构成了联想记忆。
从功能上看，深度信念网络的每一个隐藏层都代表着对输入数据的一种中间表示，而隐藏层中的每个神经元都代表着输入数据不同层次上的特征，不同层神经元之间的连接则代表着不同层次特征之间的联系，所有特征和特征之间的所有关系共同形成了对输入数据的抽象描述。
从结构上看，复杂的深度信念网络可以看成由若干简单的学习单元构成的整体，而构成它的基本单元就是受限玻尔兹曼机（restricted boltzmann machine）。受限玻尔兹曼机早在1986年便已诞生，可直到20年后才因辛顿的成果而得到重视。
受限玻尔兹曼机的模型非常简单，就是一个两层的神经网络，包括一个可见层和一个隐藏层。可见层用来接收数据，隐藏层则用来处理数据。可见层和隐藏层以全连接的方式相连，也就是任意两个不同层次中的神经元都会两两相 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/115/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/115/#content-inner">115</a><span class="page-number current">116</span><a class="page-number" href="/page/117/#content-inner">117</a><span class="space">&hellip;</span><a class="page-number" href="/page/135/#content-inner">135</a><a class="extend next" rel="next" href="/page/117/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/AI%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E7%BE%8E/"><span class="card-category-list-name">AI大模型之美</span><span class="card-category-list-count">31</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/AI%E6%8A%80%E6%9C%AF%E5%86%85%E5%8F%82/"><span class="card-category-list-name">AI技术内参</span><span class="card-category-list-count">166</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/AI%E7%BB%98%E7%94%BB%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"><span class="card-category-list-name">AI绘画核心技术与实战</span><span class="card-category-list-count">31</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/DDD%E5%AE%9E%E6%88%98%E8%AF%BE/"><span class="card-category-list-name">DDD实战课</span><span class="card-category-list-count">26</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Java%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E9%9D%A2%E8%AF%95%E7%B2%BE%E8%AE%B2/"><span class="card-category-list-name">Java核心技术面试精讲</span><span class="card-category-list-count">44</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/LangChain%E5%AE%9E%E6%88%98%E8%AF%BE/"><span class="card-category-list-name">LangChain实战课</span><span class="card-category-list-count">25</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"><span class="card-category-list-name">Redis核心技术与实战</span><span class="card-category-list-count">53</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E8%AF%BE/"><span class="card-category-list-name">人工智能基础课</span><span class="card-category-list-count">59</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E5%AD%A6%E6%9E%B6%E6%9E%84/"><span class="card-category-list-name">从0开始学架构</span><span class="card-category-list-count">66</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE%E4%B8%8E%E7%AE%97%E6%B3%95%E5%AE%9E%E6%88%98/"><span class="card-category-list-name">分布式协议与算法实战</span><span class="card-category-list-count">23</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%90%8E%E7%AB%AF%E6%8A%80%E6%9C%AF%E9%9D%A2%E8%AF%9538%E8%AE%B2/"><span class="card-category-list-name">后端技术面试38讲</span><span class="card-category-list-count">45</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97/"><span class="card-category-list-name">大厂晋升指南</span><span class="card-category-list-count">45</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/"><span class="card-category-list-name">如何设计一个秒杀系统</span><span class="card-category-list-count">10</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E/"><span class="card-category-list-name">左耳听风</span><span class="card-category-list-count">119</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%88%90%E4%B8%BAAI%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/"><span class="card-category-list-name">成为AI产品经理</span><span class="card-category-list-count">41</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%95%86%E4%B8%9A%E6%A1%88%E4%BE%8B%E8%A7%A3%E8%AF%BB/"><span class="card-category-list-name">技术与商业案例解读</span><span class="card-category-list-count">163</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%9C%B1%E8%B5%9F%E7%9A%84%E6%8A%80%E6%9C%AF%E7%AE%A1%E7%90%86%E8%AF%BE/"><span class="card-category-list-name">朱赟的技术管理课</span><span class="card-category-list-count">39</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"><span class="card-category-list-name">深入浅出计算机组成原理</span><span class="card-category-list-count">62</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E7%A8%8B%E5%BA%8F%E5%91%98%E8%BF%9B%E9%98%B6%E6%94%BB%E7%95%A5/"><span class="card-category-list-name">程序员进阶攻略</span><span class="card-category-list-count">65</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%BE%8E/"><span class="card-category-list-name">设计模式之美</span><span class="card-category-list-count">113</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%B6%A3%E8%B0%88%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"><span class="card-category-list-name">趣谈网络协议</span><span class="card-category-list-count">51</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E9%9B%B6%E5%9F%BA%E7%A1%80GPT%E5%BA%94%E7%94%A8%E5%85%A5%E9%97%A8%E8%AF%BE/"><span class="card-category-list-name">零基础GPT应用入门课</span><span class="card-category-list-count">19</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A140%E9%97%AE/"><span class="card-category-list-name">高并发系统设计40问</span><span class="card-category-list-count">49</span></a></li>
            </ul></div></div></div></main><footer id="footer" style="background-image: url('https://s2.loli.net/2023/10/21/zfMGZnL6qB9S3Ue.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By 码农张三</div></div><script src="https://cdn.bootcdn.net/ajax/libs/mermaid/9.4.0/mermaid.min.js"></script></footer></div><div id="rightside"><div id="rightside-config-hide"></div><div id="rightside-config-show"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    window.typed = new Typed("#subtitle", {
      strings: ["有志者事竟成。——曹操","读书破万卷，下笔如有神。——杜甫","成功源于不懈的努力。——爱迪生","机会只对进取有为的人开放。——林肯","人生没有彩排，每天都是现场直播。——佚名","活到老学到老。——毛泽东","知之者不如好之者，好之者不如乐之者。——孔子","天行健，君子以自强不息；地势坤，君子以厚德载物。——《易经》","己所不欲勿施于人。——《论语》","成功是一种态度，而不是一种结果。——亨利·福特","人生没有后悔药可吃。——佚名","世上无难事，只怕有心人。——陶行知","一寸光阴一寸金，寸金难买寸光阴。——俗语","成功路上充满荆棘，只有坚持不懈才能到达终点。——华罗庚","机会永远留给那些有准备的人。——路易斯·帕斯特尔","失败乃成功之母。——俗语","人生就像一杯茶，不会苦一辈子，但总会苦一阵子。——佚名","没有口水与汗水，就没有成功的泪水。——科比·布莱恩特","生活不是等待风暴过去，而是学会在雨中跳舞。——维维安·格林","一个人最大的破产是绝望，最大的资产是希望。——肯尼迪","成功的关键不在于避免失败，而在于从失败中学习。——比尔·坎贝尔","人生就像骑自行车，要保持平衡就得往前走。——爱因斯坦","没有付出就没有收获。——佚名","成功需要付出代价，不成功则需要付出更高的代价。——欧内斯特·海明威","成功不是终点，失败也不是终结，只有勇气才是永恒。——温斯顿·丘吉尔","做你自己，别人已经有人在做了。——奥斯卡·王尔德","人生最大的成就是成为一个好人。——马丁·路德·金","成功的秘诀在于坚持到底，即使没有人相信你。——温斯顿·丘吉尔","机会只对进取有为的人开放。——林肯","人生的意义不在于拥有一切，而在于成为一切。——阿尔伯特·爱因斯坦"],
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("subtitle").innerHTML = '有志者事竟成。——曹操'
  }
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js').then(subtitleType)
  }
} else {
  subtitleType()
}</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div></div></body></html>