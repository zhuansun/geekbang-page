<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>geekbang</title>
  
  
  <link href="https://zhuansun.github.io/geekbang/atom.xml" rel="self"/>
  
  <link href="https://zhuansun.github.io/geekbang/"/>
  <updated>2024-03-21T07:44:22.342Z</updated>
  <id>https://zhuansun.github.io/geekbang/</id>
  
  <author>
    <name>码农张三</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>03 | 高性能IO模型：为什么单线程Redis能那么快？</title>
    <link href="https://zhuansun.github.io/geekbang/posts/3906181922.html"/>
    <id>https://zhuansun.github.io/geekbang/posts/3906181922.html</id>
    <published>2024-03-04T22:10:14.000Z</published>
    <updated>2024-03-21T07:44:22.342Z</updated>
    
    <content type="html"><![CDATA[<h1 id="03-高性能IO模型：为什么单线程Redis能那么快？"><a href="#03-高性能IO模型：为什么单线程Redis能那么快？" class="headerlink" title="03 | 高性能IO模型：为什么单线程Redis能那么快？"></a>03 | 高性能IO模型：为什么单线程Redis能那么快？</h1><p>你好，我是蒋德钧。</p><p>今天，我们来探讨一个很多人都很关心的问题：“为什么单线程的Redis能那么快？”</p><p>首先，我要和你厘清一个事实，我们通常说，Redis是单线程，主要是指 <strong>Redis的网络IO和键值对读写是由一个线程来完成的，这也是Redis对外提供键值存储服务的主要流程</strong>。但Redis的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。</p><p>所以，严格来说，Redis并不是单线程，但是我们一般把Redis称为单线程高性能，这样显得“酷”些。接下来，我也会把Redis称为单线程模式。而且，这也会促使你紧接着提问：“为什么用单线程？为什么单线程能这么快？”</p><p>要弄明白这个问题，我们就要深入地学习下Redis的单线程设计机制以及多路复用机制。之后你在调优Redis性能时，也能更有针对性地避免会导致Redis单线程阻塞的操作，例如执行复杂度高的命令。</p><p>好了，话不多说，接下来，我们就先来学习下Redis采用单线程的原因。</p><h2 id="Redis为什么用单线程？"><a href="#Redis为什么用单线程？" class="headerlink" title="Redis为什么用单线程？"></a>Redis为什么用单线程？</h2><p>要更好地理解Redis为什么用单线程，我们就要先了解多线程的开销。</p><h3 id="多线程的开销"><a href="#多线程的开销" class="headerlink" title="多线程的开销"></a>多线程的开销</h3><p>日常写程序时，我们经常会听到一种说法：“使用多线程，可以增加系统吞吐率，或是可以增加系统扩展性。”的确，对于一个多线程的系统来说，在有合理的资源分配的情况下，可以增加系统中处理请求操作的资源实体，进而提升系统能够同时处理的请求数，即吞吐率。下面的左图是我们采用多线程时所期待的结果。</p><p>但是，请你注意，通常情况下，在我们采用多线程后，如果没有良好的系统设计，实际得到的结果，其实是右图所展示的那样。我们刚开始增加线程数时，系统吞吐率会增加，但是，再进一步增加线程时，系统吞吐率就增长迟缓了，有时甚至还会出现下降的情况。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/cbd394e62219cc5a6d9ae64035e51733.jpg"></p><p>为什么会出现这种情况呢？一个关键的瓶颈在于，系统中通常会存在被多线程同时访问的共享资源，比如一个共享的数据结构。当有多个线程要修改这个共享资源时，为了保证共享资源的正确性，就需要有额外的机制进行保证，而这个额外的机制，就会带来额外的开销。</p><p>拿Redis来说，在上节课中，我提到过，Redis有List的数据类型，并提供出队（LPOP）和入队（LPUSH）操作。假设Redis采用多线程设计，如下图所示，现在有两个线程A和B，线程A对一个List做LPUSH操作，并对队列长度加1。同时，线程B对该List执行LPOP操作，并对队列长度减1。为了保证队列长度的正确性，Redis需要让线程A和B的LPUSH和LPOP串行执行，这样一来，Redis可以无误地记录它们对List长度的修改。否则，我们可能就会得到错误的长度结果。这就是 <strong>多线程编程模式面临的共享资源的并发访问控制问题</strong>。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/303255dcce6d0837bf7e2440df0f8e08.jpg"></p><p>并发访问控制一直是多线程开发中的一个难点问题，如果没有精细的设计，比如说，只是简单地采用一个粗粒度互斥锁，就会出现不理想的结果：即使增加了线程，大部分线程也在等待获取访问共享资源的互斥锁，并行变串行，系统吞吐率并没有随着线程的增加而增加。</p><p>而且，采用多线程开发一般会引入同步原语来保护共享资源的并发访问，这也会降低系统代码的易调试性和可维护性。为了避免这些问题，Redis直接采用了单线程模式。</p><p>讲到这里，你应该已经明白了“Redis为什么用单线程”，那么，接下来，我们就来看看，为什么单线程Redis能获得高性能。</p><h2 id="单线程Redis为什么那么快？"><a href="#单线程Redis为什么那么快？" class="headerlink" title="单线程Redis为什么那么快？"></a>单线程Redis为什么那么快？</h2><p>通常来说，单线程的处理能力要比多线程差很多，但是Redis却能使用单线程模型达到每秒数十万级别的处理能力，这是为什么呢？其实，这是Redis多方面设计选择的一个综合结果。</p><p>一方面，Redis的大部分操作在内存上完成，再加上它采用了高效的数据结构，例如哈希表和跳表，这是它实现高性能的一个重要原因。另一方面，就是Redis采用了 <strong>多路复用机制</strong>，使其在网络IO操作中能并发处理大量的客户端请求，实现高吞吐率。接下来，我们就重点学习下多路复用机制。</p><p>首先，我们要弄明白网络操作的基本IO模型和潜在的阻塞点。毕竟，Redis采用单线程进行IO，如果线程被阻塞了，就无法进行多路复用了。</p><h3 id="基本IO模型与阻塞点"><a href="#基本IO模型与阻塞点" class="headerlink" title="基本IO模型与阻塞点"></a>基本IO模型与阻塞点</h3><p>你还记得我在 <a href="https://time.geekbang.org/column/article/268262">第一节课</a> 介绍的具有网络框架的SimpleKV吗？</p><p>以Get请求为例，SimpleKV为了处理一个Get请求，需要监听客户端请求（bind&#x2F;listen），和客户端建立连接（accept），从socket中读取请求（recv），解析客户端发送请求（parse），根据请求类型读取键值数据（get），最后给客户端返回结果，即向socket中写回数据（send）。</p><p>下图显示了这一过程，其中，bind&#x2F;listen、accept、recv、parse和send属于网络IO处理，而get属于键值数据操作。既然Redis是单线程，那么，最基本的一种实现是在一个线程中依次执行上面说的这些操作。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/e18499ab244e4428a0e60b4da6575bc9.jpg"></p><p>但是，在这里的网络IO操作中，有潜在的阻塞点，分别是accept()和recv()。当Redis监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在accept()函数这里，导致其他客户端无法和Redis建立连接。类似的，当Redis通过recv()从一个客户端读取数据时，如果数据一直没有到达，Redis也会一直阻塞在recv()。</p><p>这就导致Redis整个线程阻塞，无法处理其他客户端请求，效率很低。不过，幸运的是，socket网络模型本身支持非阻塞模式。</p><h3 id="非阻塞模式"><a href="#非阻塞模式" class="headerlink" title="非阻塞模式"></a>非阻塞模式</h3><p>Socket网络模型的非阻塞模式设置，主要体现在三个关键的函数调用上，如果想要使用socket非阻塞模式，就必须要了解这三个函数的调用返回类型和设置模式。接下来，我们就重点学习下它们。</p><p>在socket模型中，不同操作调用后会返回不同的套接字类型。socket()方法会返回主动套接字，然后调用listen()方法，将主动套接字转化为监听套接字，此时，可以监听来自客户端的连接请求。最后，调用accept()方法接收到达的客户端连接，并返回已连接套接字。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/1ccc62ab3eb2a63c4965027b4248f34a.jpg"></p><p>针对监听套接字，我们可以设置非阻塞模式：当Redis调用accept()但一直未有连接请求到达时，Redis线程可以返回处理其他操作，而不用一直等待。但是，你要注意的是，调用accept()时，已经存在监听套接字了。</p><p>虽然Redis线程可以不用继续等待，但是总得有机制继续在监听套接字上等待后续连接请求，并在有请求时通知Redis。</p><p>类似的，我们也可以针对已连接套接字设置非阻塞模式：Redis调用recv()后，如果已连接套接字上一直没有数据到达，Redis线程同样可以返回处理其他操作。我们也需要有机制继续监听该已连接套接字，并在有数据达到时通知Redis。</p><p>这样才能保证Redis线程，既不会像基本IO模型中一直在阻塞点等待，也不会导致Redis无法处理实际到达的连接请求或数据。</p><p>到此，Linux中的IO多路复用机制就要登场了。</p><h3 id="基于多路复用的高性能I-O模型"><a href="#基于多路复用的高性能I-O模型" class="headerlink" title="基于多路复用的高性能I&#x2F;O模型"></a>基于多路复用的高性能I&#x2F;O模型</h3><p>Linux中的IO多路复用机制是指一个线程处理多个IO流，就是我们经常听到的select&#x2F;epoll机制。简单来说，在Redis只运行单线程的情况下， <strong>该机制允许内核中，同时存在多个监听套接字和已连接套接字</strong>。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给Redis线程处理，这就实现了一个Redis线程处理多个IO流的效果。</p><p>下图就是基于多路复用的Redis IO模型。图中的多个FD就是刚才所说的多个套接字。Redis网络框架调用epoll机制，让内核监听这些套接字。此时，Redis线程不会阻塞在某一个特定的监听或已连接套接字上，也就是说，不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis可以同时和多个客户端连接并处理请求，从而提升并发性。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/00ff790d4f6225aaeeebba34a71d8bea.jpg"></p><p>为了在请求到达时能通知到Redis线程，select&#x2F;epoll提供了 <strong>基于事件的回调机制</strong>，即 <strong>针对不同事件的发生，调用相应的处理函数</strong>。</p><p>那么，回调机制是怎么工作的呢？其实，select&#x2F;epoll一旦监测到FD上有请求到达时，就会触发相应的事件。</p><p>这些事件会被放进一个事件队列，Redis单线程对该事件队列不断进行处理。这样一来，Redis无需一直轮询是否有请求实际发生，这就可以避免造成CPU资源浪费。同时，Redis在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。因为Redis一直在对事件队列进行处理，所以能及时响应客户端请求，提升Redis的响应性能。</p><p>为了方便你理解，我再以连接请求和读数据请求为例，具体解释一下。</p><p>这两个请求分别对应Accept事件和Read事件，Redis分别对这两个事件注册accept和get回调函数。当Linux内核监听到有连接请求或读数据请求时，就会触发Accept事件和Read事件，此时，内核就会回调Redis相应的accept和get函数进行处理。</p><p>这就像病人去医院瞧病。在医生实际诊断前，每个病人（等同于请求）都需要先分诊、测体温、登记等。如果这些工作都由医生来完成，医生的工作效率就会很低。所以，医院都设置了分诊台，分诊台会一直处理这些诊断前的工作（类似于Linux内核监听请求），然后再转交给医生做实际诊断。这样即使一个医生（相当于Redis单线程），效率也能提升。</p><p>不过，需要注意的是，即使你的应用场景中部署了不同的操作系统，多路复用机制也是适用的。因为这个机制的实现有很多种，既有基于Linux系统下的select和epoll实现，也有基于FreeBSD的kqueue实现，以及基于Solaris的evport实现，这样，你可以根据Redis实际运行的操作系统，选择相应的多路复用实现。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>今天，我们重点学习了Redis线程的三个问题：“Redis真的只有单线程吗？”“为什么用单线程？”“单线程为什么这么快？”</p><p>现在，我们知道了，Redis单线程是指它对网络IO和数据读写的操作采用了一个线程，而采用单线程的一个核心原因是避免多线程开发的并发控制问题。单线程的Redis也能获得高性能，跟多路复用的IO模型密切相关，因为这避免了accept()和send()&#x2F;recv()潜在的网络IO操作阻塞点。</p><p>搞懂了这些，你就走在了很多人的前面。如果你身边还有不清楚这几个问题的朋友，欢迎你分享给他&#x2F;她，解决他们的困惑。</p><p>另外，我也剧透下，可能你也注意到了，2020年5月，Redis 6.0的稳定版发布了，Redis 6.0中提出了多线程模型。那么，这个多线程模型和这节课所说的IO模型有什么关联？会引入复杂的并发控制问题吗？会给Redis 6.0带来多大提升？关于这些问题，我会在后面的课程中和你具体介绍。</p><h2 id="每课一问"><a href="#每课一问" class="headerlink" title="每课一问"></a>每课一问</h2><p>这节课，我给你提个小问题，在“Redis基本IO模型”图中，你觉得还有哪些潜在的性能瓶颈吗？欢迎在留言区写下你的思考和答案，我们一起交流讨论。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;03-高性能IO模型：为什么单线程Redis能那么快？&quot;&gt;&lt;a href=&quot;#03-高性能IO模型：为什么单线程Redis能那么快？&quot; class=&quot;headerlink&quot; title=&quot;03 | 高性能IO模型：为什么单线程Redis能那么快？&quot;&gt;&lt;/a&gt;03 </summary>
      
    
    
    
    <category term="Redis核心技术与实战" scheme="https://zhuansun.github.io/geekbang/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    
    
  </entry>
  
  <entry>
    <title>02 | 数据结构：快速的Redis有哪些慢操作？</title>
    <link href="https://zhuansun.github.io/geekbang/posts/741410782.html"/>
    <id>https://zhuansun.github.io/geekbang/posts/741410782.html</id>
    <published>2024-03-04T22:10:14.000Z</published>
    <updated>2024-03-21T07:44:22.340Z</updated>
    
    <content type="html"><![CDATA[<h1 id="02-数据结构：快速的Redis有哪些慢操作？"><a href="#02-数据结构：快速的Redis有哪些慢操作？" class="headerlink" title="02 | 数据结构：快速的Redis有哪些慢操作？"></a>02 | 数据结构：快速的Redis有哪些慢操作？</h1><p>你好，我是蒋德钧。</p><p>一提到Redis，我们的脑子里马上就会出现一个词：“快。”但是你有没有想过，Redis的快，到底是快在哪里呢？实际上，这里有一个重要的表现：它接收到一个键值对操作后，能以 <strong>微秒级别</strong> 的速度找到数据，并快速完成操作。</p><p>数据库这么多，为啥Redis能有这么突出的表现呢？一方面，这是因为它是内存数据库，所有操作都在内存上完成，内存的访问速度本身就很快。另一方面，这要归功于它的数据结构。这是因为，键值对是按一定的数据结构来组织的，操作键值对最终就是对数据结构进行增删改查操作，所以高效的数据结构是Redis快速处理数据的基础。这节课，我就来和你聊聊数据结构。</p><p>说到这儿，你肯定会说：“这个我知道，不就是String（字符串）、List（列表）、Hash（哈希）、Set（集合）和Sorted Set（有序集合）吗？”其实，这些只是Redis键值对中值的数据类型，也就是数据的保存形式。而这里，我们说的数据结构，是要去看看它们的底层实现。</p><p>简单来说，底层数据结构一共有6种，分别是简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组。它们和数据类型的对应关系如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/8219f7yy651e566d47cc9f661b399f01.jpg"></p><p>可以看到，String类型的底层实现只有一种数据结构，也就是简单动态字符串。而List、Hash、Set和Sorted Set这四种数据类型，都有两种底层实现结构。通常情况下，我们会把这四种类型称为集合类型，它们的特点是 <strong>一个键对应了一个集合的数据</strong>。</p><p>看到这里，其实有些问题已经值得我们去考虑了：</p><ul><li>这些数据结构都是值的底层实现，键和值本身之间用什么结构组织？</li><li>为什么集合类型有那么多的底层结构，它们都是怎么组织数据的，都很快吗？</li><li>什么是简单动态字符串，和常用的字符串是一回事吗？</li></ul><p>接下来，我就和你聊聊前两个问题。这样，你不仅可以知道Redis“快”的基本原理，还可以借此理解Redis中有哪些潜在的“慢操作”，最大化Redis的性能优势。而关于简单动态字符串，我会在后面的课程中再和你讨论。</p><p>我们先来看看键和值之间是用什么结构组织的。</p><h2 id="键和值用什么结构组织？"><a href="#键和值用什么结构组织？" class="headerlink" title="键和值用什么结构组织？"></a>键和值用什么结构组织？</h2><p>为了实现从键到值的快速访问，Redis使用了一个哈希表来保存所有键值对。</p><p>一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。所以，我们常说，一个哈希表是由多个哈希桶组成的，每个哈希桶中保存了键值对数据。</p><p>看到这里，你可能会问了：“如果值是集合类型的话，作为数组元素的哈希桶怎么来保存呢？”其实，哈希桶中的元素保存的并不是值本身，而是指向具体值的指针。这也就是说，不管值是String，还是集合类型，哈希桶中的元素都是指向它们的指针。</p><p>在下图中，可以看到，哈希桶中的entry元素中保存了 <code>*key</code> 和 <code>*value</code> 指针，分别指向了实际的键和值，这样一来，即使值是一个集合，也可以通过 <code>*value</code> 指针被查找到。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/1cc8eaed5d1ca4e3cdbaa5a3d48dfb5f.jpg"></p><p>因为这个哈希表保存了所有的键值对，所以，我也把它称为 <strong>全局哈希表</strong>。哈希表的最大好处很明显，就是让我们可以用O(1)的时间复杂度来快速查找到键值对——我们只需要计算键的哈希值，就可以知道它所对应的哈希桶位置，然后就可以访问相应的entry元素。</p><p>你看，这个查找过程主要依赖于哈希计算，和数据量的多少并没有直接关系。也就是说，不管哈希表里有10万个键还是100万个键，我们只需要一次计算就能找到相应的键。</p><p>但是，如果你只是了解了哈希表的O(1)复杂度和快速查找特性，那么，当你往Redis中写入大量数据后，就可能发现操作有时候会突然变慢了。这其实是因为你忽略了一个潜在的风险点，那就是 <strong>哈希表的冲突问题和rehash可能带来的操作阻塞。</strong></p><h3 id="为什么哈希表操作变慢了？"><a href="#为什么哈希表操作变慢了？" class="headerlink" title="为什么哈希表操作变慢了？"></a>为什么哈希表操作变慢了？</h3><p>当你往哈希表中写入更多数据时，哈希冲突是不可避免的问题。这里的哈希冲突，也就是指，两个key的哈希值和哈希桶计算对应关系时，正好落在了同一个哈希桶中。</p><p>毕竟，哈希桶的个数通常要少于key的数量，这也就是说，难免会有一些key的哈希值对应到了同一个哈希桶中。</p><p>Redis解决哈希冲突的方式，就是链式哈希。链式哈希也很容易理解，就是指 <strong>同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接</strong>。</p><p>如下图所示：entry1、entry2和entry3都需要保存在哈希桶3中，导致了哈希冲突。此时，entry1元素会通过一个 <code>*next</code> 指针指向entry2，同样，entry2也会通过 <code>*next</code> 指针指向entry3。这样一来，即使哈希桶3中的元素有100个，我们也可以通过entry元素中的指针，把它们连起来。这就形成了一个链表，也叫作哈希冲突链。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/8ac4cc6cf94968a502161f85d072e428.jpg"></p><p>但是，这里依然存在一个问题，哈希冲突链上的元素只能通过指针逐一查找再操作。如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低。对于追求“快”的Redis来说，这是不太能接受的。</p><p>所以，Redis会对哈希表做rehash操作。rehash也就是增加现有的哈希桶数量，让逐渐增多的entry元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。那具体怎么做呢？</p><p>其实，为了使rehash操作更高效，Redis默认使用了两个全局哈希表：哈希表1和哈希表2。一开始，当你刚插入数据时，默认使用哈希表1，此时的哈希表2并没有被分配空间。随着数据逐步增多，Redis开始执行rehash，这个过程分为三步：</p><ol><li>给哈希表2分配更大的空间，例如是当前哈希表1大小的两倍；</li><li>把哈希表1中的数据重新映射并拷贝到哈希表2中；</li><li>释放哈希表1的空间。</li></ol><p>到此，我们就可以从哈希表1切换到哈希表2，用增大的哈希表2保存更多数据，而原来的哈希表1留作下一次rehash扩容备用。</p><p>这个过程看似简单，但是第二步涉及大量的数据拷贝，如果一次性把哈希表1中的数据都迁移完，会造成Redis线程阻塞，无法服务其他请求。此时，Redis就无法快速访问数据了。</p><p>为了避免这个问题，Redis采用了 <strong>渐进式rehash</strong>。</p><p>简单来说就是在第二步拷贝数据时，Redis仍然正常处理客户端请求，每处理一个请求时，从哈希表1中的第一个索引位置开始，顺带着将这个索引位置上的所有entries拷贝到哈希表2中；等处理下一个请求时，再顺带拷贝哈希表1中的下一个索引位置的entries。如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/73fb212d0b0928d96a0d7d6ayy76da0c.jpg"></p><p>这样就巧妙地把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操作，保证了数据的快速访问。</p><p>好了，到这里，你应该就能理解，Redis的键和值是怎么通过哈希表组织的了。对于String类型来说，找到哈希桶就能直接增删改查了，所以，哈希表的O(1)操作复杂度也就是它的复杂度了。</p><p>但是，对于集合类型来说，即使找到哈希桶了，还要在集合中再进一步操作。接下来，我们来看集合类型的操作效率又是怎样的。</p><h2 id="集合数据操作效率"><a href="#集合数据操作效率" class="headerlink" title="集合数据操作效率"></a>集合数据操作效率</h2><p>和String类型不同，一个集合类型的值，第一步是通过全局哈希表找到对应的哈希桶位置，第二步是在集合中再增删改查。那么，集合的操作效率和哪些因素相关呢？</p><p>首先，与集合的底层数据结构有关。例如，使用哈希表实现的集合，要比使用链表实现的集合访问效率更高。其次，操作效率和这些操作本身的执行特点有关，比如读写一个元素的操作要比读写所有元素的效率高。</p><p>接下来，我们就分别聊聊集合类型的底层数据结构和操作复杂度。</p><h3 id="有哪些底层数据结构？"><a href="#有哪些底层数据结构？" class="headerlink" title="有哪些底层数据结构？"></a>有哪些底层数据结构？</h3><p>刚才，我也和你介绍过，集合类型的底层数据结构主要有5种：整数数组、双向链表、哈希表、压缩列表和跳表。</p><p>其中，哈希表的操作特点我们刚刚已经学过了；整数数组和双向链表也很常见，它们的操作特征都是顺序读写，也就是通过数组下标或者链表的指针逐个元素访问，操作复杂度基本是O(N)，操作效率比较低；压缩列表和跳表我们平时接触得可能不多，但它们也是Redis重要的数据结构，所以我来重点解释一下。</p><p>压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段zlbytes、zltail和zllen，分别表示列表长度、列表尾的偏移量和列表中的entry个数；压缩列表在表尾还有一个zlend，表示列表结束。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/9587e483f6ea82f560ff10484aaca4a0.jpg"></p><p>在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是O(N)了。</p><p>我们再来看下跳表。</p><p>有序链表只能逐一查找元素，导致操作起来非常缓慢，于是就出现了跳表。具体来说，跳表在链表的基础上， <strong>增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位</strong>，如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/1eca7135d38de2yy16681c2bbc4f3fb4.jpg"></p><p>如果我们要在链表中查找33这个元素，只能从头开始遍历链表，查找6次，直到找到33为止。此时，复杂度是O(N)，查找效率很低。</p><p>为了提高查找速度，我们来增加一级索引：从第一个元素开始，每两个元素选一个出来作为索引。这些索引再通过指针指向原始的链表。例如，从前两个元素中抽取元素1作为一级索引，从第三、四个元素中抽取元素11作为一级索引。此时，我们只需要4次查找就能定位到元素33了。</p><p>如果我们还想再快，可以再增加二级索引：从一级索引中，再抽取部分元素作为二级索引。例如，从一级索引中抽取1、27、100作为二级索引，二级索引指向一级索引。这样，我们只需要3次查找，就能定位到元素33了。</p><p>可以看到，这个查找过程就是在多级索引上跳来跳去，最后定位到元素。这也正好符合“跳”表的叫法。当数据量很大时，跳表的查找复杂度就是O(logN)。</p><p>好了，我们现在可以按照查找的时间复杂度给这些数据结构分下类了：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/fb7e3612ddee8a0ea49b7c40673a0cf0.jpg"></p><h3 id="不同操作的复杂度"><a href="#不同操作的复杂度" class="headerlink" title="不同操作的复杂度"></a>不同操作的复杂度</h3><p>集合类型的操作类型很多，有读写单个集合元素的，例如HGET、HSET，也有操作多个元素的，例如SADD，还有对整个集合进行遍历操作的，例如SMEMBERS。这么多操作，它们的复杂度也各不相同。而复杂度的高低又是我们选择集合类型的重要依据。</p><p>我总结了一个“四句口诀”，希望能帮助你快速记住集合常见操作的复杂度。这样你在使用过程中，就可以提前规避高复杂度操作了。</p><ul><li>单元素操作是基础；</li><li>范围操作非常耗时；</li><li>统计操作通常高效；</li><li>例外情况只有几个。</li></ul><p>第一， <strong>单元素操作，是指每一种集合类型对单个数据实现的增删改查操作</strong>。例如，Hash类型的HGET、HSET和HDEL，Set类型的SADD、SREM、SRANDMEMBER等。这些操作的复杂度由集合采用的数据结构决定，例如，HGET、HSET和HDEL是对哈希表做操作，所以它们的复杂度都是O(1)；Set类型用哈希表作为底层数据结构时，它的SADD、SREM、SRANDMEMBER复杂度也是O(1)。</p><p>这里，有个地方你需要注意一下，集合类型支持同时对多个元素进行增删改查，例如Hash类型的HMGET和HMSET，Set类型的SADD也支持同时增加多个元素。此时，这些操作的复杂度，就是由单个元素操作复杂度和元素个数决定的。例如，HMSET增加M个元素时，复杂度就从O(1)变成O(M)了。</p><p>第二， <strong>范围操作，是指集合类型中的遍历操作，可以返回集合中的所有数据</strong>，比如Hash类型的HGETALL和Set类型的SMEMBERS，或者返回一个范围内的部分数据，比如List类型的LRANGE和ZSet类型的ZRANGE。 <strong>这类操作的复杂度一般是O(N)，比较耗时，我们应该尽量避免</strong>。</p><p>不过，Redis从2.8版本开始提供了SCAN系列操作（包括HSCAN，SSCAN和ZSCAN），这类操作实现了渐进式遍历，每次只返回有限数量的数据。这样一来，相比于HGETALL、SMEMBERS这类操作来说，就避免了一次性返回所有元素而导致的Redis阻塞。</p><p>第三，统计操作，是指 <strong>集合类型对集合中所有元素个数的记录</strong>，例如LLEN和SCARD。这类操作复杂度只有O(1)，这是因为当集合类型采用压缩列表、双向链表、整数数组这些数据结构时，这些结构中专门记录了元素的个数统计，因此可以高效地完成相关操作。</p><p>第四，例外情况，是指某些数据结构的特殊记录，例如 <strong>压缩列表和双向链表都会记录表头和表尾的偏移量</strong>。这样一来，对于List类型的LPOP、RPOP、LPUSH、RPUSH这四个操作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂度也只有O(1)，可以实现快速操作。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这节课，我们学习了Redis的底层数据结构，这既包括了Redis中用来保存每个键和值的全局哈希表结构，也包括了支持集合类型实现的双向链表、压缩列表、整数数组、哈希表和跳表这五大底层结构。</p><p>Redis之所以能快速操作键值对，一方面是因为O(1)复杂度的哈希表被广泛使用，包括String、Hash和Set，它们的操作复杂度基本由哈希表决定，另一方面，Sorted Set也采用了O(logN)复杂度的跳表。不过，集合类型的范围操作，因为要遍历底层数据结构，复杂度通常是O(N)。这里，我的建议是： <strong>用其他命令来替代</strong>，例如可以用SCAN来代替，避免在Redis内部产生费时的全集合遍历操作。</p><p>当然，我们不能忘了复杂度较高的List类型，它的两种底层实现结构：双向链表和压缩列表的操作复杂度都是O(N)。因此，我的建议是： <strong>因地制宜地使用List类型</strong>。例如，既然它的POP&#x2F;PUSH效率很高，那么就将它主要用于FIFO队列场景，而不是作为一个可以随机读写的集合。</p><p>Redis数据类型丰富，每个类型的操作繁多，我们通常无法一下子记住所有操作的复杂度。所以，最好的办法就是 <strong>掌握原理，以不变应万变</strong>。这里，你可以看到，一旦掌握了数据结构基本原理，你可以从原理上推断不同操作的复杂度，即使这个操作你不一定熟悉。这样一来，你不用死记硬背，也能快速合理地做出选择了。</p><h2 id="每课一问"><a href="#每课一问" class="headerlink" title="每课一问"></a>每课一问</h2><p>整数数组和压缩列表在查找时间复杂度方面并没有很大的优势，那为什么Redis还会把它们作为底层数据结构呢？</p><p>数据结构是了解Redis性能的必修课，如果你身边还有不太清楚数据结构的朋友，欢迎你把今天的内容分享给他&#x2F;她，期待你在留言区和我交流讨论。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;02-数据结构：快速的Redis有哪些慢操作？&quot;&gt;&lt;a href=&quot;#02-数据结构：快速的Redis有哪些慢操作？&quot; class=&quot;headerlink&quot; title=&quot;02 | 数据结构：快速的Redis有哪些慢操作？&quot;&gt;&lt;/a&gt;02 | 数据结构：快速的Re</summary>
      
    
    
    
    <category term="Redis核心技术与实战" scheme="https://zhuansun.github.io/geekbang/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    
    
  </entry>
  
  <entry>
    <title>04 | AOF日志：宕机了，Redis如何避免数据丢失？</title>
    <link href="https://zhuansun.github.io/geekbang/posts/1099821369.html"/>
    <id>https://zhuansun.github.io/geekbang/posts/1099821369.html</id>
    <published>2024-03-04T22:10:14.000Z</published>
    <updated>2024-03-21T07:44:22.344Z</updated>
    
    <content type="html"><![CDATA[<h1 id="04-AOF日志：宕机了，Redis如何避免数据丢失？"><a href="#04-AOF日志：宕机了，Redis如何避免数据丢失？" class="headerlink" title="04 | AOF日志：宕机了，Redis如何避免数据丢失？"></a>04 | AOF日志：宕机了，Redis如何避免数据丢失？</h1><p>你好，我是蒋德钧。</p><p>如果有人问你：“你会把Redis用在什么业务场景下？”我想你大概率会说：“我会把它当作缓存使用，因为它把后端数据库中的数据存储在内存中，然后直接从内存中读取数据，响应速度会非常快。”没错，这确实是Redis的一个普遍使用场景，但是，这里也有一个绝对不能忽略的问题： <strong>一旦服务器宕机，内存中的数据将全部丢失。</strong></p><p>我们很容易想到的一个解决方案是，从后端数据库恢复这些数据，但这种方式存在两个问题：一是，需要频繁访问数据库，会给数据库带来巨大的压力；二是，这些数据是从慢速数据库中读取出来的，性能肯定比不上从Redis中读取，导致使用这些数据的应用程序响应变慢。所以，对Redis来说，实现数据的持久化，避免从后端数据库中进行恢复，是至关重要的。</p><p>目前，Redis的持久化主要有两大机制，即AOF（Append Only File）日志和RDB快照。在接下来的两节课里，我们就分别学习一下吧。这节课，我们先重点学习下AOF日志。</p><h2 id="AOF日志是如何实现的？"><a href="#AOF日志是如何实现的？" class="headerlink" title="AOF日志是如何实现的？"></a>AOF日志是如何实现的？</h2><p>说到日志，我们比较熟悉的是数据库的写前日志（Write Ahead Log, WAL），也就是说，在实际写数据前，先把修改的数据记到日志文件中，以便故障时进行恢复。不过，AOF日志正好相反，它是写后日志，“写后”的意思是Redis是先执行命令，把数据写入内存，然后才记录日志，如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/407f2686083afc37351cfd9107319a1f.jpg"></p><p>那AOF为什么要先执行命令再记日志呢？要回答这个问题，我们要先知道AOF里记录了什么内容。</p><p>传统数据库的日志，例如redo log（重做日志），记录的是修改后的数据，而AOF里记录的是Redis收到的每一条命令，这些命令是以文本形式保存的。</p><p>我们以Redis收到“set testkey testvalue”命令后记录的日志为例，看看AOF日志的内容。其中，“ <code>*3</code>”表示当前命令有三个部分，每部分都是由“ <code>$+数字</code>”开头，后面紧跟着具体的命令、键或值。这里，“数字”表示这部分中的命令、键或值一共有多少字节。例如，“ <code>$3 set</code>”表示这部分有3个字节，也就是“set”命令。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/4d120bee623642e75fdf1c0700623a9f.jpg"></p><p>但是，为了避免额外的检查开销，Redis在向AOF里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis在使用日志恢复数据时，就可能会出错。</p><p>而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中，否则，系统就会直接向客户端报错。所以，Redis使用写后日志这一方式的一大好处是，可以避免出现记录错误命令的情况。</p><p>除此之外，AOF还有一个好处：它是在命令执行后才记录日志，所以 <strong>不会阻塞当前的写操作</strong>。</p><p>不过，AOF也有两个潜在的风险。</p><p>首先，如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。如果此时Redis是用作缓存，还可以从后端数据库重新读入数据进行恢复，但是，如果Redis是直接用作数据库的话，此时，因为命令没有记入日志，所以就无法用日志进行恢复了。</p><p>其次，AOF虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因为，AOF日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。</p><p>仔细分析的话，你就会发现，这两个风险都是和AOF写回磁盘的时机相关的。这也就意味着，如果我们能够控制一个写命令执行完后AOF日志写回磁盘的时机，这两个风险就解除了。</p><h2 id="三种写回策略"><a href="#三种写回策略" class="headerlink" title="三种写回策略"></a>三种写回策略</h2><p>其实，对于这个问题，AOF机制给我们提供了三个选择，也就是AOF配置项appendfsync的三个可选值。</p><ul><li><strong>Always</strong>，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；</li><li><strong>Everysec</strong>，每秒写回：每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；</li><li><strong>No</strong>，操作系统控制的写回：每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。</li></ul><p>针对避免主线程阻塞和减少数据丢失问题，这三种写回策略都无法做到两全其美。我们来分析下其中的原因。</p><ul><li>“同步写回”可以做到基本不丢数据，但是它在每一个写命令后都有一个慢速的落盘操作，不可避免地会影响主线程性能；</li><li>虽然“操作系统控制的写回”在写完缓冲区后，就可以继续执行后续的命令，但是落盘的时机已经不在Redis手中了，只要AOF记录没有写回磁盘，一旦宕机对应的数据就丢失了；</li><li>“每秒写回”采用一秒写回一次的频率，避免了“同步写回”的性能开销，虽然减少了对系统性能的影响，但是如果发生宕机，上一秒内未落盘的命令操作仍然会丢失。所以，这只能算是，在避免影响主线程性能和避免数据丢失两者间取了个折中。</li></ul><p>我把这三种策略的写回时机，以及优缺点汇总在了一张表格里，以方便你随时查看。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/72f547f18dbac788c7d11yy167d7ebf8.jpg"></p><p>到这里，我们就可以根据系统对高性能和高可靠性的要求，来选择使用哪种写回策略了。总结一下就是：想要获得高性能，就选择No策略；如果想要得到高可靠性保证，就选择Always策略；如果允许数据有一点丢失，又希望性能别受太大影响的话，那么就选择Everysec策略。</p><p>但是，按照系统的性能需求选定了写回策略，并不是“高枕无忧”了。毕竟，AOF是以文件的形式在记录接收到的所有写命令。随着接收的写命令越来越多，AOF文件会越来越大。这也就意味着，我们一定要小心AOF文件过大带来的性能问题。</p><p>这里的“性能问题”，主要在于以下三个方面：一是，文件系统本身对文件大小有限制，无法保存过大的文件；二是，如果文件太大，之后再往里面追加命令记录的话，效率也会变低；三是，如果发生宕机，AOF中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到Redis的正常使用。</p><p>所以，我们就要采取一定的控制手段，这个时候， <strong>AOF重写机制</strong> 就登场了。</p><h2 id="日志文件太大了怎么办？"><a href="#日志文件太大了怎么办？" class="headerlink" title="日志文件太大了怎么办？"></a>日志文件太大了怎么办？</h2><p>简单来说，AOF重写机制就是在重写时，Redis根据数据库的现状创建一个新的AOF文件，也就是说，读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入。比如说，当读取了键值对“testkey”: “testvalue”之后，重写机制会记录set testkey testvalue这条命令。这样，当需要恢复时，可以重新执行该命令，实现“testkey”: “testvalue”的写入。</p><p>为什么重写机制可以把日志文件变小呢? 实际上，重写机制具有“多变一”功能。所谓的“多变一”，也就是说，旧日志文件中的多条命令，在重写后的新日志中变成了一条命令。</p><p>我们知道，AOF文件是以追加的方式，逐一记录接收到的写命令的。当一个键值对被多条写命令反复修改时，AOF文件会记录相应的多条命令。但是，在重写的时候，是根据这个键值对当前的最新状态，为它生成对应的写入命令。这样一来，一个键值对在重写日志中只用一条命令就行了，而且，在日志恢复时，只用执行这条命令，就可以直接完成这个键值对的写入了。</p><p>下面这张图就是一个例子：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/6528c699fdcf40b404af57040bb8d208.jpg"></p><p>当我们对一个列表先后做了6次修改操作后，列表的最后状态是[“D”, “C”, “N”]，此时，只用LPUSH u:list “N”, “C”, “D”这一条命令就能实现该数据的恢复，这就节省了五条命令的空间。对于被修改过成百上千次的键值对来说，重写能节省的空间当然就更大了。</p><p>不过，虽然AOF重写后，日志文件会缩小，但是，要把整个数据库的最新数据的操作日志都写回磁盘，仍然是一个非常耗时的过程。这时，我们就要继续关注另一个问题了：重写会不会阻塞主线程？</p><h2 id="AOF重写会阻塞吗"><a href="#AOF重写会阻塞吗" class="headerlink" title="AOF重写会阻塞吗?"></a>AOF重写会阻塞吗?</h2><p>和AOF日志由主线程写回不同，重写过程是由后台子进程bgrewriteaof来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。</p><p>我把重写的过程总结为“ <strong>一个拷贝，两处日志</strong>”。</p><p>“一个拷贝”就是指，每次执行重写时，主线程fork出后台的bgrewriteaof子进程。此时，fork会把主线程的内存拷贝一份给bgrewriteaof子进程，这里面就包含了数据库的最新数据。然后，bgrewriteaof子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。</p><p>“两处日志”又是什么呢？</p><p>因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，第一处日志就是指正在使用的AOF日志，Redis会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个AOF日志的操作仍然是齐全的，可以用于恢复。</p><p>而第二处日志，就是指新的AOF重写日志。这个操作也会被写到重写日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的AOF文件，以保证数据库最新状态的记录。此时，我们就可以用新的AOF文件替代旧文件了。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/6b054eb1aed0734bd81ddab9a31d0be8.jpg"></p><p>总结来说，每次AOF重写时，Redis会先执行一个内存拷贝，用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为Redis采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这节课，我向你介绍了Redis用于避免数据丢失的AOF方法。这个方法通过逐一记录操作命令，在恢复时再逐一执行命令的方式，保证了数据的可靠性。</p><p>这个方法看似“简单”，但也是充分考虑了对Redis性能的影响。总结来说，它提供了AOF日志的三种写回策略，分别是Always、Everysec和No，这三种策略在可靠性上是从高到低，而在性能上则是从低到高。</p><p>此外，为了避免日志文件过大，Redis还提供了AOF重写机制，直接根据数据库里数据的最新状态，生成这些数据的插入命令，作为新日志。这个过程通过后台线程完成，避免了对主线程的阻塞。</p><p>其中，三种写回策略体现了系统设计中的一个重要原则 ，即trade-off，或者称为“取舍”，指的就是在性能和可靠性保证之间做取舍。我认为，这是做系统设计和开发的一个关键哲学，我也非常希望，你能充分地理解这个原则，并在日常开发中加以应用。</p><p>不过，你可能也注意到了，落盘时机和重写机制都是在“记日志”这一过程中发挥作用的。例如，落盘时机的选择可以避免记日志时阻塞主线程，重写可以避免日志文件过大。但是，在“用日志”的过程中，也就是使用AOF进行故障恢复时，我们仍然需要把所有的操作记录都运行一遍。再加上Redis的单线程设计，这些命令操作只能一条一条按顺序执行，这个“重放”的过程就会很慢了。</p><p>那么，有没有既能避免数据丢失，又能更快地恢复的方法呢？当然有，那就是RDB快照了。下节课，我们就一起学习一下，敬请期待。</p><h2 id="每课一问"><a href="#每课一问" class="headerlink" title="每课一问"></a>每课一问</h2><p>这节课，我给你提两个小问题：</p><ol><li>AOF日志重写的时候，是由bgrewriteaof子进程来完成的，不用主线程参与，我们今天说的非阻塞也是指子进程的执行不阻塞主线程。但是，你觉得，这个重写过程有没有其他潜在的阻塞风险呢？如果有的话，会在哪里阻塞？</li><li>AOF重写也有一个重写日志，为什么它不共享使用AOF本身的日志呢？</li></ol><p>希望你能好好思考一下这两个问题，欢迎在留言区分享你的答案。另外，也欢迎你把这节课的内容转发出去，和更多的人一起交流讨论。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;04-AOF日志：宕机了，Redis如何避免数据丢失？&quot;&gt;&lt;a href=&quot;#04-AOF日志：宕机了，Redis如何避免数据丢失？&quot; class=&quot;headerlink&quot; title=&quot;04 | AOF日志：宕机了，Redis如何避免数据丢失？&quot;&gt;&lt;/a&gt;04 </summary>
      
    
    
    
    <category term="Redis核心技术与实战" scheme="https://zhuansun.github.io/geekbang/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    
    
  </entry>
  
  <entry>
    <title>05 | 内存快照：宕机后，Redis如何实现快速恢复？</title>
    <link href="https://zhuansun.github.io/geekbang/posts/3361679303.html"/>
    <id>https://zhuansun.github.io/geekbang/posts/3361679303.html</id>
    <published>2024-03-04T22:10:14.000Z</published>
    <updated>2024-03-21T07:44:22.345Z</updated>
    
    <content type="html"><![CDATA[<h1 id="05-内存快照：宕机后，Redis如何实现快速恢复？"><a href="#05-内存快照：宕机后，Redis如何实现快速恢复？" class="headerlink" title="05 | 内存快照：宕机后，Redis如何实现快速恢复？"></a>05 | 内存快照：宕机后，Redis如何实现快速恢复？</h1><p>你好，我是蒋德钧。</p><p>上节课，我们学习了Redis避免数据丢失的AOF方法。这个方法的好处，是每次执行只需要记录操作命令，需要持久化的数据量不大。一般而言，只要你采用的不是always的持久化策略，就不会对性能造成太大影响。</p><p>但是，也正因为记录的是操作命令，而不是实际的数据，所以，用AOF方法进行故障恢复的时候，需要逐一把操作日志都执行一遍。如果操作日志非常多，Redis就会恢复得很缓慢，影响到正常使用。这当然不是理想的结果。那么，还有没有既可以保证可靠性，还能在宕机时实现快速恢复的其他方法呢？</p><p>当然有了，这就是我们今天要一起学习的另一种持久化方法： <strong>内存快照</strong>。所谓内存快照，就是指内存中的数据在某一个时刻的状态记录。这就类似于照片，当你给朋友拍照时，一张照片就能把朋友一瞬间的形象完全记下来。</p><p>对Redis来说，它实现类似照片记录效果的方式，就是把某一时刻的状态以文件的形式写到磁盘上，也就是快照。这样一来，即使宕机，快照文件也不会丢失，数据的可靠性也就得到了保证。这个快照文件就称为RDB文件，其中，RDB就是Redis DataBase的缩写。</p><p>和AOF相比，RDB记录的是某一时刻的数据，并不是操作，所以，在做数据恢复时，我们可以直接把RDB文件读入内存，很快地完成恢复。听起来好像很不错，但内存快照也并不是最优选项。为什么这么说呢？</p><p>我们还要考虑两个关键问题：</p><ul><li>对哪些数据做快照？这关系到快照的执行效率问题；</li><li>做快照时，数据还能被增删改吗？这关系到Redis是否被阻塞，能否同时正常处理请求。</li></ul><p>这么说可能你还不太好理解，我还是拿拍照片来举例子。我们在拍照时，通常要关注两个问题：</p><ul><li>如何取景？也就是说，我们打算把哪些人、哪些物拍到照片中；</li><li>在按快门前，要记着提醒朋友不要乱动，否则拍出来的照片就模糊了。</li></ul><p>你看，这两个问题是不是非常重要呢？那么，接下来，我们就来具体地聊一聊。先说“取景”问题，也就是我们对哪些数据做快照。</p><h2 id="给哪些内存数据做快照？"><a href="#给哪些内存数据做快照？" class="headerlink" title="给哪些内存数据做快照？"></a>给哪些内存数据做快照？</h2><p>Redis的数据都在内存中，为了提供所有数据的可靠性保证，它执行的是 <strong>全量快照</strong>，也就是说，把内存中的所有数据都记录到磁盘中，这就类似于给100个人拍合影，把每一个人都拍进照片里。这样做的好处是，一次性记录了所有数据，一个都不少。</p><p>当你给一个人拍照时，只用协调一个人就够了，但是，拍100人的大合影，却需要协调100个人的位置、状态，等等，这当然会更费时费力。同样，给内存的全量数据做快照，把它们全部写入磁盘也会花费很多时间。而且，全量数据越多，RDB文件就越大，往磁盘上写数据的时间开销就越大。</p><p>对于Redis而言，它的单线程模型就决定了，我们要尽量避免所有会阻塞主线程的操作，所以，针对任何操作，我们都会提一个灵魂之问：“它会阻塞主线程吗?”RDB文件的生成是否会阻塞主线程，这就关系到是否会降低Redis的性能。</p><p>Redis提供了两个命令来生成RDB文件，分别是save和bgsave。</p><ul><li>save：在主线程中执行，会导致阻塞；</li><li>bgsave：创建一个子进程，专门用于写入RDB文件，避免了主线程的阻塞，这也是Redis RDB文件生成的默认配置。</li></ul><p>好了，这个时候，我们就可以通过bgsave命令来执行全量快照，这既提供了数据的可靠性保证，也避免了对Redis的性能影响。</p><p>接下来，我们要关注的问题就是，在对内存数据做快照时，这些数据还能“动”吗? 也就是说，这些数据还能被修改吗？ 这个问题非常重要，这是因为，如果数据能被修改，那就意味着Redis还能正常处理写操作。否则，所有写操作都得等到快照完了才能执行，性能一下子就降低了。</p><h2 id="快照时数据能修改吗"><a href="#快照时数据能修改吗" class="headerlink" title="快照时数据能修改吗?"></a>快照时数据能修改吗?</h2><p>在给别人拍照时，一旦对方动了，那么这张照片就拍糊了，我们就需要重拍，所以我们当然希望对方保持不动。对于内存快照而言，我们也不希望数据“动”。</p><p>举个例子。我们在时刻t给内存做快照，假设内存数据量是4GB，磁盘的写入带宽是0.2GB&#x2F;s，简单来说，至少需要20s（4&#x2F;0.2 &#x3D; 20）才能做完。如果在时刻t+5s时，一个还没有被写入磁盘的内存数据A，被修改成了A’，那么就会破坏快照的完整性，因为A’不是时刻t时的状态。因此，和拍照类似，我们在做快照时也不希望数据“动”，也就是不能被修改。</p><p>但是，如果快照执行期间数据不能被修改，是会有潜在问题的。对于刚刚的例子来说，在做快照的20s时间里，如果这4GB的数据都不能被修改，Redis就不能处理对这些数据的写操作，那无疑就会给业务服务造成巨大的影响。</p><p>你可能会想到，可以用bgsave避免阻塞啊。这里我就要说到一个常见的误区了， <strong>避免阻塞和正常处理写操作并不是一回事</strong>。此时，主线程的确没有阻塞，可以正常接收请求，但是，为了保证快照完整性，它只能处理读操作，因为不能修改正在执行快照的数据。</p><p>为了快照而暂停写操作，肯定是不能接受的。所以这个时候，Redis就会借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。</p><p>简单来说，bgsave子进程是由主线程fork生成的，可以共享主线程的所有内存数据。bgsave子进程运行后，开始读取主线程的内存数据，并把它们写入RDB文件。</p><p>此时，如果主线程对这些数据也都是读操作（例如图中的键值对A），那么，主线程和bgsave子进程相互不影响。但是，如果主线程要修改一块数据（例如图中的键值对C），那么，这块数据就会被复制一份，生成该数据的副本（键值对C’）。然后，主线程在这个数据副本上进行修改。同时，bgsave子进程可以继续把原来的数据（键值对C）写入RDB文件。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/a2e5a3571e200cb771ed8a1cd14d5558.jpg"></p><p>这既保证了快照的完整性，也允许主线程同时对数据进行修改，避免了对正常业务的影响。</p><p>到这里，我们就解决了对“哪些数据做快照”以及“做快照时数据能否修改”这两大问题：Redis会使用bgsave对当前内存中的所有数据做快照，这个操作是子进程在后台完成的，这就允许主线程同时可以修改数据。</p><p>现在，我们再来看另一个问题：多久做一次快照？我们在拍照的时候，还有项技术叫“连拍”，可以记录人或物连续多个瞬间的状态。那么，快照也适合“连拍”吗？</p><h2 id="可以每秒做一次快照吗？"><a href="#可以每秒做一次快照吗？" class="headerlink" title="可以每秒做一次快照吗？"></a>可以每秒做一次快照吗？</h2><p>对于快照来说，所谓“连拍”就是指连续地做快照。这样一来，快照的间隔时间变得很短，即使某一时刻发生宕机了，因为上一时刻快照刚执行，丢失的数据也不会太多。但是，这其中的快照间隔时间就很关键了。</p><p>如下图所示，我们先在T0时刻做了一次快照，然后又在T0+t时刻做了一次快照，在这期间，数据块5和9被修改了。如果在t这段时间内，机器宕机了，那么，只能按照T0时刻的快照进行恢复。此时，数据块5和9的修改值因为没有快照记录，就无法恢复了。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/711c873a61bafde79b25c110735289ab.jpg"></p><p>所以，要想尽可能恢复数据，t值就要尽可能小，t越小，就越像“连拍”。那么，t值可以小到什么程度呢，比如说是不是可以每秒做一次快照？毕竟，每次快照都是由bgsave子进程在后台执行，也不会阻塞主线程。</p><p>这种想法其实是错误的。虽然bgsave执行时不阻塞主线程，但是， <strong>如果频繁地执行全量快照，也会带来两方面的开销</strong>。</p><p>一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。</p><p>另一方面，bgsave子进程需要通过fork操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁fork出bgsave子进程，这就会频繁阻塞主线程了（所以，在Redis中如果有一个bgsave在运行，就不会再启动第二个bgsave子进程）。那么，有什么其他好方法吗？</p><p>此时，我们可以做增量快照，所谓增量快照，就是指，做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。</p><p>在第一次做完全量快照后，T1和T2时刻如果再做快照，我们只需要将被修改的数据写入快照文件就行。但是，这么做的前提是， <strong>我们需要记住哪些数据被修改了</strong>。你可不要小瞧这个“记住”功能，它需要我们使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的空间开销问题。如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/8a1d515269cd23595ee1813e8dff28a5.jpg"></p><p>如果我们对每一个键值对的修改，都做个记录，那么，如果有1万个被修改的键值对，我们就需要有1万条额外的记录。而且，有的时候，键值对非常小，比如只有32字节，而记录它被修改的元数据信息，可能就需要8字节，这样的画，为了“记住”修改，引入的额外空间开销比较大。这对于内存资源宝贵的Redis来说，有些得不偿失。</p><p>到这里，你可以发现，虽然跟AOF相比，快照的恢复速度快，但是，快照的频率不好把握，如果频率太低，两次快照间一旦宕机，就可能有比较多的数据丢失。如果频率太高，又会产生额外开销，那么，还有什么方法既能利用RDB的快速恢复，又能以较小的开销做到尽量少丢数据呢？</p><p>Redis 4.0中提出了一个 <strong>混合使用AOF日志和内存快照</strong> 的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用AOF日志记录这期间的所有命令操作。</p><p>这样一来，快照不用很频繁地执行，这就避免了频繁fork对主线程的影响。而且，AOF日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。</p><p>如下图所示，T1和T2时刻的修改，用AOF日志记录，等到第二次做全量快照时，就可以清空AOF日志，因为此时的修改都已经记录到快照中了，恢复时就不再用日志了。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/e4c5846616c19fe03dbf528437beb320.jpg"></p><p>这个方法既能享受到RDB文件快速恢复的好处，又能享受到AOF只记录操作命令的简单优势，颇有点“鱼和熊掌可以兼得”的感觉，建议你在实践中用起来。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这节课，我们学习了Redis用于避免数据丢失的内存快照方法。这个方法的优势在于，可以快速恢复数据库，也就是只需要把RDB文件直接读入内存，这就避免了AOF需要顺序、逐一重新执行操作命令带来的低效性能问题。</p><p>不过，内存快照也有它的局限性。它拍的是一张内存的“大合影”，不可避免地会耗时耗力。虽然，Redis设计了bgsave和写时复制方式，尽可能减少了内存快照对正常读写的影响，但是，频繁快照仍然是不太能接受的。而混合使用RDB和AOF，正好可以取两者之长，避两者之短，以较小的性能开销保证数据可靠性和性能。</p><p>最后，关于AOF和RDB的选择问题，我想再给你提三点建议：</p><ul><li>数据不能丢失时，内存快照和AOF的混合使用是一个很好的选择；</li><li>如果允许分钟级别的数据丢失，可以只使用RDB；</li><li>如果只用AOF，优先使用everysec的配置选项，因为它在可靠性和性能之间取了一个平衡。</li></ul><h2 id="每课一问"><a href="#每课一问" class="headerlink" title="每课一问"></a>每课一问</h2><p>我曾碰到过这么一个场景：我们使用一个2核CPU、4GB内存、500GB磁盘的云主机运行Redis，Redis数据库的数据量大小差不多是2GB，我们使用了RDB做持久化保证。当时Redis的运行负载以修改操作为主，写读比例差不多在8:2左右，也就是说，如果有100个请求，80个请求执行的是修改操作。你觉得，在这个场景下，用RDB做持久化有什么风险吗？你能帮着一起分析分析吗？</p><p>到这里，关于持久化我们就讲完了，这块儿内容是熟练掌握Redis的基础，建议你一定好好学习下这两节课。如果你觉得有收获，希望你能帮我分享给更多的人，帮助更多人解决持久化的问题。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;05-内存快照：宕机后，Redis如何实现快速恢复？&quot;&gt;&lt;a href=&quot;#05-内存快照：宕机后，Redis如何实现快速恢复？&quot; class=&quot;headerlink&quot; title=&quot;05 | 内存快照：宕机后，Redis如何实现快速恢复？&quot;&gt;&lt;/a&gt;05 | 内</summary>
      
    
    
    
    <category term="Redis核心技术与实战" scheme="https://zhuansun.github.io/geekbang/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    
    
  </entry>
  
  <entry>
    <title>07 | 哨兵机制：主库挂了，如何不间断服务？</title>
    <link href="https://zhuansun.github.io/geekbang/posts/3323054262.html"/>
    <id>https://zhuansun.github.io/geekbang/posts/3323054262.html</id>
    <published>2024-03-04T22:10:14.000Z</published>
    <updated>2024-03-21T07:44:22.349Z</updated>
    
    <content type="html"><![CDATA[<h1 id="07-哨兵机制：主库挂了，如何不间断服务？"><a href="#07-哨兵机制：主库挂了，如何不间断服务？" class="headerlink" title="07 | 哨兵机制：主库挂了，如何不间断服务？"></a>07 | 哨兵机制：主库挂了，如何不间断服务？</h1><p>你好，我是蒋德钧。</p><p>上节课，我们学习了主从库集群模式。在这个模式下，如果从库发生故障了，客户端可以继续向主库或其他从库发送请求，进行相关的操作，但是如果主库发生故障了，那就直接会影响到从库的同步，因为从库没有相应的主库可以进行数据复制操作了。</p><p>而且，如果客户端发送的都是读操作请求，那还可以由从库继续提供服务，这在纯读的业务场景下还能被接受。但是，一旦有写操作请求了，按照主从库模式下的读写分离要求，需要由主库来完成写操作。此时，也没有实例可以来服务客户端的写操作请求了，如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/d828d7eee133cec690dc140e99e26f20.jpg"></p><p>无论是写服务中断，还是从库无法进行数据同步，都是不能接受的。所以，如果主库挂了，我们就需要运行一个新主库，比如说把一个从库切换为主库，把它当成主库。这就涉及到三个问题：</p><ol><li>主库真的挂了吗？</li><li>该选择哪个从库作为主库？</li><li>怎么把新主库的相关信息通知给从库和客户端呢？</li></ol><p>这就要提到哨兵机制了。在Redis主从集群中，哨兵机制是实现主从库自动切换的关键机制，它有效地解决了主从复制模式下故障转移的这三个问题。</p><p>接下来，我们就一起学习下哨兵机制。</p><h2 id="哨兵机制的基本流程"><a href="#哨兵机制的基本流程" class="headerlink" title="哨兵机制的基本流程"></a>哨兵机制的基本流程</h2><p>哨兵其实就是一个运行在特殊模式下的Redis进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。</p><p>我们先看监控。监控是指哨兵进程在运行时，周期性地给所有的主从库发送PING命令，检测它们是否仍然在线运行。如果从库没有在规定时间内响应哨兵的PING命令，哨兵就会把它标记为“下线状态”；同样，如果主库也没有在规定时间内响应哨兵的PING命令，哨兵就会判定主库下线，然后开始 <strong>自动切换主库</strong> 的流程。</p><p>这个流程首先是执行哨兵的第二个任务，选主。主库挂了以后，哨兵就需要从很多个从库里，按照一定的规则选择一个从库实例，把它作为新的主库。这一步完成后，现在的集群里就有了新主库。</p><p>然后，哨兵会执行最后一个任务：通知。在执行通知任务时，哨兵会把新主库的连接信息发给其他从库，让它们执行replicaof命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。</p><p>我画了一张图片，展示了这三个任务以及它们各自的目标。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/efcfa517d0f09d057be7da32a84cf2a1.jpg"></p><p>在这三个任务中，通知任务相对来说比较简单，哨兵只需要把新主库信息发给从库和客户端，让它们和新主库建立连接就行，并不涉及决策的逻辑。但是，在监控和选主这两个任务中，哨兵需要做出两个决策：</p><ul><li>在监控任务中，哨兵需要判断主库是否处于下线状态；</li><li>在选主任务中，哨兵也要决定选择哪个从库实例作为主库。</li></ul><p>接下来，我们就先说说如何判断主库的下线状态。</p><p>你首先要知道的是，哨兵对主库的下线判断有“主观下线”和“客观下线”两种。那么，为什么会存在两种判断呢？它们的区别和联系是什么呢？</p><h2 id="主观下线和客观下线"><a href="#主观下线和客观下线" class="headerlink" title="主观下线和客观下线"></a>主观下线和客观下线</h2><p>我先解释下什么是“主观下线”。</p><p><strong>哨兵进程会使用PING命令检测它自己和主、从库的网络连接情况，用来判断实例的状态</strong>。如果哨兵发现主库或从库对PING命令的响应超时了，那么，哨兵就会先把它标记为“主观下线”。</p><p>如果检测的是从库，那么，哨兵简单地把它标记为“主观下线”就行了，因为从库的下线影响一般不太大，集群的对外服务不会间断。</p><p>但是，如果检测的是主库，那么，哨兵还不能简单地把它标记为“主观下线”，开启主从切换。因为很有可能存在这么一个情况：那就是哨兵误判了，其实主库并没有故障。可是，一旦启动了主从切换，后续的选主和通知操作都会带来额外的计算和通信开销。</p><p>为了避免这些不必要的开销，我们要特别注意误判的情况。</p><p>首先，我们要知道啥叫误判。很简单，就是主库实际并没有下线，但是哨兵误以为它下线了。误判一般会发生在集群网络压力较大、网络拥塞，或者是主库本身压力较大的情况下。</p><p>一旦哨兵判断主库下线了，就会开始选择新主库，并让从库和新主库进行数据同步，这个过程本身就会有开销，例如，哨兵要花时间选出新主库，从库也需要花时间和新主库同步。而在误判的情况下，主库本身根本就不需要进行切换的，所以这个过程的开销是没有价值的。正因为这样，我们需要判断是否有误判，以及减少误判。</p><p>那怎么减少误判呢？在日常生活中，当我们要对一些重要的事情做判断的时候，经常会和家人或朋友一起商量一下，然后再做决定。</p><p>哨兵机制也是类似的，它 <strong>通常会采用多实例组成的集群模式进行部署，这也被称为哨兵集群</strong>。引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。</p><p>这节课，你只需要先理解哨兵集群在减少误判方面的作用，就行了。至于具体的运行机制，下节课我们再重点学习。</p><p>在判断主库是否下线时，不能由一个哨兵说了算，只有大多数的哨兵实例，都判断主库已经“主观下线”了，主库才会被标记为“客观下线”，这个叫法也是表明主库下线成为一个客观事实了。这个判断原则就是：少数服从多数。同时，这会进一步触发哨兵开始主从切换流程。</p><p>为了方便你理解，我再画一张图展示一下这里的逻辑。</p><p>如下图所示，Redis主从集群有一个主库、三个从库，还有三个哨兵实例。在图片的左边，哨兵2判断主库为“主观下线”，但哨兵1和3却判定主库是上线状态，此时，主库仍然被判断为处于上线状态。在图片的右边，哨兵1和2都判断主库为“主观下线”，此时，即使哨兵3仍然判断主库为上线状态，主库也被标记为“客观下线”了。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/1945703abf16ee14e2f7559873e4e60d.jpg"></p><p>简单来说，“客观下线”的标准就是，当有N个哨兵实例时，最好要有N&#x2F;2 + 1个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。这样一来，就可以减少误判的概率，也能避免误判带来的无谓的主从库切换。（当然，有多少个实例做出“主观下线”的判断才可以，可以由Redis管理员自行设定）。</p><p>好了，到这里，你可以看到，借助于多个哨兵实例的共同判断机制，我们就可以更准确地判断出主库是否处于下线状态。如果主库的确下线了，哨兵就要开始下一个决策过程了，即从许多从库中，选出一个从库来做新主库。</p><h2 id="如何选定新主库？"><a href="#如何选定新主库？" class="headerlink" title="如何选定新主库？"></a>如何选定新主库？</h2><p>一般来说，我把哨兵选择新主库的过程称为“筛选+打分”。简单来说，我们在多个从库中，先按照 <strong>一定的筛选条件</strong>，把不符合条件的从库去掉。然后，我们再按照 <strong>一定的规则</strong>，给剩下的从库逐个打分，将得分最高的从库选为新主库，如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/f2e9b8830db46d959daa6a39fbf4a14c.jpg"></p><p>在刚刚的这段话里，需要注意的是两个“一定”，现在，我们要考虑这里的“一定”具体是指什么。</p><p>首先来看筛选的条件。</p><p>一般情况下，我们肯定要先保证所选的从库仍然在线运行。不过，在选主时从库正常在线，这只能表示从库的现状良好，并不代表它就是最适合做主库的。</p><p>设想一下，如果在选主时，一个从库正常运行，我们把它选为新主库开始使用了。可是，很快它的网络出了故障，此时，我们就得重新选主了。这显然不是我们期望的结果。</p><p>所以，在选主时， <strong>除了要检查从库的当前在线状态，还要判断它之前的网络连接状态</strong>。如果从库总是和主库断连，而且断连次数超出了一定的阈值，我们就有理由相信，这个从库的网络状况并不是太好，就可以把这个从库筛掉了。</p><p>具体怎么判断呢？你使用配置项down-after-milliseconds * 10。其中，down-after-milliseconds是我们认定主从库断连的最大连接超时时间。如果在down-after-milliseconds毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了。如果发生断连的次数超过了10次，就说明这个从库的网络状况不好，不适合作为新主库。</p><p>好了，这样我们就过滤掉了不适合做主库的从库，完成了筛选工作。</p><p>接下来就要给剩余的从库打分了。我们可以分别按照三个规则依次进行三轮打分，这三个规则分别是 <strong>从库优先级、从库复制进度以及从库ID号</strong>。只要在某一轮中，有从库得分最高，那么它就是主库了，选主过程到此结束。如果没有出现得分最高的从库，那么就继续进行下一轮。</p><p><strong>第一轮：优先级最高的从库得分高。</strong></p><p>用户可以通过slave-priority配置项，给不同的从库设置不同优先级。比如，你有两个从库，它们的内存大小不一样，你可以手动给内存大的实例设置一个高优先级。在选主时，哨兵会给优先级高的从库打高分，如果有一个从库优先级最高，那么它就是新主库了。如果从库的优先级都一样，那么哨兵开始第二轮打分。</p><p><strong>第二轮：和旧主库同步程度最接近的从库得分高。</strong></p><p>这个规则的依据是，如果选择和旧主库同步最接近的那个从库作为主库，那么，这个新主库上就有最新的数据。</p><p>如何判断从库和旧主库间的同步进度呢？</p><p>上节课我向你介绍过，主从库同步时有个命令传播的过程。在这个过程中，主库会用master_repl_offset记录当前的最新写操作在repl_backlog_buffer中的位置，而从库会用slave_repl_offset这个值记录当前的复制进度。</p><p>此时，我们想要找的从库，它的slave_repl_offset需要最接近master_repl_offset。如果在所有从库中，有从库的slave_repl_offset最接近master_repl_offset，那么它的得分就最高，可以作为新主库。</p><p>就像下图所示，旧主库的master_repl_offset是1000，从库1、2和3的slave_repl_offset分别是950、990和900，那么，从库2就应该被选为新主库。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/626yy88853a2d15b5196b922367140df.jpg"></p><p>当然，如果有两个从库的slave_repl_offset值大小是一样的（例如，从库1和从库2的slave_repl_offset值都是990），我们就需要给它们进行第三轮打分了。</p><p><strong>第三轮：ID号小的从库得分高。</strong></p><p>每个实例都会有一个ID，这个ID就类似于这里的从库的编号。目前，Redis在选主库时，有一个默认的规定： <strong>在优先级和复制进度都相同的情况下，ID号最小的从库得分最高，会被选为新主库</strong>。</p><p>到这里，新主库就被选出来了，“选主”这个过程就完成了。</p><p>我们再回顾下这个流程。首先，哨兵会按照在线状态、网络状态，筛选过滤掉一部分不符合要求的从库，然后，依次按照优先级、复制进度、ID号大小再对剩余的从库进行打分，只要有得分最高的从库出现，就把它选为新主库。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这节课，我们一起学习了哨兵机制，它是实现Redis不间断服务的重要保证。具体来说，主从集群的数据同步，是数据可靠的基础保证；而在主库发生故障时，自动的主从切换是服务不间断的关键支撑。</p><p>Redis的哨兵机制自动完成了以下三大功能，从而实现了主从库的自动切换，可以降低Redis集群的运维开销：</p><ul><li>监控主库运行状态，并判断主库是否客观下线；</li><li>在主库客观下线后，选取新主库；</li><li>选出新主库后，通知从库和客户端。</li></ul><p>为了降低误判率，在实际应用时，哨兵机制通常采用多实例的方式进行部署，多个哨兵实例通过“少数服从多数”的原则，来判断主库是否客观下线。一般来说，我们可以部署三个哨兵，如果有两个哨兵认定主库“主观下线”，就可以开始切换过程。当然，如果你希望进一步提升判断准确率，也可以再适当增加哨兵个数，比如说使用五个哨兵。</p><p>但是，使用多个哨兵实例来降低误判率，其实相当于组成了一个哨兵集群，我们会因此面临着一些新的挑战，例如：</p><ul><li>哨兵集群中有实例挂了，怎么办，会影响主库状态判断和选主吗？</li><li>哨兵集群多数实例达成共识，判断出主库“客观下线”后，由哪个实例来执行主从切换呢？</li></ul><p>要搞懂这些问题，就不得不提哨兵集群了，下节课，我们来具体聊聊哨兵集群的机制和问题。</p><h2 id="每课一问"><a href="#每课一问" class="headerlink" title="每课一问"></a>每课一问</h2><p>按照惯例，我给你提个小问题。这节课，我提到，通过哨兵机制，可以实现主从库的自动切换，这是实现服务不间断的关键支撑，同时，我也提到了主从库切换是需要一定时间的。所以，请你考虑下，在这个切换过程中，客户端能否正常地进行请求操作呢？如果想要应用程序不感知服务的中断，还需要哨兵或需要客户端再做些什么吗？</p><p>欢迎你在留言区跟我交流讨论，也欢迎你能帮我把今天的内容分享给更多人，帮助他们一起解决问题。我们下节课见。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;07-哨兵机制：主库挂了，如何不间断服务？&quot;&gt;&lt;a href=&quot;#07-哨兵机制：主库挂了，如何不间断服务？&quot; class=&quot;headerlink&quot; title=&quot;07 | 哨兵机制：主库挂了，如何不间断服务？&quot;&gt;&lt;/a&gt;07 | 哨兵机制：主库挂了，如何不间断服</summary>
      
    
    
    
    <category term="Redis核心技术与实战" scheme="https://zhuansun.github.io/geekbang/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    
    
  </entry>
  
  <entry>
    <title>10 | 第1～9讲课后思考题答案及常见问题答疑</title>
    <link href="https://zhuansun.github.io/geekbang/posts/3719796141.html"/>
    <id>https://zhuansun.github.io/geekbang/posts/3719796141.html</id>
    <published>2024-03-04T22:10:14.000Z</published>
    <updated>2024-03-21T07:44:22.354Z</updated>
    
    <content type="html"><![CDATA[<h1 id="10-第1～9讲课后思考题答案及常见问题答疑"><a href="#10-第1～9讲课后思考题答案及常见问题答疑" class="headerlink" title="10 | 第1～9讲课后思考题答案及常见问题答疑"></a>10 | 第1～9讲课后思考题答案及常见问题答疑</h1><p>你好，我是蒋德钧。</p><p>咱们的课程已经更新9讲了，这段时间，我收到了很多留言。很多同学都认真地回答了课后思考题，有些回答甚至可以说是标准答案。另外，还有很多同学针对Redis的基本原理和关键机制，提出了非常好的问题，值得好好讨论一下。</p><p>今天，我就和你聊一聊课后题答案，并且挑选一些典型问题，集中进行一次讲解，希望可以解决你的困惑。</p><h2 id="课后思考题答案"><a href="#课后思考题答案" class="headerlink" title="课后思考题答案"></a>课后思考题答案</h2><h3 id="第1讲"><a href="#第1讲" class="headerlink" title="第1讲"></a><a href="https://time.geekbang.org/column/article/268262">第1讲</a></h3><p><strong>问题：和跟Redis相比，SimpleKV还缺少什么？</strong></p><p>@曾轼麟、@Kaito 同学给出的答案都非常棒。他们从数据结构到功能扩展，从内存效率到事务性，从高可用集群再到高可扩展集群，对SimpleKV和Redis进行了详细的对比。而且，他们还从运维使用的角度进行了分析。我先分享一下两位同学的答案。</p><p>@曾轼麟同学：</p><blockquote><ol><li>数据结构：缺乏广泛的数据结构支持，比如支持范围查询的SkipList和Stream等数据结构。</li><li>高可用：缺乏哨兵或者master-slave模式的高可用设计；</li><li>横向扩展：缺乏集群和分片功能；</li><li>内存安全性：缺乏内存过载时的key淘汰算法的支持；</li><li>内存利用率：没有充分对数据结构进行优化，提高内存利用率，例如使用压缩性的数据结构；</li><li>功能扩展：需要具备后续功能的拓展；</li><li>不具备事务性：无法保证多个操作的原子性。</li></ol></blockquote><p>@Kaito同学：</p><blockquote><p>SimpleKV所缺少的有：丰富的数据类型、支持数据压缩、过期机制、数据淘汰策略、主从复制、集群化、高可用集群等，另外，还可以增加统计模块、通知模块、调试模块、元数据查询等辅助功能。</p></blockquote><p>我也给个答案总结。还记得我在 <a href="https://time.geekbang.org/column/article/268247">开篇词</a> 讲过的“两大维度”“三大主线”吗？这里我们也可以借助这个框架进行分析，如下表所示。此外，在表格最后，我还从键值数据库开发和运维的辅助工具上，对SimpleKV和Redis做了对比。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/67e77bea2568a4f0997c1853d9c60036.jpg"></p><h3 id="第2讲"><a href="#第2讲" class="headerlink" title="第2讲"></a><a href="https://time.geekbang.org/column/article/268253">第2讲</a></h3><p><strong>问题：整数数组和压缩列表作为底层数据结构的优势是什么？</strong></p><p>整数数组和压缩列表的设计，充分体现了Redis“又快又省”特点中的“省”，也就是节省内存空间。整数数组和压缩列表都是在内存中分配一块地址连续的空间，然后把集合中的元素一个接一个地放在这块空间内，非常紧凑。因为元素是挨个连续放置的，我们不用再通过额外的指针把元素串接起来，这就避免了额外指针带来的空间开销。</p><p>我画一张图，展示下这两个结构的内存布局。整数数组和压缩列表中的entry都是实际的集合元素，它们一个挨一个保存，非常节省内存空间。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/2c57cc1c548a0733bd1bf09f397f342a.jpg"></p><p>Redis之所以采用不同的数据结构，其实是在性能和内存使用效率之间进行的平衡。</p><h3 id="第3讲"><a href="#第3讲" class="headerlink" title="第3讲"></a><a href="https://time.geekbang.org/column/article/270474">第3讲</a></h3><p><strong>问题：Redis基本IO模型中还有哪些潜在的性能瓶颈？</strong></p><p>这个问题是希望你能进一步理解阻塞操作对Redis单线程性能的影响。在Redis基本IO模型中，主要是主线程在执行操作，任何耗时的操作，例如bigkey、全量返回等操作，都是潜在的性能瓶颈。</p><h3 id="第4讲"><a href="#第4讲" class="headerlink" title="第4讲"></a><a href="https://time.geekbang.org/column/article/271754">第4讲</a></h3><p><strong>问题1：AOF重写过程中有没有其他潜在的阻塞风险？</strong></p><p>这里有两个风险。</p><p>风险一：Redis主线程fork创建bgrewriteaof子进程时，内核需要创建用于管理子进程的相关数据结构，这些数据结构在操作系统中通常叫作进程控制块（Process Control Block，简称为PCB）。内核要把主线程的PCB内容拷贝给子进程。这个创建和拷贝过程由内核执行，是会阻塞主线程的。而且，在拷贝过程中，子进程要拷贝父进程的页表，这个过程的耗时和Redis实例的内存大小有关。如果Redis实例内存大，页表就会大，fork执行时间就会长，这就会给主线程带来阻塞风险。</p><p>风险二：bgrewriteaof子进程会和主线程共享内存。当主线程收到新写或修改的操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作的是bigkey，也就是数据量大的集合类型数据，那么，主线程会因为申请大空间而面临阻塞风险。因为操作系统在分配内存空间时，有查找和锁的开销，这就会导致阻塞。</p><p><strong>问题2：AOF 重写为什么不共享使用 AOF 本身的日志？</strong></p><p>如果都用AOF日志的话，主线程要写，bgrewriteaof子进程也要写，这两者会竞争文件系统的锁，这就会对Redis主线程的性能造成影响。</p><h3 id="第5讲"><a href="#第5讲" class="headerlink" title="第5讲"></a><a href="https://time.geekbang.org/column/article/271839">第5讲</a></h3><p>问题：使用一个 2 核 CPU、4GB 内存、500GB 磁盘的云主机运行 Redis，Redis 数据库的数据量大小差不多是 2GB。当时 Redis主要以修改操作为主，写读比例差不多在 8:2 左右，也就是说，如果有 100 个请求，80 个请求执行的是修改操作。在这个场景下，用 RDB 做持久化有什么风险吗？</p><p>@Kaito同学的回答从内存资源和CPU资源两方面分析了风险，非常棒。我稍微做了些完善和精简，你可以参考一下。</p><p><strong>内存不足的风险</strong>：Redis fork一个bgsave子进程进行RDB写入，如果主线程再接收到写操作，就会采用写时复制。写时复制需要给写操作的数据分配新的内存空间。本问题中写的比例为80%，那么，在持久化过程中，为了保存80%写操作涉及的数据，写时复制机制会在实例内存中，为这些数据再分配新内存空间，分配的内存量相当于整个实例数据量的80%，大约是1.6GB，这样一来，整个系统内存的使用量就接近饱和了。此时，如果实例还有大量的新key写入或key修改，云主机内存很快就会被吃光。如果云主机开启了Swap机制，就会有一部分数据被换到磁盘上，当访问磁盘上的这部分数据时，性能会急剧下降。如果云主机没有开启Swap，会直接触发OOM，整个Redis实例会面临被系统kill掉的风险。</p><p><strong>主线程和子进程竞争使用CPU的风险</strong>：生成RDB的子进程需要CPU核运行，主线程本身也需要CPU核运行，而且，如果Redis还启用了后台线程，此时，主线程、子进程和后台线程都会竞争CPU资源。由于云主机只有2核CPU，这就会影响到主线程处理请求的速度。</p><h3 id="第6讲"><a href="#第6讲" class="headerlink" title="第6讲"></a><a href="https://time.geekbang.org/column/article/272852">第6讲</a></h3><p><strong>问题：为什么主从库间的复制不使用 AOF？</strong></p><p>答案：有两个原因。</p><ol><li>RDB文件是二进制文件，无论是要把RDB写入磁盘，还是要通过网络传输RDB，IO效率都比记录和传输AOF的高。</li><li>在从库端进行恢复时，用RDB的恢复效率要高于用AOF。</li></ol><h3 id="第7讲"><a href="#第7讲" class="headerlink" title="第7讲"></a><a href="https://time.geekbang.org/column/article/274483">第7讲</a></h3><p><strong>问题1：在主从切换过程中，客户端能否正常地进行请求操作呢？</strong></p><p>主从集群一般是采用读写分离模式，当主库故障后，客户端仍然可以把读请求发送给从库，让从库服务。但是，对于写请求操作，客户端就无法执行了。</p><p><strong>问题2：如果想要应用程序不感知服务的中断，还需要哨兵或客户端再做些什么吗？</strong></p><p>一方面，客户端需要能缓存应用发送的写请求。只要不是同步写操作（Redis应用场景一般也没有同步写），写请求通常不会在应用程序的关键路径上，所以，客户端缓存写请求后，给应用程序返回一个确认就行。</p><p>另一方面，主从切换完成后，客户端要能和新主库重新建立连接，哨兵需要提供订阅频道，让客户端能够订阅到新主库的信息。同时，客户端也需要能主动和哨兵通信，询问新主库的信息。</p><h3 id="第8讲"><a href="#第8讲" class="headerlink" title="第8讲"></a><a href="https://time.geekbang.org/column/article/275337">第8讲</a></h3><p><strong>问题1：5个哨兵实例的集群，quorum值设为2。在运行过程中，如果有3个哨兵实例都发生故障了，此时，Redis主库如果有故障，还能正确地判断主库“客观下线”吗？如果可以的话，还能进行主从库自动切换吗？</strong></p><p>因为判定主库“客观下线”的依据是，认为主库“主观下线”的哨兵个数要大于等于quorum值，现在还剩2个哨兵实例，个数正好等于quorum值，所以还能正常判断主库是否处于“客观下线”状态。如果一个哨兵想要执行主从切换，就要获到半数以上的哨兵投票赞成，也就是至少需要3个哨兵投票赞成。但是，现在只有2个哨兵了，所以就无法进行主从切换了。</p><p><strong>问题2：哨兵实例是不是越多越好呢？如果同时调大down-after-milliseconds值，对减少误判是不是也有好处？</strong></p><p>哨兵实例越多，误判率会越低，但是在判定主库下线和选举Leader时，实例需要拿到的赞成票数也越多，等待所有哨兵投完票的时间可能也会相应增加，主从库切换的时间也会变长，客户端容易堆积较多的请求操作，可能会导致客户端请求溢出，从而造成请求丢失。如果业务层对Redis的操作有响应时间要求，就可能会因为新主库一直没有选定，新操作无法执行而发生超时报警。</p><p>调大down-after-milliseconds后，可能会导致这样的情况：主库实际已经发生故障了，但是哨兵过了很长时间才判断出来，这就会影响到Redis对业务的可用性。</p><h3 id="第9讲"><a href="#第9讲" class="headerlink" title="第9讲"></a><a href="https://time.geekbang.org/column/article/276545">第9讲</a></h3><p>问题：为什么Redis不直接用一个表，把键值对和实例的对应关系记录下来？</p><p>如果使用表记录键值对和实例的对应关系，一旦键值对和实例的对应关系发生了变化（例如实例有增减或者数据重新分布），就要修改表。如果是单线程操作表，那么所有操作都要串行执行，性能慢；如果是多线程操作表，就涉及到加锁开销。此外，如果数据量非常大，使用表记录键值对和实例的对应关系，需要的额外存储空间也会增加。</p><p>基于哈希槽计算时，虽然也要记录哈希槽和实例的对应关系，但是哈希槽的个数要比键值对的个数少很多，无论是修改哈希槽和实例的对应关系，还是使用额外空间存储哈希槽和实例的对应关系，都比直接记录键值对和实例的关系的开销小得多。</p><p>好了，这些问题你都回答上来了吗？如果你还有其他想法，也欢迎多多留言，跟我和其他同学进行交流讨论。</p><h2 id="典型问题讲解"><a href="#典型问题讲解" class="headerlink" title="典型问题讲解"></a>典型问题讲解</h2><p>接下来，我再讲一些代表性问题，包括Redis rehash的时机和执行机制，主线程、子进程和后台线程的联系和区别，写时复制的底层实现原理，以及replication buffer和repl_backlog_buffer的区别。</p><h3 id="问题1：rehash的触发时机和渐进式执行机制"><a href="#问题1：rehash的触发时机和渐进式执行机制" class="headerlink" title="问题1：rehash的触发时机和渐进式执行机制"></a>问题1：rehash的触发时机和渐进式执行机制</h3><p>我发现，很多同学对Redis的哈希表数据结构都很感兴趣，尤其是哈希表的rehash操作，所以，我再集中回答两个问题。</p><p><strong>1.Redis什么时候做rehash？</strong></p><p>Redis会使用装载因子（load factor）来判断是否需要做rehash。装载因子的计算方式是，哈希表中所有entry的个数除以哈希表的哈希桶个数。Redis会根据装载因子的两种情况，来触发rehash操作：</p><ul><li>装载因子≥1，同时，哈希表被允许进行rehash；</li><li>装载因子≥5。</li></ul><p>在第一种情况下，如果装载因子等于1，同时我们假设，所有键值对是平均分布在哈希表的各个桶中的，那么，此时，哈希表可以不用链式哈希，因为一个哈希桶正好保存了一个键值对。</p><p>但是，如果此时再有新的数据写入，哈希表就要使用链式哈希了，这会对查询性能产生影响。在进行RDB生成和AOF重写时，哈希表的rehash是被禁止的，这是为了避免对RDB和AOF重写造成影响。如果此时，Redis没有在生成RDB和重写AOF，那么，就可以进行rehash。否则的话，再有数据写入时，哈希表就要开始使用查询较慢的链式哈希了。</p><p>在第二种情况下，也就是装载因子大于等于5时，就表明当前保存的数据量已经远远大于哈希桶的个数，哈希桶里会有大量的链式哈希存在，性能会受到严重影响，此时，就立马开始做rehash。</p><p>刚刚说的是触发rehash的情况，如果装载因子小于1，或者装载因子大于1但是小于5，同时哈希表暂时不被允许进行rehash（例如，实例正在生成RDB或者重写AOF），此时，哈希表是不会进行rehash操作的。</p><p><strong>2.采用渐进式hash时，如果实例暂时没有收到新请求，是不是就不做rehash了？</strong></p><p>其实不是的。Redis会执行定时任务，定时任务中就包含了rehash操作。所谓的定时任务，就是按照一定频率（例如每100ms&#x2F;次）执行的任务。</p><p>在rehash被触发后，即使没有收到新请求，Redis也会定时执行一次rehash操作，而且，每次执行时长不会超过1ms，以免对其他任务造成影响。</p><h3 id="问题2：主线程、子进程和后台线程的联系与区别"><a href="#问题2：主线程、子进程和后台线程的联系与区别" class="headerlink" title="问题2：主线程、子进程和后台线程的联系与区别"></a>问题2：主线程、子进程和后台线程的联系与区别</h3><p>我在课程中提到了主线程、主进程、子进程、子线程和后台线程这几个词，有些同学可能会有疑惑，我再帮你总结下它们的区别。</p><p>首先，我来解释一下进程和线程的区别。</p><p>从操作系统的角度来看，进程一般是指资源分配单元，例如一个进程拥有自己的堆、栈、虚存空间（页表）、文件描述符等；而线程一般是指CPU进行调度和执行的实体。</p><p>了解了进程和线程的区别后，我们再来看下什么是主进程和主线程。</p><p>如果一个进程启动后，没有再创建额外的线程，那么，这样的进程一般称为主进程或主线程。</p><p>举个例子，下面是我写的一个C程序片段，main函数会直接调用一个worker函数，函数worker就是执行一个for循环计算。下面这个程序运行后，它自己就是一个主进程，同时也是个主线程。</p><pre class="line-numbers language-none"><code class="language-none">int counter &#x3D; 0;void *worker() &#123;   for (int i&#x3D;0;i&lt;10;i++) &#123;      counter++;   &#125;   return NULL;&#125;int main(int argc, char *argv[]) &#123;   worker();&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>和这段代码类似，Redis启动以后，本身就是一个进程，它会接收客户端发送的请求，并处理读写操作请求。而且，接收请求和处理请求操作是Redis的主要工作，Redis没有再依赖于其他线程，所以，我一般把完成这个主要工作的Redis进程，称为主进程或主线程。</p><p>在主线程中，我们还可以使用fork创建子进程，或是使用pthread_create创建线程。下面我先介绍下Redis中用fork创建的子进程有哪些。</p><ul><li>创建RDB的后台子进程，同时由它负责在主从同步时传输RDB给从库；</li><li>通过无盘复制方式传输RDB的子进程；</li><li>bgrewriteaof子进程。</li></ul><p>然后，我们再看下Redis使用的线程。从4.0版本开始，Redis也开始使用pthread_create创建线程，这些线程在创建后，一般会自行执行一些任务，例如执行异步删除任务。相对于完成主要工作的主线程来说，我们一般可以称这些线程为后台线程。关于Redis后台线程的具体执行机制，我会在第16讲具体介绍。</p><p>为了帮助你更好地理解，我画了一张图，展示了它们的区别。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/c2c5bd3a66921b1b0cc1d377dfabd451.jpg"></p><h3 id="问题3：写时复制的底层实现机制"><a href="#问题3：写时复制的底层实现机制" class="headerlink" title="问题3：写时复制的底层实现机制"></a>问题3：写时复制的底层实现机制</h3><p>Redis在使用RDB方式进行持久化时，会用到写时复制机制。我在第5节课讲写时复制的时候，着重介绍了写时复制的效果：bgsave子进程相当于复制了原始数据，而主线程仍然可以修改原来的数据。</p><p>今天，我再具体讲一讲写时复制的底层实现机制。</p><p>对Redis来说，主线程fork出bgsave子进程后，bgsave子进程实际是复制了主线程的页表。这些页表中，就保存了在执行bgsave命令时，主线程的所有数据块在内存中的物理地址。这样一来，bgsave子进程生成RDB时，就可以根据页表读取这些数据，再写入磁盘中。如果此时，主线程接收到了新写或修改操作，那么，主线程会使用写时复制机制。具体来说，写时复制就是指，主线程在有写操作时，才会把这个新写或修改后的数据写入到一个新的物理地址中，并修改自己的页表映射。</p><p>我来借助下图中的例子，具体展示一下写时复制的底层机制。</p><p>bgsave子进程复制主线程的页表以后，假如主线程需要修改虚页7里的数据，那么，主线程就需要新分配一个物理页（假设是物理页53），然后把修改后的虚页7里的数据写到物理页53上，而虚页7里原来的数据仍然保存在物理页33上。这个时候，虚页7到物理页33的映射关系，仍然保留在bgsave子进程中。所以，bgsave子进程可以无误地把虚页7的原始数据写入RDB文件。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/cc98dc9f65a1079f3638158aacf81aeb.jpg"></p><h3 id="问题4：replication-buffer和repl-backlog-buffer的区别"><a href="#问题4：replication-buffer和repl-backlog-buffer的区别" class="headerlink" title="问题4：replication buffer和repl_backlog_buffer的区别"></a>问题4：replication buffer和repl_backlog_buffer的区别</h3><p>在进行主从复制时，Redis会使用replication buffer和repl_backlog_buffer，有些同学可能不太清楚它们的区别，我再解释下。</p><p>总的来说，replication buffer是主从库在进行全量复制时，主库上用于和从库连接的客户端的buffer，而repl_backlog_buffer是为了支持从库增量复制，主库上用于持续保存写操作的一块专用buffer。</p><p>Redis主从库在进行复制时，当主库要把全量复制期间的写操作命令发给从库时，主库会先创建一个客户端，用来连接从库，然后通过这个客户端，把写操作命令发给从库。在内存中，主库上的客户端就会对应一个buffer，这个buffer就被称为replication buffer。Redis通过client_buffer配置项来控制这个buffer的大小。主库会给每个从库建立一个客户端，所以replication buffer不是共享的，而是每个从库都有一个对应的客户端。</p><p>repl_backlog_buffer是一块专用buffer，在Redis服务器启动后，开始一直接收写操作命令，这是所有从库共享的。主库和从库会各自记录自己的复制进度，所以，不同的从库在进行恢复时，会把自己的复制进度（slave_repl_offset）发给主库，主库就可以和它独立同步。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/7a1795yy4f6dc064f0d34ef1231203a8.jpg"></p><p>好了，这节课就到这里。非常感谢你的仔细思考和提问，每个问题都很精彩，在看留言的过程中，我自己也受益匪浅。另外，我希望我们可以组建起一个Redis学习团，在接下来的课程中，欢迎你继续在留言区畅所欲言，我们一起进步，希望每个人都能成为Redis达人！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;10-第1～9讲课后思考题答案及常见问题答疑&quot;&gt;&lt;a href=&quot;#10-第1～9讲课后思考题答案及常见问题答疑&quot; class=&quot;headerlink&quot; title=&quot;10 | 第1～9讲课后思考题答案及常见问题答疑&quot;&gt;&lt;/a&gt;10 | 第1～9讲课后思考题答案及</summary>
      
    
    
    
    <category term="Redis核心技术与实战" scheme="https://zhuansun.github.io/geekbang/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    
    
  </entry>
  
  <entry>
    <title>09 | 切片集群：数据增多了，是该加内存还是加实例？</title>
    <link href="https://zhuansun.github.io/geekbang/posts/2841884422.html"/>
    <id>https://zhuansun.github.io/geekbang/posts/2841884422.html</id>
    <published>2024-03-04T22:10:14.000Z</published>
    <updated>2024-03-21T07:44:22.352Z</updated>
    
    <content type="html"><![CDATA[<h1 id="09-切片集群：数据增多了，是该加内存还是加实例？"><a href="#09-切片集群：数据增多了，是该加内存还是加实例？" class="headerlink" title="09 | 切片集群：数据增多了，是该加内存还是加实例？"></a>09 | 切片集群：数据增多了，是该加内存还是加实例？</h1><p>你好，我是蒋德钧。今天我们来学习切片集群。</p><p>我曾遇到过这么一个需求：要用Redis保存5000万个键值对，每个键值对大约是512B，为了能快速部署并对外提供服务，我们采用云主机来运行Redis实例，那么，该如何选择云主机的内存容量呢？</p><p>我粗略地计算了一下，这些键值对所占的内存空间大约是25GB（5000万*512B）。所以，当时，我想到的第一个方案就是：选择一台32GB内存的云主机来部署Redis。因为32GB的内存能保存所有数据，而且还留有7GB，可以保证系统的正常运行。同时，我还采用RDB对数据做持久化，以确保Redis实例故障后，还能从RDB恢复数据。</p><p>但是，在使用的过程中，我发现，Redis的响应有时会非常慢。后来，我们使用INFO命令查看Redis的latest_fork_usec指标值（表示最近一次fork的耗时），结果显示这个指标值特别高，快到秒级别了。</p><p>这跟Redis的持久化机制有关系。在使用RDB进行持久化时，Redis会fork子进程来完成，fork操作的用时和Redis的数据量是正相关的，而fork在执行时会阻塞主线程。数据量越大，fork操作造成的主线程阻塞的时间越长。所以，在使用RDB对25GB的数据进行持久化时，数据量较大，后台运行的子进程在fork创建时阻塞了主线程，于是就导致Redis响应变慢了。</p><p>看来，第一个方案显然是不可行的，我们必须要寻找其他的方案。这个时候，我们注意到了Redis的切片集群。虽然组建切片集群比较麻烦，但是它可以保存大量数据，而且对Redis主线程的阻塞影响较小。</p><p>切片集群，也叫分片集群，就是指启动多个Redis实例组成一个集群，然后按照一定的规则，把收到的数据划分成多份，每一份用一个实例来保存。回到我们刚刚的场景中，如果把25GB的数据平均分成5份（当然，也可以不做均分），使用5个实例来保存，每个实例只需要保存5GB数据。如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/793251ca784yyf6ac37fe46389094b26.jpg"></p><p>那么，在切片集群中，实例在为5GB数据生成RDB时，数据量就小了很多，fork子进程一般不会给主线程带来较长时间的阻塞。采用多个实例保存数据切片后，我们既能保存25GB数据，又避免了fork子进程阻塞主线程而导致的响应突然变慢。</p><p>在实际应用Redis时，随着用户或业务规模的扩展，保存大量数据的情况通常是无法避免的。而切片集群，就是一个非常好的解决方案。这节课，我们就来学习一下。</p><h2 id="如何保存更多数据？"><a href="#如何保存更多数据？" class="headerlink" title="如何保存更多数据？"></a>如何保存更多数据？</h2><p>在刚刚的案例里，为了保存大量数据，我们使用了大内存云主机和切片集群两种方法。实际上，这两种方法分别对应着Redis应对数据量增多的两种方案：纵向扩展（scale up）和横向扩展（scale out）。</p><ul><li><strong>纵向扩展</strong>：升级单个Redis实例的资源配置，包括增加内存容量、增加磁盘容量、使用更高配置的CPU。就像下图中，原来的实例内存是8GB，硬盘是50GB，纵向扩展后，内存增加到24GB，磁盘增加到150GB。</li><li><strong>横向扩展</strong>：横向增加当前Redis实例的个数，就像下图中，原来使用1个8GB内存、50GB磁盘的实例，现在使用三个相同配置的实例。</li></ul><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/7a512fec7eba789c6d098b834929701a.jpg"></p><p>那么，这两种方式的优缺点分别是什么呢？</p><p>首先，纵向扩展的好处是， <strong>实施起来简单、直接</strong>。不过，这个方案也面临两个潜在的问题。</p><p>第一个问题是，当使用RDB对数据进行持久化时，如果数据量增加，需要的内存也会增加，主线程fork子进程时就可能会阻塞（比如刚刚的例子中的情况）。不过，如果你不要求持久化保存Redis数据，那么，纵向扩展会是一个不错的选择。</p><p>不过，这时，你还要面对第二个问题： <strong>纵向扩展会受到硬件和成本的限制</strong>。这很容易理解，毕竟，把内存从32GB扩展到64GB还算容易，但是，要想扩充到1TB，就会面临硬件容量和成本上的限制了。</p><p>与纵向扩展相比，横向扩展是一个扩展性更好的方案。这是因为，要想保存更多的数据，采用这种方案的话，只用增加Redis的实例个数就行了，不用担心单个实例的硬件和成本限制。 <strong>在面向百万、千万级别的用户规模时，横向扩展的Redis切片集群会是一个非常好的选择</strong>。</p><p>不过，在只使用单个实例的时候，数据存在哪儿，客户端访问哪儿，都是非常明确的，但是，切片集群不可避免地涉及到多个实例的分布式管理问题。要想把切片集群用起来，我们就需要解决两大问题：</p><ul><li>数据切片后，在多个实例之间如何分布？</li><li>客户端怎么确定想要访问的数据在哪个实例上？</li></ul><p>接下来，我们就一个个地解决。</p><h2 id="数据切片和实例的对应分布关系"><a href="#数据切片和实例的对应分布关系" class="headerlink" title="数据切片和实例的对应分布关系"></a>数据切片和实例的对应分布关系</h2><p>在切片集群中，数据需要分布在不同实例上，那么，数据和实例之间如何对应呢？这就和接下来我要讲的Redis Cluster方案有关了。不过，我们要先弄明白切片集群和Redis Cluster的联系与区别。</p><p>实际上，切片集群是一种保存大量数据的通用机制，这个机制可以有不同的实现方案。在Redis 3.0之前，官方并没有针对切片集群提供具体的方案。从3.0开始，官方提供了一个名为Redis Cluster的方案，用于实现切片集群。Redis Cluster方案中就规定了数据和实例的对应规则。</p><p>具体来说，Redis Cluster方案采用哈希槽（Hash Slot，接下来我会直接称之为Slot），来处理数据和实例之间的映射关系。在Redis Cluster方案中，一个切片集群共有16384个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的key，被映射到一个哈希槽中。</p><p>具体的映射过程分为两大步：首先根据键值对的key，按照 <a href="https://en.wikipedia.org/wiki/Cyclic_redundancy_check">CRC16算法</a> 计算一个16 bit的值；然后，再用这个16bit值对16384取模，得到0~16383范围内的模数，每个模数代表一个相应编号的哈希槽。关于CRC16算法，不是这节课的重点，你简单看下链接中的资料就可以了。</p><p>那么，这些哈希槽又是如何被映射到具体的Redis实例上的呢？</p><p>我们在部署Redis Cluster方案时，可以使用cluster create命令创建集群，此时，Redis会自动把这些槽平均分布在集群实例上。例如，如果集群中有N个实例，那么，每个实例上的槽个数为16384&#x2F;N个。</p><p>当然， 我们也可以使用cluster meet命令手动建立实例间的连接，形成集群，再使用cluster addslots命令，指定每个实例上的哈希槽个数。</p><p>举个例子，假设集群中不同Redis实例的内存大小配置不一，如果把哈希槽均分在各个实例上，在保存相同数量的键值对时，和内存大的实例相比，内存小的实例就会有更大的容量压力。遇到这种情况时，你可以根据不同实例的资源配置情况，使用cluster addslots命令手动分配哈希槽。</p><p>为了便于你理解，我画一张示意图来解释一下，数据、哈希槽、实例这三者的映射分布情况。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/7d070c8b19730b308bfaabbe82c2f1ab.jpg"></p><p>示意图中的切片集群一共有3个实例，同时假设有5个哈希槽，我们首先可以通过下面的命令手动分配哈希槽：实例1保存哈希槽0和1，实例2保存哈希槽2和3，实例3保存哈希槽4。</p><pre class="line-numbers language-none"><code class="language-none">redis-cli -h 172.16.19.3 –p 6379 cluster addslots 0,1redis-cli -h 172.16.19.4 –p 6379 cluster addslots 2,3redis-cli -h 172.16.19.5 –p 6379 cluster addslots 4<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>在集群运行的过程中，key1和key2计算完CRC16值后，对哈希槽总个数5取模，再根据各自的模数结果，就可以被映射到对应的实例1和实例3上了。</p><p>另外，我再给你一个小提醒， <strong>在手动分配哈希槽时，需要把16384个槽都分配完，否则Redis集群无法正常工作</strong>。</p><p>好了，通过哈希槽，切片集群就实现了数据到哈希槽、哈希槽再到实例的分配。但是，即使实例有了哈希槽的映射信息，客户端又是怎么知道要访问的数据在哪个实例上呢？接下来，我就来和你聊聊。</p><h2 id="客户端如何定位数据？"><a href="#客户端如何定位数据？" class="headerlink" title="客户端如何定位数据？"></a>客户端如何定位数据？</h2><p>在定位键值对数据时，它所处的哈希槽是可以通过计算得到的，这个计算可以在客户端发送请求时来执行。但是，要进一步定位到实例，还需要知道哈希槽分布在哪个实例上。</p><p>一般来说，客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端。但是，在集群刚刚创建的时候，每个实例只知道自己被分配了哪些哈希槽，是不知道其他实例拥有的哈希槽信息的。</p><p>那么，客户端为什么可以在访问任何一个实例时，都能获得所有的哈希槽信息呢？这是因为，Redis实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。</p><p>客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。</p><p>但是，在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个：</p><ul><li>在集群中，实例有新增或删除，Redis需要重新分配哈希槽；</li><li>为了负载均衡，Redis需要把哈希槽在所有实例上重新分布一遍。</li></ul><p>此时，实例之间还可以通过相互传递消息，获得最新的哈希槽分配信息，但是，客户端是无法主动感知这些变化的。这就会导致，它缓存的分配信息和最新的分配信息就不一致了，那该怎么办呢？</p><p>Redis Cluster方案提供了一种 <strong>重定向机制，</strong> 所谓的“重定向”，就是指，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，客户端要再给一个新实例发送操作命令。</p><p>那客户端又是怎么知道重定向时的新实例的访问地址呢？当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，那么，这个实例就会给客户端返回下面的MOVED命令响应结果，这个结果中就包含了新实例的访问地址。</p><pre class="line-numbers language-none"><code class="language-none">GET hello:key(error) MOVED 13320 172.16.19.5:6379<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>其中，MOVED命令表示，客户端请求的键值对所在的哈希槽13320，实际是在172.16.19.5这个实例上。通过返回的MOVED命令，就相当于把哈希槽所在的新实例的信息告诉给客户端了。这样一来，客户端就可以直接和172.16.19.5连接，并发送操作请求了。</p><p>我画一张图来说明一下，MOVED重定向命令的使用方法。可以看到，由于负载均衡，Slot 2中的数据已经从实例2迁移到了实例3，但是，客户端缓存仍然记录着“Slot 2在实例2”的信息，所以会给实例2发送命令。实例2给客户端返回一条MOVED命令，把Slot 2的最新位置（也就是在实例3上），返回给客户端，客户端就会再次向实例3发送请求，同时还会更新本地缓存，把Slot 2与实例的对应关系更新过来。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/350abedefcdbc39d6a8a8f1874eb0809.jpg"></p><p>需要注意的是，在上图中，当客户端给实例2发送命令时，Slot 2中的数据已经全部迁移到了实例3。在实际应用时，如果Slot 2中的数据比较多，就可能会出现一种情况：客户端向实例2发送请求，但此时，Slot 2中的数据只有一部分迁移到了实例3，还有部分数据没有迁移。在这种迁移部分完成的情况下，客户端就会收到一条ASK报错信息，如下所示：</p><pre class="line-numbers language-none"><code class="language-none">GET hello:key(error) ASK 13320 172.16.19.5:6379<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这个结果中的ASK命令就表示，客户端请求的键值对所在的哈希槽13320，在172.16.19.5这个实例上，但是这个哈希槽正在迁移。此时，客户端需要先给172.16.19.5这个实例发送一个ASKING命令。这个命令的意思是，让这个实例允许执行客户端接下来发送的命令。然后，客户端再向这个实例发送GET命令，以读取数据。</p><p>看起来好像有点复杂，我再借助图片来解释一下。</p><p>在下图中，Slot 2正在从实例2往实例3迁移，key1和key2已经迁移过去，key3和key4还在实例2。客户端向实例2请求key2后，就会收到实例2返回的ASK命令。</p><p>ASK命令表示两层含义：第一，表明Slot数据还在迁移中；第二，ASK命令把客户端所请求数据的最新实例地址返回给客户端，此时，客户端需要给实例3发送ASKING命令，然后再发送操作命令。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/e93ae7f4edf30724d58bf68yy714eeb0.jpg"></p><p>和MOVED命令不同， <strong>ASK命令并不会更新客户端缓存的哈希槽分配信息</strong>。所以，在上图中，如果客户端再次请求Slot 2中的数据，它还是会给实例2发送请求。这也就是说，ASK命令的作用只是让客户端能给新实例发送一次请求，而不像MOVED命令那样，会更改本地缓存，让后续所有命令都发往新实例。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这节课，我们学习了切片集群在保存大量数据方面的优势，以及基于哈希槽的数据分布机制和客户端定位键值对的方法。</p><p>在应对数据量扩容时，虽然增加内存这种纵向扩展的方法简单直接，但是会造成数据库的内存过大，导致性能变慢。Redis切片集群提供了横向扩展的模式，也就是使用多个实例，并给每个实例配置一定数量的哈希槽，数据可以通过键的哈希值映射到哈希槽，再通过哈希槽分散保存到不同的实例上。这样做的好处是扩展性好，不管有多少数据，切片集群都能应对。</p><p>另外，集群的实例增减，或者是为了实现负载均衡而进行的数据重新分布，会导致哈希槽和实例的映射关系发生变化，客户端发送请求时，会收到命令执行报错信息。了解了MOVED和ASK命令，你就不会为这类报错而头疼了。</p><p>我刚刚说过，在Redis 3.0 之前，Redis官方并没有提供切片集群方案，但是，其实当时业界已经有了一些切片集群的方案，例如基于客户端分区的ShardedJedis，基于代理的Codis、Twemproxy等。这些方案的应用早于Redis Cluster方案，在支撑的集群实例规模、集群稳定性、客户端友好性方面也都有着各自的优势，我会在后面的课程中，专门和你聊聊这些方案的实现机制，以及实践经验。这样一来，当你再碰到业务发展带来的数据量巨大的难题时，就可以根据这些方案的特点，选择合适的方案实现切片集群，以应对业务需求了。</p><h2 id="每课一问"><a href="#每课一问" class="headerlink" title="每课一问"></a>每课一问</h2><p>按照惯例，给你提一个小问题：Redis Cluster方案通过哈希槽的方式把键值对分配到不同的实例上，这个过程需要对键值对的key做CRC计算，然后再和哈希槽做映射，这样做有什么好处吗？如果用一个表直接把键值对和实例的对应关系记录下来（例如键值对1在实例2上，键值对2在实例1上），这样就不用计算key和哈希槽的对应关系了，只用查表就行了，Redis为什么不这么做呢？</p><p>欢迎你在留言区畅所欲言，如果你觉得有收获，也希望你能帮我把今天的内容分享给你的朋友，帮助更多人解决切片集群的问题。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;09-切片集群：数据增多了，是该加内存还是加实例？&quot;&gt;&lt;a href=&quot;#09-切片集群：数据增多了，是该加内存还是加实例？&quot; class=&quot;headerlink&quot; title=&quot;09 | 切片集群：数据增多了，是该加内存还是加实例？&quot;&gt;&lt;/a&gt;09 | 切片集群</summary>
      
    
    
    
    <category term="Redis核心技术与实战" scheme="https://zhuansun.github.io/geekbang/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    
    
  </entry>
  
  <entry>
    <title>11 | “万金油”的String，为什么不好用了？</title>
    <link href="https://zhuansun.github.io/geekbang/posts/2480174241.html"/>
    <id>https://zhuansun.github.io/geekbang/posts/2480174241.html</id>
    <published>2024-03-04T22:10:14.000Z</published>
    <updated>2024-03-21T07:44:22.356Z</updated>
    
    <content type="html"><![CDATA[<h1 id="11-“万金油”的String，为什么不好用了？"><a href="#11-“万金油”的String，为什么不好用了？" class="headerlink" title="11 | “万金油”的String，为什么不好用了？"></a>11 | “万金油”的String，为什么不好用了？</h1><p>你好，我是蒋德钧。</p><p>从今天开始，我们就要进入“实践篇”了。接下来，我们会用5节课的时间学习“数据结构”。我会介绍节省内存开销以及保存和统计海量数据的数据类型及其底层数据结构，还会围绕典型的应用场景（例如地址位置查询、时间序列数据库读写和消息队列存取），跟你分享使用Redis的数据类型和module扩展功能来满足需求的具体方案。</p><p>今天，我们先了解下String类型的内存空间消耗问题，以及选择节省内存开销的数据类型的解决方案。</p><p>先跟你分享一个我曾经遇到的需求。</p><p>当时，我们要开发一个图片存储系统，要求这个系统能快速地记录图片ID和图片在存储系统中保存时的ID（可以直接叫作图片存储对象ID）。同时，还要能够根据图片ID快速查找到图片存储对象ID。</p><p>因为图片数量巨大，所以我们就用10位数来表示图片ID和图片存储对象ID，例如，图片ID为1101000051，它在存储系统中对应的ID号是3301000051。</p><pre class="line-numbers language-none"><code class="language-none">photo_id: 1101000051photo_obj_id: 3301000051<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>可以看到，图片ID和图片存储对象ID正好一一对应，是典型的“键-单值”模式。所谓的“单值”，就是指键值对中的值就是一个值，而不是一个集合，这和String类型提供的“一个键对应一个值的数据”的保存形式刚好契合。</p><p>而且，String类型可以保存二进制字节流，就像“万金油”一样，只要把数据转成二进制字节数组，就可以保存了。</p><p>所以，我们的第一个方案就是用String保存数据。我们把图片ID和图片存储对象ID分别作为键值对的key和value来保存，其中，图片存储对象ID用了String类型。</p><p>刚开始，我们保存了1亿张图片，大约用了6.4GB的内存。但是，随着图片数据量的不断增加，我们的Redis内存使用量也在增加，结果就遇到了大内存Redis实例因为生成RDB而响应变慢的问题。很显然，String类型并不是一种好的选择，我们还需要进一步寻找能节省内存开销的数据类型方案。</p><p>在这个过程中，我深入地研究了String类型的底层结构，找到了它内存开销大的原因，对“万金油”的String类型有了全新的认知：String类型并不是适用于所有场合的，它有一个明显的短板，就是它保存数据时所消耗的内存空间较多。</p><p>同时，我还仔细研究了集合类型的数据结构。我发现，集合类型有非常节省内存空间的底层实现结构，但是，集合类型保存的数据模式，是一个键对应一系列值，并不适合直接保存单值的键值对。所以，我们就使用二级编码的方法，实现了用集合类型保存单值键值对，Redis实例的内存空间消耗明显下降了。</p><p>这节课，我就把在解决这个问题时学到的经验和方法分享给你，包括String类型的内存空间消耗在哪儿了、用什么数据结构可以节省内存，以及如何用集合类型保存单值键值对。如果你在使用String类型时也遇到了内存空间消耗较多的问题，就可以尝试下今天的解决方案了。</p><p>接下来，我们先来看看String类型的内存都消耗在哪里了。</p><h2 id="为什么String类型内存开销大？"><a href="#为什么String类型内存开销大？" class="headerlink" title="为什么String类型内存开销大？"></a>为什么String类型内存开销大？</h2><p>在刚才的案例中，我们保存了1亿张图片的信息，用了约6.4GB的内存，一个图片ID和图片存储对象ID的记录平均用了64字节。</p><p>但问题是，一组图片ID及其存储对象ID的记录，实际只需要16字节就可以了。</p><p>我们来分析一下。图片ID和图片存储对象ID都是10位数，我们可以用两个8字节的Long类型表示这两个ID。因为8字节的Long类型最大可以表示2的64次方的数值，所以肯定可以表示10位数。但是，为什么String类型却用了64字节呢？</p><p>其实，除了记录实际数据，String类型还需要额外的内存空间记录数据长度、空间使用等信息，这些信息也叫作元数据。当实际保存的数据较小时，元数据的空间开销就显得比较大了，有点“喧宾夺主”的意思。</p><p>那么，String类型具体是怎么保存数据的呢？我来解释一下。</p><p>当你保存64位有符号整数时，String类型会把它保存为一个8字节的Long类型整数，这种保存方式通常也叫作int编码方式。</p><p>但是，当你保存的数据中包含字符时，String类型就会用简单动态字符串（Simple Dynamic String，SDS）结构体来保存，如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/37c6a8d5abd65906368e7c4a6b938657.jpg"></p><ul><li><strong>buf</strong>：字节数组，保存实际数据。为了表示字节数组的结束，Redis会自动在数组最后加一个“\0”，这就会额外占用1个字节的开销。</li><li><strong>len</strong>：占4个字节，表示buf的已用长度。</li><li><strong>alloc</strong>：也占个4字节，表示buf的实际分配长度，一般大于len。</li></ul><p>可以看到，在SDS中，buf保存实际数据，而len和alloc本身其实是SDS结构体的额外开销。</p><p>另外，对于String类型来说，除了SDS的额外开销，还有一个来自于RedisObject结构体的开销。</p><p>因为Redis的数据类型有很多，而且，不同数据类型都有些相同的元数据要记录（比如最后一次访问的时间、被引用的次数等），所以，Redis会用一个RedisObject结构体来统一记录这些元数据，同时指向实际数据。</p><p>一个RedisObject包含了8字节的元数据和一个8字节指针，这个指针再进一步指向具体数据类型的实际数据所在，例如指向String类型的SDS结构所在的内存地址，可以看一下下面的示意图。关于RedisObject的具体结构细节，我会在后面的课程中详细介绍，现在你只要了解它的基本结构和元数据开销就行了。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/3409948e9d3e8aa5cd7cafb9b66c2857.jpg"></p><p>为了节省内存空间，Redis还对Long类型整数和SDS的内存布局做了专门的设计。</p><p>一方面，当保存的是Long类型整数时，RedisObject中的指针就直接赋值为整数数据了，这样就不用额外的指针再指向整数了，节省了指针的空间开销。</p><p>另一方面，当保存的是字符串数据，并且字符串小于等于44字节时，RedisObject中的元数据、指针和SDS是一块连续的内存区域，这样就可以避免内存碎片。这种布局方式也被称为embstr编码方式。</p><p>当然，当字符串大于44字节时，SDS的数据量就开始变多了，Redis就不再把SDS和RedisObject布局在一起了，而是会给SDS分配独立的空间，并用指针指向SDS结构。这种布局方式被称为raw编码模式。</p><p>为了帮助你理解int、embstr和raw这三种编码模式，我画了一张示意图，如下所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/ce83d1346c9642fdbbf5ffbe701bfbe3.jpg"></p><p>好了，知道了RedisObject所包含的额外元数据开销，现在，我们就可以计算String类型的内存使用量了。</p><p>因为10位数的图片ID和图片存储对象ID是Long类型整数，所以可以直接用int编码的RedisObject保存。每个int编码的RedisObject元数据部分占8字节，指针部分被直接赋值为8字节的整数了。此时，每个ID会使用16字节，加起来一共是32字节。但是，另外的32字节去哪儿了呢？</p><p>我在 <a href="https://time.geekbang.org/column/article/268253">第2讲</a> 中说过，Redis会使用一个全局哈希表保存所有键值对，哈希表的每一项是一个dictEntry的结构体，用来指向一个键值对。dictEntry结构中有三个8字节的指针，分别指向key、value以及下一个dictEntry，三个指针共24字节，如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/b6cbc5161388fdf4c9b49f3802ef53e7.jpg"></p><p>但是，这三个指针只有24字节，为什么会占用了32字节呢？这就要提到Redis使用的内存分配库jemalloc了。</p><p>jemalloc在分配内存时，会根据我们申请的字节数N，找一个比N大，但是最接近N的2的幂次数作为分配的空间，这样可以减少频繁分配的次数。</p><p>举个例子。如果你申请6字节空间，jemalloc实际会分配8字节空间；如果你申请24字节空间，jemalloc则会分配32字节。所以，在我们刚刚说的场景里，dictEntry结构就占用了32字节。</p><p>好了，到这儿，你应该就能理解，为什么用String类型保存图片ID和图片存储对象ID时需要用64个字节了。</p><p>你看，明明有效信息只有16字节，使用String类型保存时，却需要64字节的内存空间，有48字节都没有用于保存实际的数据。我们来换算下，如果要保存的图片有1亿张，那么1亿条的图片ID记录就需要6.4GB内存空间，其中有4.8GB的内存空间都用来保存元数据了，额外的内存空间开销很大。那么，有没有更加节省内存的方法呢？</p><h2 id="用什么数据结构可以节省内存？"><a href="#用什么数据结构可以节省内存？" class="headerlink" title="用什么数据结构可以节省内存？"></a>用什么数据结构可以节省内存？</h2><p>Redis有一种底层数据结构，叫压缩列表（ziplist），这是一种非常节省内存的结构。</p><p>我们先回顾下压缩列表的构成。表头有三个字段zlbytes、zltail和zllen，分别表示列表长度、列表尾的偏移量，以及列表中的entry个数。压缩列表尾还有一个zlend，表示列表结束。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/f6d4df5f7d6e80de29e2c6446b02429f.jpg"></p><p>压缩列表之所以能节省内存，就在于它是用一系列连续的entry保存数据。每个entry的元数据包括下面几部分。</p><ul><li><strong>prev_len</strong>，表示前一个entry的长度。prev_len有两种取值情况：1字节或5字节。取值1字节时，表示上一个entry的长度小于254字节。虽然1字节的值能表示的数值范围是0到255，但是压缩列表中zlend的取值默认是255，因此，就默认用255表示整个压缩列表的结束，其他表示长度的地方就不能再用255这个值了。所以，当上一个entry长度小于254字节时，prev_len取值为1字节，否则，就取值为5字节。</li><li><strong>len</strong>：表示自身长度，4字节；</li><li><strong>encoding</strong>：表示编码方式，1字节；</li><li><strong>content</strong>：保存实际数据。</li></ul><p>这些entry会挨个儿放置在内存中，不需要再用额外的指针进行连接，这样就可以节省指针所占用的空间。</p><p>我们以保存图片存储对象ID为例，来分析一下压缩列表是如何节省内存空间的。</p><p>每个entry保存一个图片存储对象ID（8字节），此时，每个entry的prev_len只需要1个字节就行，因为每个entry的前一个entry长度都只有8字节，小于254字节。这样一来，一个图片的存储对象ID所占用的内存大小是14字节（1+4+1+8&#x3D;14），实际分配16字节。</p><p>Redis基于压缩列表实现了List、Hash和Sorted Set这样的集合类型，这样做的最大好处就是节省了dictEntry的开销。当你用String类型时，一个键值对就有一个dictEntry，要用32字节空间。但采用集合类型时，一个key就对应一个集合的数据，能保存的数据多了很多，但也只用了一个dictEntry，这样就节省了内存。</p><p>这个方案听起来很好，但还存在一个问题：在用集合类型保存键值对时，一个键对应了一个集合的数据，但是在我们的场景中，一个图片ID只对应一个图片的存储对象ID，我们该怎么用集合类型呢？换句话说，在一个键对应一个值（也就是单值键值对）的情况下，我们该怎么用集合类型来保存这种单值键值对呢？</p><h2 id="如何用集合类型保存单值的键值对？"><a href="#如何用集合类型保存单值的键值对？" class="headerlink" title="如何用集合类型保存单值的键值对？"></a>如何用集合类型保存单值的键值对？</h2><p>在保存单值的键值对时，可以采用基于Hash类型的二级编码方法。这里说的二级编码，就是把一个单值的数据拆分成两部分，前一部分作为Hash集合的key，后一部分作为Hash集合的value，这样一来，我们就可以把单值数据保存到Hash集合中了。</p><p>以图片ID 1101000060和图片存储对象ID 3302000080为例，我们可以把图片ID的前7位（1101000）作为Hash类型的键，把图片ID的最后3位（060）和图片存储对象ID分别作为Hash类型值中的key和value。</p><p>按照这种设计方法，我在Redis中插入了一组图片ID及其存储对象ID的记录，并且用info命令查看了内存开销，我发现，增加一条记录后，内存占用只增加了16字节，如下所示：</p><pre class="line-numbers language-none"><code class="language-none">127.0.0.1:6379&gt; info memory# Memoryused_memory:1039120127.0.0.1:6379&gt; hset 1101000 060 3302000080(integer) 1127.0.0.1:6379&gt; info memory# Memoryused_memory:1039136<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在使用String类型时，每个记录需要消耗64字节，这种方式却只用了16字节，所使用的内存空间是原来的1&#x2F;4，满足了我们节省内存空间的需求。</p><p>不过，你可能也会有疑惑：“二级编码一定要把图片ID的前7位作为Hash类型的键，把最后3位作为Hash类型值中的key吗？” <strong>其实，二级编码方法中采用的ID长度是有讲究的</strong>。</p><p>在 <a href="https://time.geekbang.org/column/article/268253">第2讲</a> 中，我介绍过Redis Hash类型的两种底层实现结构，分别是压缩列表和哈希表。</p><p>那么，Hash类型底层结构什么时候使用压缩列表，什么时候使用哈希表呢？其实，Hash类型设置了用压缩列表保存数据时的两个阈值，一旦超过了阈值，Hash类型就会用哈希表来保存数据了。</p><p>这两个阈值分别对应以下两个配置项：</p><ul><li>hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数。</li><li>hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度。</li></ul><p>如果我们往Hash集合中写入的元素个数超过了hash-max-ziplist-entries，或者写入的单个元素大小超过了hash-max-ziplist-value，Redis就会自动把Hash类型的实现结构由压缩列表转为哈希表。</p><p>一旦从压缩列表转为了哈希表，Hash类型就会一直用哈希表进行保存，而不会再转回压缩列表了。在节省内存空间方面，哈希表就没有压缩列表那么高效了。</p><p><strong>为了能充分使用压缩列表的精简内存布局，我们一般要控制保存在Hash集合中的元素个数</strong>。所以，在刚才的二级编码中，我们只用图片ID最后3位作为Hash集合的key，也就保证了Hash集合的元素个数不超过1000，同时，我们把hash-max-ziplist-entries设置为1000，这样一来，Hash集合就可以一直使用压缩列表来节省内存空间了。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这节课，我们打破了对String的认知误区，以前，我们认为String是“万金油”，什么场合都适用，但是，在保存的键值对本身占用的内存空间不大时（例如这节课里提到的的图片ID和图片存储对象ID），String类型的元数据开销就占据主导了，这里面包括了RedisObject结构、SDS结构、dictEntry结构的内存开销。</p><p>针对这种情况，我们可以使用压缩列表保存数据。当然，使用Hash这种集合类型保存单值键值对的数据时，我们需要将单值数据拆分成两部分，分别作为Hash集合的键和值，就像刚才案例中用二级编码来表示图片ID，希望你能把这个方法用到自己的场景中。</p><p>最后，我还想再给你提供一个小方法：如果你想知道键值对采用不同类型保存时的内存开销，可以在 <a href="http://www.redis.cn/redis_memory/">这个网址</a> 里输入你的键值对长度和使用的数据类型，这样就能知道实际消耗的内存大小了。建议你把这个小工具用起来，它可以帮助你充分地节省内存。</p><h2 id="每课一问"><a href="#每课一问" class="headerlink" title="每课一问"></a>每课一问</h2><p>按照惯例，给你提个小问题：除了String类型和Hash类型，你觉得，还有其他合适的类型可以应用在这节课所说的保存图片的例子吗？</p><p>欢迎在留言区写下你的思考和答案，我们一起交流讨论，也欢迎你把今天的内容分享给你的朋友。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;11-“万金油”的String，为什么不好用了？&quot;&gt;&lt;a href=&quot;#11-“万金油”的String，为什么不好用了？&quot; class=&quot;headerlink&quot; title=&quot;11 | “万金油”的String，为什么不好用了？&quot;&gt;&lt;/a&gt;11 | “万金油”的S</summary>
      
    
    
    
    <category term="Redis核心技术与实战" scheme="https://zhuansun.github.io/geekbang/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    
    
  </entry>
  
  <entry>
    <title>16 | 异步机制：如何避免单线程模型的阻塞？</title>
    <link href="https://zhuansun.github.io/geekbang/posts/2541072974.html"/>
    <id>https://zhuansun.github.io/geekbang/posts/2541072974.html</id>
    <published>2024-03-04T22:10:14.000Z</published>
    <updated>2024-03-21T07:44:22.365Z</updated>
    
    <content type="html"><![CDATA[<h1 id="16-异步机制：如何避免单线程模型的阻塞？"><a href="#16-异步机制：如何避免单线程模型的阻塞？" class="headerlink" title="16 | 异步机制：如何避免单线程模型的阻塞？"></a>16 | 异步机制：如何避免单线程模型的阻塞？</h1><p>你好，我是蒋德钧。</p><p>Redis之所以被广泛应用，很重要的一个原因就是它支持高性能访问。也正因为这样，我们必须要重视所有可能影响Redis性能的因素（例如命令操作、系统配置、关键机制、硬件配置等），不仅要知道具体的机制，尽可能避免性能异常的情况出现，还要提前准备好应对异常的方案。</p><p>所以，从这节课开始，我会用6节课的时间介绍影响Redis性能的5大方面的潜在因素，分别是：</p><ul><li>Redis内部的阻塞式操作；</li><li>CPU核和NUMA架构的影响；</li><li>Redis关键系统配置；</li><li>Redis内存碎片；</li><li>Redis缓冲区。</li></ul><p>这节课，我们就先学习了解下Redis内部的阻塞式操作以及应对的方法。</p><p>在 <a href="https://time.geekbang.org/column/article/270474">第3讲</a> 中，我们学习过，Redis的网络IO和键值对读写是由主线程完成的。那么，如果在主线程上执行的操作消耗的时间太长，就会引起主线程阻塞。但是，Redis既有服务客户端请求的键值对增删改查操作，也有保证可靠性的持久化操作，还有进行主从复制时的数据同步操作，等等。操作这么多，究竟哪些会引起阻塞呢？</p><p>别着急，接下来，我就带你分门别类地梳理下这些操作，并且找出阻塞式操作。</p><h2 id="Redis实例有哪些阻塞点？"><a href="#Redis实例有哪些阻塞点？" class="headerlink" title="Redis实例有哪些阻塞点？"></a>Redis实例有哪些阻塞点？</h2><p>Redis实例在运行时，要和许多对象进行交互，这些不同的交互就会涉及不同的操作，下面我们来看看和Redis实例交互的对象，以及交互时会发生的操作。</p><ul><li><strong>客户端</strong>：网络IO，键值对增删改查操作，数据库操作；</li><li><strong>磁盘</strong>：生成RDB快照，记录AOF日志，AOF日志重写；</li><li><strong>主从节点</strong>：主库生成、传输RDB文件，从库接收RDB文件、清空数据库、加载RDB文件；</li><li><strong>切片集群实例</strong>：向其他实例传输哈希槽信息，数据迁移。</li></ul><p>为了帮助你理解，我再画一张图来展示下这4类交互对象和具体的操作之间的关系。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/6ce8abb76b3464afe1c4cb3bbe426922.jpg"></p><p>接下来，我们来逐个分析下在这些交互对象中，有哪些操作会引起阻塞。</p><p><strong>1.和客户端交互时的阻塞点</strong></p><p>网络IO有时候会比较慢，但是Redis使用了IO多路复用机制，避免了主线程一直处在等待网络连接或请求到来的状态，所以，网络IO不是导致Redis阻塞的因素。</p><p>键值对的增删改查操作是Redis和客户端交互的主要部分，也是Redis主线程执行的主要任务。所以，复杂度高的增删改查操作肯定会阻塞Redis。</p><p>那么，怎么判断操作复杂度是不是高呢？这里有一个最基本的标准，就是看操作的复杂度是否为O(N)。</p><p>Redis中涉及集合的操作复杂度通常为O(N)，我们要在使用时重视起来。例如集合元素全量查询操作HGETALL、SMEMBERS，以及集合的聚合统计操作，例如求交、并和差集。这些操作可以作为Redis的 <strong>第一个阻塞点：集合全量查询和聚合操作</strong>。</p><p>除此之外，集合自身的删除操作同样也有潜在的阻塞风险。你可能会认为，删除操作很简单，直接把数据删除就好了，为什么还会阻塞主线程呢？</p><p>其实，删除操作的本质是要释放键值对占用的内存空间。你可不要小瞧内存的释放过程。释放内存只是第一步，为了更加高效地管理内存空间，在应用程序释放内存时，操作系统需要把释放掉的内存块插入一个空闲内存块的链表，以便后续进行管理和再分配。这个过程本身需要一定时间，而且会阻塞当前释放内存的应用程序，所以，如果一下子释放了大量内存，空闲内存块链表操作时间就会增加，相应地就会造成Redis主线程的阻塞。</p><p>那么，什么时候会释放大量内存呢？其实就是在删除大量键值对数据的时候，最典型的就是删除包含了大量元素的集合，也称为bigkey删除。为了让你对bigkey的删除性能有一个直观的印象，我测试了不同元素数量的集合在进行删除操作时所消耗的时间，如下表所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/94bc8cf9yy5c34a6445434a15b1e9653.jpg"></p><p>从这张表里，我们可以得出三个结论：</p><ol><li>当元素数量从10万增加到100万时，4大集合类型的删除时间的增长幅度从5倍上升到了近20倍；</li><li>集合元素越大，删除所花费的时间就越长；</li><li>当删除有100万个元素的集合时，最大的删除时间绝对值已经达到了1.98s（Hash类型）。Redis的响应时间一般在微秒级别，所以，一个操作达到了近2s，不可避免地会阻塞主线程。</li></ol><p>经过刚刚的分析，很显然， <strong>bigkey删除操作就是Redis的第二个阻塞点</strong>。删除操作对Redis实例性能的负面影响很大，而且在实际业务开发时容易被忽略，所以一定要重视它。</p><p>既然频繁删除键值对都是潜在的阻塞点了，那么，在Redis的数据库级别操作中，清空数据库（例如FLUSHDB和FLUSHALL操作）必然也是一个潜在的阻塞风险，因为它涉及到删除和释放所有的键值对。所以，这就是 <strong>Redis的第三个阻塞点：清空数据库</strong>。</p><p><strong>2.和磁盘交互时的阻塞点</strong></p><p>我之所以把Redis与磁盘的交互单独列为一类，主要是因为磁盘IO一般都是比较费时费力的，需要重点关注。</p><p>幸运的是，Redis开发者早已认识到磁盘IO会带来阻塞，所以就把Redis进一步设计为采用子进程的方式生成RDB快照文件，以及执行AOF日志重写操作。这样一来，这两个操作由子进程负责执行，慢速的磁盘IO就不会阻塞主线程了。</p><p>但是，Redis直接记录AOF日志时，会根据不同的写回策略对数据做落盘保存。一个同步写磁盘的操作的耗时大约是1～2ms，如果有大量的写操作需要记录在AOF日志中，并同步写回的话，就会阻塞主线程了。这就得到了Redis的 <strong>第四个阻塞点了：AOF日志同步写</strong>。</p><p><strong>3.主从节点交互时的阻塞点</strong></p><p>在主从集群中，主库需要生成RDB文件，并传输给从库。主库在复制的过程中，创建和传输RDB文件都是由子进程来完成的，不会阻塞主线程。但是，对于从库来说，它在接收了RDB文件后，需要使用FLUSHDB命令清空当前数据库，这就正好撞上了刚才我们分析的 <strong>第三个阻塞点。</strong></p><p>此外，从库在清空当前数据库后，还需要把RDB文件加载到内存，这个过程的快慢和RDB文件的大小密切相关，RDB文件越大，加载过程越慢，所以， <strong>加载RDB文件就成为了Redis的第五个阻塞点</strong>。</p><p><strong>4.切片集群实例交互时的阻塞点</strong></p><p>最后，当我们部署Redis切片集群时，每个Redis实例上分配的哈希槽信息需要在不同实例间进行传递，同时，当需要进行负载均衡或者有实例增删时，数据会在不同的实例间进行迁移。不过，哈希槽的信息量不大，而数据迁移是渐进式执行的，所以，一般来说，这两类操作对Redis主线程的阻塞风险不大。</p><p>不过，如果你使用了Redis Cluster方案，而且同时正好迁移的是bigkey的话，就会造成主线程的阻塞，因为Redis Cluster使用了同步迁移。我将在第33讲中向你介绍不同切片集群方案对数据迁移造成的阻塞的解决方法，这里你只需要知道，当没有bigkey时，切片集群的各实例在进行交互时不会阻塞主线程，就可以了。</p><p>好了，你现在已经了解了Redis的各种关键操作，以及其中的阻塞式操作，我们来总结下刚刚找到的五个阻塞点：</p><ul><li>集合全量查询和聚合操作；</li><li>bigkey删除；</li><li>清空数据库；</li><li>AOF日志同步写；</li><li>从库加载RDB文件。</li></ul><p>如果在主线程中执行这些操作，必然会导致主线程长时间无法服务其他请求。为了避免阻塞式操作，Redis提供了异步线程机制。所谓的异步线程机制，就是指，Redis会启动一些子线程，然后把一些任务交给这些子线程，让它们在后台完成，而不再由主线程来执行这些任务。使用异步线程机制执行操作，可以避免阻塞主线程。</p><p>不过，这个时候，问题来了：这五大阻塞式操作都可以被异步执行吗？</p><h2 id="哪些阻塞点可以异步执行？"><a href="#哪些阻塞点可以异步执行？" class="headerlink" title="哪些阻塞点可以异步执行？"></a>哪些阻塞点可以异步执行？</h2><p>在分析阻塞式操作的异步执行的可行性之前，我们先来了解下异步执行对操作的要求。</p><p>如果一个操作能被异步执行，就意味着，它并不是Redis主线程的关键路径上的操作。我再解释下关键路径上的操作是啥。这就是说，客户端把请求发送给Redis后，等着Redis返回数据结果的操作。</p><p>这么说可能有点抽象，我画一张图片来解释下。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/f196035e3d2ba65257b211ed436b0b61.jpg"></p><p>主线程接收到操作1后，因为操作1并不用给客户端返回具体的数据，所以，主线程可以把它交给后台子线程来完成，同时只要给客户端返回一个“OK”结果就行。在子线程执行操作1的时候，客户端又向Redis实例发送了操作2，而此时，客户端是需要使用操作2返回的数据结果的，如果操作2不返回结果，那么，客户端将一直处于等待状态。</p><p>在这个例子中，操作1就不算关键路径上的操作，因为它不用给客户端返回具体数据，所以可以由后台子线程异步执行。而操作2需要把结果返回给客户端，它就是关键路径上的操作，所以主线程必须立即把这个操作执行完。</p><p>对于Redis来说， <strong>读操作是典型的关键路径操作</strong>，因为客户端发送了读操作之后，就会等待读取的数据返回，以便进行后续的数据处理。而Redis的第一个阻塞点“集合全量查询和聚合操作”都涉及到了读操作，所以，它们是不能进行异步操作了。</p><p>我们再来看看删除操作。删除操作并不需要给客户端返回具体的数据结果，所以不算是关键路径操作。而我们刚才总结的第二个阻塞点“bigkey删除”，和第三个阻塞点“清空数据库”，都是对数据做删除，并不在关键路径上。因此，我们可以使用后台子线程来异步执行删除操作。</p><p>对于第四个阻塞点“AOF日志同步写”来说，为了保证数据可靠性，Redis实例需要保证AOF日志中的操作记录已经落盘，这个操作虽然需要实例等待，但它并不会返回具体的数据结果给实例。所以，我们也可以启动一个子线程来执行AOF日志的同步写，而不用让主线程等待AOF日志的写完成。</p><p>最后，我们再来看下“从库加载RDB文件”这个阻塞点。从库要想对客户端提供数据存取服务，就必须把RDB文件加载完成。所以，这个操作也属于关键路径上的操作，我们必须让从库的主线程来执行。</p><p>对于Redis的五大阻塞点来说，除了“集合全量查询和聚合操作”和“从库加载RDB文件”，其他三个阻塞点涉及的操作都不在关键路径上，所以，我们可以使用Redis的异步子线程机制来实现bigkey删除，清空数据库，以及AOF日志同步写。</p><p>那么，Redis实现的异步子线程机制具体是怎么执行呢？</p><h2 id="异步的子线程机制"><a href="#异步的子线程机制" class="headerlink" title="异步的子线程机制"></a>异步的子线程机制</h2><p>Redis主线程启动后，会使用操作系统提供的pthread_create函数创建3个子线程，分别由它们负责AOF日志写操作、键值对删除以及文件关闭的异步执行。</p><p>主线程通过一个链表形式的任务队列和子线程进行交互。当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成。</p><p>但实际上，这个时候删除还没有执行，等到后台子线程从任务队列中读取任务后，才开始实际删除键值对，并释放相应的内存空间。因此，我们把这种异步删除也称为惰性删除（lazy free）。此时，删除或清空操作不会阻塞主线程，这就避免了对主线程的性能影响。</p><p>和惰性删除类似，当AOF日志配置成everysec选项后，主线程会把AOF写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入AOF日志，这样主线程就不用一直等待AOF日志写完了。</p><p>下面这张图展示了Redis中的异步子线程执行机制，你可以再看下，加深印象。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/ae004728bfe6d3771c7424e4161e7969.jpg"></p><p>这里有个地方需要你注意一下，异步的键值对删除和数据库清空操作是Redis 4.0后提供的功能，Redis也提供了新的命令来执行这两个操作。</p><ul><li>键值对删除：当你的集合类型中有大量元素（例如有百万级别或千万级别元素）需要删除时，我建议你使用UNLINK命令。</li><li>清空数据库：可以在FLUSHDB和FLUSHALL命令后加上ASYNC选项，这样就可以让后台子线程异步地清空数据库，如下所示：</li></ul><pre class="line-numbers language-none"><code class="language-none">FLUSHDB ASYNCFLUSHALL AYSNC<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这节课，我们学习了Redis实例运行时的4大类交互对象：客户端、磁盘、主从库实例、切片集群实例。基于这4大类交互对象，我们梳理了会导致Redis性能受损的5大阻塞点，包括集合全量查询和聚合操作、bigkey删除、清空数据库、AOF日志同步写，以及从库加载RDB文件。</p><p>在这5大阻塞点中，bigkey删除、清空数据库、AOF日志同步写不属于关键路径操作，可以使用异步子线程机制来完成。Redis在运行时会创建三个子线程，主线程会通过一个任务队列和三个子线程进行交互。子线程会根据任务的具体类型，来执行相应的异步操作。</p><p>不过，异步删除操作是Redis 4.0以后才有的功能，如果你使用的是4.0之前的版本，当你遇到bigkey删除时，我给你个小建议：先使用集合类型提供的SCAN命令读取数据，然后再进行删除。因为用SCAN命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量key给主线程带来的阻塞。</p><p>例如，对于Hash类型的bigkey删除，你可以使用HSCAN命令，每次从Hash集合中获取一部分键值对（例如200个），再使用HDEL删除这些键值对，这样就可以把删除压力分摊到多次操作中，那么，每次删除操作的耗时就不会太长，也就不会阻塞主线程了。</p><p>最后，我想再提一下，集合全量查询和聚合操作、从库加载RDB文件是在关键路径上，无法使用异步操作来完成。对于这两个阻塞点，我也给你两个小建议。</p><ul><li>集合全量查询和聚合操作：可以使用SCAN命令，分批读取数据，再在客户端进行聚合计算；</li><li>从库加载RDB文件：把主库的数据量大小控制在2~4GB左右，以保证RDB文件能以较快的速度加载。</li></ul><h2 id="每课一问"><a href="#每课一问" class="headerlink" title="每课一问"></a>每课一问</h2><p>按照惯例，我给你提一个小问题：我们今天学习了关键路径上的操作，你觉得，Redis的写操作（例如SET、HSET、SADD等）是在关键路径上吗？</p><p>欢迎在留言区写下你的思考和答案，我们一起交流讨论。如果你觉得今天的内容对你有所帮助，也欢迎你帮我分享给更多人，我们下节课见。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;16-异步机制：如何避免单线程模型的阻塞？&quot;&gt;&lt;a href=&quot;#16-异步机制：如何避免单线程模型的阻塞？&quot; class=&quot;headerlink&quot; title=&quot;16 | 异步机制：如何避免单线程模型的阻塞？&quot;&gt;&lt;/a&gt;16 | 异步机制：如何避免单线程模型的阻</summary>
      
    
    
    
    <category term="Redis核心技术与实战" scheme="https://zhuansun.github.io/geekbang/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    
    
  </entry>
  
  <entry>
    <title>15 | 消息队列的考验：Redis有哪些解决方案？</title>
    <link href="https://zhuansun.github.io/geekbang/posts/4131872047.html"/>
    <id>https://zhuansun.github.io/geekbang/posts/4131872047.html</id>
    <published>2024-03-04T22:10:14.000Z</published>
    <updated>2024-03-21T07:44:22.363Z</updated>
    
    <content type="html"><![CDATA[<h1 id="15-消息队列的考验：Redis有哪些解决方案？"><a href="#15-消息队列的考验：Redis有哪些解决方案？" class="headerlink" title="15 | 消息队列的考验：Redis有哪些解决方案？"></a>15 | 消息队列的考验：Redis有哪些解决方案？</h1><p>你好，我是蒋德钧。</p><p>现在的互联网应用基本上都是采用分布式系统架构进行设计的，而很多分布式系统必备的一个基础软件就是消息队列。</p><p>消息队列要能支持组件通信消息的快速读写，而Redis本身支持数据的高速访问，正好可以满足消息队列的读写性能需求。不过，除了性能，消息队列还有其他的要求，所以，很多人都很关心一个问题：“Redis适合做消息队列吗？”</p><p>其实，这个问题的背后，隐含着两方面的核心问题：</p><ul><li>消息队列的消息存取需求是什么？</li><li>Redis如何实现消息队列的需求？</li></ul><p>这节课，我们就来聊一聊消息队列的特征和Redis提供的消息队列方案。只有把这两方面的知识和实践经验串连起来，才能彻底理解基于Redis实现消息队列的技术实践。以后当你需要为分布式系统组件做消息队列选型时，就可以根据组件通信量和消息通信速度的要求，选择出适合的Redis消息队列方案了。</p><p>我们先来看下第一个问题：消息队列的消息读取有什么样的需求？</p><h2 id="消息队列的消息存取需求"><a href="#消息队列的消息存取需求" class="headerlink" title="消息队列的消息存取需求"></a>消息队列的消息存取需求</h2><p>我先介绍一下消息队列存取消息的过程。在分布式系统中，当两个组件要基于消息队列进行通信时，一个组件会把要处理的数据以消息的形式传递给消息队列，然后，这个组件就可以继续执行其他操作了；远端的另一个组件从消息队列中把消息读取出来，再在本地进行处理。</p><p>为了方便你理解，我还是借助一个例子来解释一下。</p><p>假设组件1需要对采集到的数据进行求和计算，并写入数据库，但是，消息到达的速度很快，组件1没有办法及时地既做采集，又做计算，并且写入数据库。所以，我们可以使用基于消息队列的通信，让组件1把数据x和y保存为JSON格式的消息，再发到消息队列，这样它就可以继续接收新的数据了。组件2则异步地从消息队列中把数据读取出来，在服务器2上进行求和计算后，再写入数据库。这个过程如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/d79d46ec4aa22bf46fde3ae1a99fc2bc.jpg"></p><p>我们一般把消息队列中发送消息的组件称为生产者（例子中的组件1），把接收消息的组件称为消费者（例子中的组件2），下图展示了一个通用的消息队列的架构模型：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/f470bb957c1faff674c08b1fa65a3a62.jpg"></p><p>在使用消息队列时，消费者可以异步读取生产者消息，然后再进行处理。这样一来，即使生产者发送消息的速度远远超过了消费者处理消息的速度，生产者已经发送的消息也可以缓存在消息队列中，避免阻塞生产者，这是消息队列作为分布式组件通信的一大优势。</p><p><strong>不过，消息队列在存取消息时，必须要满足三个需求，分别是消息保序、处理重复的消息和保证消息可靠性。</strong></p><h3 id="需求一：消息保序"><a href="#需求一：消息保序" class="headerlink" title="需求一：消息保序"></a>需求一：消息保序</h3><p>虽然消费者是异步处理消息，但是，消费者仍然需要按照生产者发送消息的顺序来处理消息，避免后发送的消息被先处理了。对于要求消息保序的场景来说，一旦出现这种消息被乱序处理的情况，就可能会导致业务逻辑被错误执行，从而给业务方造成损失。</p><p>我们来看一个更新商品库存的场景。</p><p>假设生产者负责接收库存更新请求，消费者负责实际更新库存，现有库存量是10。生产者先后发送了消息1和消息2，消息1要把商品X的库存记录更新为5，消息2是把商品X库存更新为3。如果消息1和2在消息队列中无法保序，出现消息2早于消息1被处理的情况，那么，很显然，库存更新就出错了。这是业务应用无法接受的。</p><p>面对这种情况，你可能会想到一种解决方案：不要把更新后的库存量作为生产者发送的消息，而是 <strong>把库存扣除值作为消息的内容</strong>。这样一来，消息1是扣减库存量5，消息2是扣减库存量2。如果消息1和消息2之间没有库存查询请求的话，即使消费者先处理消息2，再处理消息1，这个方案也能够保证最终的库存量是正确的，也就是库存量为3。</p><p>但是，我们还需要考虑这样一种情况：假如消费者收到了这样三条消息：消息1是扣减库存量5，消息2是读取库存量，消息3是扣减库存量2，此时，如果消费者先处理了消息3（把库存量扣减2），那么库存量就变成了8。然后，消费者处理了消息2，读取当前的库存量是8，这就会出现库存量查询不正确的情况。从业务应用层面看，消息1、2、3应该是顺序执行的，所以，消息2查询到的应该是扣减了5以后的库存量，而不是扣减了2以后的库存量。所以，用库存扣除值作为消息的方案，在消息中同时包含读写操作的场景下，会带来数据读取错误的问题。而且，这个方案还会面临一个问题，那就是重复消息处理。</p><h3 id="需求二：重复消息处理"><a href="#需求二：重复消息处理" class="headerlink" title="需求二：重复消息处理"></a>需求二：重复消息处理</h3><p>消费者从消息队列读取消息时，有时会因为网络堵塞而出现消息重传的情况。此时，消费者可能会收到多条重复的消息。对于重复的消息，消费者如果多次处理的话，就可能造成一个业务逻辑被多次执行，如果业务逻辑正好是要修改数据，那就会出现数据被多次修改的问题了。</p><p>还是以库存更新为例，假设消费者收到了一次消息1，要扣减库存量5，然后又收到了一次消息1，那么，如果消费者无法识别这两条消息实际是一条相同消息的话，就会执行两次扣减库存量5的操作，此时，库存量就不对了。这当然也是无法接受的。</p><h3 id="需求三：消息可靠性保证"><a href="#需求三：消息可靠性保证" class="headerlink" title="需求三：消息可靠性保证"></a>需求三：消息可靠性保证</h3><p>另外，消费者在处理消息的时候，还可能出现因为故障或宕机导致消息没有处理完成的情况。此时，消息队列需要能提供消息可靠性的保证，也就是说，当消费者重启后，可以重新读取消息再次进行处理，否则，就会出现消息漏处理的问题了。</p><p>Redis的List和Streams两种数据类型，就可以满足消息队列的这三个需求。我们先来了解下基于List的消息队列实现方法。</p><h2 id="基于List的消息队列解决方案"><a href="#基于List的消息队列解决方案" class="headerlink" title="基于List的消息队列解决方案"></a>基于List的消息队列解决方案</h2><p>List本身就是按先进先出的顺序对数据进行存取的，所以，如果使用List作为消息队列保存消息的话，就已经能满足消息保序的需求了。</p><p>具体来说，生产者可以使用LPUSH命令把要发送的消息依次写入List，而消费者则可以使用RPOP命令，从List的另一端按照消息的写入顺序，依次读取消息并进行处理。</p><p>如下图所示，生产者先用LPUSH写入了两条库存消息，分别是5和3，表示要把库存更新为5和3；消费者则用RPOP把两条消息依次读出，然后进行相应的处理。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/b0959216cbce7ac383ce206b8884777c.jpg"></p><p>不过，在消费者读取数据时，有一个潜在的性能风险点。</p><p>在生产者往List中写入数据时，List并不会主动地通知消费者有新消息写入，如果消费者想要及时处理消息，就需要在程序中不停地调用RPOP命令（比如使用一个while(1)循环）。如果有新消息写入，RPOP命令就会返回结果，否则，RPOP命令返回空值，再继续循环。</p><p>所以，即使没有新消息写入List，消费者也要不停地调用RPOP命令，这就会导致消费者程序的CPU一直消耗在执行RPOP命令上，带来不必要的性能损失。</p><p>为了解决这个问题，Redis提供了BRPOP命令。 <strong>BRPOP命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据</strong>。和消费者程序自己不停地调用RPOP命令相比，这种方式能节省CPU开销。</p><p>消息保序的问题解决了，接下来，我们还需要考虑解决重复消息处理的问题，这里其实有一个要求： <strong>消费者程序本身能对重复消息进行判断。</strong></p><p>一方面，消息队列要能给每一个消息提供全局唯一的ID号；另一方面，消费者程序要把已经处理过的消息的ID号记录下来。</p><p>当收到一条消息后，消费者程序就可以对比收到的消息ID和记录的已处理过的消息ID，来判断当前收到的消息有没有经过处理。如果已经处理过，那么，消费者程序就不再进行处理了。这种处理特性也称为幂等性，幂等性就是指，对于同一条消息，消费者收到一次的处理结果和收到多次的处理结果是一致的。</p><p>不过，List本身是不会为每个消息生成ID号的，所以，消息的全局唯一ID号就需要生产者程序在发送消息前自行生成。生成之后，我们在用LPUSH命令把消息插入List时，需要在消息中包含这个全局唯一ID。</p><p>例如，我们执行以下命令，就把一条全局ID为101030001、库存量为5的消息插入了消息队列：</p><pre class="line-numbers language-none"><code class="language-none">LPUSH mq &quot;101030001:stock:5&quot;(integer) 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>最后，我们再来看下，List类型是如何保证消息可靠性的。</p><p>当消费者程序从List中读取一条消息后，List就不会再留存这条消息了。所以，如果消费者程序在处理消息的过程出现了故障或宕机，就会导致消息没有处理完成，那么，消费者程序再次启动后，就没法再次从List中读取消息了。</p><p>为了留存消息，List类型提供了BRPOPLPUSH命令，这个命令的作用是让消费者程序从一个List中读取消息，同时，Redis会把这个消息再插入到另一个List（可以叫作备份List）留存。这样一来，如果消费者程序读了消息但没能正常处理，等它重启后，就可以从备份List中重新读取消息并进行处理了。</p><p>我画了一张示意图，展示了使用BRPOPLPUSH命令留存消息，以及消费者再次读取消息的过程，你可以看下。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/5045395da08317b546aab7eb698d013d.jpg"></p><p>生产者先用LPUSH把消息“5”“3”插入到消息队列mq中。消费者程序使用BRPOPLPUSH命令读取消息“5”，同时，消息“5”还会被Redis插入到mqback队列中。如果消费者程序处理消息“5”时宕机了，等它重启后，可以从mqback中再次读取消息“5”，继续处理。</p><p>好了，到这里，你可以看到，基于List类型，我们可以满足分布式组件对消息队列的三大需求。但是，在用List做消息队列时，我们还可能遇到过一个问题： <strong>生产者消息发送很快，而消费者处理消息的速度比较慢，这就导致List中的消息越积越多，给Redis的内存带来很大压力</strong>。</p><p>这个时候，我们希望启动多个消费者程序组成一个消费组，一起分担处理List中的消息。但是，List类型并不支持消费组的实现。那么，还有没有更合适的解决方案呢？这就要说到Redis从5.0版本开始提供的Streams数据类型了。</p><p>和List相比，Streams同样能够满足消息队列的三大需求。而且，它还支持消费组形式的消息读取。接下来，我们就来了解下Streams的使用方法。</p><h2 id="基于Streams的消息队列解决方案"><a href="#基于Streams的消息队列解决方案" class="headerlink" title="基于Streams的消息队列解决方案"></a>基于Streams的消息队列解决方案</h2><p>Streams是Redis专门为消息队列设计的数据类型，它提供了丰富的消息队列操作命令。</p><ul><li>XADD：插入消息，保证有序，可以自动生成全局唯一ID；</li><li>XREAD：用于读取消息，可以按ID读取数据；</li><li>XREADGROUP：按消费组形式读取消息；</li><li>XPENDING和XACK：XPENDING命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息，而XACK命令用于向消息队列确认消息处理已完成。</li></ul><p>首先，我们来学习下Streams类型存取消息的操作XADD。</p><p>XADD命令可以往消息队列中插入新消息，消息的格式是键-值对形式。对于插入的每一条消息，Streams可以自动为其生成一个全局唯一的ID。</p><p>比如说，我们执行下面的命令，就可以往名称为mqstream的消息队列中插入一条消息，消息的键是repo，值是5。其中，消息队列名称后面的 <code>*</code>，表示让Redis为插入的数据自动生成一个全局唯一的ID，例如“1599203861727-0”。当然，我们也可以不用 <code>*</code>，直接在消息队列名称后自行设定一个ID号，只要保证这个ID号是全局唯一的就行。不过，相比自行设定ID号，使用 <code>*</code> 会更加方便高效。</p><pre class="line-numbers language-none"><code class="language-none">XADD mqstream * repo 5&quot;1599203861727-0&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>可以看到，消息的全局唯一ID由两部分组成，第一部分“1599203861727”是数据插入时，以毫秒为单位计算的当前服务器时间，第二部分表示插入消息在当前毫秒内的消息序号，这是从0开始编号的。例如，“1599203861727-0”就表示在“1599203861727”毫秒内的第1条消息。</p><p>当消费者需要读取消息时，可以直接使用XREAD命令从消息队列中读取。</p><p>XREAD在读取消息时，可以指定一个消息ID，并从这个消息ID的下一条消息开始进行读取。</p><p>例如，我们可以执行下面的命令，从ID号为1599203861727-0的消息开始，读取后续的所有消息（示例中一共3条）。</p><pre class="line-numbers language-none"><code class="language-none">XREAD BLOCK 100 STREAMS  mqstream 1599203861727-01) 1) &quot;mqstream&quot;   2) 1) 1) &quot;1599274912765-0&quot;         2) 1) &quot;repo&quot;            2) &quot;3&quot;      2) 1) &quot;1599274925823-0&quot;         2) 1) &quot;repo&quot;            2) &quot;2&quot;      3) 1) &quot;1599274927910-0&quot;         2) 1) &quot;repo&quot;            2) &quot;1&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>另外，消费者也可以在调用XRAED时设定block配置项，实现类似于BRPOP的阻塞读取操作。当消息队列中没有消息时，一旦设置了block配置项，XREAD就会阻塞，阻塞的时长可以在block配置项进行设置。</p><p>举个例子，我们来看一下下面的命令，其中，命令最后的“$”符号表示读取最新的消息，同时，我们设置了block 10000的配置项，10000的单位是毫秒，表明XREAD在读取最新消息时，如果没有消息到来，XREAD将阻塞10000毫秒（即10秒），然后再返回。下面命令中的XREAD执行后，消息队列mqstream中一直没有消息，所以，XREAD在10秒后返回空值（nil）。</p><pre class="line-numbers language-none"><code class="language-none">XREAD block 10000 streams mqstream $(nil)(10.00s)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>刚刚讲到的这些操作是List也支持的，接下来，我们再来学习下Streams特有的功能。</p><p>Streams本身可以使用XGROUP创建消费组，创建消费组之后，Streams可以使用XREADGROUP命令让消费组内的消费者读取消息，</p><p>例如，我们执行下面的命令，创建一个名为group1的消费组，这个消费组消费的消息队列是mqstream。</p><pre class="line-numbers language-none"><code class="language-none">XGROUP create mqstream group1 0OK<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>然后，我们再执行一段命令，让group1消费组里的消费者consumer1从mqstream中读取所有消息，其中，命令最后的参数“&gt;”，表示从第一条尚未被消费的消息开始读取。因为在consumer1读取消息前，group1中没有其他消费者读取过消息，所以，consumer1就得到mqstream消息队列中的所有消息了（一共4条）。</p><pre class="line-numbers language-none"><code class="language-none">XREADGROUP group group1 consumer1 streams mqstream &gt;1) 1) &quot;mqstream&quot;   2) 1) 1) &quot;1599203861727-0&quot;         2) 1) &quot;repo&quot;            2) &quot;5&quot;      2) 1) &quot;1599274912765-0&quot;         2) 1) &quot;repo&quot;            2) &quot;3&quot;      3) 1) &quot;1599274925823-0&quot;         2) 1) &quot;repo&quot;            2) &quot;2&quot;      4) 1) &quot;1599274927910-0&quot;         2) 1) &quot;repo&quot;            2) &quot;1&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>需要注意的是，消息队列中的消息一旦被消费组里的一个消费者读取了，就不能再被该消费组内的其他消费者读取了。比如说，我们执行完刚才的XREADGROUP命令后，再执行下面的命令，让group1内的consumer2读取消息时，consumer2读到的就是空值，因为消息已经被consumer1读取完了，如下所示：</p><pre class="line-numbers language-none"><code class="language-none">XREADGROUP group group1 consumer2  streams mqstream 01) 1) &quot;mqstream&quot;   2) (empty list or set)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>使用消费组的目的是让组内的多个消费者共同分担读取消息，所以，我们通常会让每个消费者读取部分消息，从而实现消息读取负载在多个消费者间是均衡分布的。例如，我们执行下列命令，让group2中的consumer1、2、3各自读取一条消息。</p><pre class="line-numbers language-none"><code class="language-none">XREADGROUP group group2 consumer1 count 1 streams mqstream &gt;1) 1) &quot;mqstream&quot;   2) 1) 1) &quot;1599203861727-0&quot;         2) 1) &quot;repo&quot;            2) &quot;5&quot;XREADGROUP group group2 consumer2 count 1 streams mqstream &gt;1) 1) &quot;mqstream&quot;   2) 1) 1) &quot;1599274912765-0&quot;         2) 1) &quot;repo&quot;            2) &quot;3&quot;XREADGROUP group group2 consumer3 count 1 streams mqstream &gt;1) 1) &quot;mqstream&quot;   2) 1) 1) &quot;1599274925823-0&quot;         2) 1) &quot;repo&quot;            2) &quot;2&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>为了保证消费者在发生故障或宕机再次重启后，仍然可以读取未处理完的消息，Streams会自动使用内部队列（也称为PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用XACK命令通知Streams“消息已经处理完成”。如果消费者没有成功处理消息，它就不会给Streams发送XACK命令，消息仍然会留存。此时，消费者可以在重启后，用XPENDING命令查看已读取、但尚未确认处理完成的消息。</p><p>例如，我们来查看一下group2中各个消费者已读取、但尚未确认的消息个数。其中，XPENDING返回结果的第二、三行分别表示group2中所有消费者读取的消息最小ID和最大ID。</p><pre class="line-numbers language-none"><code class="language-none">XPENDING mqstream group21) (integer) 32) &quot;1599203861727-0&quot;3) &quot;1599274925823-0&quot;4) 1) 1) &quot;consumer1&quot;      2) &quot;1&quot;   2) 1) &quot;consumer2&quot;      2) &quot;1&quot;   3) 1) &quot;consumer3&quot;      2) &quot;1&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果我们还需要进一步查看某个消费者具体读取了哪些数据，可以执行下面的命令：</p><pre class="line-numbers language-none"><code class="language-none">XPENDING mqstream group2 - + 10 consumer21) 1) &quot;1599274912765-0&quot;   2) &quot;consumer2&quot;   3) (integer) 513336   4) (integer) 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到，consumer2已读取的消息的ID是1599274912765-0。</p><p>一旦消息1599274912765-0被consumer2处理了，consumer2就可以使用XACK命令通知Streams，然后这条消息就会被删除。当我们再使用XPENDING命令查看时，就可以看到，consumer2已经没有已读取、但尚未确认处理的消息了。</p><pre class="line-numbers language-none"><code class="language-none"> XACK mqstream group2 1599274912765-0(integer) 1XPENDING mqstream group2 - + 10 consumer2(empty list or set)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>现在，我们就知道了用Streams实现消息队列的方法，我还想再强调下，Streams是Redis 5.0专门针对消息队列场景设计的数据类型，如果你的Redis是5.0及5.0以后的版本，就可以考虑把Streams用作消息队列了。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这节课，我们学习了分布式系统组件使用消息队列时的三大需求：消息保序、重复消息处理和消息可靠性保证，这三大需求可以进一步转换为对消息队列的三大要求：消息数据有序存取，消息数据具有全局唯一编号，以及消息数据在消费完成后被删除。</p><p>我画了一张表格，汇总了用List和Streams实现消息队列的特点和区别。当然，在实践的过程中，你也可以根据新的积累，进一步补充和完善这张表。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/b2d6581e43f573da6218e790bb8c6814.jpg"></p><p>其实，关于Redis是否适合做消息队列，业界一直是有争论的。很多人认为，要使用消息队列，就应该采用Kafka、RabbitMQ这些专门面向消息队列场景的软件，而Redis更加适合做缓存。</p><p>根据这些年做Redis研发工作的经验，我的看法是：Redis是一个非常轻量级的键值数据库，部署一个Redis实例就是启动一个进程，部署Redis集群，也就是部署多个Redis实例。而Kafka、RabbitMQ部署时，涉及额外的组件，例如Kafka的运行就需要再部署ZooKeeper。相比Redis来说，Kafka和RabbitMQ一般被认为是重量级的消息队列。</p><p>所以，关于是否用Redis做消息队列的问题，不能一概而论，我们需要考虑业务层面的数据体量，以及对性能、可靠性、可扩展性的需求。如果分布式系统中的组件消息通信量不大，那么，Redis只需要使用有限的内存空间就能满足消息存储的需求，而且，Redis的高性能特性能支持快速的消息读写，不失为消息队列的一个好的解决方案。</p><h2 id="每课一问"><a href="#每课一问" class="headerlink" title="每课一问"></a>每课一问</h2><p>按照惯例，我给你提个小问题。如果一个生产者发送给消息队列的消息，需要被多个消费者进行读取和处理（例如，一个消息是一条从业务系统采集的数据，既要被消费者1读取进行实时计算，也要被消费者2读取并留存到分布式文件系统HDFS中，以便后续进行历史查询），你会使用Redis的什么数据类型来解决这个问题呢？</p><p>欢迎在留言区写下你的思考和答案，如果觉得今天的内容对你有所帮助，也欢迎你帮我分享给更多人。我们下节课见。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;15-消息队列的考验：Redis有哪些解决方案？&quot;&gt;&lt;a href=&quot;#15-消息队列的考验：Redis有哪些解决方案？&quot; class=&quot;headerlink&quot; title=&quot;15 | 消息队列的考验：Redis有哪些解决方案？&quot;&gt;&lt;/a&gt;15 | 消息队列的考验</summary>
      
    
    
    
    <category term="Redis核心技术与实战" scheme="https://zhuansun.github.io/geekbang/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    
    
  </entry>
  
  <entry>
    <title>17 | 为什么CPU结构也会影响Redis的性能？</title>
    <link href="https://zhuansun.github.io/geekbang/posts/2330727060.html"/>
    <id>https://zhuansun.github.io/geekbang/posts/2330727060.html</id>
    <published>2024-03-04T22:10:14.000Z</published>
    <updated>2024-03-21T07:44:22.367Z</updated>
    
    <content type="html"><![CDATA[<h1 id="17-为什么CPU结构也会影响Redis的性能？"><a href="#17-为什么CPU结构也会影响Redis的性能？" class="headerlink" title="17 | 为什么CPU结构也会影响Redis的性能？"></a>17 | 为什么CPU结构也会影响Redis的性能？</h1><p>你好，我是蒋德钧。</p><p>很多人都认为Redis和CPU的关系很简单，就是Redis的线程在CPU上运行，CPU快，Redis处理请求的速度也很快。</p><p>这种认知其实是片面的。CPU的多核架构以及多CPU架构，也会影响到Redis的性能。如果不了解CPU对Redis的影响，在对Redis的性能进行调优时，就可能会遗漏一些调优方法，不能把Redis的性能发挥到极限。</p><p>今天，我们就来学习下目前主流服务器的CPU架构，以及基于CPU多核架构和多CPU架构优化Redis性能的方法。</p><h2 id="主流的CPU架构"><a href="#主流的CPU架构" class="headerlink" title="主流的CPU架构"></a>主流的CPU架构</h2><p>要了解CPU对Redis具体有什么影响，我们得先了解一下CPU架构。</p><p>一个CPU处理器中一般有多个运行核心，我们把一个运行核心称为一个物理核，每个物理核都可以运行应用程序。每个物理核都拥有私有的一级缓存（Level 1 cache，简称L1 cache），包括一级指令缓存和一级数据缓存，以及私有的二级缓存（Level 2 cache，简称L2 cache）。</p><p>这里提到了一个概念，就是物理核的私有缓存。它其实是指缓存空间只能被当前的这个物理核使用，其他的物理核无法对这个核的缓存空间进行数据存取。我们来看一下CPU物理核的架构。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/c2d620c012a82e825570df631a7fbc3a.jpg"></p><p>因为L1和L2缓存是每个物理核私有的，所以，当数据或指令保存在L1、L2缓存时，物理核访问它们的延迟不超过10纳秒，速度非常快。那么，如果Redis把要运行的指令或存取的数据保存在L1和L2缓存的话，就能高速地访问这些指令和数据。</p><p>但是，这些L1和L2缓存的大小受限于处理器的制造技术，一般只有KB级别，存不下太多的数据。如果L1、L2缓存中没有所需的数据，应用程序就需要访问内存来获取数据。而应用程序的访存延迟一般在百纳秒级别，是访问L1、L2缓存的延迟的近10倍，不可避免地会对性能造成影响。</p><p>所以，不同的物理核还会共享一个共同的三级缓存（Level 3 cache，简称为L3 cache）。L3缓存能够使用的存储资源比较多，所以一般比较大，能达到几MB到几十MB，这就能让应用程序缓存更多的数据。当L1、L2缓存中没有数据缓存时，可以访问L3，尽可能避免访问内存。</p><p>另外，现在主流的CPU处理器中，每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用L1、L2缓存。</p><p>为了方便你理解，我用一张图展示一下物理核和逻辑核，以及一级、二级缓存的关系。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/d9689a38cbe67c3008d8ba99663c2f09.jpg"></p><p>在主流的服务器上，一个CPU处理器会有10到20多个物理核。同时，为了提升服务器的处理能力，服务器上通常还会有多个CPU处理器（也称为多CPU Socket），每个处理器有自己的物理核（包括L1、L2缓存），L3缓存，以及连接的内存，同时，不同处理器间通过总线连接。</p><p>下图显示的就是多CPU Socket的架构，图中有两个Socket，每个Socket有两个物理核。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/5ceb2ab6f61c064284c8f8811431bc3d.jpg"></p><p><strong>在多CPU架构上，应用程序可以在不同的处理器上运行</strong>。在刚才的图中，Redis可以先在Socket 1上运行一段时间，然后再被调度到Socket 2上运行。</p><p>但是，有个地方需要你注意一下：如果应用程序先在一个Socket上运行，并且把数据保存到了内存，然后被调度到另一个Socket上运行，此时，应用程序再进行内存访问时，就需要访问之前Socket上连接的内存，这种访问属于 <strong>远端内存访问</strong>。 <strong>和访问Socket直接连接的内存相比，远端内存访问会增加应用程序的延迟。</strong></p><p>在多CPU架构下，一个应用程序访问所在Socket的本地内存和访问远端内存的延迟并不一致，所以，我们也把这个架构称为非统一内存访问架构（Non-Uniform Memory Access，NUMA架构）。</p><p>到这里，我们就知道了主流的CPU多核架构和多CPU架构，我们来简单总结下CPU架构对应用程序运行的影响。</p><ul><li>L1、L2缓存中的指令和数据的访问速度很快，所以，充分利用L1、L2缓存，可以有效缩短应用程序的执行时间；</li><li>在NUMA架构下，如果应用程序从一个Socket上调度到另一个Socket上，就可能会出现远端内存访问的情况，这会直接增加应用程序的执行时间。</li></ul><p>接下来，我们就先来了解下CPU多核是如何影响Redis性能的。</p><h2 id="CPU多核对Redis性能的影响"><a href="#CPU多核对Redis性能的影响" class="headerlink" title="CPU多核对Redis性能的影响"></a>CPU多核对Redis性能的影响</h2><p>在一个CPU核上运行时，应用程序需要记录自身使用的软硬件资源信息（例如栈指针、CPU核的寄存器值等），我们把这些信息称为 <strong>运行时信息</strong>。同时，应用程序访问最频繁的指令和数据还会被缓存到L1、L2缓存上，以便提升执行速度。</p><p>但是，在多核CPU的场景下，一旦应用程序需要在一个新的CPU核上运行，那么，运行时信息就需要重新加载到新的CPU核上。而且，新的CPU核的L1、L2缓存也需要重新加载数据和指令，这会导致程序的运行时间增加。</p><p>说到这儿，我想跟你分享一个我曾经在多核CPU环境下对Redis性能进行调优的案例。希望借助这个案例，帮你全方位地了解到多核CPU对Redis的性能的影响。</p><p>当时，我们的项目需求是要对Redis的99%尾延迟进行优化，要求GET尾延迟小于300微秒，PUT尾延迟小于500微秒。</p><p>可能有同学不太清楚99%尾延迟是啥，我先解释一下。我们把所有请求的处理延迟从小到大排个序， <strong>99%的请求延迟小于的值就是99%尾延迟</strong>。比如说，我们有1000个请求，假设按请求延迟从小到大排序后，第991个请求的延迟实测值是1ms，而前990个请求的延迟都小于1ms，所以，这里的99%尾延迟就是1ms。</p><p>刚开始的时候，我们使用GET&#x2F;PUT复杂度为O(1)的String类型进行数据存取，同时关闭了RDB和AOF，而且，Redis实例中没有保存集合类型的其他数据，也就没有bigkey操作，避免了可能导致延迟增加的许多情况。</p><p>但是，即使这样，我们在一台有24个CPU核的服务器上运行Redis实例，GET和PUT的99%尾延迟分别是504微秒和1175微秒，明显大于我们设定的目标。</p><p>后来，我们仔细检测了Redis实例运行时的服务器CPU的状态指标值，这才发现，CPU的context switch次数比较多。</p><p>context switch是指线程的上下文切换，这里的上下文就是线程的运行时信息。在CPU多核的环境中，一个线程先在一个CPU核上运行，之后又切换到另一个CPU核上运行，这时就会发生context switch。</p><p>当context switch发生后，Redis主线程的运行时信息需要被重新加载到另一个CPU核上，而且，此时，另一个CPU核上的L1、L2缓存中，并没有Redis实例之前运行时频繁访问的指令和数据，所以，这些指令和数据都需要重新从L3缓存，甚至是内存中加载。这个重新加载的过程是需要花费一定时间的。而且，Redis实例需要等待这个重新加载的过程完成后，才能开始处理请求，所以，这也会导致一些请求的处理时间增加。</p><p>如果在CPU多核场景下，Redis实例被频繁调度到不同CPU核上运行的话，那么，对Redis实例的请求处理时间影响就更大了。 <strong>每调度一次，一些请求就会受到运行时信息、指令和数据重新加载过程的影响，这就会导致某些请求的延迟明显高于其他请求</strong>。分析到这里，我们就知道了刚刚的例子中99%尾延迟的值始终降不下来的原因。</p><p>所以，我们要避免Redis总是在不同CPU核上来回调度执行。于是，我们尝试着把Redis实例和CPU核绑定了，让一个Redis实例固定运行在一个CPU核上。我们可以使用 <strong>taskset命令</strong> 把一个程序绑定在一个核上运行。</p><p>比如说，我们执行下面的命令，就把Redis实例绑在了0号核上，其中，“-c”选项用于设置要绑定的核编号。</p><pre class="line-numbers language-none"><code class="language-none">taskset -c 0 .&#x2F;redis-server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>绑定以后，我们进行了测试。我们发现，Redis实例的GET和PUT的99%尾延迟一下子就分别降到了260微秒和482微秒，达到了我们期望的目标。</p><p>我们来看一下绑核前后的Redis的99%尾延迟。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/eb72b9f58052d6a6023d3e1dac522157.jpg"></p><p>可以看到，在CPU多核的环境下，通过绑定Redis实例和CPU核，可以有效降低Redis的尾延迟。当然，绑核不仅对降低尾延迟有好处，同样也能降低平均延迟、提升吞吐率，进而提升Redis性能。</p><p>接下来，我们再来看看多CPU架构，也就是NUMA架构，对Redis性能的影响。</p><h2 id="CPU的NUMA架构对Redis性能的影响"><a href="#CPU的NUMA架构对Redis性能的影响" class="headerlink" title="CPU的NUMA架构对Redis性能的影响"></a>CPU的NUMA架构对Redis性能的影响</h2><p>在实际应用Redis时，我经常看到一种做法，为了提升Redis的网络性能，把操作系统的网络中断处理程序和CPU核绑定。这个做法可以避免网络中断处理程序在不同核上来回调度执行，的确能有效提升Redis的网络处理性能。</p><p>但是，网络中断程序是要和Redis实例进行网络数据交互的，一旦把网络中断程序绑核后，我们就需要注意Redis实例是绑在哪个核上了，这会关系到Redis访问网络数据的效率高低。</p><p>我们先来看下Redis实例和网络中断程序的数据交互：网络中断处理程序从网卡硬件中读取数据，并把数据写入到操作系统内核维护的一块内存缓冲区。内核会通过epoll机制触发事件，通知Redis实例，Redis实例再把数据从内核的内存缓冲区拷贝到自己的内存空间，如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/8753ce6985fd08bb9cf9a3813c8b2cd2.jpg"></p><p>那么，在CPU的NUMA架构下，当网络中断处理程序、Redis实例分别和CPU核绑定后，就会有一个潜在的风险： <strong>如果网络中断处理程序和Redis实例各自所绑的CPU核不在同一个CPU Socket上，那么，Redis实例读取网络数据时，就需要跨CPU Socket访问内存，这个过程会花费较多时间。</strong></p><p>这么说可能有点抽象，我再借助一张图来解释下。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/30cd42yy86debc0eb6e7c5b069533ab0.jpg"></p><p>可以看到，图中的网络中断处理程序被绑在了CPU Socket 1的某个核上，而Redis实例则被绑在了CPU Socket 2上。此时，网络中断处理程序读取到的网络数据，被保存在CPU Socket 1的本地内存中，当Redis实例要访问网络数据时，就需要Socket 2通过总线把内存访问命令发送到 Socket 1上，进行远程访问，时间开销比较大。</p><p>我们曾经做过测试，和访问CPU Socket本地内存相比，跨CPU Socket的内存访问延迟增加了18%，这自然会导致Redis处理请求的延迟增加。</p><p>所以，为了避免Redis跨CPU Socket访问网络数据，我们最好把网络中断程序和Redis实例绑在同一个CPU Socket上，这样一来，Redis实例就可以直接从本地内存读取网络数据了，如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/41f02b2afb08ec54249680e8cac30179.jpg"></p><p>不过，需要注意的是， <strong>在CPU的NUMA架构下，对CPU核的编号规则，并不是先把一个CPU Socket中的所有逻辑核编完，再对下一个CPU Socket中的逻辑核编码，而是先给每个CPU Socket中每个物理核的第一个逻辑核依次编号，再给每个CPU Socket中的物理核的第二个逻辑核依次编号。</strong></p><p>我给你举个例子。假设有2个CPU Socket，每个Socket上有6个物理核，每个物理核又有2个逻辑核，总共24个逻辑核。我们可以执行 <strong>lscpu命令</strong>，查看到这些核的编号：</p><pre class="line-numbers language-none"><code class="language-none">lscpuArchitecture: x86_64...NUMA node0 CPU(s): 0-5,12-17NUMA node1 CPU(s): 6-11,18-23...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到，NUMA node0的CPU核编号是0到5、12到17。其中，0到5是node0上的6个物理核中的第一个逻辑核的编号，12到17是相应物理核中的第二个逻辑核编号。NUMA node1的CPU核编号规则和node0一样。</p><p>所以，在绑核时，我们一定要注意，不能想当然地认为第一个Socket上的12个逻辑核的编号就是0到11。否则，网络中断程序和Redis实例就可能绑在了不同的CPU Socket上。</p><p>比如说，如果我们把网络中断程序和Redis实例分别绑到编号为1和7的CPU核上，此时，它们仍然是在2个CPU Socket上，Redis实例仍然需要跨Socket读取网络数据。</p><p><strong>所以，你一定要注意NUMA架构下CPU核的编号方法，这样才不会绑错核。</strong></p><p>我们先简单地总结下刚刚学习的内容。在CPU多核的场景下，用taskset命令把Redis实例和一个核绑定，可以减少Redis实例在不同核上被来回调度执行的开销，避免较高的尾延迟；在多CPU的NUMA架构下，如果你对网络中断程序做了绑核操作，建议你同时把Redis实例和网络中断程序绑在同一个CPU Socket的不同核上，这样可以避免Redis跨Socket访问内存中的网络数据的时间开销。</p><p>不过，“硬币都是有两面的”，绑核也存在一定的风险。接下来，我们就来了解下它的潜在风险点和解决方案。</p><h2 id="绑核的风险和解决方案"><a href="#绑核的风险和解决方案" class="headerlink" title="绑核的风险和解决方案"></a>绑核的风险和解决方案</h2><p>Redis除了主线程以外，还有用于RDB生成和AOF重写的子进程（可以回顾看下 <a href="https://time.geekbang.org/column/article/271754">第4讲</a> 和 <a href="https://time.geekbang.org/column/article/271839">第5讲</a>）。此外，我们还在 <a href="https://time.geekbang.org/column/article/285000">第16讲</a> 学习了Redis的后台线程。</p><p>当我们把Redis实例绑到一个CPU逻辑核上时，就会导致子进程、后台线程和Redis主线程竞争CPU资源，一旦子进程或后台线程占用CPU时，主线程就会被阻塞，导致Redis请求延迟增加。</p><p>针对这种情况，我来给你介绍两种解决方案，分别是 <strong>一个Redis实例对应绑一个物理核和优化Redis源码。</strong></p><p><strong>方案一：一个Redis实例对应绑一个物理核</strong></p><p>在给Redis实例绑核时，我们不要把一个实例和一个逻辑核绑定，而要和一个物理核绑定，也就是说，把一个物理核的2个逻辑核都用上。</p><p>我们还是以刚才的NUMA架构为例，NUMA node0的CPU核编号是0到5、12到17。其中，编号0和12、1和13、2和14等都是表示一个物理核的2个逻辑核。所以，在绑核时，我们使用属于同一个物理核的2个逻辑核进行绑核操作。例如，我们执行下面的命令，就把Redis实例绑定到了逻辑核0和12上，而这两个核正好都属于物理核1。</p><pre class="line-numbers language-none"><code class="language-none">taskset -c 0,12 .&#x2F;redis-server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>和只绑一个逻辑核相比，把Redis实例和物理核绑定，可以让主线程、子进程、后台线程共享使用2个逻辑核，可以在一定程度上缓解CPU资源竞争。但是，因为只用了2个逻辑核，它们相互之间的CPU竞争仍然还会存在。如果你还想进一步减少CPU竞争，我再给你介绍一种方案。</p><p><strong>方案二：优化Redis源码</strong></p><p>这个方案就是通过修改Redis源码，把子进程和后台线程绑到不同的CPU核上。</p><p>如果你对Redis的源码不太熟悉，也没关系，因为这是通过编程实现绑核的一个通用做法。学会了这个方案，你可以在熟悉了源码之后把它用上，也可以应用在其他需要绑核的场景中。</p><p>接下来，我先介绍一下通用的做法，然后，再具体说说可以把这个做法对应到Redis的哪部分源码中。</p><p>通过编程实现绑核时，要用到操作系统提供的1个数据结构cpu_set_t和3个函数CPU_ZERO、CPU_SET和sched_setaffinity，我先来解释下它们。</p><ul><li>cpu_set_t数据结构：是一个位图，每一位用来表示服务器上的一个CPU逻辑核。</li><li>CPU_ZERO函数：以cpu_set_t结构的位图为输入参数，把位图中所有的位设置为0。</li><li>CPU_SET函数：以CPU逻辑核编号和cpu_set_t位图为参数，把位图中和输入的逻辑核编号对应的位设置为1。</li><li>sched_setaffinity函数：以进程&#x2F;线程ID号和cpu_set_t为参数，检查cpu_set_t中哪一位为1，就把输入的ID号所代表的进程&#x2F;线程绑在对应的逻辑核上。</li></ul><p>那么，怎么在编程时把这三个函数结合起来实现绑核呢？很简单，我们分四步走就行。</p><ul><li>第一步：创建一个cpu_set_t结构的位图变量；</li><li>第二步：使用CPU_ZERO函数，把cpu_set_t结构的位图所有的位都设置为0；</li><li>第三步：根据要绑定的逻辑核编号，使用CPU_SET函数，把cpu_set_t结构的位图相应位设置为1；</li><li>第四步：使用sched_setaffinity函数，把程序绑定在cpu_set_t结构位图中为1的逻辑核上。</li></ul><p>下面，我就具体介绍下，分别把后台线程、子进程绑到不同的核上的做法。</p><p>先说后台线程。为了让你更好地理解编程实现绑核，你可以看下这段示例代码，它实现了为线程绑核的操作：</p><pre class="line-numbers language-none"><code class="language-none">&#x2F;&#x2F;线程函数void worker(int bind_cpu)&#123;    cpu_set_t cpuset;  &#x2F;&#x2F;创建位图变量    CPU_ZERO(&amp;cpu_set); &#x2F;&#x2F;位图变量所有位设置0    CPU_SET(bind_cpu, &amp;cpuset); &#x2F;&#x2F;根据输入的bind_cpu编号，把位图对应为设置为1    sched_setaffinity(0, sizeof(cpuset), &amp;cpuset); &#x2F;&#x2F;把程序绑定在cpu_set_t结构位图中为1的逻辑核    &#x2F;&#x2F;实际线程函数工作&#125;int main()&#123;    pthread_t pthread1    &#x2F;&#x2F;把创建的pthread1绑在编号为3的逻辑核上    pthread_create(&amp;pthread1, NULL, (void *)worker, 3);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于Redis来说，它是在bio.c文件中的bioProcessBackgroundJobs函数中创建了后台线程。bioProcessBackgroundJobs函数类似于刚刚的例子中的worker函数，在这个函数中实现绑核四步操作，就可以把后台线程绑到和主线程不同的核上了。</p><p>和给线程绑核类似，当我们使用fork创建子进程时，也可以把刚刚说的四步操作实现在fork后的子进程代码中，示例代码如下：</p><pre class="line-numbers language-none"><code class="language-none">int main()&#123;   &#x2F;&#x2F;用fork创建一个子进程   pid_t p &#x3D; fork();   if(p &lt; 0)&#123;      printf(&quot; fork error\n&quot;);   &#125;   &#x2F;&#x2F;子进程代码部分   else if(!p)&#123;      cpu_set_t cpuset;  &#x2F;&#x2F;创建位图变量      CPU_ZERO(&amp;cpu_set); &#x2F;&#x2F;位图变量所有位设置0      CPU_SET(3, &amp;cpuset); &#x2F;&#x2F;把位图的第3位设置为1      sched_setaffinity(0, sizeof(cpuset), &amp;cpuset);  &#x2F;&#x2F;把程序绑定在3号逻辑核      &#x2F;&#x2F;实际子进程工作      exit(0);   &#125;   ...&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于Redis来说，生成RDB和AOF日志重写的子进程分别是下面两个文件的函数中实现的。</p><ul><li>rdb.c文件：rdbSaveBackground函数；</li><li>aof.c文件：rewriteAppendOnlyFileBackground函数。</li></ul><p>这两个函数中都调用了fork创建子进程，所以，我们可以在子进程代码部分加上绑核的四步操作。</p><p>使用源码优化方案，我们既可以实现Redis实例绑核，避免切换核带来的性能影响，还可以让子进程、后台线程和主线程不在同一个核上运行，避免了它们之间的CPU资源竞争。相比使用taskset绑核来说，这个方案可以进一步降低绑核的风险。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这节课，我们学习了CPU架构对Redis性能的影响。首先，我们了解了目前主流的多核CPU架构，以及NUMA架构。</p><p>在多核CPU架构下，Redis如果在不同的核上运行，就需要频繁地进行上下文切换，这个过程会增加Redis的执行时间，客户端也会观察到较高的尾延迟了。所以，建议你在Redis运行时，把实例和某个核绑定，这样，就能重复利用核上的L1、L2缓存，可以降低响应延迟。</p><p>为了提升Redis的网络性能，我们有时还会把网络中断处理程序和CPU核绑定。在这种情况下，如果服务器使用的是NUMA架构，Redis实例一旦被调度到和中断处理程序不在同一个CPU Socket，就要跨CPU Socket访问网络数据，这就会降低Redis的性能。所以，我建议你把Redis实例和网络中断处理程序绑在同一个CPU Socket下的不同核上，这样可以提升Redis的运行性能。</p><p>虽然绑核可以帮助Redis降低请求执行时间，但是，除了主线程，Redis还有用于RDB和AOF重写的子进程，以及4.0版本之后提供的用于惰性删除的后台线程。当Redis实例和一个逻辑核绑定后，这些子进程和后台线程会和主线程竞争CPU资源，也会对Redis性能造成影响。所以，我给了你两个建议：</p><ul><li>如果你不想修改Redis代码，可以把按一个Redis实例一个物理核方式进行绑定，这样，Redis的主线程、子进程和后台线程可以共享使用一个物理核上的两个逻辑核。</li><li>如果你很熟悉Redis的源码，就可以在源码中增加绑核操作，把子进程和后台线程绑到不同的核上，这样可以避免对主线程的CPU资源竞争。不过，如果你不熟悉Redis源码，也不用太担心，Redis 6.0出来后，可以支持CPU核绑定的配置操作了，我将在第38讲中向你介绍Redis 6.0的最新特性。</li></ul><p>Redis的低延迟是我们永恒的追求目标，而多核CPU和NUMA架构已经成为了目前服务器的主流配置，所以，希望你能掌握绑核优化方案，并把它应用到实践中。</p><h2 id="每课一问"><a href="#每课一问" class="headerlink" title="每课一问"></a>每课一问</h2><p>按照惯例，我给你提个小问题。</p><p>在一台有2个CPU Socket（每个Socket 8个物理核）的服务器上，我们部署了有8个实例的Redis切片集群（8个实例都为主节点，没有主备关系），现在有两个方案：</p><ol><li>在同一个CPU Socket上运行8个实例，并和8个CPU核绑定；</li><li>在2个CPU Socket上各运行4个实例，并和相应Socket上的核绑定。</li></ol><p>如果不考虑网络数据读取的影响，你会选择哪个方案呢？</p><p>欢迎在留言区写下你的思考和答案，如果你觉得有所收获，也欢迎你帮我把今天的内容分享给你的朋友。我们下节课见。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;17-为什么CPU结构也会影响Redis的性能？&quot;&gt;&lt;a href=&quot;#17-为什么CPU结构也会影响Redis的性能？&quot; class=&quot;headerlink&quot; title=&quot;17 | 为什么CPU结构也会影响Redis的性能？&quot;&gt;&lt;/a&gt;17 | 为什么CPU结</summary>
      
    
    
    
    <category term="Redis核心技术与实战" scheme="https://zhuansun.github.io/geekbang/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    
    
  </entry>
  
  <entry>
    <title>12 | 有一亿个keys要统计，应该用哪种集合？</title>
    <link href="https://zhuansun.github.io/geekbang/posts/2047725300.html"/>
    <id>https://zhuansun.github.io/geekbang/posts/2047725300.html</id>
    <published>2024-03-04T22:10:14.000Z</published>
    <updated>2024-03-21T07:44:22.357Z</updated>
    
    <content type="html"><![CDATA[<h1 id="12-有一亿个keys要统计，应该用哪种集合？"><a href="#12-有一亿个keys要统计，应该用哪种集合？" class="headerlink" title="12 | 有一亿个keys要统计，应该用哪种集合？"></a>12 | 有一亿个keys要统计，应该用哪种集合？</h1><p>你好，我是蒋德钧。</p><p>在Web和移动应用的业务场景中，我们经常需要保存这样一种信息：一个key对应了一个数据集合。我举几个例子。</p><ul><li>手机App中的每天的用户登录信息：一天对应一系列用户ID或移动设备ID；</li><li>电商网站上商品的用户评论列表：一个商品对应了一系列的评论；</li><li>用户在手机App上的签到打卡信息：一天对应一系列用户的签到记录；</li><li>应用网站上的网页访问信息：一个网页对应一系列的访问点击。</li></ul><p>我们知道，Redis集合类型的特点就是一个键对应一系列的数据，所以非常适合用来存取这些数据。但是，在这些场景中，除了记录信息，我们往往还需要对集合中的数据进行统计，例如：</p><ul><li>在移动应用中，需要统计每天的新增用户数和第二天的留存用户数；</li><li>在电商网站的商品评论中，需要统计评论列表中的最新评论；</li><li>在签到打卡中，需要统计一个月内连续打卡的用户数；</li><li>在网页访问记录中，需要统计独立访客（Unique Visitor，UV）量。</li></ul><p>通常情况下，我们面临的用户数量以及访问量都是巨大的，比如百万、千万级别的用户数量，或者千万级别、甚至亿级别的访问信息。所以，我们必须要选择能够非常高效地统计大量数据（例如亿级）的集合类型。</p><p><strong>要想选择合适的集合，我们就得了解常用的集合统计模式。</strong> 这节课，我就给你介绍集合类型常见的四种统计模式，包括聚合统计、排序统计、二值状态统计和基数统计。我会以刚刚提到的这四个场景为例，和你聊聊在这些统计模式下，什么集合类型能够更快速地完成统计，而且还节省内存空间。掌握了今天的内容，之后再遇到集合元素统计问题时，你就能很快地选出合适的集合类型了。</p><h2 id="聚合统计"><a href="#聚合统计" class="headerlink" title="聚合统计"></a>聚合统计</h2><p>我们先来看集合元素统计的第一个场景：聚合统计。</p><p>所谓的聚合统计，就是指统计多个集合元素的聚合结果，包括：统计多个集合的共有元素（交集统计）；把两个集合相比，统计其中一个集合独有的元素（差集统计）；统计多个集合的所有元素（并集统计）。</p><p>在刚才提到的场景中，统计手机App每天的新增用户数和第二天的留存用户数，正好对应了聚合统计。</p><p>要完成这个统计任务，我们可以用一个集合记录所有登录过App的用户ID，同时，用另一个集合记录每一天登录过App的用户ID。然后，再对这两个集合做聚合统计。我们来看下具体的操作。</p><p>记录所有登录过App的用户ID还是比较简单的，我们可以直接使用Set类型，把key设置为user:id，表示记录的是用户ID，value就是一个Set集合，里面是所有登录过App的用户ID，我们可以把这个Set叫作累计用户Set，如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/990e56babf199d9a7fa4c7343167ecca.jpg"></p><p>需要注意的是，累计用户Set中没有日期信息，我们是不能直接统计每天的新增用户的。所以，我们还需要把每一天登录的用户ID，记录到一个新集合中，我们把这个集合叫作每日用户Set，它有两个特点：</p><ol><li>key是 user:id 以及当天日期，例如 user:id:20200803；</li><li>value是Set集合，记录当天登录的用户ID。</li></ol><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/a63dd95d5e44bf538fe960e67761b59e.jpg"></p><p>在统计每天的新增用户时，我们只用计算每日用户Set和累计用户Set的差集就行。</p><p>我借助一个具体的例子来解释一下。</p><p>假设我们的手机App在2020年8月3日上线，那么，8月3日前是没有用户的。此时，累计用户Set是空集，当天登录的用户ID会被记录到 key为user:id:20200803的Set中。所以，user:id:20200803这个Set中的用户就是当天的新增用户。</p><p>然后，我们计算累计用户Set和user:id:20200803 Set的并集结果，结果保存在user:id这个累计用户Set中，如下所示：</p><pre class="line-numbers language-none"><code class="language-none">SUNIONSTORE  user:id  user:id  user:id:20200803<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>此时，user:id这个累计用户Set中就有了8月3日的用户ID。等到8月4日再统计时，我们把8月4日登录的用户ID记录到user:id:20200804 的Set中。接下来，我们执行SDIFFSTORE命令计算累计用户Set和user:id:20200804 Set的差集，结果保存在key为user:new的Set中，如下所示：</p><pre class="line-numbers language-none"><code class="language-none">SDIFFSTORE  user:new  user:id:20200804 user:id<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>可以看到，这个差集中的用户ID在user:id:20200804 的Set中存在，但是不在累计用户Set中。所以，user:new这个Set中记录的就是8月4日的新增用户。</p><p>当要计算8月4日的留存用户时，我们只需要再计算user:id:20200803 和 user:id:20200804两个Set的交集，就可以得到同时在这两个集合中的用户ID了，这些就是在8月3日登录，并且在8月4日留存的用户。执行的命令如下：</p><pre class="line-numbers language-none"><code class="language-none">SINTERSTORE user:id:rem user:id:20200803 user:id:20200804<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>当你需要对多个集合进行聚合计算时，Set类型会是一个非常不错的选择。不过，我要提醒你一下，这里有一个潜在的风险。</p><p>Set的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致Redis实例阻塞。所以，我给你分享一个小建议： <strong>你可以从主从集群中选择一个从库，让它专门负责聚合计算，或者是把数据读取到客户端，在客户端来完成聚合统计</strong>，这样就可以规避阻塞主库实例和其他从库实例的风险了。</p><h2 id="排序统计"><a href="#排序统计" class="headerlink" title="排序统计"></a>排序统计</h2><p>接下来，我们再来聊一聊应对集合元素排序需求的方法。我以在电商网站上提供最新评论列表的场景为例，进行讲解。</p><p>最新评论列表包含了所有评论中的最新留言， <strong>这就要求集合类型能对元素保序</strong>，也就是说，集合中的元素可以按序排列，这种对元素保序的集合类型叫作有序集合。</p><p>在Redis常用的4个集合类型中（List、Hash、Set、Sorted Set），List和Sorted Set就属于有序集合。</p><p><strong>List是按照元素进入List的顺序进行排序的，而Sorted Set可以根据元素的权重来排序</strong>，我们可以自己来决定每个元素的权重值。比如说，我们可以根据元素插入Sorted Set的时间确定权重值，先插入的元素权重小，后插入的元素权重大。</p><p>看起来好像都可以满足需求，我们该怎么选择呢？</p><p>我先说说用List的情况。每个商品对应一个List，这个List包含了对这个商品的所有评论，而且会按照评论时间保存这些评论，每来一个新评论，就用LPUSH命令把它插入List的队头。</p><p>在只有一页评论的时候，我们可以很清晰地看到最新的评论，但是，在实际应用中，网站一般会分页显示最新的评论列表，一旦涉及到分页操作，List就可能会出现问题了。</p><p>假设当前的评论List是{A, B, C, D, E, F}（其中，A是最新的评论，以此类推，F是最早的评论），在展示第一页的3个评论时，我们可以用下面的命令，得到最新的三条评论A、B、C：</p><pre class="line-numbers language-none"><code class="language-none">LRANGE product1 0 21) &quot;A&quot;2) &quot;B&quot;3) &quot;C&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>然后，再用下面的命令获取第二页的3个评论，也就是D、E、F。</p><pre class="line-numbers language-none"><code class="language-none">LRANGE product1 3 51) &quot;D&quot;2) &quot;E&quot;3) &quot;F&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>但是，如果在展示第二页前，又产生了一个新评论G，评论G就会被LPUSH命令插入到评论List的队头，评论List就变成了{G, A, B, C, D, E, F}。此时，再用刚才的命令获取第二页评论时，就会发现，评论C又被展示出来了，也就是C、D、E。</p><pre class="line-numbers language-none"><code class="language-none">LRANGE product1 3 51) &quot;C&quot;2) &quot;D&quot;3) &quot;E&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>之所以会这样，关键原因就在于，List是通过元素在List中的位置来排序的，当有一个新元素插入时，原先的元素在List中的位置都后移了一位，比如说原来在第1位的元素现在排在了第2位。所以，对比新元素插入前后，List相同位置上的元素就会发生变化，用LRANGE读取时，就会读到旧元素。</p><p>和List相比，Sorted Set就不存在这个问题，因为它是根据元素的实际权重来排序和获取数据的。</p><p>我们可以按评论时间的先后给每条评论设置一个权重值，然后再把评论保存到Sorted Set中。Sorted Set的ZRANGEBYSCORE命令就可以按权重排序后返回元素。这样的话，即使集合中的元素频繁更新，Sorted Set也能通过ZRANGEBYSCORE命令准确地获取到按序排列的数据。</p><p>假设越新的评论权重越大，目前最新评论的权重是N，我们执行下面的命令时，就可以获得最新的10条评论：</p><pre class="line-numbers language-none"><code class="language-none">ZRANGEBYSCORE comments N-9 N<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>所以，在面对需要展示最新列表、排行榜等场景时，如果数据更新频繁或者需要分页显示，建议你优先考虑使用Sorted Set。</p><h2 id="二值状态统计"><a href="#二值状态统计" class="headerlink" title="二值状态统计"></a>二值状态统计</h2><p>现在，我们再来分析下第三个场景：二值状态统计。这里的二值状态就是指集合元素的取值就只有0和1两种。在签到打卡的场景中，我们只用记录签到（1）或未签到（0），所以它就是非常典型的二值状态，</p><p>在签到统计时，每个用户一天的签到用1个bit位就能表示，一个月（假设是31天）的签到情况用31个bit位就可以，而一年的签到也只需要用365个bit位，根本不用太复杂的集合类型。这个时候，我们就可以选择Bitmap。这是Redis提供的扩展数据类型。我来给你解释一下它的实现原理。</p><p>Bitmap本身是用String类型作为底层数据结构实现的一种统计二值状态的数据类型。String类型是会保存为二进制的字节数组，所以，Redis就把字节数组的每个bit位利用起来，用来表示一个元素的二值状态。你可以把Bitmap看作是一个bit数组。</p><p>Bitmap提供了GETBIT&#x2F;SETBIT操作，使用一个偏移值offset对bit数组的某一个bit位进行读和写。不过，需要注意的是，Bitmap的偏移量是从0开始算的，也就是说offset的最小值是0。当使用SETBIT对一个bit位进行写操作时，这个bit位会被设置为1。Bitmap还提供了BITCOUNT操作，用来统计这个bit数组中所有“1”的个数。</p><p>那么，具体该怎么用Bitmap进行签到统计呢？我还是借助一个具体的例子来说明。</p><p>假设我们要统计ID 3000的用户在2020年8月份的签到情况，就可以按照下面的步骤进行操作。</p><p>第一步，执行下面的命令，记录该用户8月3号已签到。</p><pre class="line-numbers language-none"><code class="language-none">SETBIT uid:sign:3000:202008 2 1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>第二步，检查该用户8月3日是否签到。</p><pre class="line-numbers language-none"><code class="language-none">GETBIT uid:sign:3000:202008 2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>第三步，统计该用户在8月份的签到次数。</p><pre class="line-numbers language-none"><code class="language-none">BITCOUNT uid:sign:3000:202008<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这样，我们就知道该用户在8月份的签到情况了，是不是很简单呢？接下来，你可以再思考一个问题：如果记录了1亿个用户10天的签到情况，你有办法统计出这10天连续签到的用户总数吗？</p><p>在介绍具体的方法之前，我们要先知道，Bitmap支持用BITOP命令对多个Bitmap按位做“与”“或”“异或”的操作，操作的结果会保存到一个新的Bitmap中。</p><p>我以按位“与”操作为例来具体解释一下。从下图中，可以看到，三个Bitmap bm1、bm2和bm3，对应bit位做“与”操作，结果保存到了一个新的Bitmap中（示例中，这个结果Bitmap的key被设为“resmap”）。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/4151af42513cf5f7996fe86c6064f97a.jpg"></p><p>回到刚刚的问题，在统计1亿个用户连续10天的签到情况时，你可以把每天的日期作为key，每个key对应一个1亿位的Bitmap，每一个bit对应一个用户当天的签到情况。</p><p>接下来，我们对10个Bitmap做“与”操作，得到的结果也是一个Bitmap。在这个Bitmap中，只有10天都签到的用户对应的bit位上的值才会是1。最后，我们可以用BITCOUNT统计下Bitmap中的1的个数，这就是连续签到10天的用户总数了。</p><p>现在，我们可以计算一下记录了10天签到情况后的内存开销。每天使用1个1亿位的Bitmap，大约占12MB的内存（10^8&#x2F;8&#x2F;1024&#x2F;1024），10天的Bitmap的内存开销约为120MB，内存压力不算太大。不过，在实际应用时，最好对Bitmap设置过期时间，让Redis自动删除不再需要的签到记录，以节省内存开销。</p><p>所以，如果只需要统计数据的二值状态，例如商品有没有、用户在不在等，就可以使用Bitmap，因为它只用一个bit位就能表示0或1。在记录海量数据时，Bitmap能够有效地节省内存空间。</p><h2 id="基数统计"><a href="#基数统计" class="headerlink" title="基数统计"></a>基数统计</h2><p>最后，我们再来看一个统计场景：基数统计。基数统计就是指统计一个集合中不重复的元素个数。对应到我们刚才介绍的场景中，就是统计网页的UV。</p><p>网页UV的统计有个独特的地方，就是需要去重，一个用户一天内的多次访问只能算作一次。在Redis的集合类型中，Set类型默认支持去重，所以看到有去重需求时，我们可能第一时间就会想到用Set类型。</p><p>我们来结合一个例子看一看用Set的情况。</p><p>有一个用户user1访问page1时，你把这个信息加到Set中：</p><pre class="line-numbers language-none"><code class="language-none">SADD page1:uv user1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>用户1再来访问时，Set的去重功能就保证了不会重复记录用户1的访问次数，这样，用户1就算是一个独立访客。当你需要统计UV时，可以直接用SCARD命令，这个命令会返回一个集合中的元素个数。</p><p>但是，如果page1非常火爆，UV达到了千万，这个时候，一个Set就要记录千万个用户ID。对于一个搞大促的电商网站而言，这样的页面可能有成千上万个，如果每个页面都用这样的一个Set，就会消耗很大的内存空间。</p><p>当然，你也可以用Hash类型记录UV。</p><p>例如，你可以把用户ID作为Hash集合的key，当用户访问页面时，就用HSET命令（用于设置Hash集合元素的值），对这个用户ID记录一个值“1”，表示一个独立访客，用户1访问page1后，我们就记录为1个独立访客，如下所示：</p><pre class="line-numbers language-none"><code class="language-none">HSET page1:uv user1 1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>即使用户1多次访问页面，重复执行这个HSET命令，也只会把user1的值设置为1，仍然只记为1个独立访客。当要统计UV时，我们可以用HLEN命令统计Hash集合中的所有元素个数。</p><p>但是，和Set类型相似，当页面很多时，Hash类型也会消耗很大的内存空间。那么，有什么办法既能完成统计，还能节省内存吗？</p><p>这时候，就要用到Redis提供的HyperLogLog了。</p><p>HyperLogLog是一种用于统计基数的数据集合类型，它的最大优势就在于，当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小。</p><p>在Redis中，每个 HyperLogLog只需要花费 12 KB 内存，就可以计算接近 2^64 个元素的基数。你看，和元素越多就越耗费内存的Set和Hash类型相比，HyperLogLog就非常节省空间。</p><p>在统计UV时，你可以用PFADD命令（用于向HyperLogLog中添加新元素）把访问页面的每个用户都添加到HyperLogLog中。</p><pre class="line-numbers language-none"><code class="language-none">PFADD page1:uv user1 user2 user3 user4 user5<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>接下来，就可以用PFCOUNT命令直接获得page1的UV值了，这个命令的作用就是返回HyperLogLog的统计结果。</p><pre class="line-numbers language-none"><code class="language-none">PFCOUNT page1:uv<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>关于HyperLogLog的具体实现原理，你不需要重点掌握，不会影响到你的日常使用，我就不多讲了。如果你想了解一下，课下可以看看 <a href="http://en.wikipedia.org/wiki/HyperLogLog">这条链接</a>。</p><p>不过，有一点需要你注意一下，HyperLogLog的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是0.81%。这也就意味着，你使用HyperLogLog统计的UV是100万，但实际的UV可能是101万。虽然误差率不算大，但是，如果你需要精确统计结果的话，最好还是继续用Set或Hash类型。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这节课，我们结合统计新增用户数和留存用户数、最新评论列表、用户签到数以及网页独立访客量这4种典型场景，学习了集合类型的4种统计模式，分别是聚合统计、排序统计、二值状态统计和基数统计。为了方便你掌握，我把Set、Sorted Set、Hash、List、Bitmap、HyperLogLog的支持情况和优缺点汇总在了下面的表格里，希望你把这张表格保存下来，时不时地复习一下。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/c0bb35d0d91a62ef4ca1bd939a9b136e.jpg"></p><p>可以看到，Set和Sorted Set都支持多种聚合统计，不过，对于差集计算来说，只有Set支持。Bitmap也能做多个Bitmap间的聚合计算，包括与、或和异或操作。</p><p>当需要进行排序统计时，List中的元素虽然有序，但是一旦有新元素插入，原来的元素在List中的位置就会移动，那么，按位置读取的排序结果可能就不准确了。而Sorted Set本身是按照集合元素的权重排序，可以准确地按序获取结果，所以建议你优先使用它。</p><p>如果我们记录的数据只有0和1两个值的状态，Bitmap会是一个很好的选择，这主要归功于Bitmap对于一个数据只用1个bit记录，可以节省内存。</p><p>对于基数统计来说，如果集合元素量达到亿级别而且不需要精确统计时，我建议你使用HyperLogLog。</p><p>当然，Redis的应用场景非常多，这张表中的总结不一定能覆盖到所有场景。我建议你也试着自己画一张表，把你遇到的其他场景添加进去。长久积累下来，你一定能够更加灵活地把集合类型应用到合适的实践项目中。</p><h2 id="每课一问"><a href="#每课一问" class="headerlink" title="每课一问"></a>每课一问</h2><p>依照惯例，我给你留个小问题。这节课，我们学习了4种典型的统计模式，以及各种集合类型的支持情况和优缺点，我想请你聊一聊，你还遇到过其他的统计场景吗？用的是怎样的集合类型呢？</p><p>欢迎你在留言区写下你的思考和答案，和我交流讨论。如果你身边还有需要解决这些统计问题的朋友或同事，也欢迎你把今天的内容分享给他&#x2F;她，我们下节课见。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;12-有一亿个keys要统计，应该用哪种集合？&quot;&gt;&lt;a href=&quot;#12-有一亿个keys要统计，应该用哪种集合？&quot; class=&quot;headerlink&quot; title=&quot;12 | 有一亿个keys要统计，应该用哪种集合？&quot;&gt;&lt;/a&gt;12 | 有一亿个keys要统</summary>
      
    
    
    
    <category term="Redis核心技术与实战" scheme="https://zhuansun.github.io/geekbang/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    
    
  </entry>
  
  <entry>
    <title>18 | 波动的响应延迟：如何应对变慢的Redis？（上）</title>
    <link href="https://zhuansun.github.io/geekbang/posts/280561632.html"/>
    <id>https://zhuansun.github.io/geekbang/posts/280561632.html</id>
    <published>2024-03-04T22:10:14.000Z</published>
    <updated>2024-03-21T07:44:22.369Z</updated>
    
    <content type="html"><![CDATA[<h1 id="18-波动的响应延迟：如何应对变慢的Redis？（上）"><a href="#18-波动的响应延迟：如何应对变慢的Redis？（上）" class="headerlink" title="18 | 波动的响应延迟：如何应对变慢的Redis？（上）"></a>18 | 波动的响应延迟：如何应对变慢的Redis？（上）</h1><p>你好，我是蒋德钧。</p><p>在Redis的实际部署应用中，有一个非常严重的问题，那就是Redis突然变慢了。一旦出现这个问题，不仅会直接影响用户的使用体验，还可能会影响到“旁人”，也就是和Redis在同一个业务系统中的其他系统，比如说数据库。</p><p>举个小例子，在秒杀场景下，一旦Redis变慢了，大量的用户下单请求就会被拖慢，也就是说，用户提交了下单申请，却没有收到任何响应，这会给用户带来非常糟糕的使用体验，甚至可能会导致用户流失。</p><p>而且，在实际生产环境中，Redis往往是业务系统中的一个环节（例如作为缓存或是作为数据库）。一旦Redis上的请求延迟增加，就可能引起业务系统中的一串儿“连锁反应”。</p><p>我借助一个包含了Redis的业务逻辑的小例子，简单地给你解释一下。</p><p>应用服务器（App Server）要完成一个事务性操作，包括在MySQL上执行一个写事务，在Redis上插入一个标记位，并通过一个第三方服务给用户发送一条完成消息。</p><p>这三个操作都需要保证事务原子性，所以，如果此时Redis的延迟增加，就会拖累App Server端整个事务的执行。这个事务一直完成不了，又会导致MySQL上写事务占用的资源无法释放，进而导致访问MySQL的其他请求被阻塞。很明显，Redis变慢会带来严重的连锁反应。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/58555bc098b518e992136f1128430c64.jpg"></p><p>我相信，不少人遇到过这个问题，那具体该怎么解决呢？</p><p>这个时候，切忌“病急乱投医”。如果没有一套行之有效的应对方案，大多数时候我们只能各种尝试，做无用功。在前面的 <a href="https://time.geekbang.org/column/article/285000">第16讲</a>、 <a href="https://time.geekbang.org/column/article/286082">第17讲</a> 中，我们学习了会导致Redis变慢的潜在阻塞点以及相应的解决方案，即异步线程机制和CPU绑核。除此之外，还有一些因素会导致Redis变慢。</p><p>接下来的两节课，我再向你介绍一下如何系统性地应对Redis变慢这个问题。我会从问题认定、系统性排查和应对方案这3个方面给你具体讲解。学完这两节课以后，你一定能够有章法地解决Redis变慢的问题。</p><h2 id="Redis真的变慢了吗？"><a href="#Redis真的变慢了吗？" class="headerlink" title="Redis真的变慢了吗？"></a>Redis真的变慢了吗？</h2><p>在实际解决问题之前，我们首先要弄清楚，如何判断Redis是不是真的变慢了。</p><p>一个最直接的方法，就是 <strong>查看Redis的响应延迟</strong>。</p><p>大部分时候，Redis延迟很低，但是在某些时刻，有些Redis实例会出现很高的响应延迟，甚至能达到几秒到十几秒，不过持续时间不长，这也叫延迟“毛刺”。当你发现Redis命令的执行时间突然就增长到了几秒，基本就可以认定Redis变慢了。</p><p>这种方法是看Redis延迟的绝对值，但是，在不同的软硬件环境下，Redis本身的绝对性能并不相同。比如，在我的环境中，当延迟为1ms时，我判定Redis变慢了，但是你的硬件配置高，那么，在你的运行环境下，可能延迟是0.2ms的时候，你就可以认定Redis变慢了。</p><p>所以，这里我就要说第二个方法了，也就是基于 <strong>当前环境下的Redis基线性能</strong> 做判断。所谓的基线性能呢，也就是一个系统在低压力、无干扰下的基本性能，这个性能只由当前的软硬件配置决定。</p><p>你可能会问，具体怎么确定基线性能呢？有什么好方法吗？</p><p>实际上，从2.8.7版本开始，redis-cli命令提供了–intrinsic-latency选项，可以用来监测和统计测试期间内的最大延迟，这个延迟可以作为Redis的基线性能。其中，测试时长可以用–intrinsic-latency选项的参数来指定。</p><p>举个例子，比如说，我们运行下面的命令，该命令会打印120秒内监测到的最大延迟。可以看到，这里的最大延迟是119微秒，也就是基线性能为119微秒。一般情况下，运行120秒就足够监测到最大延迟了，所以，我们可以把参数设置为120。</p><pre class="line-numbers language-none"><code class="language-none">.&#x2F;redis-cli --intrinsic-latency 120Max latency so far: 17 microseconds.Max latency so far: 44 microseconds.Max latency so far: 94 microseconds.Max latency so far: 110 microseconds.Max latency so far: 119 microseconds.36481658 total runs (avg latency: 3.2893 microseconds &#x2F; 3289.32 nanoseconds per run).Worst run took 36x longer than the average latency.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>需要注意的是，基线性能和当前的操作系统、硬件配置相关。因此，我们可以把它和Redis运行时的延迟结合起来，再进一步判断Redis性能是否变慢了。</p><p>一般来说，你要把运行时延迟和基线性能进行对比，如果你观察到的Redis运行时延迟是其基线性能的2倍及以上，就可以认定Redis变慢了。</p><p>判断基线性能这一点，对于在虚拟化环境下运行的Redis来说，非常重要。这是因为，在虚拟化环境（例如虚拟机或容器）中，由于增加了虚拟化软件层，与物理机相比，虚拟机或容器本身就会引入一定的性能开销，所以基线性能会高一些。下面的测试结果，显示的就是某一个虚拟机上运行Redis时测的基线性能。</p><pre class="line-numbers language-none"><code class="language-none">$ .&#x2F;redis-cli --intrinsic-latency 120Max latency so far: 692 microseconds.Max latency so far: 915 microseconds.Max latency so far: 2193 microseconds.Max latency so far: 9343 microseconds.Max latency so far: 9871 microseconds.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到，由于虚拟化软件本身的开销，此时的基线性能已经达到了9.871ms。如果该Redis实例的运行时延迟为10ms，这并不能算作性能变慢，因为此时，运行时延迟只比基线性能增加了1.3%。如果你不了解基线性能，一看到较高的运行时延迟，就很有可能误判Redis变慢了。</p><p>不过，我们通常是通过客户端和网络访问Redis服务，为了避免网络对基线性能的影响，刚刚说的这个命令需要在服务器端直接运行，这也就是说， <strong>我们只考虑服务器端软硬件环境的影响</strong>。</p><p>如果你想了解网络对Redis性能的影响，一个简单的方法是用iPerf这样的工具，测量从Redis客户端到服务器端的网络延迟。如果这个延迟有几十毫秒甚至是几百毫秒，就说明，Redis运行的网络环境中很可能有大流量的其他应用程序在运行，导致网络拥塞了。这个时候，你就需要协调网络运维，调整网络的流量分配了。</p><h2 id="如何应对Redis变慢？"><a href="#如何应对Redis变慢？" class="headerlink" title="如何应对Redis变慢？"></a>如何应对Redis变慢？</h2><p>经过了上一步之后，你已经能够确定Redis是否变慢了。一旦发现变慢了，接下来，就要开始查找原因并解决这个问题了，这其实是一个很有意思的诊断过程。</p><p>此时的你就像一名医生，而Redis则是一位病人。在给病人看病时，你要知道人体的机制，还要知道可能对身体造成影响的外部因素，比如不健康的食物、不好的情绪等，然后要拍CT、心电图等找出病因，最后再确定治疗方案。</p><p>在诊断“Redis变慢”这个病症时，同样也是这样。你要基于自己对Redis本身的工作原理的理解，并且结合和它交互的操作系统、存储以及网络等外部系统关键机制，再借助一些辅助工具来定位原因，并制定行之有效的解决方案。</p><p>医生诊断一般都是有章可循的。同样，Redis的性能诊断也有章可依，这就是影响Redis的关键因素。下面这张图你应该有印象，这是我们在 <a href="https://time.geekbang.org/column/article/268262">第一节课</a> 画的Redis架构图。你可以重点关注下我在图上新增的红色模块，也就是Redis自身的操作特性、文件系统和操作系统，它们是影响Redis性能的三大要素。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/cd026801924e197f5c79828c368cd706.jpg"></p><p>接下来，我将从这三大要素入手，结合实际的应用场景，依次给你介绍从不同要素出发排查和解决问题的实践经验。这节课我先给你介绍Redis的自身操作特性的影响，下节课我们再重点研究操作系统和文件系统的影响。</p><h3 id="Redis自身操作特性的影响"><a href="#Redis自身操作特性的影响" class="headerlink" title="Redis自身操作特性的影响"></a>Redis自身操作特性的影响</h3><p>首先，我们来学习下Redis提供的键值对命令操作对延迟性能的影响。我重点介绍两类关键操作：慢查询命令和过期key操作。</p><p><strong>1.慢查询命令</strong></p><p>慢查询命令，就是指在Redis中执行速度慢的命令，这会导致Redis延迟增加。Redis提供的命令操作很多，并不是所有命令都慢，这和命令操作的复杂度有关。所以，我们必须要知道Redis的不同命令的复杂度。</p><p>比如说，Value类型为String时，GET&#x2F;SET操作主要就是操作Redis的哈希表索引。这个操作复杂度基本是固定的，即O(1)。但是，当Value类型为Set时，SORT、SUNION&#x2F;SMEMBERS操作复杂度分别为O(N+M*log(M))和O(N)。其中，N为Set中的元素个数，M为SORT操作返回的元素个数。这个复杂度就增加了很多。 <a href="https://redis.io/commands/">Redis官方文档</a> 中对每个命令的复杂度都有介绍，当你需要了解某个命令的复杂度时，可以直接查询。</p><p>那该怎么应对这个问题呢？在这儿，我就要给你排查建议和解决方法了，这也是今天的第一个方法。</p><p>当你发现Redis性能变慢时，可以通过Redis日志，或者是latency monitor工具，查询变慢的请求，根据请求对应的具体命令以及官方文档，确认下是否采用了复杂度高的慢查询命令。</p><p>如果的确有大量的慢查询命令，有两种处理方式：</p><ol><li><strong>用其他高效命令代替</strong>。比如说，如果你需要返回一个SET中的所有成员时，不要使用SMEMBERS命令，而是要使用SSCAN多次迭代返回，避免一次返回大量数据，造成线程阻塞。</li><li><strong>当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用SORT、SUNION、SINTER这些命令，以免拖慢Redis实例</strong>。</li></ol><p>当然，如果业务逻辑就是要求使用慢查询命令，那你得考虑采用性能更好的CPU，更快地完成查询命令，避免慢查询的影响。</p><p>还有一个比较容易忽略的慢查询命令，就是KEYS。它用于返回和输入模式匹配的所有key，例如，以下命令返回所有包含“name”字符串的keys。</p><pre class="line-numbers language-none"><code class="language-none">redis&gt; KEYS *name*1) &quot;lastname&quot;2) &quot;firstname&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>因为KEYS命令需要遍历存储的键值对，所以操作延时高</strong>。如果你不了解它的实现而使用了它，就会导致Redis性能变慢。所以， <strong>KEYS命令一般不被建议用于生产环境中</strong>。</p><p><strong>2.过期key操作</strong></p><p>接下来，我们来看过期key的自动删除机制。它是Redis用来回收内存空间的常用机制，应用广泛，本身就会引起Redis操作阻塞，导致性能变慢，所以，你必须要知道该机制对性能的影响。</p><p>Redis键值对的key可以设置过期时间。默认情况下，Redis每100毫秒会删除一些过期key，具体的算法如下：</p><ol><li>采样ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP个数的key，并将其中过期的key全部删除；</li><li>如果超过25%的key过期了，则重复删除的过程，直到过期key的比例降至25%以下。</li></ol><p>ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP是Redis的一个参数，默认是20，那么，一秒内基本有200个过期key会被删除。这一策略对清除过期key、释放内存空间很有帮助。如果每秒钟删除200个过期key，并不会对Redis造成太大影响。</p><p>但是，如果触发了上面这个算法的第二条，Redis就会一直删除以释放内存空间。注意， <strong>删除操作是阻塞的</strong>（Redis 4.0后可以用异步线程机制来减少阻塞影响）。所以，一旦该条件触发，Redis的线程就会一直执行删除，这样一来，就没办法正常服务其他的键值操作了，就会进一步引起其他键值操作的延迟增加，Redis就会变慢。</p><p>那么，算法的第二条是怎么被触发的呢？其中一个重要来源，就是 <strong>频繁使用带有相同时间参数的EXPIREAT命令设置过期key</strong>，这就会导致，在同一秒内有大量的key同时过期。</p><p>现在，我就要给出第二条排查建议和解决方法了。</p><p>你要检查业务代码在使用EXPIREAT命令设置key过期时间时，是否使用了相同的UNIX时间戳，有没有使用EXPIRE命令给批量的key设置相同的过期秒数。因为，这都会造成大量key在同一时间过期，导致性能变慢。</p><p>遇到这种情况时，千万不要嫌麻烦，你首先要根据实际业务的使用需求，决定EXPIREAT和EXPIRE的过期时间参数。其次，如果一批key的确是同时过期，你还可以在EXPIREAT和EXPIRE的过期时间参数上，加上一个一定大小范围内的随机数，这样，既保证了key在一个邻近时间范围内被删除，又避免了同时过期造成的压力。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这节课，我首先给你介绍了Redis性能变慢带来的重要影响，希望你能充分重视这个问题。我重点介绍了判断Redis变慢的方法，一个是看响应延迟，一个是看基线性能。同时，我还给了你两种排查和解决Redis变慢这个问题的方法：</p><ol><li>从慢查询命令开始排查，并且根据业务需求替换慢查询命令；</li><li>排查过期key的时间设置，并根据实际使用需求，设置不同的过期时间。</li></ol><p>性能诊断通常是一件困难的事，所以我们一定不能毫无目标地“乱找”。这节课给你介绍的内容，就是排查和解决Redis性能变慢的章法，你一定要按照章法逐一排查，这样才可能尽快地找出原因。</p><p>当然，要真正把Redis用好，除了要了解Redis本身的原理，还要了解和Redis交互的各底层系统的关键机制，包括操作系统和文件系统。通常情况下，一些难以排查的问题是Redis的用法或设置和底层系统的工作机制不协调导致的。下节课，我会着重给你介绍文件系统、操作系统对Redis性能的影响，以及相应的排查方法和解决方案。</p><h2 id="每课一问"><a href="#每课一问" class="headerlink" title="每课一问"></a>每课一问</h2><p>这节课，我提到了KEYS命令，因为它的复杂度很高，容易引起Redis线程操作阻塞，不适用于生产环境。但是，KEYS命令本身提供的功能是上层业务应用经常需要的，即返回与输入模式匹配的keys。</p><p>请思考一下，在Redis中，还有哪些其他命令可以代替KEYS命令，实现同样的功能呢？这些命令的复杂度会导致Redis变慢吗？</p><p>欢迎在留言区写下你的思考和答案，我们一起讨论，共同学习进步。如果你觉得有所收获，欢迎你把今天的内容分享给你的朋友。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;18-波动的响应延迟：如何应对变慢的Redis？（上）&quot;&gt;&lt;a href=&quot;#18-波动的响应延迟：如何应对变慢的Redis？（上）&quot; class=&quot;headerlink&quot; title=&quot;18 | 波动的响应延迟：如何应对变慢的Redis？（上）&quot;&gt;&lt;/a&gt;18 </summary>
      
    
    
    
    <category term="Redis核心技术与实战" scheme="https://zhuansun.github.io/geekbang/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    
    
  </entry>
  
  <entry>
    <title>19 | 波动的响应延迟：如何应对变慢的Redis？（下）</title>
    <link href="https://zhuansun.github.io/geekbang/posts/3790392730.html"/>
    <id>https://zhuansun.github.io/geekbang/posts/3790392730.html</id>
    <published>2024-03-04T22:10:14.000Z</published>
    <updated>2024-03-21T07:44:22.370Z</updated>
    
    <content type="html"><![CDATA[<h1 id="19-波动的响应延迟：如何应对变慢的Redis？（下）"><a href="#19-波动的响应延迟：如何应对变慢的Redis？（下）" class="headerlink" title="19 | 波动的响应延迟：如何应对变慢的Redis？（下）"></a>19 | 波动的响应延迟：如何应对变慢的Redis？（下）</h1><p>你好，我是蒋德钧。</p><p>上节课，我介绍了判断Redis变慢的两种方法，分别是响应延迟和基线性能。除此之外，我还给你分享了从Redis的自身命令操作层面排查和解决问题的两种方案。</p><p>但是，如果在排查时，你发现Redis没有执行大量的慢查询命令，也没有同时删除大量过期keys，那么，我们是不是就束手无策了呢？</p><p>当然不是！我还有很多“锦囊妙计”，准备在这节课分享给你呢！</p><p>如果上节课的方法不管用，那就说明，你要关注影响性能的其他机制了，也就是文件系统和操作系统。</p><p>Redis会持久化保存数据到磁盘，这个过程要依赖文件系统来完成，所以，文件系统将数据写回磁盘的机制，会直接影响到Redis持久化的效率。而且，在持久化的过程中，Redis也还在接收其他请求，持久化的效率高低又会影响到Redis处理请求的性能。</p><p>另一方面，Redis是内存数据库，内存操作非常频繁，所以，操作系统的内存机制会直接影响到Redis的处理效率。比如说，如果Redis的内存不够用了，操作系统会启动swap机制，这就会直接拖慢Redis。</p><p>那么，接下来，我再从这两个层面，继续给你介绍，如何进一步解决Redis变慢的问题。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/cd026801924e197f5c79828c368cd706.jpg"></p><h2 id="文件系统：AOF模式"><a href="#文件系统：AOF模式" class="headerlink" title="文件系统：AOF模式"></a>文件系统：AOF模式</h2><p>你可能会问，Redis是个内存数据库，为什么它的性能还和文件系统有关呢？</p><p>我在前面讲过，为了保证数据可靠性，Redis会采用AOF日志或RDB快照。其中，AOF日志提供了三种日志写回策略：no、everysec、always。这三种写回策略依赖文件系统的两个系统调用完成，也就是write和fsync。</p><p>write只要把日志记录写到内核缓冲区，就可以返回了，并不需要等待日志实际写回到磁盘；而fsync需要把日志记录写回到磁盘后才能返回，时间较长。下面这张表展示了三种写回策略所执行的系统调用。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/9f1316094001ca64c8dfca37c2c49ea4.jpg"></p><p>当写回策略配置为everysec和always时，Redis需要调用fsync把日志写回磁盘。但是，这两种写回策略的具体执行情况还不太一样。</p><p>在使用everysec时，Redis允许丢失一秒的操作记录，所以，Redis主线程并不需要确保每个操作记录日志都写回磁盘。而且，fsync的执行时间很长，如果是在Redis主线程中执行fsync，就容易阻塞主线程。所以，当写回策略配置为everysec时，Redis会使用后台的子线程异步完成fsync的操作。</p><p>而对于always策略来说，Redis需要确保每个操作记录日志都写回磁盘，如果用后台子线程异步完成，主线程就无法及时地知道每个操作是否已经完成了，这就不符合always策略的要求了。所以，always策略并不使用后台子线程来执行。</p><p>另外，在使用AOF日志时，为了避免日志文件不断增大，Redis会执行AOF重写，生成体量缩小的新的AOF日志文件。AOF重写本身需要的时间很长，也容易阻塞Redis主线程，所以，Redis使用子进程来进行AOF重写。</p><p>但是，这里有一个潜在的风险点：AOF重写会对磁盘进行大量IO操作，同时，fsync又需要等到数据写到磁盘后才能返回，所以，当AOF重写的压力比较大时，就会导致fsync被阻塞。虽然fsync是由后台子线程负责执行的，但是，主线程会监控fsync的执行进度。</p><p>当主线程使用后台子线程执行了一次fsync，需要再次把新接收的操作记录写回磁盘时，如果主线程发现上一次的fsync还没有执行完，那么它就会阻塞。所以，如果后台子线程执行的fsync频繁阻塞的话（比如AOF重写占用了大量的磁盘IO带宽），主线程也会阻塞，导致Redis性能变慢。</p><p>为了帮助你理解，我再画一张图来展示下在磁盘压力小和压力大的时候，fsync后台子线程和主线程受到的影响。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/2a47b3f6fd7beaf466a675777ebd28a6.jpg"></p><p>好了，说到这里，你已经了解了，由于fsync后台子线程和AOF重写子进程的存在，主IO线程一般不会被阻塞。但是，如果在重写日志时，AOF重写子进程的写入量比较大，fsync线程也会被阻塞，进而阻塞主线程，导致延迟增加。现在，我来给出排查和解决建议。</p><p>首先，你可以检查下Redis配置文件中的appendfsync配置项，该配置项的取值表明了Redis实例使用的是哪种AOF日志写回策略，如下所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/ba770d1f25ffae79a101c13b9f8aa9e9.jpg"></p><p>如果AOF写回策略使用了everysec或always配置，请先确认下业务方对数据可靠性的要求，明确是否需要每一秒或每一个操作都记日志。有的业务方不了解Redis AOF机制，很可能就直接使用数据可靠性最高等级的always配置了。其实，在有些场景中（例如Redis用于缓存），数据丢了还可以从后端数据库中获取，并不需要很高的数据可靠性。</p><p>如果业务应用对延迟非常敏感，但同时允许一定量的数据丢失，那么，可以把配置项no-appendfsync-on-rewrite设置为yes，如下所示：</p><pre class="line-numbers language-none"><code class="language-none">no-appendfsync-on-rewrite yes<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个配置项设置为yes时，表示在AOF重写时，不进行fsync操作。也就是说，Redis实例把写命令写到内存后，不调用后台线程进行fsync操作，就可以直接返回了。当然，如果此时实例发生宕机，就会导致数据丢失。反之，如果这个配置项设置为no（也是默认配置），在AOF重写时，Redis实例仍然会调用后台线程进行fsync操作，这就会给实例带来阻塞。</p><p>如果的确需要高性能，同时也需要高可靠数据保证，我建议你考虑 <strong>采用高速的固态硬盘作为AOF日志的写入设备。</strong></p><p>高速固态盘的带宽和并发度比传统的机械硬盘的要高出10倍及以上。在AOF重写和fsync后台线程同时执行时，固态硬盘可以提供较为充足的磁盘IO资源，让AOF重写和fsync后台线程的磁盘IO资源竞争减少，从而降低对Redis的性能影响。</p><h2 id="操作系统：swap"><a href="#操作系统：swap" class="headerlink" title="操作系统：swap"></a>操作系统：swap</h2><p>如果Redis的AOF日志配置只是no，或者就没有采用AOF模式，那么，还会有什么问题导致性能变慢吗？</p><p>接下来，我就再说一个潜在的瓶颈： <strong>操作系统的内存swap</strong>。</p><p>内存swap是操作系统里将内存数据在内存和磁盘间来回换入和换出的机制，涉及到磁盘的读写，所以，一旦触发swap，无论是被换入数据的进程，还是被换出数据的进程，其性能都会受到慢速磁盘读写的影响。</p><p>Redis是内存数据库，内存使用量大，如果没有控制好内存的使用量，或者和其他内存需求大的应用一起运行了，就可能受到swap的影响，而导致性能变慢。</p><p>这一点对于Redis内存数据库而言，显得更为重要：正常情况下，Redis的操作是直接通过访问内存就能完成，一旦swap被触发了，Redis的请求操作需要等到磁盘数据读写完成才行。而且，和我刚才说的AOF日志文件读写使用fsync线程不同，swap触发后影响的是Redis主IO线程，这会极大地增加Redis的响应时间。</p><p>说到这儿，我想给你分享一个我曾经遇到过的因为swap而导致性能降低的例子。</p><p>在正常情况下，我们运行的一个实例完成5000万个GET请求时需要300s，但是，有一次，这个实例完成5000万GET请求，花了将近4个小时的时间。经过问题复现，我们发现，当时Redis处理请求用了近4小时的情况下，该实例所在的机器已经发生了swap。从300s到4个小时，延迟增加了将近48倍，可以看到swap对性能造成的严重影响。</p><p>那么，什么时候会触发swap呢？</p><p>通常，触发swap的原因主要是 <strong>物理机器内存不足</strong>，对于Redis而言，有两种常见的情况：</p><ul><li>Redis实例自身使用了大量的内存，导致物理机器的可用内存不足；</li><li>和Redis实例在同一台机器上运行的其他进程，在进行大量的文件读写操作。文件读写本身会占用系统内存，这会导致分配给Redis实例的内存量变少，进而触发Redis发生swap。</li></ul><p>针对这个问题，我也给你提供一个解决思路： <strong>增加机器的内存或者使用Redis集群</strong>。</p><p>操作系统本身会在后台记录每个进程的swap使用情况，即有多少数据量发生了swap。你可以先通过下面的命令查看Redis的进程号，这里是5332。</p><pre class="line-numbers language-none"><code class="language-none">$ redis-cli info | grep process_idprocess_id: 5332<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>然后，进入Redis所在机器的&#x2F;proc目录下的该进程目录中：</p><pre class="line-numbers language-none"><code class="language-none">$ cd &#x2F;proc&#x2F;5332<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>最后，运行下面的命令，查看该Redis进程的使用情况。在这儿，我只截取了部分结果：</p><pre class="line-numbers language-none"><code class="language-none">$cat smaps | egrep &#39;^(Swap|Size)&#39;Size: 584 kBSwap: 0 kBSize: 4 kBSwap: 4 kBSize: 4 kBSwap: 0 kBSize: 462044 kBSwap: 462008 kBSize: 21392 kBSwap: 0 kB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>每一行Size表示的是Redis实例所用的一块内存大小，而Size下方的Swap和它相对应，表示这块Size大小的内存区域有多少已经被换出到磁盘上了。如果这两个值相等，就表示这块内存区域已经完全被换出到磁盘了。</p><p>作为内存数据库，Redis本身会使用很多大小不一的内存块，所以，你可以看到有很多Size行，有的很小，就是4KB，而有的很大，例如462044KB。 <strong>不同内存块被换出到磁盘上的大小也不一样</strong>，例如刚刚的结果中的第一个4KB内存块，它下方的Swap也是4KB，这表示这个内存块已经被换出了；另外，462044KB这个内存块也被换出了462008KB，差不多有462MB。</p><p>这里有个重要的地方，我得提醒你一下，当出现百MB，甚至GB级别的swap大小时，就表明，此时，Redis实例的内存压力很大，很有可能会变慢。所以，swap的大小是排查Redis性能变慢是否由swap引起的重要指标。</p><p>一旦发生内存swap，最直接的解决方法就是 <strong>增加机器内存</strong>。如果该实例在一个Redis切片集群中，可以增加Redis集群的实例个数，来分摊每个实例服务的数据量，进而减少每个实例所需的内存量。</p><p>当然，如果Redis实例和其他操作大量文件的程序（例如数据分析程序）共享机器，你可以将Redis实例迁移到单独的机器上运行，以满足它的内存需求量。如果该实例正好是Redis主从集群中的主库，而从库的内存很大，也可以考虑进行主从切换，把大内存的从库变成主库，由它来处理客户端请求。</p><h2 id="操作系统：内存大页"><a href="#操作系统：内存大页" class="headerlink" title="操作系统：内存大页"></a>操作系统：内存大页</h2><p>除了内存swap，还有一个和内存相关的因素，即内存大页机制（Transparent Huge Page, THP），也会影响Redis性能。</p><p>Linux内核从2.6.38开始支持内存大页机制，该机制支持2MB大小的内存页分配，而常规的内存页分配是按4KB的粒度来执行的。</p><p>很多人都觉得：“Redis是内存数据库，内存大页不正好可以满足Redis的需求吗？而且在分配相同的内存量时，内存大页还能减少分配次数，不也是对Redis友好吗?”</p><p>其实，系统的设计通常是一个取舍过程，我们称之为trade-off。很多机制通常都是优势和劣势并存的。Redis使用内存大页就是一个典型的例子。</p><p>虽然内存大页可以给Redis带来内存分配方面的收益，但是，不要忘了，Redis为了提供数据可靠性保证，需要将数据做持久化保存。这个写入过程由额外的线程执行，所以，此时，Redis主线程仍然可以接收客户端写请求。客户端的写请求可能会修改正在进行持久化的数据。在这一过程中，Redis就会采用写时复制机制，也就是说，一旦有数据要被修改，Redis并不会直接修改内存中的数据，而是将这些数据拷贝一份，然后再进行修改。</p><p>如果采用了内存大页，那么，即使客户端请求只修改100B的数据，Redis也需要拷贝2MB的大页。相反，如果是常规内存页机制，只用拷贝4KB。两者相比，你可以看到，当客户端请求修改或新写入数据较多时，内存大页机制将导致大量的拷贝，这就会影响Redis正常的访存操作，最终导致性能变慢。</p><p>那该怎么办呢？很简单，关闭内存大页，就行了。</p><p>首先，我们要先排查下内存大页。方法是：在Redis实例运行的机器上执行如下命令:</p><pre class="line-numbers language-none"><code class="language-none">cat &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;enabled<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果执行结果是always，就表明内存大页机制被启动了；如果是never，就表示，内存大页机制被禁止。</p><p>在实际生产环境中部署时，我建议你不要使用内存大页机制，操作也很简单，只需要执行下面的命令就可以了：</p><pre class="line-numbers language-none"><code class="language-none">echo never &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;enabled<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这节课，我从文件系统和操作系统两个维度，给你介绍了应对Redis变慢的方法。</p><p>为了方便你应用，我给你梳理了一个包含9个检查点的Checklist，希望你在遇到Redis性能变慢时，按照这些步骤逐一检查，高效地解决问题。</p><ol><li>获取Redis实例在当前环境下的基线性能。</li><li>是否用了慢查询命令？如果是的话，就使用其他命令替代慢查询命令，或者把聚合计算命令放在客户端做。</li><li>是否对过期key设置了相同的过期时间？对于批量删除的key，可以在每个key的过期时间上加一个随机数，避免同时删除。</li><li>是否存在bigkey？ 对于bigkey的删除操作，如果你的Redis是4.0及以上的版本，可以直接利用异步线程机制减少主线程阻塞；如果是Redis 4.0以前的版本，可以使用SCAN命令迭代删除；对于bigkey的集合查询和聚合操作，可以使用SCAN命令在客户端完成。</li><li>Redis AOF配置级别是什么？业务层面是否的确需要这一可靠性级别？如果我们需要高性能，同时也允许数据丢失，可以将配置项no-appendfsync-on-rewrite设置为yes，避免AOF重写和fsync竞争磁盘IO资源，导致Redis延迟增加。当然， 如果既需要高性能又需要高可靠性，最好使用高速固态盘作为AOF日志的写入盘。</li><li>Redis实例的内存使用是否过大？发生swap了吗？如果是的话，就增加机器内存，或者是使用Redis集群，分摊单机Redis的键值对数量和内存压力。同时，要避免出现Redis和其他内存需求大的应用共享机器的情况。</li><li>在Redis实例的运行环境中，是否启用了透明大页机制？如果是的话，直接关闭内存大页机制就行了。</li><li>是否运行了Redis主从集群？如果是的话，把主库实例的数据量大小控制在2~4GB，以免主从复制时，从库因加载大的RDB文件而阻塞。</li><li>是否使用了多核CPU或NUMA架构的机器运行Redis实例？使用多核CPU时，可以给Redis实例绑定物理核；使用NUMA架构时，注意把Redis实例和网络中断处理程序运行在同一个CPU Socket上。</li></ol><p>实际上，影响系统性能的因素还有很多，这两节课给你讲的都是应对最常见问题的解决方案。</p><p>如果你遇到了一些特殊情况，也不要慌，我再给你分享一个小技巧：仔细检查下有没有恼人的“邻居”，具体点说，就是Redis所在的机器上有没有一些其他占内存、磁盘IO和网络IO的程序，比如说数据库程序或者数据采集程序。如果有的话，我建议你将这些程序迁移到其他机器上运行。</p><p>为了保证Redis高性能，我们需要给Redis充足的计算、内存和IO资源，给它提供一个“安静”的环境。</p><h2 id="每课一问"><a href="#每课一问" class="headerlink" title="每课一问"></a>每课一问</h2><p>这两节课，我向你介绍了系统性定位、排查和解决Redis变慢的方法。所以，我想请你聊一聊，你遇到过Redis变慢的情况吗？如果有的话，你是怎么解决的呢？</p><p>欢迎你在留言区分享一下自己的经验，如果觉得今天的内容对你有所帮助，也欢迎分享给你的朋友或同事，我们下节课见。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;19-波动的响应延迟：如何应对变慢的Redis？（下）&quot;&gt;&lt;a href=&quot;#19-波动的响应延迟：如何应对变慢的Redis？（下）&quot; class=&quot;headerlink&quot; title=&quot;19 | 波动的响应延迟：如何应对变慢的Redis？（下）&quot;&gt;&lt;/a&gt;19 </summary>
      
    
    
    
    <category term="Redis核心技术与实战" scheme="https://zhuansun.github.io/geekbang/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    
    
  </entry>
  
  <entry>
    <title>20 | 删除数据后，为什么内存占用率还是很高？</title>
    <link href="https://zhuansun.github.io/geekbang/posts/3799613451.html"/>
    <id>https://zhuansun.github.io/geekbang/posts/3799613451.html</id>
    <published>2024-03-04T22:10:14.000Z</published>
    <updated>2024-03-21T07:44:22.372Z</updated>
    
    <content type="html"><![CDATA[<h1 id="20-删除数据后，为什么内存占用率还是很高？"><a href="#20-删除数据后，为什么内存占用率还是很高？" class="headerlink" title="20 | 删除数据后，为什么内存占用率还是很高？"></a>20 | 删除数据后，为什么内存占用率还是很高？</h1><p>你好，我是蒋德钧。</p><p>在使用Redis时，我们经常会遇到这样一个问题：明明做了数据删除，数据量已经不大了，为什么使用top命令查看时，还会发现Redis占用了很多内存呢？</p><p>实际上，这是因为，当数据删除后，Redis释放的内存空间会由内存分配器管理，并不会立即返回给操作系统。所以，操作系统仍然会记录着给Redis分配了大量内存。</p><p>但是，这往往会伴随一个潜在的风险点：Redis释放的内存空间可能并不是连续的，那么，这些不连续的内存空间很有可能处于一种闲置的状态。这就会导致一个问题：虽然有空闲空间，Redis却无法用来保存数据，不仅会减少Redis能够实际保存的数据量，还会降低Redis运行机器的成本回报率。</p><p>打个形象的比喻。我们可以把Redis的内存空间比作高铁上的车厢座位数。如果高铁的车厢座位数很多，但运送的乘客数很少，那么，高铁运行一次的效率低，成本高，性价比就会降低，Redis也是一样。如果你正好租用了一台16GB内存的云主机运行Redis，但是却只保存了8GB的数据，那么，你租用这台云主机的成本回报率也会降低一半，这个结果肯定不是你想要的。</p><p>所以，这节课，我就和你聊聊Redis的内存空间存储效率问题，探索一下，为什么数据已经删除了，但内存却闲置着没有用，以及相应的解决方案。</p><h2 id="什么是内存碎片？"><a href="#什么是内存碎片？" class="headerlink" title="什么是内存碎片？"></a>什么是内存碎片？</h2><p>通常情况下，内存空间闲置，往往是因为操作系统发生了较为严重的内存碎片。那么，什么是内存碎片呢？</p><p>为了方便你理解，我还是借助高铁的车厢座位来进行解释。假设一个车厢的座位总共有60个，现在已经卖了57张票，你和2个小伙伴要乘坐高铁出门旅行，刚好需要三张票。不过，你们想要坐在一起，这样可以在路上聊天。但是，在选座位时，你们却发现，已经买不到连续的座位了。于是，你们只好换了一趟车。这样一来，你们需要改变出行时间，而且这趟车就空置了三个座位。</p><p>其实，这趟车的空座位是和你们的人数相匹配的，只是这些空座位是分散的，如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/23ebc99ff968f2c7edd0f8ddf7def8df.jpg"></p><p>我们可以把这些分散的空座位叫作“车厢座位碎片”，知道了这一点，操作系统的内存碎片就很容易理解了。虽然操作系统的剩余内存空间总量足够，但是，应用申请的是一块连续地址空间的N字节，但在剩余的内存空间中，没有大小为N字节的连续空间了，那么，这些剩余空间就是内存碎片（比如上图中的“空闲2字节”和“空闲1字节”，就是这样的碎片）。</p><p>那么，Redis中的内存碎片是什么原因导致的呢？接下来，我带你来具体看一看。我们只有了解了内存碎片的成因，才能对症下药，把Redis占用的内存空间充分利用起来，增加存储的数据量。</p><h2 id="内存碎片是如何形成的？"><a href="#内存碎片是如何形成的？" class="headerlink" title="内存碎片是如何形成的？"></a>内存碎片是如何形成的？</h2><p>其实，内存碎片的形成有内因和外因两个层面的原因。简单来说，内因是操作系统的内存分配机制，外因是Redis的负载特征。</p><h3 id="内因：内存分配器的分配策略"><a href="#内因：内存分配器的分配策略" class="headerlink" title="内因：内存分配器的分配策略"></a>内因：内存分配器的分配策略</h3><p>内存分配器的分配策略就决定了操作系统无法做到“按需分配”。这是因为，内存分配器一般是按固定大小来分配内存，而不是完全按照应用程序申请的内存空间大小给程序分配。</p><p>Redis可以使用libc、jemalloc、tcmalloc多种内存分配器来分配内存，默认使用jemalloc。接下来，我就以jemalloc为例，来具体解释一下。其他分配器也存在类似的问题。</p><p>jemalloc的分配策略之一，是按照一系列固定的大小划分内存空间，例如8字节、16字节、32字节、48字节，…, 2KB、4KB、8KB等。当程序申请的内存最接近某个固定值时，jemalloc会给它分配相应大小的空间。</p><p>这样的分配方式本身是为了减少分配次数。例如，Redis申请一个20字节的空间保存数据，jemalloc就会分配32字节，此时，如果应用还要写入10字节的数据，Redis就不用再向操作系统申请空间了，因为刚才分配的32字节已经够用了，这就避免了一次分配操作。</p><p>但是，如果Redis每次向分配器申请的内存空间大小不一样，这种分配方式就会有形成碎片的风险，而这正好来源于Redis的外因了。</p><h3 id="外因：键值对大小不一样和删改操作"><a href="#外因：键值对大小不一样和删改操作" class="headerlink" title="外因：键值对大小不一样和删改操作"></a>外因：键值对大小不一样和删改操作</h3><p>Redis通常作为共用的缓存系统或键值数据库对外提供服务，所以，不同业务应用的数据都可能保存在Redis中，这就会带来不同大小的键值对。这样一来，Redis申请内存空间分配时，本身就会有大小不一的空间需求。这是第一个外因。</p><p>但是咱们刚刚讲过，内存分配器只能按固定大小分配内存，所以，分配的内存空间一般都会比申请的空间大一些，不会完全一致，这本身就会造成一定的碎片，降低内存空间存储效率。</p><p>比如说，应用A保存6字节数据，jemalloc按分配策略分配8字节。如果应用A不再保存新数据，那么，这里多出来的2字节空间就是内存碎片了，如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/46d93f2ef50a7f6f91812d0c21ebd6a5.jpg"></p><p>第二个外因是，这些键值对会被修改和删除，这会导致空间的扩容和释放。具体来说，一方面，如果修改后的键值对变大或变小了，就需要占用额外的空间或者释放不用的空间。另一方面，删除的键值对就不再需要内存空间了，此时，就会把空间释放出来，形成空闲空间。</p><p>我画了下面这张图来帮助你理解。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/4d5265c6a38d1839bf4943918f6b6db8.jpg"></p><p>一开始，应用A、B、C、D分别保存了3、1、2、4字节的数据，并占据了相应的内存空间。然后，应用D删除了1个字节，这个1字节的内存空间就空出来了。紧接着，应用A修改了数据，从3字节变成了4字节。为了保持A数据的空间连续性，操作系统就需要把B的数据拷贝到别的空间，比如拷贝到D刚刚释放的空间中。此时，应用C和D也分别删除了2字节和1字节的数据，整个内存空间上就分别出现了2字节和1字节的空闲碎片。如果应用E想要一个3字节的连续空间，显然是不能得到满足的。因为，虽然空间总量够，但却是碎片空间，并不是连续的。</p><p>好了，到这里，我们就知道了造成内存碎片的内外因素，其中，内存分配器策略是内因，而Redis的负载属于外因，包括了大小不一的键值对和键值对修改删除带来的内存空间变化。</p><p>大量内存碎片的存在，会造成Redis的内存实际利用率变低，接下来，我们就要来解决这个问题了。不过，在解决问题前，我们要先判断Redis运行过程中是否存在内存碎片。</p><h2 id="如何判断是否有内存碎片？"><a href="#如何判断是否有内存碎片？" class="headerlink" title="如何判断是否有内存碎片？"></a>如何判断是否有内存碎片？</h2><p>Redis是内存数据库，内存利用率的高低直接关系到Redis运行效率的高低。为了让用户能监控到实时的内存使用情况，Redis自身提供了INFO命令，可以用来查询内存使用的详细信息，命令如下：</p><pre class="line-numbers language-none"><code class="language-none">INFO memory# Memoryused_memory:1073741736used_memory_human:1024.00Mused_memory_rss:1997159792used_memory_rss_human:1.86G…mem_fragmentation_ratio:1.86<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里有一个mem_fragmentation_ratio的指标，它表示的就是Redis当前的内存碎片率。那么，这个碎片率是怎么计算的呢？其实，就是上面的命令中的两个指标used_memory_rss和used_memory相除的结果。</p><pre class="line-numbers language-none"><code class="language-none">mem_fragmentation_ratio &#x3D; used_memory_rss&#x2F; used_memory<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>used_memory_rss是操作系统实际分配给Redis的物理内存空间，里面就包含了碎片；而used_memory是Redis为了保存数据实际申请使用的空间。</p><p>我简单举个例子。例如，Redis申请使用了100字节（used_memory），操作系统实际分配了128字节（used_memory_rss），此时，mem_fragmentation_ratio就是1.28。</p><p>那么，知道了这个指标，我们该如何使用呢？在这儿，我提供一些经验阈值：</p><ul><li><strong>mem_fragmentation_ratio 大于1但小于1.5</strong>。这种情况是合理的。这是因为，刚才我介绍的那些因素是难以避免的。毕竟，内因的内存分配器是一定要使用的，分配策略都是通用的，不会轻易修改；而外因由Redis负载决定，也无法限制。所以，存在内存碎片也是正常的。</li><li><strong>mem_fragmentation_ratio 大于 1.5</strong> 。这表明内存碎片率已经超过了50%。一般情况下，这个时候，我们就需要采取一些措施来降低内存碎片率了。</li></ul><h2 id="如何清理内存碎片？"><a href="#如何清理内存碎片？" class="headerlink" title="如何清理内存碎片？"></a>如何清理内存碎片？</h2><p>当Redis发生内存碎片后，一个“简单粗暴”的方法就是 <strong>重启Redis实例</strong>。当然，这并不是一个“优雅”的方法，毕竟，重启Redis会带来两个后果：</p><ul><li>如果Redis中的数据没有持久化，那么，数据就会丢失；</li><li>即使Redis数据持久化了，我们还需要通过AOF或RDB进行恢复，恢复时长取决于AOF或RDB的大小，如果只有一个Redis实例，恢复阶段无法提供服务。</li></ul><p>所以，还有什么其他好办法吗?</p><p>幸运的是，从4.0-RC3版本以后，Redis自身提供了一种内存碎片自动清理的方法，我们先来看这个方法的基本机制。</p><p>内存碎片清理，简单来说，就是“搬家让位，合并空间”。</p><p>我还以刚才的高铁车厢选座为例，来解释一下。你和小伙伴不想耽误时间，所以直接买了座位不在一起的三张票。但是，上车后，你和小伙伴通过和别人调换座位，又坐到了一起。</p><p>这么一说，碎片清理的机制就很容易理解了。当有数据把一块连续的内存空间分割成好几块不连续的空间时，操作系统就会把数据拷贝到别处。此时，数据拷贝需要能把这些数据原来占用的空间都空出来，把原本不连续的内存空间变成连续的空间。否则，如果数据拷贝后，并没有形成连续的内存空间，这就不能算是清理了。</p><p>我画一张图来解释一下。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/6480b6af5b2423b271ef3fb59f555842.jpg"></p><p>在进行碎片清理前，这段10字节的空间中分别有1个2字节和1个1字节的空闲空间，只是这两个空间并不连续。操作系统在清理碎片时，会先把应用D的数据拷贝到2字节的空闲空间中，并释放D原先所占的空间。然后，再把B的数据拷贝到D原来的空间中。这样一来，这段10字节空间的最后三个字节就是一块连续空间了。到这里，碎片清理结束。</p><p>不过，需要注意的是： <strong>碎片清理是有代价的</strong>，操作系统需要把多份数据拷贝到新位置，把原有空间释放出来，这会带来时间开销。因为Redis是单线程，在数据拷贝时，Redis只能等着，这就导致Redis无法及时处理请求，性能就会降低。而且，有的时候，数据拷贝还需要注意顺序，就像刚刚说的清理内存碎片的例子，操作系统需要先拷贝D，并释放D的空间后，才能拷贝B。这种对顺序性的要求，会进一步增加Redis的等待时间，导致性能降低。</p><p>那么，有什么办法可以尽量缓解这个问题吗？这就要提到，Redis专门为自动内存碎片清理功机制设置的参数了。我们可以通过设置参数，来控制碎片清理的开始和结束时机，以及占用的CPU比例，从而减少碎片清理对Redis本身请求处理的性能影响。</p><p>首先，Redis需要启用自动内存碎片清理，可以把activedefrag配置项设置为yes，命令如下：</p><pre class="line-numbers language-none"><code class="language-none">config set activedefrag yes<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个命令只是启用了自动清理功能，但是，具体什么时候清理，会受到下面这两个参数的控制。这两个参数分别设置了触发内存清理的一个条件，如果同时满足这两个条件，就开始清理。在清理的过程中，只要有一个条件不满足了，就停止自动清理。</p><ul><li><strong>active-defrag-ignore-bytes 100mb</strong>：表示内存碎片的字节数达到100MB时，开始清理；</li><li><strong>active-defrag-threshold-lower 10</strong>：表示内存碎片空间占操作系统分配给Redis的总空间比例达到10%时，开始清理。</li></ul><p>为了尽可能减少碎片清理对Redis正常请求处理的影响，自动内存碎片清理功能在执行时，还会监控清理操作占用的CPU时间，而且还设置了两个参数，分别用于控制清理操作占用的CPU时间比例的上、下限，既保证清理工作能正常进行，又避免了降低Redis性能。这两个参数具体如下：</p><ul><li><strong>active-defrag-cycle-min 25</strong>： 表示自动清理过程所用CPU时间的比例不低于25%，保证清理能正常开展；</li><li><strong>active-defrag-cycle-max 75</strong>：表示自动清理过程所用CPU时间的比例不高于75%，一旦超过，就停止清理，从而避免在清理时，大量的内存拷贝阻塞Redis，导致响应延迟升高。</li></ul><p>自动内存碎片清理机制在控制碎片清理启停的时机上，既考虑了碎片的空间占比、对Redis内存使用效率的影响，还考虑了清理机制本身的CPU时间占比、对Redis性能的影响。而且，清理机制还提供了4个参数，让我们可以根据实际应用中的数据量需求和性能要求灵活使用，建议你在实践中好好地把这个机制用起来。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这节课，我和你一起了解了Redis的内存空间效率问题，这里面的一个关键技术点就是要识别和处理内存碎片。简单来说，就是“三个一”：</p><ul><li>info memory命令是一个 <strong>好工具</strong>，可以帮助你查看碎片率的情况；</li><li>碎片率阈值是一个 <strong>好经验</strong>，可以帮忙你有效地判断是否要进行碎片清理了；</li><li>内存碎片自动清理是一个 <strong>好方法</strong>，可以避免因为碎片导致Redis的内存实际利用率降低，提升成本收益率。</li></ul><p>内存碎片并不可怕，我们要做的就是了解它，重视它，并借用高效的方法解决它。</p><p>最后，我再给你提供一个小贴士：内存碎片自动清理涉及内存拷贝，这对Redis而言，是个潜在的风险。如果你在实践过程中遇到Redis性能变慢，记得通过日志看下是否正在进行碎片清理。如果Redis的确正在清理碎片，那么，我建议你调小active-defrag-cycle-max的值，以减轻对正常请求处理的影响。</p><h2 id="每课一问"><a href="#每课一问" class="headerlink" title="每课一问"></a>每课一问</h2><p>按照惯例，我给你提一个小问题。在这节课中，我提到，可以使用mem_fragmentation_ratio来判断Redis当前的内存碎片率是否严重，我给出的经验阈值都是大于1的。那么，我想请你来聊一聊，如果mem_fragmentation_ratio小于1了，Redis的内存使用是什么情况呢？会对Redis的性能和内存空间利用率造成什么影响呢？</p><p>欢迎你在留言区写下你的思考和答案，和我一起交流讨论，如果觉得今天的内容对你有所帮助，也欢迎分享给你的朋友或同事，我们下节课见。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;20-删除数据后，为什么内存占用率还是很高？&quot;&gt;&lt;a href=&quot;#20-删除数据后，为什么内存占用率还是很高？&quot; class=&quot;headerlink&quot; title=&quot;20 | 删除数据后，为什么内存占用率还是很高？&quot;&gt;&lt;/a&gt;20 | 删除数据后，为什么内存占用</summary>
      
    
    
    
    <category term="Redis核心技术与实战" scheme="https://zhuansun.github.io/geekbang/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    
    
  </entry>
  
  <entry>
    <title>23 | 旁路缓存：Redis是如何工作的？</title>
    <link href="https://zhuansun.github.io/geekbang/posts/3779642275.html"/>
    <id>https://zhuansun.github.io/geekbang/posts/3779642275.html</id>
    <published>2024-03-04T22:10:14.000Z</published>
    <updated>2024-03-21T07:44:22.378Z</updated>
    
    <content type="html"><![CDATA[<h1 id="23-旁路缓存：Redis是如何工作的？"><a href="#23-旁路缓存：Redis是如何工作的？" class="headerlink" title="23 | 旁路缓存：Redis是如何工作的？"></a>23 | 旁路缓存：Redis是如何工作的？</h1><p>你好，我是蒋德钧。</p><p>我们知道，Redis提供了高性能的数据存取功能，所以广泛应用在缓存场景中，既能有效地提升业务应用的响应速度，还可以避免把高并发大压力的请求发送到数据库层。</p><p>但是，如果Redis做缓存时出现了问题，比如说缓存失效，那么，大量请求就会直接积压到数据库层，必然会给数据库带来巨大的压力，很可能会导致数据库宕机或是故障，那么，业务应用就没有办法存取数据、响应用户请求了。这种生产事故，肯定不是我们希望看到的。</p><p>正因为Redis用作缓存的普遍性以及它在业务应用中的重要作用，所以，我们需要系统地掌握缓存的一系列内容，包括工作原理、替换策略、异常处理和扩展机制。具体来说，我们需要解决四个关键问题：</p><ul><li>Redis缓存具体是怎么工作的？</li><li>Redis缓存如果满了，该怎么办？</li><li>为什么会有缓存一致性、缓存穿透、缓存雪崩、缓存击穿等异常，该如何应对？</li><li>Redis的内存毕竟有限，如果用快速的固态硬盘来保存数据，可以增加缓存的数据量，那么，Redis缓存可以使用快速固态硬盘吗？</li></ul><p>这节课，我们来了解下缓存的特征和Redis适用于缓存的天然优势，以及Redis缓存的具体工作机制。</p><h2 id="缓存的特征"><a href="#缓存的特征" class="headerlink" title="缓存的特征"></a>缓存的特征</h2><p>要想弄明白Redis为什么适合用作缓存，我们得清楚缓存都有什么特征。</p><p>首先，你要知道，一个系统中的不同层之间的访问速度不一样，所以我们才需要缓存，这样就可以把一些需要频繁访问的数据放在缓存中，以加快它们的访问速度。</p><p>为了让你能更好地理解，我以计算机系统为例，来解释一下。下图是计算机系统中的三层存储结构，以及它们各自的常用容量和访问性能。最上面是处理器，中间是内存，最下面是磁盘。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/ac80f6e1714f3e1e8eabcfd8da3d689c.jpg"></p><p>从图上可以看到，CPU、内存和磁盘这三层的访问速度从几十ns到100ns，再到几ms，性能的差异很大。</p><p>想象一下，如果每次CPU处理数据时，都要从ms级别的慢速磁盘中读取数据，然后再进行处理，那么，CPU只能等磁盘的数据传输完成。这样一来，高速的CPU就被慢速的磁盘拖累了，整个计算机系统的运行速度会变得非常慢。</p><p>所以，计算机系统中，默认有两种缓存：</p><ul><li>CPU里面的末级缓存，即LLC，用来缓存内存中的数据，避免每次从内存中存取数据；</li><li>内存中的高速页缓存，即page cache，用来缓存磁盘中的数据，避免每次从磁盘中存取数据。</li></ul><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/7dyycf727f9396eb9788644474855a44.jpg"></p><p>跟内存相比，LLC的访问速度更快，而跟磁盘相比，内存的访问是更快的。所以，我们可以看出来缓存的 <strong>第一个特征</strong>：在一个层次化的系统中，缓存一定是一个快速子系统，数据存在缓存中时，能避免每次从慢速子系统中存取数据。对应到互联网应用来说，Redis就是快速子系统，而数据库就是慢速子系统了。</p><p>知道了这一点，你就能理解，为什么我们必须想尽办法让Redis提供高性能的访问，因为，如果访问速度很慢，Redis作为缓存的价值就不大了。</p><p>我们再看一下刚才的计算机分层结构。LLC的大小是MB级别，page cache的大小是GB级别，而磁盘的大小是TB级别。这其实包含了缓存的 <strong>第二个特征：缓存系统的容量大小总是小于后端慢速系统的，我们不可能把所有数据都放在缓存系统中</strong>。</p><p>这个很有意思，它表明，缓存的容量终究是有限的，缓存中的数据量也是有限的，肯定是没法时刻都满足访问需求的。所以，缓存和后端慢速系统之间，必然存在数据写回和再读取的交互过程。简单来说，缓存中的数据需要按一定规则淘汰出去，写回后端系统，而新的数据又要从后端系统中读取进来，写入缓存。</p><p>说到这儿，你肯定会想到，Redis本身是支持按一定规则淘汰数据的，相当于实现了缓存的数据淘汰，其实，这也是Redis适合用作缓存的一个重要原因。</p><p>好了，我们现在了解了缓存的两个重要特征，那么，接下来，我们就来学习下，缓存是怎么处理请求的。实际上，业务应用在访问Redis缓存中的数据时，数据不一定存在，因此，处理的方式也不同。</p><h2 id="Redis缓存处理请求的两种情况"><a href="#Redis缓存处理请求的两种情况" class="headerlink" title="Redis缓存处理请求的两种情况"></a>Redis缓存处理请求的两种情况</h2><p>把Redis用作缓存时，我们会把Redis部署在数据库的前端，业务应用在访问数据时，会先查询Redis中是否保存了相应的数据。此时，根据数据是否存在缓存中，会有两种情况。</p><ul><li><strong>缓存命中</strong>：Redis中有相应数据，就直接读取Redis，性能非常快。</li><li><strong>缓存缺失</strong>：Redis中没有保存相应数据，就从后端数据库中读取数据，性能就会变慢。而且，一旦发生缓存缺失，为了让后续请求能从缓存中读取到数据，我们需要把缺失的数据写入Redis，这个过程叫作缓存更新。缓存更新操作会涉及到保证缓存和数据库之间的数据一致性问题，关于这一点，我会在第25讲中再具体介绍。</li></ul><p>我画了一张图，清晰地展示了发生缓存命中或缺失时，应用读取数据的情况，你可以看下这张图片。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/6b0b489ec0c1c5049c8df84d77fa243d.jpg"></p><p>假设我们在一个Web应用中，使用Redis作为缓存。用户请求发送给Tomcat，Tomcat负责处理业务逻辑。如果要访问数据，就需要从MySQL中读写数据。那么，我们可以把Redis部署在MySQL前端。如果访问的数据在Redis中，此时缓存命中，Tomcat可以直接从Redis中读取数据，加速应用的访问。否则，Tomcat就需要从慢速的数据库中读取数据了。</p><p>到这里，你可能已经发现了，使用Redis缓存时，我们基本有三个操作：</p><ul><li>应用读取数据时，需要先读取Redis；</li><li>发生缓存缺失时，需要从数据库读取数据；</li><li>发生缓存缺失时，还需要更新缓存。</li></ul><p>那么，这些操作具体是由谁来做的呢？这和Redis缓存的使用方式相关。接下来，我就来和你聊聊Redis作为旁路缓存的使用操作方式。</p><h2 id="Redis作为旁路缓存的使用操作"><a href="#Redis作为旁路缓存的使用操作" class="headerlink" title="Redis作为旁路缓存的使用操作"></a>Redis作为旁路缓存的使用操作</h2><p>Redis是一个独立的系统软件，和业务应用程序是两个软件，当我们部署了Redis实例后，它只会被动地等待客户端发送请求，然后再进行处理。所以，如果应用程序想要使用Redis缓存，我们就要在程序中增加相应的缓存操作代码。所以，我们也把Redis称为旁路缓存，也就是说，读取缓存、读取数据库和更新缓存的操作都需要在应用程序中来完成。</p><p>这和我刚才讲的计算机系统中的LLC和page cache不一样。你可以回想下，平时在开发程序时，我们是没有专门在代码中显式地创建LLC或page cache的实例的，也没有显式调用过它们的GET接口。这是因为，我们在构建计算机硬件系统时，已经把LLC和page cache放在了应用程序的数据访问路径上，应用程序访问数据时直接就能用上缓存。</p><p>那么，使用Redis缓存时，具体来说，我们需要在应用程序中增加三方面的代码：</p><ul><li>当应用程序需要读取数据时，我们需要在代码中显式调用Redis的GET操作接口，进行查询；</li><li>如果缓存缺失了，应用程序需要再和数据库连接，从数据库中读取数据；</li><li>当缓存中的数据需要更新时，我们也需要在应用程序中显式地调用SET操作接口，把更新的数据写入缓存。</li></ul><p>那么，代码应该怎么加呢？我给你展示一段Web应用中使用Redis缓存的伪代码示例。</p><pre class="line-numbers language-none"><code class="language-none">String cacheKey &#x3D; “productid_11010003”;String cacheValue &#x3D; redisCache.get(cacheKey)；&#x2F;&#x2F;缓存命中if ( cacheValue !&#x3D; NULL)   return cacheValue;&#x2F;&#x2F;缓存缺失else   cacheValue &#x3D; getProductFromDB();   redisCache.put(cacheValue)  &#x2F;&#x2F;缓存更新<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到，为了使用缓存，Web应用程序需要有一个表示缓存系统的实例对象redisCache，还需要主动调用Redis的GET接口，并且要处理缓存命中和缓存缺失时的逻辑，例如在缓存缺失时，需要更新缓存。</p><p>了解了这一点，我们在使用Redis缓存时，有一个地方就需要注意了：因为需要新增程序代码来使用缓存，所以，Redis并不适用于那些无法获得源码的应用，例如一些很早之前开发的应用程序，它们的源码已经没有再维护了，或者是第三方供应商开发的应用，没有提供源码，所以，我们就没有办法在这些应用中进行缓存操作。</p><p>在使用旁路缓存时，我们需要在应用程序中增加操作代码，增加了使用Redis缓存的额外工作量，但是，也正因为Redis是旁路缓存，是一个独立的系统，我们可以单独对Redis缓存进行扩容或性能优化。而且，只要保持操作接口不变，我们在应用程序中增加的代码就不用再修改了。</p><p>好了，到这里，我们知道了，通过在应用程序中加入Redis的操作代码，我们可以让应用程序使用Redis缓存数据了。不过，除了从Redis缓存中查询、读取数据以外，应用程序还可能会对数据进行修改，这时，我们既可以在缓存中修改，也可以在后端数据库中进行修改，我们该怎么选择呢？</p><p>其实，这就涉及到了Redis缓存的两种类型：只读缓存和读写缓存。只读缓存能加速读请求，而读写缓存可以同时加速读写请求。而且，读写缓存又有两种数据写回策略，可以让我们根据业务需求，在保证性能和保证数据可靠性之间进行选择。所以，接下来，我们来具体了解下Redis的缓存类型和相应的写回策略。</p><h2 id="缓存的类型"><a href="#缓存的类型" class="headerlink" title="缓存的类型"></a>缓存的类型</h2><p>按照Redis缓存是否接受写请求，我们可以把它分成只读缓存和读写缓存。先来了解下只读缓存。</p><h3 id="只读缓存"><a href="#只读缓存" class="headerlink" title="只读缓存"></a>只读缓存</h3><p>当Redis用作只读缓存时，应用要读取数据的话，会先调用Redis GET接口，查询数据是否存在。而所有的数据写请求，会直接发往后端的数据库，在数据库中增删改。对于删改的数据来说，如果Redis已经缓存了相应的数据，应用需要把这些缓存的数据删除，Redis中就没有这些数据了。</p><p>当应用再次读取这些数据时，会发生缓存缺失，应用会把这些数据从数据库中读出来，并写到缓存中。这样一来，这些数据后续再被读取时，就可以直接从缓存中获取了，能起到加速访问的效果。</p><p>我给你举个例子。假设业务应用要修改数据A，此时，数据A在Redis中也缓存了，那么，应用会先直接在数据库里修改A，并把Redis中的A删除。等到应用需要读取数据A时，会发生缓存缺失，此时，应用从数据库中读取A，并写入Redis，以便后续请求从缓存中直接读取，如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/464ea24a098c87b9d292cf61a2b2fecd.jpg"></p><p>只读缓存直接在数据库中更新数据的好处是，所有最新的数据都在数据库中，而数据库是提供数据可靠性保障的，这些数据不会有丢失的风险。当我们需要缓存图片、短视频这些用户只读的数据时，就可以使用只读缓存这个类型了。</p><h3 id="读写缓存"><a href="#读写缓存" class="headerlink" title="读写缓存"></a>读写缓存</h3><p>知道了只读缓存，读写缓存也就很容易理解了。</p><p>对于读写缓存来说，除了读请求会发送到缓存进行处理（直接在缓存中查询数据是否存在)，所有的写请求也会发送到缓存，在缓存中直接对数据进行增删改操作。此时，得益于Redis的高性能访问特性，数据的增删改操作可以在缓存中快速完成，处理结果也会快速返回给业务应用，这就可以提升业务应用的响应速度。</p><p>但是，和只读缓存不一样的是，在使用读写缓存时，最新的数据是在Redis中，而Redis是内存数据库，一旦出现掉电或宕机，内存中的数据就会丢失。这也就是说，应用的最新数据可能会丢失，给应用业务带来风险。</p><p>所以，根据业务应用对数据可靠性和缓存性能的不同要求，我们会有同步直写和异步写回两种策略。其中，同步直写策略优先保证数据可靠性，而异步写回策略优先提供快速响应。学习了解这两种策略，可以帮助我们根据业务需求，做出正确的设计选择。</p><p>接下来，我们来具体看下这两种策略。</p><p>同步直写是指，写请求发给缓存的同时，也会发给后端数据库进行处理，等到缓存和数据库都写完数据，才给客户端返回。这样，即使缓存宕机或发生故障，最新的数据仍然保存在数据库中，这就提供了数据可靠性保证。</p><p>不过，同步直写会降低缓存的访问性能。这是因为缓存中处理写请求的速度是很快的，而数据库处理写请求的速度较慢。即使缓存很快地处理了写请求，也需要等待数据库处理完所有的写请求，才能给应用返回结果，这就增加了缓存的响应延迟。</p><p>而异步写回策略，则是优先考虑了响应延迟。此时，所有写请求都先在缓存中处理。等到这些增改的数据要被从缓存中淘汰出来时，缓存将它们写回后端数据库。这样一来，处理这些数据的操作是在缓存中进行的，很快就能完成。只不过，如果发生了掉电，而它们还没有被写回数据库，就会有丢失的风险了。</p><p>为了便于你理解，我也画了下面这张图，你可以看下。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/009d055bb91d42c28b9316c649f87f66.jpg"></p><p>关于是选择只读缓存，还是读写缓存，主要看我们对写请求是否有加速的需求。</p><ul><li>如果需要对写请求进行加速，我们选择读写缓存；</li><li>如果写请求很少，或者是只需要提升读请求的响应速度的话，我们选择只读缓存。</li></ul><p>举个例子，在商品大促的场景中，商品的库存信息会一直被修改。如果每次修改都需到数据库中处理，就会拖慢整个应用，此时，我们通常会选择读写缓存的模式。而在短视频App的场景中，虽然视频的属性有很多，但是，一般确定后，修改并不频繁，此时，在数据库中进行修改对缓存影响不大，所以只读缓存模式是一个合适的选择。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>今天，我们学习了缓存的两个特征，分别是在分层系统中，数据暂存在快速子系统中有助于加速访问；缓存容量有限，缓存写满时，数据需要被淘汰。而Redis天然就具有高性能访问和数据淘汰机制，正好符合缓存的这两个特征的要求，所以非常适合用作缓存。</p><p>另外，我们还学习了Redis作为旁路缓存的特性，旁路缓存就意味着需要在应用程序中新增缓存逻辑处理的代码。当然，如果是无法修改源码的应用场景，就不能使用Redis做缓存了。</p><p>Redis做缓存时，还有两种模式，分别是只读缓存和读写缓存。其中，读写缓存还提供了同步直写和异步写回这两种模式，同步直写模式侧重于保证数据可靠性，而异步写回模式则侧重于提供低延迟访问，我们要根据实际的业务场景需求来进行选择。</p><p>这节课，虽然我提到了Redis有数据淘汰机制，但是并没有展开讲具体的淘汰策略。那么，Redis究竟是怎么淘汰数据的呢？我会在下节课给你具体介绍。</p><h2 id="每课一问"><a href="#每课一问" class="headerlink" title="每课一问"></a>每课一问</h2><p>按照惯例，我给你提一个小问题。这节课，我提到了Redis只读缓存和使用直写策略的读写缓存，这两种缓存都会把数据同步写到后端数据库中，你觉得，它们有什么区别吗？</p><p>欢迎在留言区写下你的思考和答案，我们一起交流讨论。如果你觉得今天的内容对你有所帮助，也欢迎你分享给你的朋友或同事。我们下节课见。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;23-旁路缓存：Redis是如何工作的？&quot;&gt;&lt;a href=&quot;#23-旁路缓存：Redis是如何工作的？&quot; class=&quot;headerlink&quot; title=&quot;23 | 旁路缓存：Redis是如何工作的？&quot;&gt;&lt;/a&gt;23 | 旁路缓存：Redis是如何工作的？&lt;/</summary>
      
    
    
    
    <category term="Redis核心技术与实战" scheme="https://zhuansun.github.io/geekbang/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    
    
  </entry>
  
  <entry>
    <title>21 | 缓冲区：一个可能引发“惨案”的地方</title>
    <link href="https://zhuansun.github.io/geekbang/posts/3309845710.html"/>
    <id>https://zhuansun.github.io/geekbang/posts/3309845710.html</id>
    <published>2024-03-04T22:10:14.000Z</published>
    <updated>2024-03-21T07:44:22.374Z</updated>
    
    <content type="html"><![CDATA[<h1 id="21-缓冲区：一个可能引发“惨案”的地方"><a href="#21-缓冲区：一个可能引发“惨案”的地方" class="headerlink" title="21 | 缓冲区：一个可能引发“惨案”的地方"></a>21 | 缓冲区：一个可能引发“惨案”的地方</h1><p>你好，我是蒋德钧。今天，我们一起来学习下Redis中缓冲区的用法。</p><p>缓冲区的功能其实很简单，主要就是用一块内存空间来暂时存放命令数据，以免出现因为数据和命令的处理速度慢于发送速度而导致的数据丢失和性能问题。但因为缓冲区的内存空间有限，如果往里面写入数据的速度持续地大于从里面读取数据的速度，就会导致缓冲区需要越来越多的内存来暂存数据。当缓冲区占用的内存超出了设定的上限阈值时，就会出现缓冲区溢出。</p><p>如果发生了溢出，就会丢数据了。那是不是不给缓冲区的大小设置上限，就可以了呢？显然不是，随着累积的数据越来越多，缓冲区占用内存空间越来越大，一旦耗尽了Redis实例所在机器的可用内存，就会导致Redis实例崩溃。</p><p>所以毫不夸张地说，缓冲区是用来避免请求或数据丢失的惨案的，但也只有用对了，才能真正起到“避免”的作用。</p><p>我们知道，Redis是典型的client-server架构，所有的操作命令都需要通过客户端发送给服务器端。所以，缓冲区在Redis中的一个主要应用场景，就是在客户端和服务器端之间进行通信时，用来暂存客户端发送的命令数据，或者是服务器端返回给客户端的数据结果。此外，缓冲区的另一个主要应用场景，是在主从节点间进行数据同步时，用来暂存主节点接收的写命令和数据。</p><p>这节课，我们就分别聊聊服务器端和客户端、主从集群间的缓冲区溢出问题，以及应对方案。</p><h2 id="客户端输入和输出缓冲区"><a href="#客户端输入和输出缓冲区" class="headerlink" title="客户端输入和输出缓冲区"></a>客户端输入和输出缓冲区</h2><p>我们先来看看服务器端和客户端之间的缓冲区。</p><p>为了避免客户端和服务器端的请求发送和处理速度不匹配，服务器端给每个连接的客户端都设置了一个输入缓冲区和输出缓冲区，我们称之为客户端输入缓冲区和输出缓冲区。</p><p>输入缓冲区会先把客户端发送过来的命令暂存起来，Redis主线程再从输入缓冲区中读取命令，进行处理。当Redis主线程处理完数据后，会把结果写入到输出缓冲区，再通过输出缓冲区返回给客户端，如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/b86be61e91bd7ca207989c220991fce4.jpg"></p><p>下面，我们就分别学习下输入缓冲区和输出缓冲区发生溢出的情况，以及相应的应对方案。</p><h3 id="如何应对输入缓冲区溢出？"><a href="#如何应对输入缓冲区溢出？" class="headerlink" title="如何应对输入缓冲区溢出？"></a>如何应对输入缓冲区溢出？</h3><p>我们前面已经分析过了，输入缓冲区就是用来暂存客户端发送的请求命令的，所以可能导致溢出的情况主要是下面两种：</p><ul><li>写入了bigkey，比如一下子写入了多个百万级别的集合类型数据；</li><li>服务器端处理请求的速度过慢，例如，Redis主线程出现了间歇性阻塞，无法及时处理正常发送的请求，导致客户端发送的请求在缓冲区越积越多。</li></ul><p>接下来，我们就从 <strong>如何查看输入缓冲区的内存使用情况，以及如何避免溢出</strong> 这两个问题出发，来继续学习吧。</p><p>要查看和服务器端相连的每个客户端对输入缓冲区的使用情况，我们可以 <strong>使用CLIENT LIST命令</strong>：</p><pre class="line-numbers language-none"><code class="language-none">CLIENT LISTid&#x3D;5 addr&#x3D;127.0.0.1:50487 fd&#x3D;9 name&#x3D; age&#x3D;4 idle&#x3D;0 flags&#x3D;N db&#x3D;0 sub&#x3D;0 psub&#x3D;0 multi&#x3D;-1 qbuf&#x3D;26 qbuf-free&#x3D;32742 obl&#x3D;0 oll&#x3D;0 omem&#x3D;0 events&#x3D;r cmd&#x3D;client<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>CLIENT命令返回的信息虽然很多，但我们只需要重点关注两类信息就可以了。</p><p>一类是与服务器端连接的客户端的信息。这个案例展示的是一个客户端的输入缓冲区情况，如果有多个客户端，输出结果中的addr会显示不同客户端的IP和端口号。</p><p>另一类是与输入缓冲区相关的三个参数：</p><ul><li>cmd，表示客户端最新执行的命令。这个例子中执行的是CLIENT命令。</li><li>qbuf，表示输入缓冲区已经使用的大小。这个例子中的CLIENT命令已使用了26字节大小的缓冲区。</li><li>qbuf-free，表示输入缓冲区尚未使用的大小。这个例子中的CLIENT命令还可以使用32742字节的缓冲区。qbuf和qbuf-free的总和就是，Redis服务器端当前为已连接的这个客户端分配的缓冲区总大小。这个例子中总共分配了 26 + 32742 &#x3D; 32768字节，也就是32KB的缓冲区。</li></ul><p>有了CLIENT LIST命令，我们就可以通过输出结果来判断客户端输入缓冲区的内存占用情况了。如果qbuf很大，而同时qbuf-free很小，就要引起注意了，因为这时候输入缓冲区已经占用了很多内存，而且没有什么空闲空间了。此时，客户端再写入大量命令的话，就会引起客户端输入缓冲区溢出，Redis的处理办法就是把客户端连接关闭，结果就是业务程序无法进行数据存取了。</p><p>通常情况下，Redis服务器端不止服务一个客户端，当多个客户端连接占用的内存总量，超过了Redis的maxmemory配置项时（例如4GB），就会触发Redis进行数据淘汰。一旦数据被淘汰出Redis，再要访问这部分数据，就需要去后端数据库读取，这就降低了业务应用的访问性能。此外，更糟糕的是，如果使用多个客户端，导致Redis内存占用过大，也会导致内存溢出（out-of-memory）问题，进而会引起Redis崩溃，给业务应用造成严重影响。</p><p>所以，我们必须得想办法避免输入缓冲区溢出。 <strong>我们可以从两个角度去考虑如何避免，一是把缓冲区调大，二是从数据命令的发送和处理速度入手。</strong></p><p>我们先看看，到底有没有办法通过参数调整输入缓冲区的大小呢？答案是没有。</p><p>Redis的客户端输入缓冲区大小的上限阈值，在代码中就设定为了1GB。也就是说，Redis服务器端允许为每个客户端最多暂存1GB的命令和数据。1GB的大小，对于一般的生产环境已经是比较合适的了。一方面，这个大小对于处理绝大部分客户端的请求已经够用了；另一方面，如果再大的话，Redis就有可能因为客户端占用了过多的内存资源而崩溃。</p><p>所以，Redis并没有提供参数让我们调节客户端输入缓冲区的大小。如果要避免输入缓冲区溢出，那我们就只能从数据命令的发送和处理速度入手，也就是前面提到的避免客户端写入bigkey，以及避免Redis主线程阻塞。</p><p>接下来，我们再来看看输出缓冲区的溢出问题。</p><h3 id="如何应对输出缓冲区溢出？"><a href="#如何应对输出缓冲区溢出？" class="headerlink" title="如何应对输出缓冲区溢出？"></a>如何应对输出缓冲区溢出？</h3><p>Redis的输出缓冲区暂存的是Redis主线程要返回给客户端的数据。一般来说，主线程返回给客户端的数据，既有简单且大小固定的OK响应（例如，执行SET命令）或报错信息，也有大小不固定的、包含具体数据的执行结果（例如，执行HGET命令）。</p><p>因此，Redis为每个客户端设置的输出缓冲区也包括两部分：一部分，是一个大小为16KB的固定缓冲空间，用来暂存OK响应和出错信息；另一部分，是一个可以动态增加的缓冲空间，用来暂存大小可变的响应结果。</p><p><strong>那什么情况下会发生输出缓冲区溢出呢？</strong> 我为你总结了三种：</p><ul><li>服务器端返回bigkey的大量结果；</li><li>执行了MONITOR命令；</li><li>缓冲区大小设置得不合理。</li></ul><p>其中，bigkey原本就会占用大量的内存空间，所以服务器端返回的结果包含bigkey，必然会影响输出缓冲区。接下来，我们就重点看下，执行MONITOR命令和设置缓冲区大小这两种情况吧。</p><p>MONITOR命令是用来监测Redis执行的。执行这个命令之后，就会持续输出监测到的各个命令操作，如下所示：</p><pre class="line-numbers language-none"><code class="language-none">MONITOROK1600617456.437129 [0 127.0.0.1:50487] &quot;COMMAND&quot;1600617477.289667 [0 127.0.0.1:50487] &quot;info&quot; &quot;memory&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>到这里，你有没有看出什么问题呢？MONITOR的输出结果会持续占用输出缓冲区，并越占越多，最后的结果就是发生溢出。所以，我要给你一个小建议： <strong>MONITOR命令主要用在调试环境中，不要在线上生产环境中持续使用MONITOR</strong>。当然，如果在线上环境中偶尔使用MONITOR检查Redis的命令执行情况，是没问题的。</p><p><strong>接下来，我们看下输出缓冲区大小设置的问题</strong>。和输入缓冲区不同，我们可以通过client-output-buffer-limit配置项，来设置缓冲区的大小。具体设置的内容包括两方面：</p><ul><li>设置缓冲区大小的上限阈值；</li><li>设置输出缓冲区持续写入数据的数量上限阈值，和持续写入数据的时间的上限阈值。</li></ul><p>在具体使用client-output-buffer-limit来设置缓冲区大小的时候，我们需要先区分下客户端的类型。</p><p>对于和Redis实例进行交互的应用程序来说，主要使用两类客户端和Redis服务器端交互，分别是常规和Redis服务器端进行读写命令交互的普通客户端，以及订阅了Redis频道的订阅客户端。此外，在Redis主从集群中，主节点上也有一类客户端（从节点客户端）用来和从节点进行数据同步，我会在介绍主从集群中的缓冲区时，向你具体介绍。</p><p>当我们给普通客户端设置缓冲区大小时，通常可以在Redis配置文件中进行这样的设置：</p><pre class="line-numbers language-none"><code class="language-none">client-output-buffer-limit normal 0 0 0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中，normal表示当前设置的是普通客户端，第1个0设置的是缓冲区大小限制，第2个0和第3个0分别表示缓冲区持续写入量限制和持续写入时间限制。</p><p>对于普通客户端来说，它每发送完一个请求，会等到请求结果返回后，再发送下一个请求，这种发送方式称为阻塞式发送。在这种情况下，如果不是读取体量特别大的bigkey，服务器端的输出缓冲区一般不会被阻塞的。</p><p>所以，我们通常把普通客户端的缓冲区大小限制，以及持续写入量限制、持续写入时间限制都设置为0，也就是不做限制。</p><p>对于订阅客户端来说，一旦订阅的Redis频道有消息了，服务器端都会通过输出缓冲区把消息发给客户端。所以，订阅客户端和服务器间的消息发送方式，不属于阻塞式发送。不过，如果频道消息较多的话，也会占用较多的输出缓冲区空间。</p><p>因此，我们会给订阅客户端设置缓冲区大小限制、缓冲区持续写入量限制，以及持续写入时间限制，可以在Redis配置文件中这样设置：</p><pre class="line-numbers language-none"><code class="language-none">client-output-buffer-limit pubsub 8mb 2mb 60<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中，pubsub参数表示当前是对订阅客户端进行设置；8mb表示输出缓冲区的大小上限为8MB，一旦实际占用的缓冲区大小要超过8MB，服务器端就会直接关闭客户端的连接；2mb和60表示，如果连续60秒内对输出缓冲区的写入量超过2MB的话，服务器端也会关闭客户端连接。</p><p>好了，我们来总结下如何应对输出缓冲区溢出：</p><ul><li>避免bigkey操作返回大量数据结果；</li><li>避免在线上环境中持续使用MONITOR命令。</li><li>使用client-output-buffer-limit设置合理的缓冲区大小上限，或是缓冲区连续写入时间和写入量上限。</li></ul><p>以上就是关于客户端缓冲区，我们要重点掌握的内容了。我们继续看看在主从集群间使用缓冲区，需要注意什么问题。</p><h2 id="主从集群中的缓冲区"><a href="#主从集群中的缓冲区" class="headerlink" title="主从集群中的缓冲区"></a>主从集群中的缓冲区</h2><p>主从集群间的数据复制包括全量复制和增量复制两种。全量复制是同步所有数据，而增量复制只会把主从库网络断连期间主库收到的命令，同步给从库。无论在哪种形式的复制中，为了保证主从节点的数据一致，都会用到缓冲区。但是，这两种复制场景下的缓冲区，在溢出影响和大小设置方面并不一样。所以，我们分别来学习下吧。</p><h3 id="复制缓冲区的溢出问题"><a href="#复制缓冲区的溢出问题" class="headerlink" title="复制缓冲区的溢出问题"></a>复制缓冲区的溢出问题</h3><p>在全量复制过程中，主节点在向从节点传输RDB文件的同时，会继续接收客户端发送的写命令请求。这些写命令就会先保存在复制缓冲区中，等RDB文件传输完成后，再发送给从节点去执行。主节点上会为每个从节点都维护一个复制缓冲区，来保证主从节点间的数据同步。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/a39cd9a9f62c547e2069e6977239de7a.jpg"></p><p>所以，如果在全量复制时，从节点接收和加载RDB较慢，同时主节点接收到了大量的写命令，写命令在复制缓冲区中就会越积越多，最终导致溢出。</p><p>其实，主节点上的复制缓冲区，本质上也是一个用于和从节点连接的客户端（我们称之为从节点客户端），使用的输出缓冲区。复制缓冲区一旦发生溢出，主节点也会直接关闭和从节点进行复制操作的连接，导致全量复制失败。那如何避免复制缓冲区发生溢出呢？</p><p>一方面，我们可以控制主节点保存的数据量大小。按通常的使用经验，我们会把主节点的数据量控制在2~4GB，这样可以让全量同步执行得更快些，避免复制缓冲区累积过多命令。</p><p>另一方面，我们可以使用client-output-buffer-limit配置项，来设置合理的复制缓冲区大小。设置的依据，就是主节点的数据量大小、主节点的写负载压力和主节点本身的内存大小。</p><p>我们通过一个具体的例子，来学习下具体怎么设置。在主节点执行如下命令：</p><pre class="line-numbers language-none"><code class="language-none">config set client-output-buffer-limit slave 512mb 128mb 60<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中，slave参数表明该配置项是针对复制缓冲区的。512mb代表将缓冲区大小的上限设置为512MB；128mb和60代表的设置是，如果连续60秒内的写入量超过128MB的话，也会触发缓冲区溢出。</p><p>我们再继续看看这个设置对我们有啥用。假设一条写命令数据是1KB，那么，复制缓冲区可以累积512K条（512MB&#x2F;1KB &#x3D; 512K）写命令。同时，主节点在全量复制期间，可以承受的写命令速率上限是2000条&#x2F;s（128MB&#x2F;1KB&#x2F;60 约等于2000）。</p><p>这样一来，我们就得到了一种方法：在实际应用中设置复制缓冲区的大小时，可以根据写命令数据的大小和应用的实际负载情况（也就是写命令速率），来粗略估计缓冲区中会累积的写命令数据量；然后，再和所设置的复制缓冲区大小进行比较，判断设置的缓冲区大小是否足够支撑累积的写命令数据量。</p><p>关于复制缓冲区，我们还会遇到一个问题。主节点上复制缓冲区的内存开销，会是每个从节点客户端输出缓冲区占用内存的总和。如果集群中的从节点数非常多的话，主节点的内存开销就会非常大。所以，我们还必须得控制和主节点连接的从节点个数，不要使用大规模的主从集群。</p><p>好了，我们先总结一下这部分的内容。为了避免复制缓冲区累积过多命令造成溢出，引发全量复制失败，我们可以控制主节点保存的数据量大小，并设置合理的复制缓冲区大小。同时，我们需要控制从节点的数量，来避免主节点中复制缓冲区占用过多内存的问题。</p><h3 id="复制积压缓冲区的溢出问题"><a href="#复制积压缓冲区的溢出问题" class="headerlink" title="复制积压缓冲区的溢出问题"></a>复制积压缓冲区的溢出问题</h3><p>接下来，我们再来看下增量复制时使用的缓冲区，这个缓冲区称为复制积压缓冲区。</p><p>主节点在把接收到的写命令同步给从节点时，同时会把这些写命令写入复制积压缓冲区。一旦从节点发生网络闪断，再次和主节点恢复连接后，从节点就会从复制积压缓冲区中，读取断连期间主节点接收到的写命令，进而进行增量同步，如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/aedc9b41b31860e283c5d140bdb3318f.jpg"></p><p>看到这里你是不是感觉有些熟悉？没错，我们在 <a href="https://time.geekbang.org/column/article/272852">第6讲</a> 时已经学过复制积压缓冲区了，只不过我当时告诉你的是它的英文名字repl_backlog_buffer。所以这一讲，我们从缓冲区溢出的角度再来回顾下两个重点：复制积压缓冲区溢出的影响，以及如何应对复制积压缓冲区的溢出问题。</p><p>首先，复制积压缓冲区是一个大小有限的环形缓冲区。当主节点把复制积压缓冲区写满后，会覆盖缓冲区中的旧命令数据。如果从节点还没有同步这些旧命令数据，就会造成主从节点间重新开始执行全量复制。</p><p>其次，为了应对复制积压缓冲区的溢出问题，我们可以调整复制积压缓冲区的大小，也就是设置repl_backlog_size这个参数的值。具体的调整依据，你可以再看下 <a href="https://time.geekbang.org/column/article/272852">第6讲</a> 中提供的repl_backlog_size大小的计算依据。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这节课，我们一起学习了Redis中使用的缓冲区。使用缓冲区以后，当命令数据的接收方处理速度跟不上发送方的发送速度时，缓冲区可以避免命令数据的丢失。</p><p>按照缓冲区的用途，例如是用于客户端通信还是用于主从节点复制，我把缓冲区分成了客户端的输入和输出缓冲区，以及主从集群中主节点上的复制缓冲区和复制积压缓冲区。这样学习的好处是，你可以很清楚Redis中到底有哪些地方使用了缓冲区，那么在排查问题的时候，就可以快速找到方向——从客户端和服务器端的通信过程以及主从节点的复制过程中分析原因。</p><p>现在，从缓冲区溢出对Redis的影响的角度，我再把这四个缓冲区分成两类做个总结。</p><ul><li>缓冲区溢出导致网络连接关闭：普通客户端、订阅客户端，以及从节点客户端，它们使用的缓冲区，本质上都是Redis客户端和服务器端之间，或是主从节点之间为了传输命令数据而维护的。这些缓冲区一旦发生溢出，处理机制都是直接把客户端和服务器端的连接，或是主从节点间的连接关闭。网络连接关闭造成的直接影响，就是业务程序无法读写Redis，或者是主从节点全量同步失败，需要重新执行。</li><li>缓冲区溢出导致命令数据丢失：主节点上的复制积压缓冲区属于环形缓冲区，一旦发生溢出，新写入的命令数据就会覆盖旧的命令数据，导致旧命令数据的丢失，进而导致主从节点重新进行全量复制。</li></ul><p>从本质上看，缓冲区溢出，无非就是三个原因：命令数据发送过快过大；命令数据处理较慢；缓冲区空间过小。明白了这个，我们就可以有针对性地拿出应对策略了。</p><ul><li>针对命令数据发送过快过大的问题，对于普通客户端来说可以避免bigkey，而对于复制缓冲区来说，就是避免过大的RDB文件。</li><li>针对命令数据处理较慢的问题，解决方案就是减少Redis主线程上的阻塞操作，例如使用异步的删除操作。</li><li>针对缓冲区空间过小的问题，解决方案就是使用client-output-buffer-limit配置项设置合理的输出缓冲区、复制缓冲区和复制积压缓冲区大小。当然，我们不要忘了，输入缓冲区的大小默认是固定的，我们无法通过配置来修改它，除非直接去修改Redis源码。</li></ul><p>有了上面这些应对方法，我相信你在实际应用时，就可以避免缓冲区溢出带来的命令数据丢失、Redis崩溃的这些“惨案”了。</p><h2 id="每课一问"><a href="#每课一问" class="headerlink" title="每课一问"></a>每课一问</h2><p>最后，我给你提个小问题吧。</p><p>在这节课上，我们提到Redis采用了client-server架构，服务器端会为每个客户端维护输入、输出缓冲区。那么，应用程序和Redis实例交互时，应用程序中使用的客户端需要使用缓冲区吗？如果使用的话，对Redis的性能和内存使用会有影响吗？</p><p>欢迎在留言区写下你的思考和答案，我们一起交流讨论。如果你觉得今天的内容对你有所帮助，也欢迎你分享给你的朋友或同事，我们下节课见。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;21-缓冲区：一个可能引发“惨案”的地方&quot;&gt;&lt;a href=&quot;#21-缓冲区：一个可能引发“惨案”的地方&quot; class=&quot;headerlink&quot; title=&quot;21 | 缓冲区：一个可能引发“惨案”的地方&quot;&gt;&lt;/a&gt;21 | 缓冲区：一个可能引发“惨案”的地方&lt;/</summary>
      
    
    
    
    <category term="Redis核心技术与实战" scheme="https://zhuansun.github.io/geekbang/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    
    
  </entry>
  
  <entry>
    <title>22 | 第11～21讲课后思考题答案及常见问题答疑</title>
    <link href="https://zhuansun.github.io/geekbang/posts/3800514353.html"/>
    <id>https://zhuansun.github.io/geekbang/posts/3800514353.html</id>
    <published>2024-03-04T22:10:14.000Z</published>
    <updated>2024-03-21T07:44:22.376Z</updated>
    
    <content type="html"><![CDATA[<h1 id="22-第11～21讲课后思考题答案及常见问题答疑"><a href="#22-第11～21讲课后思考题答案及常见问题答疑" class="headerlink" title="22 | 第11～21讲课后思考题答案及常见问题答疑"></a>22 | 第11～21讲课后思考题答案及常见问题答疑</h1><p>你好，我是蒋德钧。</p><p>咱们的课程已经更新到第21讲了，今天，我们来进行一场答疑。</p><p>前半部分，我会给你讲解第11～21讲的课后思考题。在学习这部分内容时，可以和你的答案进行对照，看看还有哪里没有考虑到。当然，有些问题不一定有标准答案，我们还可以继续讨论。</p><p>后半部分，我会围绕着许多同学都很关注的如何排查慢查询命令和bigkey的问题，重点解释一下，希望可以解答你的困惑。</p><p>好了，我们现在开始。</p><h2 id="课后思考题答案"><a href="#课后思考题答案" class="headerlink" title="课后思考题答案"></a>课后思考题答案</h2><h3 id="第11讲"><a href="#第11讲" class="headerlink" title="第11讲"></a><a href="https://time.geekbang.org/column/article/279649">第11讲</a></h3><p><strong>问题：除了String类型和Hash类型，还有什么类型适合保存第11讲中所说的图片吗？</strong></p><p>答案：除了String和Hash，我们还可以使用Sorted Set类型进行保存。Sorted Set的元素有member值和score值，可以像Hash那样，使用二级编码进行保存。具体做法是，把图片ID的前7位作为Sorted Set的key，把图片ID的后3位作为member值，图片存储对象ID作为score值。</p><p>Sorted Set中元素较少时，Redis会使用压缩列表进行存储，可以节省内存空间。不过，和Hash不一样，Sorted Set插入数据时，需要按score值的大小排序。当底层结构是压缩列表时，Sorted Set的插入性能就比不上Hash。所以，在我们这节课描述的场景中，Sorted Set类型虽然可以用来保存，但并不是最优选项。</p><h3 id="第12讲"><a href="#第12讲" class="headerlink" title="第12讲"></a><a href="https://time.geekbang.org/column/article/280680">第12讲</a></h3><p>问题：我在第12讲中介绍了4种典型的统计模式，分别是聚合统计、排序统计、二值状态统计和基数统计，以及它们各自适合的集合类型。你还遇到过其他的统计场景吗？用的是什么集合类型呢？</p><p>答案：@海拉鲁同学在留言中提供了一种场景：他们曾使用List+Lua统计最近200个客户的触达率。具体做法是，每个List元素表示一个客户，元素值为0，代表触达；元素值为1，就代表未触达。在进行统计时，应用程序会把代表客户的元素写入队列中。当需要统计触达率时，就使用LRANGE key 0 -1 取出全部元素，计算0的比例，这个比例就是触达率。</p><p>这个例子需要获取全部元素，不过数据量只有200个，不算大，所以，使用List，在实际应用中也是可以接受的。但是，如果数据量很大，又有其他查询需求的话（例如查询单个元素的触达情况），List的操作复杂度较高，就不合适了，可以考虑使用Hash类型。</p><h3 id="第13讲"><a href="#第13讲" class="headerlink" title="第13讲"></a><a href="https://time.geekbang.org/column/article/281745">第13讲</a></h3><p>问题：你在日常的实践过程中，还用过Redis的其他数据类型吗？</p><p>答案：除了我们课程上介绍的5大基本数据类型，以及HyperLogLog、Bitmap、GEO，Redis还有一种数据类型，叫作布隆过滤器。它的查询效率很高，经常会用在缓存场景中，可以用来判断数据是否存在缓存中。我会在后面（第25讲）具体地介绍一下它。</p><h3 id="第14讲"><a href="#第14讲" class="headerlink" title="第14讲"></a><a href="https://time.geekbang.org/column/article/282478">第14讲</a></h3><p>问题：在用Sorted Set保存时间序列数据时，如果把时间戳作为score，把实际的数据作为member，这样保存数据有没有潜在的风险？另外，如果你是Redis的开发维护者，你会把聚合计算也设计为Sorted Set的一个内在功能吗？</p><p>答案：Sorted Set和Set一样，都会对集合中的元素进行去重，也就是说，如果我们往集合中插入的member值，和之前已经存在的member值一样，那么，原来member的score就会被新写入的member的score覆盖。相同member的值，在Sorted Set中只会保留一个。</p><p>对于时间序列数据来说，这种去重的特性是会带来数据丢失风险的。毕竟，某一时间段内的多个时间序列数据的值可能是相同的。如果我们往Sorted Set中写入的数据是在不同时刻产生的，但是写入的时刻不同，Sorted Set中只会保存一份最近时刻的数据。这样一来，其他时刻的数据就都没有保存下来。</p><p>举个例子，在记录物联网设备的温度时，一个设备一个上午的温度值可能都是26。在Sorted Set中，我们把温度值作为member，把时间戳作为score。我们用ZADD命令把上午不同时刻的温度值写入Sorted Set。由于member值一样，所以只会把score更新为最新时间戳，最后只有一个最新时间戳（例如上午12点）下的温度值。这肯定是无法满足保存多个时刻数据的需求的。</p><p>关于是否把聚合计算作为Sorted Set的内在功能，考虑到Redis的读写功能是由单线程执行，在进行数据读写时，本身就会消耗较多的CPU资源，如果再在Sorted Set中实现聚合计算，就会进一步增加CPU的资源消耗，影响到Redis的正常数据读取。所以，如果我是Redis的开发维护者，除非对Redis的线程模型做修改，比如说在Redis中使用额外的线程池做聚合计算，否则，我不会把聚合计算作为Redis的内在功能实现的。</p><h3 id="第15讲"><a href="#第15讲" class="headerlink" title="第15讲"></a><a href="https://time.geekbang.org/column/article/284291">第15讲</a></h3><p>问题：如果一个生产者发送给消息队列的消息，需要被多个消费者进行读取和处理（例如，一个消息是一条从业务系统采集的数据，既要被消费者1读取并进行实时计算，也要被消费者2读取并留存到分布式文件系统HDFS中，以便后续进行历史查询），你会使用Redis的什么数据类型来解决这个问题呢？</p><p>答案：有同学提到，可以使用Streams数据类型的消费组，同时消费生产者的数据，这是可以的。但是，有个地方需要注意，如果只是使用一个消费组的话，消费组内的多个消费者在消费消息时是互斥的，换句话说，在一个消费组内，一个消息只能被一个消费者消费。我们希望消息既要被消费者1读取，也要被消费者2读取，是一个多消费者的需求。所以，如果使用消费组模式，需要让消费者1和消费者2属于不同的消费组，这样它们就能同时消费了。</p><p>另外，Redis基于字典和链表数据结构，实现了发布和订阅功能，这个功能可以实现一个消息被多个消费者消费使用，可以满足问题中的场景需求。</p><h3 id="第16讲"><a href="#第16讲" class="headerlink" title="第16讲"></a><a href="https://time.geekbang.org/column/article/285000">第16讲</a></h3><p>问题：Redis的写操作（例如SET、HSET、SADD等）是在关键路径上吗？</p><p>答案：Redis本身是内存数据库，所以，写操作都需要在内存上完成执行后才能返回，这就意味着，如果这些写操作处理的是大数据集，例如1万个数据，那么，主线程需要等这1万个数据都写完，才能继续执行后面的命令。所以说，Redis的写操作也是在关键路径上的。</p><p>这个问题是希望你把面向内存和面向磁盘的写操作区分开。当一个写操作需要把数据写到磁盘时，一般来说，写操作只要把数据写到操作系统的内核缓冲区就行。不过，如果我们执行了同步写操作，那就必须要等到数据写回磁盘。所以，面向磁盘的写操作一般不会在关键路径上。</p><p>我看到有同学说，根据写操作命令的返回值来决定是否在关键路径上，如果返回值是OK，或者客户端不关心是否写成功，那么，此时的写操作就不算在关键路径上。</p><p>这个思路不错，不过，需要注意的是，客户端经常会阻塞等待发送的命令返回结果，在上一个命令还没有返回结果前，客户端会一直等待，直到返回结果后，才会发送下一个命令。此时，即使我们不关心返回结果，客户端也要等到写操作执行完成才行。所以，在不关心写操作返回结果的场景下，可以对Redis客户端做异步改造。具体点说，就是使用异步线程发送这些不关心返回结果的命令，而不是在Redis客户端中等待这些命令的结果。</p><h3 id="第17讲"><a href="#第17讲" class="headerlink" title="第17讲"></a><a href="https://time.geekbang.org/column/article/286082">第17讲</a></h3><p>问题：在一台有两个CPU Socket（每个Socket 8个物理核）的服务器上，我们部署了一个有着8个实例的Redis切片集群（8个实例都为主节点，没有主备关系），现在有两个方案：</p><ol><li>在同一个CPU Socket上运行8个实例，并和8个CPU核绑定；</li><li>在两个CPU Socket上各运行4个实例，并和相应Socket上的核绑定。</li></ol><p>如果不考虑网络数据读取的影响，你会选择哪个方案呢？</p><p>答案：建议使用第二个方案，主要有两方面的原因。</p><ol><li><p>同一个CPU Socket上的进程，会共享L3缓存。如果把8个实例都部署在同一个Socket上，它们会竞争L3缓存，这就会导致它们的L3缓存命中率降低，影响访问性能。</p></li><li><p>同一个CPU Socket上的进程，会使用同一个Socket上的内存空间。8个实例共享同一个Socket上的内存空间，肯定会竞争内存资源。如果有实例保存的数据量大，其他实例能用到的内存空间可能就不够了，此时，其他实例就会跨Socket申请内存，进而造成跨Socket访问内存，造成实例的性能降低。</p></li></ol><p>另外，在切片集群中，不同实例间通过网络进行消息通信和数据迁移，并不会使用共享内存空间进行跨实例的数据访问。所以，即使把不同的实例部署到不同的Socket上，它们之间也不会发生跨Socket内存的访问，不会受跨Socket内存访问的负面影响。</p><h3 id="第18讲"><a href="#第18讲" class="headerlink" title="第18讲"></a><a href="https://time.geekbang.org/column/article/286549">第18讲</a></h3><p>问题：在Redis中，还有哪些命令可以代替KEYS命令，实现对键值对的key的模糊查询呢？这些命令的复杂度会导致Redis变慢吗？</p><p>答案：Redis提供的SCAN命令，以及针对集合类型数据提供的SSCAN、HSCAN等，可以根据执行时设定的数量参数，返回指定数量的数据，这就可以避免像KEYS命令一样同时返回所有匹配的数据，不会导致Redis变慢。以HSCAN为例，我们可以执行下面的命令，从user这个Hash集合中返回key前缀以103开头的100个键值对。</p><pre class="line-numbers language-none"><code class="language-none">HSCAN user 0  match &quot;103*&quot; 100<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="第19讲"><a href="#第19讲" class="headerlink" title="第19讲"></a><a href="https://time.geekbang.org/column/article/287819">第19讲</a></h3><p>问题：你遇到过Redis变慢的情况吗？如果有的话，你是怎么解决的呢？</p><p>答案：@Kaito同学在留言区分享了他排查Redis变慢问题的Checklist，而且还提供了解决方案，非常好，我把Kaito同学给出的导致Redis变慢的原因汇总并完善一下，分享给你：</p><ol><li>使用复杂度过高的命令或一次查询全量数据；</li><li>操作bigkey；</li><li>大量key集中过期；</li><li>内存达到maxmemory；</li><li>客户端使用短连接和Redis相连；</li><li>当Redis实例的数据量大时，无论是生成RDB，还是AOF重写，都会导致fork耗时严重；</li><li>AOF的写回策略为always，导致每个操作都要同步刷回磁盘；</li><li>Redis实例运行机器的内存不足，导致swap发生，Redis需要到swap分区读取数据；</li><li>进程绑定CPU不合理；</li><li>Redis实例运行机器上开启了透明内存大页机制；</li><li>网卡压力过大。</li></ol><h3 id="第20讲"><a href="#第20讲" class="headerlink" title="第20讲"></a><a href="https://time.geekbang.org/column/article/289140">第20讲</a></h3><p>问题：我们可以使用mem_fragmentation_ratio来判断Redis当前的内存碎片率是否严重，我给出的经验阈值都是大于1的。我想请你思考一下，如果mem_fragmentation_ratio小于1，Redis的内存使用是什么情况呢？会对Redis的性能和内存空间利用率造成什么影响呢？</p><p>答案：如果mem_fragmentation_ratio小于1，就表明，操作系统分配给Redis的内存空间已经小于Redis所申请的空间大小了，此时，运行Redis实例的服务器上的内存已经不够用了，可能已经发生swap了。这样一来，Redis的读写性能也会受到影响，因为Redis实例需要在磁盘上的swap分区中读写数据，速度较慢。</p><h3 id="第21讲"><a href="#第21讲" class="headerlink" title="第21讲"></a><a href="https://time.geekbang.org/column/article/291277">第21讲</a></h3><p>问题：在和Redis实例交互时，应用程序中使用的客户端需要使用缓冲区吗？如果使用的话，对Redis的性能和内存使用会有影响吗？</p><p>答案：应用程序中使用的Redis客户端，需要把要发送的请求暂存在缓冲区。这有两方面的好处。</p><p>一方面，可以在客户端控制发送速率，避免把过多的请求一下子全部发到Redis实例，导致实例因压力过大而性能下降。不过，客户端缓冲区不会太大，所以，对Redis实例的内存使用没有什么影响。</p><p>另一方面，在应用Redis主从集群时，主从节点进行故障切换是需要一定时间的，此时，主节点无法服务外来请求。如果客户端有缓冲区暂存请求，那么，客户端仍然可以正常接收业务应用的请求，这就可以避免直接给应用返回无法服务的错误。</p><h2 id="代表性问题"><a href="#代表性问题" class="headerlink" title="代表性问题"></a>代表性问题</h2><p>在前面的课程中，我重点介绍了避免Redis变慢的方法。慢查询命令的执行时间和bigkey操作的耗时都很长，会阻塞Redis。很多同学学完之后，知道了要尽量避免Redis阻塞，但是还不太清楚，具体应该如何排查阻塞的命令和bigkey呢。</p><p>所以，接下来，我就再重点解释一下，如何排查慢查询命令，以及如何排查bigkey。</p><p><strong>问题1：如何使用慢查询日志和latency monitor排查执行慢的操作？</strong></p><p>在第18讲中，我提到，可以使用Redis日志（慢查询日志）和latency monitor来排查执行较慢的命令操作，那么，我们该如何使用慢查询日志和latency monitor呢？</p><p>Redis的慢查询日志记录了执行时间超过一定阈值的命令操作。当我们发现Redis响应变慢、请求延迟增加时，就可以在慢查询日志中进行查找，确定究竟是哪些命令执行时间很长。</p><p>在使用慢查询日志前，我们需要设置两个参数。</p><ul><li><strong>slowlog-log-slower-than</strong>：这个参数表示，慢查询日志对执行时间大于多少微秒的命令进行记录。</li><li><strong>slowlog-max-len</strong>：这个参数表示，慢查询日志最多能记录多少条命令记录。慢查询日志的底层实现是一个具有预定大小的先进先出队列，一旦记录的命令数量超过了队列长度，最先记录的命令操作就会被删除。这个值默认是128。但是，如果慢查询命令较多的话，日志里就存不下了；如果这个值太大了，又会占用一定的内存空间。所以，一般建议设置为1000左右，这样既可以多记录些慢查询命令，方便排查，也可以避免内存开销。</li></ul><p>设置好参数后，慢查询日志就会把执行时间超过slowlog-log-slower-than阈值的命令操作记录在日志中。</p><p>我们可以使用SLOWLOG GET命令，来查看慢查询日志中记录的命令操作，例如，我们执行如下命令，可以查看最近的一条慢查询的日志信息。</p><pre class="line-numbers language-none"><code class="language-none">SLOWLOG GET 11) 1) (integer) 33           &#x2F;&#x2F;每条日志的唯一ID编号   2) (integer) 1600990583   &#x2F;&#x2F;命令执行时的时间戳   3) (integer) 20906        &#x2F;&#x2F;命令执行的时长，单位是微秒   4) 1) &quot;keys&quot;               &#x2F;&#x2F;具体的执行命令和参数      2) &quot;abc*&quot;   5) &quot;127.0.0.1:54793&quot;      &#x2F;&#x2F;客户端的IP和端口号   6) &quot;&quot;                     &#x2F;&#x2F;客户端的名称，此处为空<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到，KEYS “abc*“这条命令的执行时间是20906微秒，大约20毫秒，的确是一条执行较慢的命令操作。如果我们想查看更多的慢日志，只要把SLOWLOG GET后面的数字参数改为想查看的日志条数，就可以了。</p><p>好了，有了慢查询日志后，我们就可以快速确认，究竟是哪些命令的执行时间比较长，然后可以反馈给业务部门，让业务开发人员避免在应用Redis的过程中使用这些命令，或是减少操作的数据量，从而降低命令的执行复杂度。</p><p>除了慢查询日志以外，Redis从2.8.13版本开始，还提供了latency monitor监控工具，这个工具可以用来监控Redis运行过程中的峰值延迟情况。</p><p>和慢查询日志的设置相类似，要使用latency monitor，首先要设置命令执行时长的阈值。当一个命令的实际执行时长超过该阈值时，就会被latency monitor监控到。比如，我们可以把latency monitor监控的命令执行时长阈值设为1000微秒，如下所示：</p><pre class="line-numbers language-none"><code class="language-none">config set latency-monitor-threshold 1000<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>设置好了latency monitor的参数后，我们可以使用latency latest命令，查看最新和最大的超过阈值的延迟情况，如下所示：</p><pre class="line-numbers language-none"><code class="language-none">latency latest1) 1) &quot;command&quot;   2) (integer) 1600991500    &#x2F;&#x2F;命令执行的时间戳   3) (integer) 2500           &#x2F;&#x2F;最近的超过阈值的延迟   4) (integer) 10100          &#x2F;&#x2F;最大的超过阈值的延迟<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>问题2：如何排查Redis的bigkey？</strong></p><p>在应用Redis时，我们要尽量避免bigkey的使用，这是因为，Redis主线程在操作bigkey时，会被阻塞。那么，一旦业务应用中使用了bigkey，我们该如何进行排查呢？</p><p>Redis可以在执行redis-cli命令时带上–bigkeys选项，进而对整个数据库中的键值对大小情况进行统计分析，比如说，统计每种数据类型的键值对个数以及平均大小。此外，这个命令执行后，会输出每种数据类型中最大的bigkey的信息，对于String类型来说，会输出最大bigkey的字节长度，对于集合类型来说，会输出最大bigkey的元素个数，如下所示：</p><pre class="line-numbers language-none"><code class="language-none">.&#x2F;redis-cli  --bigkeys-------- summary -------Sampled 32 keys in the keyspace!Total key length in bytes is 184 (avg len 5.75)&#x2F;&#x2F;统计每种数据类型中元素个数最多的bigkeyBiggest   list found &#39;product1&#39; has 8 itemsBiggest   hash found &#39;dtemp&#39; has 5 fieldsBiggest string found &#39;page2&#39; has 28 bytesBiggest stream found &#39;mqstream&#39; has 4 entriesBiggest    set found &#39;userid&#39; has 5 membersBiggest   zset found &#39;device:temperature&#39; has 6 members&#x2F;&#x2F;统计每种数据类型的总键值个数，占所有键值个数的比例，以及平均大小4 lists with 15 items (12.50% of keys, avg size 3.75)5 hashs with 14 fields (15.62% of keys, avg size 2.80)10 strings with 68 bytes (31.25% of keys, avg size 6.80)1 streams with 4 entries (03.12% of keys, avg size 4.00)7 sets with 19 members (21.88% of keys, avg size 2.71)5 zsets with 17 members (15.62% of keys, avg size 3.40)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>不过，在使用–bigkeys选项时，有一个地方需要注意一下。这个工具是通过扫描数据库来查找bigkey的，所以，在执行的过程中，会对Redis实例的性能产生影响。如果你在使用主从集群，我建议你在从节点上执行该命令。因为主节点上执行时，会阻塞主节点。如果没有从节点，那么，我给你两个小建议：第一个建议是，在Redis实例业务压力的低峰阶段进行扫描查询，以免影响到实例的正常运行；第二个建议是，可以使用-i参数控制扫描间隔，避免长时间扫描降低Redis实例的性能。例如，我们执行如下命令时，redis-cli会每扫描100次暂停100毫秒（0.1秒）。</p><pre class="line-numbers language-none"><code class="language-none">.&#x2F;redis-cli  --bigkeys -i 0.1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>当然，使用Redis自带的–bigkeys选项排查bigkey，有两个不足的地方：</p><ol><li>这个方法只能返回每种类型中最大的那个bigkey，无法得到大小排在前N位的bigkey；</li><li>对于集合类型来说，这个方法只统计集合元素个数的多少，而不是实际占用的内存量。但是，一个集合中的元素个数多，并不一定占用的内存就多。因为，有可能每个元素占用的内存很小，这样的话，即使元素个数有很多，总内存开销也不大。</li></ol><p>所以，如果我们想统计每个数据类型中占用内存最多的前N个bigkey，可以自己开发一个程序，来进行统计。</p><p>我给你提供一个基本的开发思路：使用SCAN命令对数据库扫描，然后用TYPE命令获取返回的每一个key的类型。接下来，对于String类型，可以直接使用STRLEN命令获取字符串的长度，也就是占用的内存空间字节数。</p><p>对于集合类型来说，有两种方法可以获得它占用的内存大小。</p><p>如果你能够预先从业务层知道集合元素的平均大小，那么，可以使用下面的命令获取集合元素的个数，然后乘以集合元素的平均大小，这样就能获得集合占用的内存大小了。</p><ul><li>List类型：LLEN命令；</li><li>Hash类型：HLEN命令；</li><li>Set类型：SCARD命令；</li><li>Sorted Set类型：ZCARD命令；</li></ul><p>如果你不能提前知道写入集合的元素大小，可以使用MEMORY USAGE命令（需要Redis 4.0及以上版本），查询一个键值对占用的内存空间。例如，执行以下命令，可以获得key为user:info这个集合类型占用的内存空间大小。</p><pre class="line-numbers language-none"><code class="language-none">MEMORY USAGE user:info(integer) 315663239<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这样一来，你就可以在开发的程序中，把每一种数据类型中的占用内存空间大小排在前 N 位的key统计出来，这也就是每个数据类型中的前N个bigkey。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>从第11讲到第21讲，我们重点介绍的知识点比较多，也比较细。其实，我们可以分成两大部分来掌握：一个是多种多样的数据结构，另一个是如何避免Redis性能变慢。</p><p>希望这节课的答疑，能帮助你更加深入地理解前面学过的内容。通过这节课，你应该也看到了，课后思考题是一种很好地梳理重点内容、拓展思路的方式，所以，在接下来的课程里，希望你能多留言聊一聊你的想法，这样可以进一步巩固你所学的知识。而且，还能在和其他同学的交流中，收获更多东西。好了，这节课就到这里，我们下节课见。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;22-第11～21讲课后思考题答案及常见问题答疑&quot;&gt;&lt;a href=&quot;#22-第11～21讲课后思考题答案及常见问题答疑&quot; class=&quot;headerlink&quot; title=&quot;22 | 第11～21讲课后思考题答案及常见问题答疑&quot;&gt;&lt;/a&gt;22 | 第11～21讲</summary>
      
    
    
    
    <category term="Redis核心技术与实战" scheme="https://zhuansun.github.io/geekbang/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    
    
  </entry>
  
  <entry>
    <title>25 | 缓存异常（上）：如何解决缓存和数据库的数据不一致问题？</title>
    <link href="https://zhuansun.github.io/geekbang/posts/2606993339.html"/>
    <id>https://zhuansun.github.io/geekbang/posts/2606993339.html</id>
    <published>2024-03-04T22:10:14.000Z</published>
    <updated>2024-03-21T07:44:22.381Z</updated>
    
    <content type="html"><![CDATA[<h1 id="25-缓存异常（上）：如何解决缓存和数据库的数据不一致问题？"><a href="#25-缓存异常（上）：如何解决缓存和数据库的数据不一致问题？" class="headerlink" title="25 | 缓存异常（上）：如何解决缓存和数据库的数据不一致问题？"></a>25 | 缓存异常（上）：如何解决缓存和数据库的数据不一致问题？</h1><p>你好，我是蒋德钧。</p><p>在实际应用Redis缓存时，我们经常会遇到一些异常问题，概括来说有4个方面：缓存中的数据和数据库中的不一致；缓存雪崩；缓存击穿和缓存穿透。</p><p>只要我们使用Redis缓存，就必然会面对缓存和数据库间的一致性保证问题，这也算是Redis缓存应用中的“必答题”了。最重要的是，如果数据不一致，那么业务应用从缓存中读取的数据就不是最新数据，这会导致严重的错误。比如说，我们把电商商品的库存信息缓存在Redis中，如果库存信息不对，那么业务层下单操作就可能出错，这当然是不能接受的。所以，这节课我就重点和你聊聊这个问题。关于缓存雪崩、穿透和击穿等问题，我会在下一节课向你介绍。</p><p>接下来，我们就来看看，缓存和数据库之间的数据不一致是怎么引起的。</p><h2 id="缓存和数据库的数据不一致是如何发生的？"><a href="#缓存和数据库的数据不一致是如何发生的？" class="headerlink" title="缓存和数据库的数据不一致是如何发生的？"></a>缓存和数据库的数据不一致是如何发生的？</h2><p>首先，我们得清楚“数据的一致性”具体是啥意思。其实，这里的“一致性”包含了两种情况：</p><ul><li>缓存中有数据，那么，缓存的数据值需要和数据库中的值相同；</li><li>缓存中本身没有数据，那么，数据库中的值必须是最新值。</li></ul><p>不符合这两种情况的，就属于缓存和数据库的数据不一致问题了。不过，当缓存的读写模式不同时，缓存数据不一致的发生情况不一样，我们的应对方法也会有所不同，所以，我们先按照缓存读写模式，来分别了解下不同模式下的缓存不一致情况。我在 <a href="https://time.geekbang.org/column/article/293929">第23讲</a> 中讲过，根据是否接收写请求，我们可以把缓存分成读写缓存和只读缓存。</p><p>对于读写缓存来说，如果要对数据进行增删改，就需要在缓存中进行，同时还要根据采取的写回策略，决定是否同步写回到数据库中。</p><ul><li>同步直写策略：写缓存时，也同步写数据库，缓存和数据库中的数据一致；</li><li>异步写回策略：写缓存时不同步写数据库，等到数据从缓存中淘汰时，再写回数据库。使用这种策略时，如果数据还没有写回数据库，缓存就发生了故障，那么，此时，数据库就没有最新的数据了。</li></ul><p>所以，对于读写缓存来说，要想保证缓存和数据库中的数据一致，就要采用同步直写策略。不过，需要注意的是，如果采用这种策略，就需要同时更新缓存和数据库。所以，我们要在业务应用中使用事务机制，来保证缓存和数据库的更新具有原子性，也就是说，两者要不一起更新，要不都不更新，返回错误信息，进行重试。否则，我们就无法实现同步直写。</p><p>当然，在有些场景下，我们对数据一致性的要求可能不是那么高，比如说缓存的是电商商品的非关键属性或者短视频的创建或修改时间等，那么，我们可以使用异步写回策略。</p><p>下面我们再来说说只读缓存。对于只读缓存来说，如果有数据新增，会直接写入数据库；而有数据删改时，就需要把只读缓存中的数据标记为无效。这样一来，应用后续再访问这些增删改的数据时，因为缓存中没有相应的数据，就会发生缓存缺失。此时，应用再从数据库中把数据读入缓存，这样后续再访问数据时，就能够直接从缓存中读取了。</p><p>接下来，我以Tomcat向MySQL中写入和删改数据为例，来给你解释一下，数据的增删改操作具体是如何进行的，如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/15ae0147459ecc46436f35a0f3e5yydc.jpg"></p><p>从图中可以看到，Tomcat上运行的应用，无论是新增（Insert操作）、修改（Update操作）、还是删除（Delete操作）数据X，都会直接在数据库中增改删。当然，如果应用执行的是修改或删除操作，还会删除缓存的数据X。</p><p>那么，这个过程中会不会出现数据不一致的情况呢？考虑到新增数据和删改数据的情况不一样，所以我们分开来看。</p><p><strong>1.新增数据</strong></p><p>如果是新增数据，数据会直接写到数据库中，不用对缓存做任何操作，此时，缓存中本身就没有新增数据，而数据库中是最新值，这种情况符合我们刚刚所说的一致性的第2种情况，所以，此时，缓存和数据库的数据是一致的。</p><p><strong>2.删改数据</strong></p><p>如果发生删改操作，应用既要更新数据库，也要在缓存中删除数据。这两个操作如果无法保证原子性，也就是说，要不都完成，要不都没完成，此时，就会出现数据不一致问题了。这个问题比较复杂，我们来分析一下。</p><p>我们假设应用先删除缓存，再更新数据库，如果缓存删除成功，但是数据库更新失败，那么，应用再访问数据时，缓存中没有数据，就会发生缓存缺失。然后，应用再访问数据库，但是数据库中的值为旧值，应用就访问到旧值了。</p><p>我来举个例子说明一下，可以先看看下面的图片。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/b305a6355c9da145e4d1f86d23f4f0ae.jpg"></p><p>应用要把数据X的值从10更新为3，先在Redis缓存中删除了X的缓存值，但是更新数据库却失败了。如果此时有其他并发的请求访问X，会发现Redis中缓存缺失，紧接着，请求就会访问数据库，读到的却是旧值10。</p><p>你可能会问，如果我们先更新数据库，再删除缓存中的值，是不是就可以解决这个问题呢？我们再来分析下。</p><p>如果应用先完成了数据库的更新，但是，在删除缓存时失败了，那么，数据库中的值是新值，而缓存中的是旧值，这肯定是不一致的。这个时候，如果有其他的并发请求来访问数据，按照正常的缓存访问流程，就会先在缓存中查询，但此时，就会读到旧值了。</p><p>我还是借助一个例子来说明一下。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/767b4b2b1bafffd9a4b6368f05930a77.jpg"></p><p>应用要把数据X的值从10更新为3，先成功更新了数据库，然后在Redis缓存中删除X的缓存，但是这个操作却失败了，这个时候，数据库中X的新值为3，Redis中的X的缓存值为10，这肯定是不一致的。如果刚好此时有其他客户端也发送请求访问X，会先在Redis中查询，该客户端会发现缓存命中，但是读到的却是旧值10。</p><p>好了，到这里，我们可以看到，在更新数据库和删除缓存值的过程中，无论这两个操作的执行顺序谁先谁后，只要有一个操作失败了，就会导致客户端读取到旧值。我画了下面这张表，总结了刚刚所说的这两种情况。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/2c376b536aff9d14d8606499f401cdac.jpg"></p><p>问题发生的原因我们知道了，那该怎么解决呢？</p><h2 id="如何解决数据不一致问题？"><a href="#如何解决数据不一致问题？" class="headerlink" title="如何解决数据不一致问题？"></a>如何解决数据不一致问题？</h2><p>首先，我给你介绍一种方法：重试机制。</p><p>具体来说，可以把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用Kafka消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。</p><p>如果能够成功地删除或更新，我们就要把这些值从消息队列中去除，以免重复操作，此时，我们也可以保证数据库和缓存的数据一致了。否则的话，我们还需要再次进行重试。如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。</p><p>下图显示了先更新数据库，再删除缓存值时，如果缓存删除失败，再次重试后删除成功的情况，你可以看下。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/74a66b9ce185d7c5b53986fc522dfcab.jpg"></p><p>刚刚说的是在更新数据库和删除缓存值的过程中，其中一个操作失败的情况，实际上，即使这两个操作第一次执行时都没有失败，当有大量并发请求时，应用还是有可能读到不一致的数据。</p><p>同样，我们按照不同的删除和更新顺序，分成两种情况来看。在这两种情况下，我们的解决方法也有所不同。</p><p><strong>情况一：先删除缓存，再更新数据库。</strong></p><p>假设线程A删除缓存值后，还没有来得及更新数据库（比如说有网络延迟），线程B就开始读取数据了，那么这个时候，线程B会发现缓存缺失，就只能去数据库读取。这会带来两个问题：</p><ol><li>线程B读取到了旧值；</li><li>线程B是在缓存缺失的情况下读取的数据库，所以，它还会把旧值写入缓存，这可能会导致其他线程从缓存中读到旧值。</li></ol><p>等到线程B从数据库读取完数据、更新了缓存后，线程A才开始更新数据库，此时，缓存中的数据是旧值，而数据库中的是最新值，两者就不一致了。</p><p>我用一张表来汇总下这种情况。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/857c2b5449d9a04de6fe93yy1e355c12.jpg"></p><p>这该怎么办呢？我来给你提供一种解决方案。</p><p><strong>在线程A更新完数据库值以后，我们可以让它先sleep一小段时间，再进行一次缓存删除操作。</strong></p><p>之所以要加上sleep的这段时间，就是为了让线程B能够先从数据库读取数据，再把缺失的数据写入缓存，然后，线程A再进行删除。所以，线程A sleep的时间，就需要大于线程B读取数据再写入缓存的时间。这个时间怎么确定呢？建议你在业务程序运行的时候，统计下线程读数据和写缓存的操作时间，以此为基础来进行估算。</p><p>这样一来，其它线程读取数据时，会发现缓存缺失，所以会从数据库中读取最新值。因为这个方案会在第一次删除缓存值后，延迟一段时间再次进行删除，所以我们也把它叫做“延迟双删”。</p><p>下面的这段伪代码就是“延迟双删”方案的示例，你可以看下。</p><pre class="line-numbers language-none"><code class="language-none">redis.delKey(X)db.update(X)Thread.sleep(N)redis.delKey(X)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><strong>情况二：先更新数据库值，再删除缓存值。</strong></p><p>如果线程A删除了数据库中的值，但还没来得及删除缓存值，线程B就开始读取数据了，那么此时，线程B查询缓存时，发现缓存命中，就会直接从缓存中读取旧值。不过，在这种情况下，如果其他线程并发读缓存的请求不多，那么，就不会有很多请求读取到旧值。而且，线程A一般也会很快删除缓存值，这样一来，其他线程再次读取时，就会发生缓存缺失，进而从数据库中读取最新值。所以，这种情况对业务的影响较小。</p><p>我再画一张表，带你总结下先更新数据库、再删除缓存值的情况。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/a1c66ee114yyc9f37f2a35f21b46010b.jpg"></p><p>好了，到这里，我们了解到了，缓存和数据库的数据不一致一般是由两个原因导致的，我给你提供了相应的解决方案。</p><ul><li>删除缓存值或更新数据库失败而导致数据不一致，你可以使用重试机制确保删除或更新操作成功。</li><li>在删除缓存值、更新数据库的这两步操作中，有其他线程的并发读操作，导致其他线程读取到旧值，应对方案是延迟双删。</li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>在这节课，我们学习了在使用Redis缓存时，最常遇见的一个问题，也就是缓存和数据库不一致的问题。针对这个问题，我们可以分成读写缓存和只读缓存两种情况进行分析。</p><p>对于读写缓存来说，如果我们采用同步写回策略，那么可以保证缓存和数据库中的数据一致。只读缓存的情况比较复杂，我总结了一张表，以便于你更加清晰地了解数据不一致的问题原因、现象和应对方案。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/11ae5e620c63de76448bc658fe6a496f.jpg"></p><p>希望你能把我总结的这张表格放入到你的学习笔记中，时不时复习一下。</p><p>最后，我还想再多说几句。在大多数业务场景下，我们会把Redis作为只读缓存使用。针对只读缓存来说，我们既可以先删除缓存值再更新数据库，也可以先更新数据库再删除缓存。我的建议是，优先使用先更新数据库再删除缓存的方法，原因主要有两个：</p><ol><li>先删除缓存值再更新数据库，有可能导致请求因缓存缺失而访问数据库，给数据库带来压力；</li><li>如果业务应用中读取数据库和写缓存的时间不好估算，那么，延迟双删中的等待时间就不好设置。</li></ol><p>不过，当使用先更新数据库再删除缓存时，也有个地方需要注意，如果业务层要求必须读取一致的数据，那么，我们就需要在更新数据库时，先在Redis缓存客户端暂存并发读请求，等数据库更新完、缓存值删除后，再读取数据，从而保证数据一致性。</p><h2 id="每课一问"><a href="#每课一问" class="headerlink" title="每课一问"></a>每课一问</h2><p>按照惯例，我给你提个小问题。这节课，我提到，在只读缓存中进行数据的删改操作时，需要在缓存中删除相应的缓存值。我想请你思考一下，如果在这个过程中，我们不是删除缓存值，而是直接更新缓存的值，你觉得和删除缓存值相比，有什么好处和不足吗？</p><p>欢迎在留言区写下你的思考和答案，我们一起交流讨论。如果你觉得今天的内容对你有所帮助，也欢迎你分享给你的朋友或同事。我们下节课见。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;25-缓存异常（上）：如何解决缓存和数据库的数据不一致问题？&quot;&gt;&lt;a href=&quot;#25-缓存异常（上）：如何解决缓存和数据库的数据不一致问题？&quot; class=&quot;headerlink&quot; title=&quot;25 | 缓存异常（上）：如何解决缓存和数据库的数据不一致问题？</summary>
      
    
    
    
    <category term="Redis核心技术与实战" scheme="https://zhuansun.github.io/geekbang/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    
    
  </entry>
  
  <entry>
    <title>26 | 缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？</title>
    <link href="https://zhuansun.github.io/geekbang/posts/4172864862.html"/>
    <id>https://zhuansun.github.io/geekbang/posts/4172864862.html</id>
    <published>2024-03-04T22:10:14.000Z</published>
    <updated>2024-03-21T07:44:22.383Z</updated>
    
    <content type="html"><![CDATA[<h1 id="26-缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？"><a href="#26-缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？" class="headerlink" title="26 | 缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？"></a>26 | 缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？</h1><p>你好，我是蒋德钧。</p><p>上节课，我们学习了缓存和数据库的数据不一致问题和应对方法。除了数据不一致问题，我们常常还会面临缓存异常的三个问题，分别是缓存雪崩、缓存击穿和缓存穿透。这三个问题一旦发生，会导致大量的请求积压到数据库层。如果请求的并发量很大，就会导致数据库宕机或是故障，这就是很严重的生产事故了。</p><p>这节课，我就来和你聊聊这三个问题的表现、诱发原因以及解决方法。俗话说，知己知彼，百战不殆。了解了问题的成因，我们就能够在应用Redis缓存时，进行合理的缓存设置，以及相应的业务应用前端设置，提前做好准备。</p><p>接下来，我们就先看下缓存雪崩的问题和应对方案。</p><h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h2><p>缓存雪崩是指大量的应用请求无法在Redis缓存中进行处理，紧接着，应用将大量请求发送到数据库层，导致数据库层的压力激增。</p><p>缓存雪崩一般是由两个原因导致的，应对方案也有所不同，我们一个个来看。</p><p>第一个原因是：缓存中有大量数据同时过期，导致大量请求无法得到处理。</p><p>具体来说，当数据保存在缓存中，并且设置了过期时间时，如果在某一个时刻，大量数据同时过期，此时，应用再访问这些数据的话，就会发生缓存缺失。紧接着，应用就会把请求发送给数据库，从数据库中读取数据。如果应用的并发请求量很大，那么数据库的压力也就很大，这会进一步影响到数据库的其他正常业务请求处理。我们来看一个简单的例子，如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/74bb1aa4b2213e3ff29e2ee701e8f72e.jpg"></p><p>针对大量数据同时失效带来的缓存雪崩问题，我给你提供两种解决方案。</p><p>首先，我们可以避免给大量的数据设置相同的过期时间。如果业务层的确要求有些数据同时失效，你可以在用EXPIRE命令给每个数据设置过期时间时，给这些数据的过期时间增加一个较小的随机数（例如，随机增加1~3分钟），这样一来，不同数据的过期时间有所差别，但差别又不会太大，既避免了大量数据同时过期，同时也保证了这些数据基本在相近的时间失效，仍然能满足业务需求。</p><p>除了微调过期时间，我们还可以通过服务降级，来应对缓存雪崩。</p><p>所谓的服务降级，是指发生缓存雪崩时，针对不同的数据采取不同的处理方式。</p><ul><li>当业务应用访问的是非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；</li><li>当业务应用访问的是核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。</li></ul><p>这样一来，只有部分过期数据的请求会发送到数据库，数据库的压力就没有那么大了。下面这张图显示的是服务降级时数据请求的执行情况，你可以看下。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/4ab3be5ba24cf172879e6b2cff649ca8.jpg"></p><p><strong>除了大量数据同时失效会导致缓存雪崩，还有一种情况也会发生缓存雪崩，那就是，Redis缓存实例发生故障宕机了，无法处理请求，这就会导致大量请求一下子积压到数据库层，从而发生缓存雪崩。</strong></p><p>一般来说，一个Redis实例可以支持数万级别的请求处理吞吐量，而单个数据库可能只能支持数千级别的请求处理吞吐量，它们两个的处理能力可能相差了近十倍。由于缓存雪崩，Redis缓存失效，所以，数据库就可能要承受近十倍的请求压力，从而因为压力过大而崩溃。</p><p>此时，因为Redis实例发生了宕机，我们需要通过其他方法来应对缓存雪崩了。我给你提供两个建议。</p><p><strong>第一个建议，是在业务系统中实现服务熔断或请求限流机制。</strong></p><p>所谓的服务熔断，是指在发生缓存雪崩时，为了防止引发连锁的数据库雪崩，甚至是整个系统的崩溃，我们暂停业务应用对缓存系统的接口访问。再具体点说，就是业务应用调用缓存接口时，缓存客户端并不把请求发给Redis缓存实例，而是直接返回，等到Redis缓存实例重新恢复服务后，再允许应用请求发送到缓存系统。</p><p>这样一来，我们就避免了大量请求因缓存缺失，而积压到数据库系统，保证了数据库系统的正常运行。</p><p>在业务系统运行时，我们可以监测Redis缓存所在机器和数据库所在机器的负载指标，例如每秒请求数、CPU利用率、内存利用率等。如果我们发现Redis缓存实例宕机了，而数据库所在机器的负载压力突然增加（例如每秒请求数激增），此时，就发生缓存雪崩了。大量请求被发送到数据库进行处理。我们可以启动服务熔断机制，暂停业务应用对缓存服务的访问，从而降低对数据库的访问压力，如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/17d39f6233c3332161c588b42eccaeb5.jpg"></p><p>服务熔断虽然可以保证数据库的正常运行，但是暂停了整个缓存系统的访问，对业务应用的影响范围大。为了尽可能减少这种影响，我们也可以进行请求限流。这里说的请求限流，就是指，我们在业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。</p><p>我给你举个例子。假设业务系统正常运行时，请求入口前端允许每秒进入系统的请求是1万个，其中，9000个请求都能在缓存系统中进行处理，只有1000个请求会被应用发送到数据库进行处理。</p><p>一旦发生了缓存雪崩，数据库的每秒请求数突然增加到每秒1万个，此时，我们就可以启动请求限流机制，在请求入口前端只允许每秒进入系统的请求数为1000个，再多的请求就会在入口前端被直接拒绝服务。所以，使用了请求限流，就可以避免大量并发请求压力传递到数据库层。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/d5a0928e1d97cae2f4a4fb5b93e5c854.jpg"></p><p>使用服务熔断或是请求限流机制，来应对Redis实例宕机导致的缓存雪崩问题，是属于“事后诸葛亮”，也就是已经发生缓存雪崩了，我们使用这两个机制，来降低雪崩对数据库和整个业务系统的影响。</p><p><strong>我给你的第二个建议就是事前预防。</strong></p><p>通过主从节点的方式构建Redis缓存高可靠集群。如果Redis缓存的主节点故障宕机了，从节点还可以切换成为主节点，继续提供缓存服务，避免了由于缓存实例宕机而导致的缓存雪崩问题。</p><p>缓存雪崩是发生在大量数据同时失效的场景下，而接下来我要向你介绍的缓存击穿，是发生在某个热点数据失效的场景下。和缓存雪崩相比，缓存击穿失效的数据数量要小很多，应对方法也不一样，我们来看下。</p><h2 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h2><p>缓存击穿是指，针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。缓存击穿的情况，经常发生在热点数据过期失效时，如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/d4c77da4yy7d6e34aca460642923ab4b.jpg"></p><p>为了避免缓存击穿给数据库带来的激增压力，我们的解决方法也比较直接，对于访问特别频繁的热点数据，我们就不设置过期时间了。这样一来，对热点数据的访问请求，都可以在缓存中进行处理，而Redis数万级别的高吞吐量可以很好地应对大量的并发请求访问。</p><p>好了，到这里，你了解了缓存雪崩和缓存击穿问题，以及它们的应对方案。当发生缓存雪崩或击穿时，数据库中还是保存了应用要访问的数据。接下来，我向你介绍的缓存穿透问题，和雪崩、击穿问题不一样，缓存穿透发生时，数据也不在数据库中，这会同时给缓存和数据库带来访问压力，那该怎么办呢？我们来具体看下。</p><h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h2><p>缓存穿透是指要访问的数据既不在Redis缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。此时，应用也无法从数据库中读取数据再写入缓存，来服务后续请求，这样一来，缓存也就成了“摆设”，如果应用持续有大量请求访问数据，就会同时给缓存和数据库带来巨大压力，如下图所示：</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/46c49dd155665579c5204a66da8ffc2e.jpg"></p><p>那么，缓存穿透会发生在什么时候呢？一般来说，有两种情况。</p><ul><li>业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据；</li><li>恶意攻击：专门访问数据库中没有的数据。</li></ul><p>为了避免缓存穿透的影响，我来给你提供三种应对方案。</p><p><strong>第一种方案是，缓存空值或缺省值。</strong></p><p>一旦发生缓存穿透，我们就可以针对查询的数据，在Redis中缓存一个空值或是和业务层协商确定的缺省值（例如，库存的缺省值可以设为0）。紧接着，应用发送的后续请求再进行查询时，就可以直接从Redis中读取空值或缺省值，返回给业务应用了，避免了把大量请求发送给数据库处理，保持了数据库的正常运行。</p><p><strong>第二种方案是，使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。</strong></p><p>我们先来看下，布隆过滤器是如何工作的。</p><p>布隆过滤器由一个初值都为0的bit数组和N个哈希函数组成，可以用来快速判断某个数据是否存在。当我们想标记某个数据存在时（例如，数据已被写入数据库），布隆过滤器会通过三个操作完成标记：</p><ul><li>首先，使用N个哈希函数，分别计算这个数据的哈希值，得到N个哈希值。</li><li>然后，我们把这N个哈希值对bit数组的长度取模，得到每个哈希值在数组中的对应位置。</li><li>最后，我们把对应位置的bit位设置为1，这就完成了在布隆过滤器中标记数据的操作。</li></ul><p>如果数据不存在（例如，数据库里没有写入数据），我们也就没有用布隆过滤器标记过数据，那么，bit数组对应bit位的值仍然为0。</p><p>当需要查询某个数据时，我们就执行刚刚说的计算过程，先得到这个数据在bit数组中对应的N个位置。紧接着，我们查看bit数组中这N个位置上的bit值。只要这N个bit值有一个不为1，这就表明布隆过滤器没有对该数据做过标记，所以，查询的数据一定没有在数据库中保存。为了便于你理解，我画了一张图，你可以看下。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/98f7d32499e4386b40aebc3622aa7268.jpg"></p><p>图中布隆过滤器是一个包含10个bit位的数组，使用了3个哈希函数，当在布隆过滤器中标记数据X时，X会被计算3次哈希值，并对10取模，取模结果分别是1、3、7。所以，bit数组的第1、3、7位被设置为1。当应用想要查询X时，只要查看数组的第1、3、7位是否为1，只要有一个为0，那么，X就肯定不在数据库中。</p><p>正是基于布隆过滤器的快速检测特性，我们可以在把数据写入数据库时，使用布隆过滤器做个标记。当缓存缺失后，应用查询数据库时，可以通过查询布隆过滤器快速判断数据是否存在。如果不存在，就不用再去数据库中查询了。这样一来，即使发生缓存穿透了，大量请求只会查询Redis和布隆过滤器，而不会积压到数据库，也就不会影响数据库的正常运行。布隆过滤器可以使用Redis实现，本身就能承担较大的并发访问压力。</p><p>最后一种方案是，在请求入口的 <strong>前端进行请求检测。</strong> 缓存穿透的一个原因是有大量的恶意请求访问不存在的数据，所以，一个有效的应对方案是在请求入口前端，对业务系统接收到的请求进行合法性检测，把恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉，不让它们访问后端缓存和数据库。这样一来，也就不会出现缓存穿透问题了。</p><p>跟缓存雪崩、缓存击穿这两类问题相比，缓存穿透的影响更大一些，希望你能重点关注一下。从预防的角度来说，我们需要避免误删除数据库和缓存中的数据；从应对角度来说，我们可以在业务系统中使用缓存空值或缺省值、使用布隆过滤器，以及进行恶意请求检测等方法。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这节课，我们学习了缓存雪崩、击穿和穿透这三类异常问题。从问题成因来看，缓存雪崩和击穿主要是因为数据不在缓存中了，而缓存穿透则是因为数据既不在缓存中，也不在数据库中。所以，缓存雪崩或击穿时，一旦数据库中的数据被再次写入到缓存后，应用又可以在缓存中快速访问数据了，数据库的压力也会相应地降低下来，而缓存穿透发生时，Redis缓存和数据库会同时持续承受请求压力。</p><p>为了方便你掌握，我把这三大问题的原因和应对方案总结到了一张表格，你可以再复习一下。</p><p><img src="https://note-1252548816.cos.ap-nanjing.myqcloud.com/uPic/202403/b5bd931239be18bef24b2ef36c70e9e1.jpg"></p><p>最后，我想强调一下，服务熔断、服务降级、请求限流这些方法都是属于“有损”方案，在保证数据库和整体系统稳定的同时，会对业务应用带来负面影响。例如使用服务降级时，有部分数据的请求就只能得到错误返回信息，无法正常处理。如果使用了服务熔断，那么，整个缓存系统的服务都被暂停了，影响的业务范围更大。而使用了请求限流机制后，整个业务系统的吞吐率会降低，能并发处理的用户请求会减少，会影响到用户体验。</p><p>所以，我给你的建议是，尽量使用预防式方案：</p><ul><li>针对缓存雪崩，合理地设置数据过期时间，以及搭建高可靠缓存集群；</li><li>针对缓存击穿，在缓存访问非常频繁的热点数据时，不要设置过期时间；</li><li>针对缓存穿透，提前在入口前端实现恶意请求检测，或者规范数据库的数据删除操作，避免误删除。</li></ul><h2 id="每课一问"><a href="#每课一问" class="headerlink" title="每课一问"></a>每课一问</h2><p>按照惯例，我给你提个小问题。在讲到缓存雪崩时，我提到，可以采用服务熔断、服务降级、请求限流的方法来应对。请你思考下，这三个机制可以用来应对缓存穿透问题吗？</p><p>欢迎在留言区写下你的思考和答案，我们一起交流讨论。如果你觉得今天的内容对你有所帮助，也欢迎你分享给你的朋友或同事。我们下节课见。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;26-缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？&quot;&gt;&lt;a href=&quot;#26-缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？&quot; class=&quot;headerlink&quot; title=&quot;26 | 缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？&quot;&gt;&lt;/a&gt;</summary>
      
    
    
    
    <category term="Redis核心技术与实战" scheme="https://zhuansun.github.io/geekbang/categories/Redis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/"/>
    
    
  </entry>
  
</feed>
